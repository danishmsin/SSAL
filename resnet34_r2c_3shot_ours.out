Dataset multi Source real Target clipart Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  70358
Unlabelled Target Dataset Size:  18325
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  18325 Source:  70358
Unlabeled Target Data Batches: 381
S real T clipart Train Ep: 0 lr0.01 	 Loss Classification: 5.012639 Loss T 0.470213 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9863, Accuracy: 9/1134 F1 (0.7937%)


Test set: Average loss: 5.0071, Accuracy: 143/18312 F1 (0.7809%)


Val set: Average loss: 4.9721, Accuracy: 5/360 F1 (1.3889%)

best acc test 0.780909  acc val 1.388889 acc labeled target 0.793651
saving model...
S real T clipart Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.618121 Loss T 0.298419 Method MME

S real T clipart Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.495512 Loss T 0.239666 Method MME

S real T clipart Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.364246 Loss T 0.181013 Method MME

S real T clipart Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 0.878797 Loss T 0.152821 Method MME

S real T clipart Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.809483 Loss T 0.147560 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5721, Accuracy: 500/1134 F1 (44.0917%)


Test set: Average loss: 2.2543, Accuracy: 9159/18312 F1 (50.0164%)


Val set: Average loss: 2.3211, Accuracy: 163/360 F1 (45.2778%)

best acc test 50.016383  acc val 45.277778 acc labeled target 44.091711
saving model...
S real T clipart Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.436405 Loss T 0.172151 Method MME

S real T clipart Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.879111 Loss T 0.148439 Method MME

S real T clipart Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.462212 Loss T 0.155638 Method MME

S real T clipart Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.606719 Loss T 0.122449 Method MME

S real T clipart Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.481088 Loss T 0.137972 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4723, Accuracy: 544/1134 F1 (47.9718%)


Test set: Average loss: 2.1146, Accuracy: 9869/18312 F1 (53.8936%)


Val set: Average loss: 2.2116, Accuracy: 191/360 F1 (53.0556%)

best acc test 53.893622  acc val 53.055556 acc labeled target 47.971781
saving model...
S real T clipart Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.719404 Loss T 0.145618 Method MME

S real T clipart Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.074313 Loss T 0.113492 Method MME

S real T clipart Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.064393 Loss T 0.126599 Method MME

S real T clipart Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.877814 Loss T 0.134901 Method MME

S real T clipart Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.569739 Loss T 0.103021 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1820, Accuracy: 585/1134 F1 (51.5873%)


Test set: Average loss: 1.9877, Accuracy: 10433/18312 F1 (56.9736%)


Val set: Average loss: 2.0397, Accuracy: 201/360 F1 (55.8333%)

best acc test 56.973569  acc val 55.833333 acc labeled target 51.587302
saving model...
S real T clipart Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.288587 Loss T 0.110784 Method MME

S real T clipart Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.770014 Loss T 0.136582 Method MME

S real T clipart Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.836186 Loss T 0.105466 Method MME

S real T clipart Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.843826 Loss T 0.107431 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.22222222 0.5555556  0.11111111 0.33333334
 0.33333334 0.6666667  0.5555556  0.         0.6666667  0.44444445
 0.11111111 0.7777778  0.7777778  0.         1.         0.7777778
 0.7777778  0.5555556  0.         0.6666667  0.6666667  0.5555556
 0.44444445 0.5555556  0.5555556  0.7777778  0.         0.5555556
 0.33333334 0.         0.44444445 0.8888889  0.11111111 0.8888889
 1.         0.44444445 0.6666667  0.11111111 1.         0.6666667
 0.6666667  0.7777778  0.33333334 0.7777778  0.6666667  0.5555556
 0.33333334 0.5555556  1.         0.22222222 1.         0.7777778
 0.8888889  0.8888889  0.8888889  0.8888889  0.33333334 0.6666667
 0.6666667  0.5555556  1.         0.5555556  0.8888889  0.11111111
 0.33333334 0.44444445 0.6666667  0.         0.5555556  0.22222222
 0.5555556  0.11111111 0.22222222 0.33333334 0.6666667  0.6666667
 0.11111111 0.8888889  0.         0.5555556  0.         0.22222222
 0.8888889  1.         0.44444445 0.6666667  0.         0.33333334
 0.33333334 0.6666667  0.         0.6666667  0.33333334 0.7777778
 0.6666667  0.33333334 0.44444445 0.         0.7777778  0.33333334
 0.         0.         0.22222222 0.33333334 0.6666667  0.33333334
 0.11111111 0.44444445 0.11111111 0.6666667  0.6666667  0.8888889
 0.8888889  0.7777778  0.44444445 1.         0.         0.33333334
 0.8888889  0.8888889  0.44444445 1.         0.         0.7777778 ]
Top k classes which perform poorly are:  [118, 99, 31, 15, 102, 103, 82, 28, 9, 88, 92, 124, 69, 80, 20, 108, 39, 78, 110, 34, 65, 73, 12, 4, 2, 83, 104, 74, 51, 71, 6, 58, 94, 48, 90, 44, 5, 89, 105, 75, 119, 101, 97, 30, 107, 66, 37, 24, 122, 98, 67, 116, 86, 109, 11, 32, 63, 70, 61, 3, 47, 49, 8, 81, 72, 29, 19, 26, 25, 23, 77, 87, 76, 106, 91, 60, 7, 10, 21, 22, 38, 68, 41, 96, 46, 93, 112, 111, 59, 42, 100, 95, 125, 53, 115, 45, 43, 27, 18, 17, 14, 13, 120, 121, 113, 114, 0, 84, 79, 64, 57, 56, 55, 54, 33, 35, 123, 1, 16, 40, 117, 85, 50, 52, 36, 62]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.4004, 1.2869, 1.4474, 1.3583, 1.3583, 1.2567, 1.2869,
        1.5000, 1.2567, 1.3206, 1.4474, 1.2297, 1.2297, 1.5000, 1.1839, 1.2297,
        1.2297, 1.2869, 1.5000, 1.2567, 1.2567, 1.2869, 1.3206, 1.2869, 1.2869,
        1.2297, 1.5000, 1.2869, 1.3583, 1.5000, 1.3206, 1.2056, 1.4474, 1.2056,
        1.1839, 1.3206, 1.2567, 1.4474, 1.1839, 1.2567, 1.2567, 1.2297, 1.3583,
        1.2297, 1.2567, 1.2869, 1.3583, 1.2869, 1.1839, 1.4004, 1.1839, 1.2297,
        1.2056, 1.2056, 1.2056, 1.2056, 1.3583, 1.2567, 1.2567, 1.2869, 1.1839,
        1.2869, 1.2056, 1.4474, 1.3583, 1.3206, 1.2567, 1.5000, 1.2869, 1.4004,
        1.2869, 1.4474, 1.4004, 1.3583, 1.2567, 1.2567, 1.4474, 1.2056, 1.5000,
        1.2869, 1.5000, 1.4004, 1.2056, 1.1839, 1.3206, 1.2567, 1.5000, 1.3583,
        1.3583, 1.2567, 1.5000, 1.2567, 1.3583, 1.2297, 1.2567, 1.3583, 1.3206,
        1.5000, 1.2297, 1.3583, 1.5000, 1.5000, 1.4004, 1.3583, 1.2567, 1.3583,
        1.4474, 1.3206, 1.4474, 1.2567, 1.2567, 1.2056, 1.2056, 1.2297, 1.3206,
        1.1839, 1.5000, 1.3583, 1.2056, 1.2056, 1.3206, 1.1839, 1.5000, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.5996, 0.7131, 0.5526, 0.6417, 0.6417, 0.7433, 0.7131,
        0.5000, 0.7433, 0.6794, 0.5526, 0.7703, 0.7703, 0.5000, 0.8161, 0.7703,
        0.7703, 0.7131, 0.5000, 0.7433, 0.7433, 0.7131, 0.6794, 0.7131, 0.7131,
        0.7703, 0.5000, 0.7131, 0.6417, 0.5000, 0.6794, 0.7944, 0.5526, 0.7944,
        0.8161, 0.6794, 0.7433, 0.5526, 0.8161, 0.7433, 0.7433, 0.7703, 0.6417,
        0.7703, 0.7433, 0.7131, 0.6417, 0.7131, 0.8161, 0.5996, 0.8161, 0.7703,
        0.7944, 0.7944, 0.7944, 0.7944, 0.6417, 0.7433, 0.7433, 0.7131, 0.8161,
        0.7131, 0.7944, 0.5526, 0.6417, 0.6794, 0.7433, 0.5000, 0.7131, 0.5996,
        0.7131, 0.5526, 0.5996, 0.6417, 0.7433, 0.7433, 0.5526, 0.7944, 0.5000,
        0.7131, 0.5000, 0.5996, 0.7944, 0.8161, 0.6794, 0.7433, 0.5000, 0.6417,
        0.6417, 0.7433, 0.5000, 0.7433, 0.6417, 0.7703, 0.7433, 0.6417, 0.6794,
        0.5000, 0.7703, 0.6417, 0.5000, 0.5000, 0.5996, 0.6417, 0.7433, 0.6417,
        0.5526, 0.6794, 0.5526, 0.7433, 0.7433, 0.7944, 0.7944, 0.7703, 0.6794,
        0.8161, 0.5000, 0.6417, 0.7944, 0.7944, 0.6794, 0.8161, 0.5000, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.304668 Loss T 0.120723 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5227, Accuracy: 564/1134 F1 (49.7355%)


Test set: Average loss: 2.1351, Accuracy: 10180/18312 F1 (55.5920%)


Val set: Average loss: 2.2898, Accuracy: 202/360 F1 (56.1111%)

best acc test 55.591962  acc val 56.111111 acc labeled target 49.735450
saving model...
S real T clipart Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.649327 Loss T 0.129393 Method MME

S real T clipart Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 1.493964 Loss T 0.098988 Method MME

S real T clipart Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.341089 Loss T 0.069985 Method MME

S real T clipart Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.329487 Loss T 0.116617 Method MME

S real T clipart Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.310176 Loss T 0.120592 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1871, Accuracy: 634/1134 F1 (55.9083%)


Test set: Average loss: 1.8755, Accuracy: 11156/18312 F1 (60.9218%)


Val set: Average loss: 2.0428, Accuracy: 209/360 F1 (58.0556%)

best acc test 60.921800  acc val 58.055556 acc labeled target 55.908289
saving model...
S real T clipart Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 1.068907 Loss T 0.088853 Method MME

S real T clipart Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.796557 Loss T 0.108940 Method MME

S real T clipart Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.959917 Loss T 0.113190 Method MME

S real T clipart Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.978411 Loss T 0.105474 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.6666667  0.6666667  0.5555556  0.11111111 0.33333334
 0.22222222 0.6666667  0.33333334 0.         0.6666667  0.33333334
 0.11111111 0.33333334 0.8888889  0.         1.         0.7777778
 0.6666667  0.6666667  0.         0.33333334 0.7777778  0.5555556
 0.33333334 0.7777778  0.6666667  0.8888889  0.         0.5555556
 0.5555556  0.33333334 0.7777778  1.         0.6666667  0.8888889
 0.6666667  0.6666667  0.5555556  0.         1.         0.7777778
 0.6666667  0.33333334 0.11111111 0.8888889  0.6666667  0.6666667
 0.33333334 0.6666667  0.6666667  0.8888889  1.         1.
 0.8888889  0.8888889  1.         1.         0.11111111 0.7777778
 0.7777778  0.         0.7777778  0.5555556  1.         0.5555556
 0.33333334 1.         0.6666667  0.         0.5555556  0.6666667
 0.8888889  0.         0.11111111 0.5555556  0.44444445 0.8888889
 0.         0.7777778  0.         0.6666667  0.         0.22222222
 1.         0.8888889  0.5555556  0.7777778  0.         0.6666667
 0.5555556  0.6666667  0.22222222 0.44444445 0.33333334 0.8888889
 0.7777778  0.33333334 0.8888889  0.         0.8888889  0.5555556
 0.33333334 0.         0.33333334 0.33333334 0.22222222 0.22222222
 0.22222222 0.6666667  0.33333334 0.7777778  0.7777778  1.
 0.7777778  0.7777778  0.5555556  0.8888889  0.         0.7777778
 1.         0.7777778  0.7777778  1.         0.         0.6666667 ]
Top k classes which perform poorly are:  [88, 28, 103, 118, 20, 99, 124, 15, 69, 73, 61, 80, 82, 9, 78, 39, 74, 44, 4, 58, 12, 108, 107, 83, 106, 6, 92, 105, 102, 94, 66, 48, 97, 110, 104, 43, 13, 11, 21, 31, 24, 5, 8, 93, 76, 65, 63, 70, 101, 23, 116, 75, 29, 30, 3, 86, 90, 38, 7, 91, 81, 10, 2, 71, 1, 89, 68, 36, 125, 47, 37, 34, 18, 19, 26, 50, 49, 109, 46, 42, 112, 96, 122, 115, 111, 121, 114, 119, 62, 79, 17, 22, 25, 60, 32, 59, 41, 87, 85, 14, 117, 27, 35, 45, 51, 55, 100, 77, 72, 98, 54, 95, 53, 123, 84, 16, 120, 64, 113, 33, 40, 57, 56, 52, 67, 0]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2567, 1.2567, 1.2869, 1.4474, 1.3583, 1.4004, 1.2567, 1.3583,
        1.5000, 1.2567, 1.3583, 1.4474, 1.3583, 1.2056, 1.5000, 1.1839, 1.2297,
        1.2567, 1.2567, 1.5000, 1.3583, 1.2297, 1.2869, 1.3583, 1.2297, 1.2567,
        1.2056, 1.5000, 1.2869, 1.2869, 1.3583, 1.2297, 1.1839, 1.2567, 1.2056,
        1.2567, 1.2567, 1.2869, 1.5000, 1.1839, 1.2297, 1.2567, 1.3583, 1.4474,
        1.2056, 1.2567, 1.2567, 1.3583, 1.2567, 1.2567, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.4474, 1.2297, 1.2297, 1.5000, 1.2297,
        1.2869, 1.1839, 1.2869, 1.3583, 1.1839, 1.2567, 1.5000, 1.2869, 1.2567,
        1.2056, 1.5000, 1.4474, 1.2869, 1.3206, 1.2056, 1.5000, 1.2297, 1.5000,
        1.2567, 1.5000, 1.4004, 1.1839, 1.2056, 1.2869, 1.2297, 1.5000, 1.2567,
        1.2869, 1.2567, 1.4004, 1.3206, 1.3583, 1.2056, 1.2297, 1.3583, 1.2056,
        1.5000, 1.2056, 1.2869, 1.3583, 1.5000, 1.3583, 1.3583, 1.4004, 1.4004,
        1.4004, 1.2567, 1.3583, 1.2297, 1.2297, 1.1839, 1.2297, 1.2297, 1.2869,
        1.2056, 1.5000, 1.2297, 1.1839, 1.2297, 1.2297, 1.1839, 1.5000, 1.2567])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7433, 0.7433, 0.7131, 0.5526, 0.6417, 0.5996, 0.7433, 0.6417,
        0.5000, 0.7433, 0.6417, 0.5526, 0.6417, 0.7944, 0.5000, 0.8161, 0.7703,
        0.7433, 0.7433, 0.5000, 0.6417, 0.7703, 0.7131, 0.6417, 0.7703, 0.7433,
        0.7944, 0.5000, 0.7131, 0.7131, 0.6417, 0.7703, 0.8161, 0.7433, 0.7944,
        0.7433, 0.7433, 0.7131, 0.5000, 0.8161, 0.7703, 0.7433, 0.6417, 0.5526,
        0.7944, 0.7433, 0.7433, 0.6417, 0.7433, 0.7433, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.5526, 0.7703, 0.7703, 0.5000, 0.7703,
        0.7131, 0.8161, 0.7131, 0.6417, 0.8161, 0.7433, 0.5000, 0.7131, 0.7433,
        0.7944, 0.5000, 0.5526, 0.7131, 0.6794, 0.7944, 0.5000, 0.7703, 0.5000,
        0.7433, 0.5000, 0.5996, 0.8161, 0.7944, 0.7131, 0.7703, 0.5000, 0.7433,
        0.7131, 0.7433, 0.5996, 0.6794, 0.6417, 0.7944, 0.7703, 0.6417, 0.7944,
        0.5000, 0.7944, 0.7131, 0.6417, 0.5000, 0.6417, 0.6417, 0.5996, 0.5996,
        0.5996, 0.7433, 0.6417, 0.7703, 0.7703, 0.8161, 0.7703, 0.7703, 0.7131,
        0.7944, 0.5000, 0.7703, 0.8161, 0.7703, 0.7703, 0.8161, 0.5000, 0.7433])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.586043 Loss T 0.072648 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4370, Accuracy: 590/1134 F1 (52.0282%)


Test set: Average loss: 2.1738, Accuracy: 10725/18312 F1 (58.5682%)


Val set: Average loss: 2.2366, Accuracy: 206/360 F1 (57.2222%)

best acc test 60.921800  acc val 57.222222 acc labeled target 52.028219
saving model...
S real T clipart Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.674185 Loss T 0.092693 Method MME

S real T clipart Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.660119 Loss T 0.105626 Method MME

S real T clipart Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 1.397087 Loss T 0.105674 Method MME

S real T clipart Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.475591 Loss T 0.077636 Method MME

S real T clipart Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 1.184179 Loss T 0.091405 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0194, Accuracy: 667/1134 F1 (58.8183%)


Test set: Average loss: 1.7760, Accuracy: 11783/18312 F1 (64.3458%)


Val set: Average loss: 1.9514, Accuracy: 222/360 F1 (61.6667%)

best acc test 64.345784  acc val 61.666667 acc labeled target 58.818342
saving model...
S real T clipart Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.960063 Loss T 0.081403 Method MME

S real T clipart Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.424654 Loss T 0.080116 Method MME

S real T clipart Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.686280 Loss T 0.071247 Method MME

S real T clipart Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.700567 Loss T 0.084665 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.6666667  0.6666667  0.22222222 0.11111111
 0.33333334 0.5555556  0.6666667  0.         0.5555556  0.5555556
 0.33333334 0.33333334 0.6666667  0.5555556  1.         1.
 0.6666667  0.5555556  0.         0.5555556  0.7777778  0.6666667
 0.7777778  0.7777778  0.44444445 0.7777778  0.44444445 0.44444445
 0.44444445 0.22222222 0.8888889  1.         1.         1.
 0.6666667  0.5555556  0.5555556  0.         1.         0.8888889
 0.5555556  1.         0.         0.7777778  0.7777778  0.6666667
 0.33333334 0.6666667  0.6666667  0.7777778  1.         0.7777778
 0.7777778  0.7777778  0.7777778  0.8888889  0.22222222 1.
 0.6666667  0.44444445 1.         0.5555556  1.         0.8888889
 0.33333334 0.11111111 0.8888889  0.         0.44444445 0.5555556
 0.44444445 0.33333334 0.         0.5555556  0.33333334 1.
 0.         1.         0.         0.8888889  0.         0.
 0.8888889  1.         0.5555556  0.7777778  0.         0.33333334
 0.22222222 0.5555556  0.         0.8888889  0.22222222 0.8888889
 0.8888889  0.7777778  1.         0.6666667  0.8888889  0.8888889
 0.11111111 0.11111111 0.33333334 0.33333334 0.44444445 0.6666667
 0.11111111 0.6666667  0.22222222 0.7777778  0.7777778  0.8888889
 0.8888889  0.6666667  0.5555556  1.         0.33333334 0.44444445
 0.8888889  0.7777778  0.8888889  1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [39, 78, 92, 74, 44, 80, 124, 82, 9, 83, 20, 69, 88, 103, 67, 102, 108, 5, 94, 110, 31, 90, 4, 58, 13, 76, 118, 73, 48, 89, 6, 66, 12, 105, 104, 70, 106, 72, 29, 61, 119, 30, 28, 26, 91, 7, 63, 10, 11, 15, 37, 38, 21, 71, 42, 75, 116, 86, 19, 107, 0, 109, 2, 3, 8, 14, 18, 23, 60, 36, 47, 115, 49, 50, 99, 46, 56, 55, 54, 53, 121, 87, 22, 111, 24, 25, 27, 112, 45, 51, 97, 101, 120, 114, 113, 100, 122, 125, 68, 95, 93, 41, 84, 81, 96, 57, 65, 32, 33, 98, 117, 16, 1, 123, 17, 34, 52, 40, 43, 59, 64, 77, 79, 85, 35, 62]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.2567, 1.2567, 1.4004, 1.4474, 1.3583, 1.2869, 1.2567,
        1.5000, 1.2869, 1.2869, 1.3583, 1.3583, 1.2567, 1.2869, 1.1839, 1.1839,
        1.2567, 1.2869, 1.5000, 1.2869, 1.2297, 1.2567, 1.2297, 1.2297, 1.3206,
        1.2297, 1.3206, 1.3206, 1.3206, 1.4004, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2869, 1.2869, 1.5000, 1.1839, 1.2056, 1.2869, 1.1839, 1.5000,
        1.2297, 1.2297, 1.2567, 1.3583, 1.2567, 1.2567, 1.2297, 1.1839, 1.2297,
        1.2297, 1.2297, 1.2297, 1.2056, 1.4004, 1.1839, 1.2567, 1.3206, 1.1839,
        1.2869, 1.1839, 1.2056, 1.3583, 1.4474, 1.2056, 1.5000, 1.3206, 1.2869,
        1.3206, 1.3583, 1.5000, 1.2869, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000,
        1.2056, 1.5000, 1.5000, 1.2056, 1.1839, 1.2869, 1.2297, 1.5000, 1.3583,
        1.4004, 1.2869, 1.5000, 1.2056, 1.4004, 1.2056, 1.2056, 1.2297, 1.1839,
        1.2567, 1.2056, 1.2056, 1.4474, 1.4474, 1.3583, 1.3583, 1.3206, 1.2567,
        1.4474, 1.2567, 1.4004, 1.2297, 1.2297, 1.2056, 1.2056, 1.2567, 1.2869,
        1.1839, 1.3583, 1.3206, 1.2056, 1.2297, 1.2056, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.7433, 0.7433, 0.5996, 0.5526, 0.6417, 0.7131, 0.7433,
        0.5000, 0.7131, 0.7131, 0.6417, 0.6417, 0.7433, 0.7131, 0.8161, 0.8161,
        0.7433, 0.7131, 0.5000, 0.7131, 0.7703, 0.7433, 0.7703, 0.7703, 0.6794,
        0.7703, 0.6794, 0.6794, 0.6794, 0.5996, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7131, 0.7131, 0.5000, 0.8161, 0.7944, 0.7131, 0.8161, 0.5000,
        0.7703, 0.7703, 0.7433, 0.6417, 0.7433, 0.7433, 0.7703, 0.8161, 0.7703,
        0.7703, 0.7703, 0.7703, 0.7944, 0.5996, 0.8161, 0.7433, 0.6794, 0.8161,
        0.7131, 0.8161, 0.7944, 0.6417, 0.5526, 0.7944, 0.5000, 0.6794, 0.7131,
        0.6794, 0.6417, 0.5000, 0.7131, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000,
        0.7944, 0.5000, 0.5000, 0.7944, 0.8161, 0.7131, 0.7703, 0.5000, 0.6417,
        0.5996, 0.7131, 0.5000, 0.7944, 0.5996, 0.7944, 0.7944, 0.7703, 0.8161,
        0.7433, 0.7944, 0.7944, 0.5526, 0.5526, 0.6417, 0.6417, 0.6794, 0.7433,
        0.5526, 0.7433, 0.5996, 0.7703, 0.7703, 0.7944, 0.7944, 0.7433, 0.7131,
        0.8161, 0.6417, 0.6794, 0.7944, 0.7703, 0.7944, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.457670 Loss T 0.080660 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1545, Accuracy: 651/1134 F1 (57.4074%)


Test set: Average loss: 1.8351, Accuracy: 11643/18312 F1 (63.5813%)


Val set: Average loss: 2.0663, Accuracy: 213/360 F1 (59.1667%)

best acc test 64.345784  acc val 59.166667 acc labeled target 57.407407
saving model...
S real T clipart Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.497635 Loss T 0.097703 Method MME

S real T clipart Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.916059 Loss T 0.077574 Method MME

S real T clipart Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 1.138324 Loss T 0.077086 Method MME

S real T clipart Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.708590 Loss T 0.084024 Method MME

S real T clipart Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.567511 Loss T 0.061498 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0553, Accuracy: 667/1134 F1 (58.8183%)


Test set: Average loss: 1.7259, Accuracy: 12135/18312 F1 (66.2680%)


Val set: Average loss: 1.8504, Accuracy: 235/360 F1 (65.2778%)

best acc test 66.268021  acc val 65.277778 acc labeled target 58.818342
saving model...
S real T clipart Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.601796 Loss T 0.070368 Method MME

S real T clipart Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.569593 Loss T 0.064179 Method MME

S real T clipart Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.479419 Loss T 0.068936 Method MME

S real T clipart Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.303957 Loss T 0.085194 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.6666667  0.5555556  0.         0.33333334
 0.33333334 0.6666667  0.7777778  0.         0.5555556  0.44444445
 0.11111111 0.22222222 0.7777778  0.44444445 1.         1.
 0.8888889  0.5555556  0.         0.33333334 0.7777778  0.6666667
 0.5555556  0.44444445 0.6666667  1.         0.22222222 0.33333334
 0.5555556  0.22222222 0.8888889  0.7777778  0.7777778  1.
 0.6666667  0.6666667  0.6666667  0.11111111 1.         0.5555556
 0.5555556  0.6666667  0.11111111 0.6666667  1.         0.6666667
 0.33333334 0.6666667  0.6666667  0.5555556  1.         1.
 1.         0.8888889  0.8888889  0.8888889  0.6666667  0.7777778
 0.7777778  0.44444445 1.         0.6666667  1.         1.
 0.         0.         0.5555556  0.         0.5555556  0.5555556
 0.5555556  0.33333334 0.11111111 0.5555556  0.11111111 1.
 0.11111111 1.         0.         0.8888889  0.         0.11111111
 0.8888889  0.8888889  0.33333334 1.         0.         0.5555556
 0.33333334 0.33333334 0.         0.7777778  0.33333334 0.8888889
 0.8888889  0.5555556  0.8888889  0.5555556  0.6666667  1.
 0.22222222 0.11111111 0.33333334 0.33333334 0.44444445 0.7777778
 0.33333334 0.6666667  0.6666667  1.         1.         0.8888889
 0.8888889  0.8888889  0.5555556  1.         0.11111111 0.44444445
 0.8888889  0.6666667  0.7777778  1.         0.         0.7777778 ]
Top k classes which perform poorly are:  [67, 88, 20, 82, 9, 69, 124, 66, 80, 4, 92, 44, 39, 83, 78, 74, 118, 76, 12, 103, 102, 13, 31, 28, 91, 104, 5, 6, 90, 105, 86, 73, 48, 21, 108, 29, 94, 106, 61, 11, 25, 15, 119, 68, 3, 89, 10, 97, 51, 75, 30, 24, 70, 71, 72, 99, 42, 41, 116, 19, 63, 100, 47, 45, 121, 36, 37, 38, 43, 26, 7, 23, 49, 50, 110, 109, 58, 2, 8, 122, 14, 22, 59, 125, 34, 60, 93, 107, 33, 98, 120, 96, 114, 113, 115, 0, 18, 85, 84, 81, 32, 95, 55, 57, 56, 117, 27, 87, 17, 16, 1, 123, 35, 40, 52, 112, 111, 53, 54, 64, 65, 77, 101, 79, 46, 62]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2567, 1.2869, 1.5000, 1.3583, 1.3583, 1.2567, 1.2297,
        1.5000, 1.2869, 1.3206, 1.4474, 1.4004, 1.2297, 1.3206, 1.1839, 1.1839,
        1.2056, 1.2869, 1.5000, 1.3583, 1.2297, 1.2567, 1.2869, 1.3206, 1.2567,
        1.1839, 1.4004, 1.3583, 1.2869, 1.4004, 1.2056, 1.2297, 1.2297, 1.1839,
        1.2567, 1.2567, 1.2567, 1.4474, 1.1839, 1.2869, 1.2869, 1.2567, 1.4474,
        1.2567, 1.1839, 1.2567, 1.3583, 1.2567, 1.2567, 1.2869, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.2056, 1.2567, 1.2297, 1.2297, 1.3206, 1.1839,
        1.2567, 1.1839, 1.1839, 1.5000, 1.5000, 1.2869, 1.5000, 1.2869, 1.2869,
        1.2869, 1.3583, 1.4474, 1.2869, 1.4474, 1.1839, 1.4474, 1.1839, 1.5000,
        1.2056, 1.5000, 1.4474, 1.2056, 1.2056, 1.3583, 1.1839, 1.5000, 1.2869,
        1.3583, 1.3583, 1.5000, 1.2297, 1.3583, 1.2056, 1.2056, 1.2869, 1.2056,
        1.2869, 1.2567, 1.1839, 1.4004, 1.4474, 1.3583, 1.3583, 1.3206, 1.2297,
        1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.2869,
        1.1839, 1.4474, 1.3206, 1.2056, 1.2567, 1.2297, 1.1839, 1.5000, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7433, 0.7131, 0.5000, 0.6417, 0.6417, 0.7433, 0.7703,
        0.5000, 0.7131, 0.6794, 0.5526, 0.5996, 0.7703, 0.6794, 0.8161, 0.8161,
        0.7944, 0.7131, 0.5000, 0.6417, 0.7703, 0.7433, 0.7131, 0.6794, 0.7433,
        0.8161, 0.5996, 0.6417, 0.7131, 0.5996, 0.7944, 0.7703, 0.7703, 0.8161,
        0.7433, 0.7433, 0.7433, 0.5526, 0.8161, 0.7131, 0.7131, 0.7433, 0.5526,
        0.7433, 0.8161, 0.7433, 0.6417, 0.7433, 0.7433, 0.7131, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.7944, 0.7433, 0.7703, 0.7703, 0.6794, 0.8161,
        0.7433, 0.8161, 0.8161, 0.5000, 0.5000, 0.7131, 0.5000, 0.7131, 0.7131,
        0.7131, 0.6417, 0.5526, 0.7131, 0.5526, 0.8161, 0.5526, 0.8161, 0.5000,
        0.7944, 0.5000, 0.5526, 0.7944, 0.7944, 0.6417, 0.8161, 0.5000, 0.7131,
        0.6417, 0.6417, 0.5000, 0.7703, 0.6417, 0.7944, 0.7944, 0.7131, 0.7944,
        0.7131, 0.7433, 0.8161, 0.5996, 0.5526, 0.6417, 0.6417, 0.6794, 0.7703,
        0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.7131,
        0.8161, 0.5526, 0.6794, 0.7944, 0.7433, 0.7703, 0.8161, 0.5000, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 1.238915 Loss T 0.057393 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2685, Accuracy: 637/1134 F1 (56.1728%)


Test set: Average loss: 1.9109, Accuracy: 11729/18312 F1 (64.0509%)


Val set: Average loss: 2.1867, Accuracy: 216/360 F1 (60.0000%)

best acc test 66.268021  acc val 60.000000 acc labeled target 56.172840
saving model...
S real T clipart Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.513533 Loss T 0.082518 Method MME

S real T clipart Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.384007 Loss T 0.060876 Method MME

S real T clipart Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 1.439237 Loss T 0.088985 Method MME

S real T clipart Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.267949 Loss T 0.065707 Method MME

S real T clipart Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.712321 Loss T 0.059140 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9147, Accuracy: 698/1134 F1 (61.5520%)


Test set: Average loss: 1.6723, Accuracy: 12263/18312 F1 (66.9670%)


Val set: Average loss: 1.8764, Accuracy: 229/360 F1 (63.6111%)

best acc test 66.268021  acc val 63.611111 acc labeled target 61.552028
saving model...
S real T clipart Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.672462 Loss T 0.058516 Method MME

S real T clipart Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.748561 Loss T 0.072143 Method MME

S real T clipart Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.162685 Loss T 0.067399 Method MME

S real T clipart Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.529039 Loss T 0.062929 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.6666667  0.33333334 0.11111111 0.11111111
 0.33333334 0.5555556  0.6666667  0.         0.7777778  0.6666667
 0.22222222 0.6666667  1.         0.11111111 1.         1.
 1.         0.7777778  0.         0.5555556  0.6666667  0.6666667
 0.33333334 0.6666667  0.6666667  0.7777778  0.33333334 0.7777778
 0.33333334 0.22222222 0.8888889  1.         0.8888889  0.8888889
 0.5555556  0.7777778  0.33333334 0.         1.         0.8888889
 0.5555556  0.7777778  0.11111111 0.6666667  0.6666667  0.6666667
 0.33333334 0.6666667  0.6666667  0.8888889  1.         1.
 1.         1.         1.         0.8888889  0.5555556  1.
 0.8888889  0.6666667  1.         0.6666667  0.8888889  1.
 0.22222222 0.8888889  0.6666667  0.         0.5555556  0.6666667
 0.8888889  0.44444445 0.33333334 0.33333334 0.33333334 1.
 0.         1.         0.         0.5555556  0.         0.44444445
 0.8888889  1.         0.5555556  0.5555556  0.         0.44444445
 0.33333334 0.33333334 0.         0.8888889  0.33333334 0.8888889
 0.8888889  0.7777778  1.         0.33333334 0.8888889  1.
 0.         0.22222222 0.33333334 0.33333334 0.8888889  0.5555556
 0.33333334 0.6666667  0.5555556  1.         0.7777778  1.
 1.         0.7777778  0.44444445 1.         0.11111111 0.44444445
 1.         0.6666667  0.7777778  1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [69, 102, 78, 92, 80, 124, 9, 82, 39, 88, 20, 5, 4, 15, 118, 44, 103, 12, 31, 66, 30, 75, 99, 108, 104, 105, 94, 38, 48, 24, 74, 76, 91, 28, 90, 3, 6, 119, 73, 89, 116, 83, 70, 58, 81, 0, 87, 21, 86, 42, 107, 7, 36, 110, 47, 25, 26, 71, 68, 46, 121, 13, 11, 61, 23, 8, 109, 2, 50, 49, 45, 63, 22, 10, 19, 122, 43, 29, 115, 112, 97, 37, 27, 95, 96, 100, 106, 93, 125, 84, 32, 34, 35, 51, 57, 60, 41, 67, 72, 64, 59, 123, 1, 14, 120, 16, 17, 117, 18, 79, 114, 113, 111, 77, 40, 85, 52, 53, 54, 55, 101, 56, 65, 98, 33, 62]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.2567, 1.3583, 1.4474, 1.4474, 1.3583, 1.2869, 1.2567,
        1.5000, 1.2297, 1.2567, 1.4004, 1.2567, 1.1839, 1.4474, 1.1839, 1.1839,
        1.1839, 1.2297, 1.5000, 1.2869, 1.2567, 1.2567, 1.3583, 1.2567, 1.2567,
        1.2297, 1.3583, 1.2297, 1.3583, 1.4004, 1.2056, 1.1839, 1.2056, 1.2056,
        1.2869, 1.2297, 1.3583, 1.5000, 1.1839, 1.2056, 1.2869, 1.2297, 1.4474,
        1.2567, 1.2567, 1.2567, 1.3583, 1.2567, 1.2567, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2869, 1.1839, 1.2056, 1.2567, 1.1839,
        1.2567, 1.2056, 1.1839, 1.4004, 1.2056, 1.2567, 1.5000, 1.2869, 1.2567,
        1.2056, 1.3206, 1.3583, 1.3583, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000,
        1.2869, 1.5000, 1.3206, 1.2056, 1.1839, 1.2869, 1.2869, 1.5000, 1.3206,
        1.3583, 1.3583, 1.5000, 1.2056, 1.3583, 1.2056, 1.2056, 1.2297, 1.1839,
        1.3583, 1.2056, 1.1839, 1.5000, 1.4004, 1.3583, 1.3583, 1.2056, 1.2869,
        1.3583, 1.2567, 1.2869, 1.1839, 1.2297, 1.1839, 1.1839, 1.2297, 1.3206,
        1.1839, 1.4474, 1.3206, 1.1839, 1.2567, 1.2297, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.7433, 0.6417, 0.5526, 0.5526, 0.6417, 0.7131, 0.7433,
        0.5000, 0.7703, 0.7433, 0.5996, 0.7433, 0.8161, 0.5526, 0.8161, 0.8161,
        0.8161, 0.7703, 0.5000, 0.7131, 0.7433, 0.7433, 0.6417, 0.7433, 0.7433,
        0.7703, 0.6417, 0.7703, 0.6417, 0.5996, 0.7944, 0.8161, 0.7944, 0.7944,
        0.7131, 0.7703, 0.6417, 0.5000, 0.8161, 0.7944, 0.7131, 0.7703, 0.5526,
        0.7433, 0.7433, 0.7433, 0.6417, 0.7433, 0.7433, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7131, 0.8161, 0.7944, 0.7433, 0.8161,
        0.7433, 0.7944, 0.8161, 0.5996, 0.7944, 0.7433, 0.5000, 0.7131, 0.7433,
        0.7944, 0.6794, 0.6417, 0.6417, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000,
        0.7131, 0.5000, 0.6794, 0.7944, 0.8161, 0.7131, 0.7131, 0.5000, 0.6794,
        0.6417, 0.6417, 0.5000, 0.7944, 0.6417, 0.7944, 0.7944, 0.7703, 0.8161,
        0.6417, 0.7944, 0.8161, 0.5000, 0.5996, 0.6417, 0.6417, 0.7944, 0.7131,
        0.6417, 0.7433, 0.7131, 0.8161, 0.7703, 0.8161, 0.8161, 0.7703, 0.6794,
        0.8161, 0.5526, 0.6794, 0.8161, 0.7433, 0.7703, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.825067 Loss T 0.067009 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9995, Accuracy: 668/1134 F1 (58.9065%)


Test set: Average loss: 1.7734, Accuracy: 12217/18312 F1 (66.7158%)


Val set: Average loss: 2.0289, Accuracy: 231/360 F1 (64.1667%)

best acc test 66.268021  acc val 64.166667 acc labeled target 58.906526
saving model...
S real T clipart Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.608936 Loss T 0.061872 Method MME

S real T clipart Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.522408 Loss T 0.051587 Method MME

S real T clipart Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.189958 Loss T 0.078725 Method MME

S real T clipart Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.192493 Loss T 0.075419 Method MME

S real T clipart Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.284776 Loss T 0.063306 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8831, Accuracy: 723/1134 F1 (63.7566%)


Test set: Average loss: 1.7096, Accuracy: 12594/18312 F1 (68.7746%)


Val set: Average loss: 2.0084, Accuracy: 223/360 F1 (61.9444%)

best acc test 66.268021  acc val 61.944444 acc labeled target 63.756614
saving model...
S real T clipart Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.362601 Loss T 0.056813 Method MME

S real T clipart Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.119888 Loss T 0.070632 Method MME

S real T clipart Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.383886 Loss T 0.058160 Method MME

S real T clipart Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.554374 Loss T 0.060310 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  1.         0.6666667  0.5555556  0.33333334 0.11111111
 0.33333334 0.6666667  0.44444445 0.         0.6666667  0.5555556
 0.6666667  1.         1.         0.6666667  0.8888889  1.
 0.8888889  1.         0.         0.8888889  0.7777778  0.6666667
 0.6666667  0.5555556  0.5555556  0.7777778  0.33333334 0.5555556
 0.7777778  0.33333334 0.6666667  0.8888889  0.8888889  1.
 0.6666667  0.8888889  0.33333334 0.         1.         0.5555556
 0.5555556  0.44444445 0.33333334 1.         0.8888889  0.6666667
 0.33333334 0.6666667  0.7777778  1.         1.         1.
 1.         1.         0.8888889  1.         0.44444445 1.
 0.8888889  0.7777778  1.         0.44444445 1.         1.
 0.33333334 0.6666667  1.         0.         0.6666667  0.6666667
 0.8888889  0.11111111 0.         0.6666667  0.44444445 0.8888889
 0.11111111 0.7777778  0.44444445 0.5555556  0.         0.33333334
 1.         1.         0.6666667  1.         0.         0.33333334
 0.33333334 0.22222222 0.         0.8888889  0.33333334 0.7777778
 0.8888889  0.6666667  1.         0.11111111 0.6666667  1.
 0.22222222 0.22222222 0.33333334 0.33333334 0.44444445 0.7777778
 0.22222222 0.6666667  0.6666667  1.         0.6666667  1.
 0.7777778  0.7777778  0.6666667  1.         0.11111111 0.5555556
 1.         0.6666667  0.5555556  1.         0.11111111 1.        ]
Top k classes which perform poorly are:  [9, 82, 74, 88, 39, 20, 92, 69, 118, 78, 73, 5, 99, 124, 91, 102, 108, 103, 31, 38, 104, 44, 105, 48, 83, 89, 28, 90, 4, 6, 94, 66, 80, 63, 76, 58, 8, 43, 106, 3, 42, 26, 11, 122, 119, 25, 29, 81, 41, 67, 109, 70, 75, 110, 71, 100, 36, 49, 47, 116, 86, 32, 24, 23, 112, 97, 15, 121, 12, 10, 7, 2, 79, 95, 0, 107, 22, 27, 30, 115, 114, 50, 61, 16, 96, 18, 93, 21, 77, 34, 33, 72, 37, 46, 56, 60, 113, 117, 120, 123, 111, 62, 98, 1, 13, 14, 17, 19, 35, 40, 45, 51, 52, 53, 54, 55, 57, 59, 64, 65, 68, 84, 85, 87, 101, 125]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.1839, 1.2567, 1.2869, 1.3583, 1.4474, 1.3583, 1.2567, 1.3206,
        1.5000, 1.2567, 1.2869, 1.2567, 1.1839, 1.1839, 1.2567, 1.2056, 1.1839,
        1.2056, 1.1839, 1.5000, 1.2056, 1.2297, 1.2567, 1.2567, 1.2869, 1.2869,
        1.2297, 1.3583, 1.2869, 1.2297, 1.3583, 1.2567, 1.2056, 1.2056, 1.1839,
        1.2567, 1.2056, 1.3583, 1.5000, 1.1839, 1.2869, 1.2869, 1.3206, 1.3583,
        1.1839, 1.2056, 1.2567, 1.3583, 1.2567, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.3206, 1.1839, 1.2056, 1.2297, 1.1839,
        1.3206, 1.1839, 1.1839, 1.3583, 1.2567, 1.1839, 1.5000, 1.2567, 1.2567,
        1.2056, 1.4474, 1.5000, 1.2567, 1.3206, 1.2056, 1.4474, 1.2297, 1.3206,
        1.2869, 1.5000, 1.3583, 1.1839, 1.1839, 1.2567, 1.1839, 1.5000, 1.3583,
        1.3583, 1.4004, 1.5000, 1.2056, 1.3583, 1.2297, 1.2056, 1.2567, 1.1839,
        1.4474, 1.2567, 1.1839, 1.4004, 1.4004, 1.3583, 1.3583, 1.3206, 1.2297,
        1.4004, 1.2567, 1.2567, 1.1839, 1.2567, 1.1839, 1.2297, 1.2297, 1.2567,
        1.1839, 1.4474, 1.2869, 1.1839, 1.2567, 1.2869, 1.1839, 1.4474, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.8161, 0.7433, 0.7131, 0.6417, 0.5526, 0.6417, 0.7433, 0.6794,
        0.5000, 0.7433, 0.7131, 0.7433, 0.8161, 0.8161, 0.7433, 0.7944, 0.8161,
        0.7944, 0.8161, 0.5000, 0.7944, 0.7703, 0.7433, 0.7433, 0.7131, 0.7131,
        0.7703, 0.6417, 0.7131, 0.7703, 0.6417, 0.7433, 0.7944, 0.7944, 0.8161,
        0.7433, 0.7944, 0.6417, 0.5000, 0.8161, 0.7131, 0.7131, 0.6794, 0.6417,
        0.8161, 0.7944, 0.7433, 0.6417, 0.7433, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.6794, 0.8161, 0.7944, 0.7703, 0.8161,
        0.6794, 0.8161, 0.8161, 0.6417, 0.7433, 0.8161, 0.5000, 0.7433, 0.7433,
        0.7944, 0.5526, 0.5000, 0.7433, 0.6794, 0.7944, 0.5526, 0.7703, 0.6794,
        0.7131, 0.5000, 0.6417, 0.8161, 0.8161, 0.7433, 0.8161, 0.5000, 0.6417,
        0.6417, 0.5996, 0.5000, 0.7944, 0.6417, 0.7703, 0.7944, 0.7433, 0.8161,
        0.5526, 0.7433, 0.8161, 0.5996, 0.5996, 0.6417, 0.6417, 0.6794, 0.7703,
        0.5996, 0.7433, 0.7433, 0.8161, 0.7433, 0.8161, 0.7703, 0.7703, 0.7433,
        0.8161, 0.5526, 0.7131, 0.8161, 0.7433, 0.7131, 0.8161, 0.5526, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 1.045104 Loss T 0.070012 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1697, Accuracy: 659/1134 F1 (58.1129%)


Test set: Average loss: 1.8849, Accuracy: 11926/18312 F1 (65.1267%)


Val set: Average loss: 2.1005, Accuracy: 212/360 F1 (58.8889%)

best acc test 66.268021  acc val 58.888889 acc labeled target 58.112875
saving model...
S real T clipart Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.455044 Loss T 0.063984 Method MME

S real T clipart Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.536555 Loss T 0.055848 Method MME

S real T clipart Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.931110 Loss T 0.057564 Method MME

S real T clipart Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.471489 Loss T 0.059769 Method MME

S real T clipart Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.320384 Loss T 0.045057 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7445, Accuracy: 728/1134 F1 (64.1975%)


Test set: Average loss: 1.6393, Accuracy: 12672/18312 F1 (69.2005%)


Val set: Average loss: 1.7071, Accuracy: 235/360 F1 (65.2778%)

best acc test 69.200524  acc val 65.277778 acc labeled target 64.197531
saving model...
S real T clipart Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.395642 Loss T 0.059634 Method MME

S real T clipart Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.474164 Loss T 0.038385 Method MME

S real T clipart Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.440898 Loss T 0.058890 Method MME

S real T clipart Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.988865 Loss T 0.052437 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 0.7777778  0.6666667  0.6666667  0.         0.33333334
 0.33333334 0.6666667  0.5555556  0.         0.8888889  0.22222222
 0.22222222 0.6666667  1.         0.7777778  1.         0.8888889
 1.         0.6666667  0.         0.6666667  0.7777778  0.6666667
 0.5555556  0.44444445 0.5555556  0.7777778  0.44444445 0.8888889
 0.6666667  0.33333334 0.8888889  1.         0.8888889  1.
 0.6666667  0.8888889  0.6666667  0.         1.         0.8888889
 0.6666667  0.22222222 0.22222222 0.8888889  1.         0.6666667
 0.33333334 0.6666667  1.         1.         1.         1.
 1.         1.         1.         0.7777778  0.44444445 1.
 0.7777778  0.44444445 1.         0.5555556  1.         0.8888889
 0.22222222 0.11111111 1.         0.         0.5555556  0.6666667
 0.6666667  0.5555556  0.11111111 0.33333334 0.         1.
 0.33333334 0.8888889  0.7777778  0.6666667  0.         0.33333334
 0.8888889  1.         0.22222222 1.         0.         0.33333334
 0.33333334 0.22222222 0.22222222 0.5555556  0.22222222 1.
 1.         0.6666667  1.         0.6666667  0.8888889  1.
 0.         0.44444445 0.33333334 0.33333334 0.33333334 1.
 0.44444445 0.6666667  0.44444445 1.         1.         1.
 0.8888889  1.         0.6666667  1.         0.5555556  0.5555556
 1.         0.7777778  0.8888889  0.8888889  0.22222222 1.        ]
Top k classes which perform poorly are:  [88, 76, 69, 82, 20, 9, 39, 4, 102, 67, 74, 94, 44, 86, 43, 66, 91, 92, 12, 11, 124, 106, 31, 75, 78, 105, 6, 104, 89, 90, 5, 48, 83, 108, 61, 0, 110, 25, 28, 58, 103, 119, 118, 70, 26, 73, 24, 93, 8, 63, 109, 72, 71, 97, 81, 116, 42, 23, 19, 13, 30, 7, 38, 47, 99, 3, 21, 2, 49, 36, 80, 27, 121, 22, 15, 60, 1, 57, 17, 123, 10, 84, 122, 29, 100, 32, 34, 37, 41, 45, 65, 114, 79, 111, 120, 107, 117, 115, 113, 101, 112, 62, 96, 14, 16, 18, 33, 35, 40, 46, 50, 51, 52, 53, 54, 55, 56, 59, 64, 68, 77, 85, 87, 95, 98, 125]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.2297, 1.2567, 1.2567, 1.5000, 1.3583, 1.3583, 1.2567, 1.2869,
        1.5000, 1.2056, 1.4004, 1.4004, 1.2567, 1.1839, 1.2297, 1.1839, 1.2056,
        1.1839, 1.2567, 1.5000, 1.2567, 1.2297, 1.2567, 1.2869, 1.3206, 1.2869,
        1.2297, 1.3206, 1.2056, 1.2567, 1.3583, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2567, 1.2056, 1.2567, 1.5000, 1.1839, 1.2056, 1.2567, 1.4004, 1.4004,
        1.2056, 1.1839, 1.2567, 1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.3206, 1.1839, 1.2297, 1.3206, 1.1839,
        1.2869, 1.1839, 1.2056, 1.4004, 1.4474, 1.1839, 1.5000, 1.2869, 1.2567,
        1.2567, 1.2869, 1.4474, 1.3583, 1.5000, 1.1839, 1.3583, 1.2056, 1.2297,
        1.2567, 1.5000, 1.3583, 1.2056, 1.1839, 1.4004, 1.1839, 1.5000, 1.3583,
        1.3583, 1.4004, 1.4004, 1.2869, 1.4004, 1.1839, 1.1839, 1.2567, 1.1839,
        1.2567, 1.2056, 1.1839, 1.5000, 1.3206, 1.3583, 1.3583, 1.3583, 1.1839,
        1.3206, 1.2567, 1.3206, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2567,
        1.1839, 1.2869, 1.2869, 1.1839, 1.2297, 1.2056, 1.2056, 1.4004, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.7703, 0.7433, 0.7433, 0.5000, 0.6417, 0.6417, 0.7433, 0.7131,
        0.5000, 0.7944, 0.5996, 0.5996, 0.7433, 0.8161, 0.7703, 0.8161, 0.7944,
        0.8161, 0.7433, 0.5000, 0.7433, 0.7703, 0.7433, 0.7131, 0.6794, 0.7131,
        0.7703, 0.6794, 0.7944, 0.7433, 0.6417, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7433, 0.7944, 0.7433, 0.5000, 0.8161, 0.7944, 0.7433, 0.5996, 0.5996,
        0.7944, 0.8161, 0.7433, 0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.6794, 0.8161, 0.7703, 0.6794, 0.8161,
        0.7131, 0.8161, 0.7944, 0.5996, 0.5526, 0.8161, 0.5000, 0.7131, 0.7433,
        0.7433, 0.7131, 0.5526, 0.6417, 0.5000, 0.8161, 0.6417, 0.7944, 0.7703,
        0.7433, 0.5000, 0.6417, 0.7944, 0.8161, 0.5996, 0.8161, 0.5000, 0.6417,
        0.6417, 0.5996, 0.5996, 0.7131, 0.5996, 0.8161, 0.8161, 0.7433, 0.8161,
        0.7433, 0.7944, 0.8161, 0.5000, 0.6794, 0.6417, 0.6417, 0.6417, 0.8161,
        0.6794, 0.7433, 0.6794, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7433,
        0.8161, 0.7131, 0.7131, 0.8161, 0.7703, 0.7944, 0.7944, 0.5996, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.867962 Loss T 0.041092 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9861, Accuracy: 683/1134 F1 (60.2293%)


Test set: Average loss: 1.7217, Accuracy: 12544/18312 F1 (68.5015%)


Val set: Average loss: 1.9142, Accuracy: 224/360 F1 (62.2222%)

best acc test 69.200524  acc val 62.222222 acc labeled target 60.229277
saving model...
S real T clipart Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.634615 Loss T 0.072937 Method MME

S real T clipart Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.465940 Loss T 0.044657 Method MME

S real T clipart Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.426854 Loss T 0.054777 Method MME

S real T clipart Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.569386 Loss T 0.052944 Method MME

S real T clipart Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.593456 Loss T 0.056588 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1545, Accuracy: 1087/1134 F1 (95.8554%)


Test set: Average loss: 1.4280, Accuracy: 13378/18312 F1 (73.0559%)


Val set: Average loss: 1.4903, Accuracy: 250/360 F1 (69.4444%)

best acc test 73.055920  acc val 69.444444 acc labeled target 95.855379
saving model...
S real T clipart Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.501780 Loss T 0.059779 Method MME

S real T clipart Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.734781 Loss T 0.041781 Method MME

S real T clipart Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.248022 Loss T 0.065360 Method MME

S real T clipart Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.815778 Loss T 0.051040 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        0.7777778 0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 0.8888889 1.        1.        0.6666667 0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889]
Top k classes which perform poorly are:  [103, 63, 47, 5, 38, 97, 41, 95, 43, 44, 48, 92, 50, 125, 34, 57, 59, 84, 61, 66, 80, 78, 70, 72, 91, 90, 74, 6, 9, 117, 111, 23, 20, 110, 19, 11, 15, 13, 1, 121, 85, 118, 86, 107, 120, 83, 82, 81, 79, 122, 123, 77, 119, 87, 116, 89, 106, 105, 104, 109, 102, 101, 100, 99, 76, 96, 112, 113, 94, 93, 114, 115, 108, 88, 98, 0, 73, 31, 30, 29, 28, 27, 26, 25, 24, 22, 21, 18, 17, 16, 14, 12, 10, 8, 7, 4, 3, 2, 32, 33, 35, 36, 71, 69, 68, 67, 65, 64, 124, 60, 58, 56, 75, 55, 53, 52, 51, 49, 46, 45, 42, 40, 39, 37, 54, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2567, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7433, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.225494 Loss T 0.043046 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1303, Accuracy: 1096/1134 F1 (96.6490%)


Test set: Average loss: 1.5698, Accuracy: 13111/18312 F1 (71.5979%)


Val set: Average loss: 1.6612, Accuracy: 252/360 F1 (70.0000%)

best acc test 71.597859  acc val 70.000000 acc labeled target 96.649030
saving model...
S real T clipart Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.352065 Loss T 0.033651 Method MME

S real T clipart Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.376334 Loss T 0.046937 Method MME

S real T clipart Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.724650 Loss T 0.040380 Method MME

S real T clipart Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.035811 Loss T 0.034480 Method MME

S real T clipart Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.826059 Loss T 0.052154 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1054, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 1.4092, Accuracy: 13606/18312 F1 (74.3010%)


Val set: Average loss: 1.4544, Accuracy: 262/360 F1 (72.7778%)

best acc test 74.301005  acc val 72.777778 acc labeled target 97.178131
saving model...
S real T clipart Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.518770 Loss T 0.030587 Method MME

S real T clipart Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.618515 Loss T 0.045090 Method MME

S real T clipart Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.426084 Loss T 0.046310 Method MME

S real T clipart Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.415104 Loss T 0.047435 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        0.8888889 0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.5555556 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.7777778 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 20, 93, 48, 32, 29, 84, 25, 24, 108, 82, 95, 19, 112, 42, 6, 59, 2, 76, 9, 73, 4, 80, 5, 72, 92, 90, 89, 88, 79, 86, 85, 74, 75, 83, 77, 78, 81, 87, 0, 101, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 94, 111, 109, 107, 106, 105, 104, 102, 71, 100, 99, 98, 97, 110, 70, 62, 68, 35, 34, 33, 31, 30, 28, 27, 26, 23, 22, 21, 36, 18, 16, 15, 14, 13, 12, 11, 10, 8, 7, 3, 1, 17, 69, 37, 39, 67, 66, 65, 64, 124, 61, 60, 58, 57, 56, 55, 38, 54, 52, 51, 50, 49, 47, 46, 45, 44, 43, 41, 40, 53, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2869, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7131, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.727546 Loss T 0.039551 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1291, Accuracy: 1095/1134 F1 (96.5608%)


Test set: Average loss: 1.5081, Accuracy: 13449/18312 F1 (73.4436%)


Val set: Average loss: 1.6260, Accuracy: 253/360 F1 (70.2778%)

best acc test 74.301005  acc val 70.277778 acc labeled target 96.560847
saving model...
S real T clipart Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.478213 Loss T 0.045762 Method MME

S real T clipart Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.441564 Loss T 0.053209 Method MME

S real T clipart Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.313757 Loss T 0.034488 Method MME

S real T clipart Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.202577 Loss T 0.045100 Method MME

S real T clipart Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.532673 Loss T 0.039480 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0639, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.4098, Accuracy: 13837/18312 F1 (75.5625%)


Val set: Average loss: 1.4751, Accuracy: 262/360 F1 (72.7778%)

best acc test 75.562473  acc val 72.777778 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.268852 Loss T 0.024844 Method MME

S real T clipart Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.277085 Loss T 0.023554 Method MME

S real T clipart Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.227346 Loss T 0.026754 Method MME

S real T clipart Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.535846 Loss T 0.078583 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.7777778 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 82, 106, 37, 94, 46, 103, 81, 80, 34, 110, 62, 12, 124, 118, 77, 89, 68, 88, 87, 86, 85, 84, 69, 76, 70, 71, 72, 73, 74, 75, 78, 83, 79, 93, 92, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 90, 109, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 67, 108, 66, 0, 64, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 65, 29, 31, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 30, 49, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 33, 32, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.229041 Loss T 0.050669 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1559, Accuracy: 1089/1134 F1 (96.0317%)


Test set: Average loss: 1.4619, Accuracy: 13576/18312 F1 (74.1372%)


Val set: Average loss: 1.4375, Accuracy: 263/360 F1 (73.0556%)

best acc test 74.137178  acc val 73.055556 acc labeled target 96.031746
saving model...
S real T clipart Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.355999 Loss T 0.048410 Method MME

S real T clipart Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.324894 Loss T 0.039841 Method MME

S real T clipart Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.261238 Loss T 0.048440 Method MME

S real T clipart Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.338609 Loss T 0.041772 Method MME

S real T clipart Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.392277 Loss T 0.028398 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0905, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.3525, Accuracy: 13995/18312 F1 (76.4253%)


Val set: Average loss: 1.3866, Accuracy: 267/360 F1 (74.1667%)

best acc test 76.425295  acc val 74.166667 acc labeled target 97.266314
saving model...
S real T clipart Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.620887 Loss T 0.043161 Method MME

S real T clipart Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.199236 Loss T 0.030445 Method MME

S real T clipart Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.167042 Loss T 0.034601 Method MME

S real T clipart Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.119704 Loss T 0.045542 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.5555556 1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 103, 63, 34, 93, 90, 32, 31, 100, 86, 25, 23, 52, 39, 80, 41, 1, 67, 122, 11, 9, 5, 118, 59, 78, 92, 89, 88, 72, 73, 74, 85, 84, 75, 83, 76, 81, 77, 79, 87, 82, 0, 95, 123, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 99, 71, 98, 97, 96, 94, 70, 62, 68, 30, 29, 28, 27, 26, 24, 22, 21, 20, 19, 18, 33, 17, 15, 14, 13, 12, 10, 8, 7, 6, 4, 3, 2, 16, 69, 35, 37, 66, 65, 64, 124, 61, 60, 58, 57, 56, 55, 54, 36, 53, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 38, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2869, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7131, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.352734 Loss T 0.053590 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1173, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.4381, Accuracy: 13766/18312 F1 (75.1748%)


Val set: Average loss: 1.4565, Accuracy: 264/360 F1 (73.3333%)

best acc test 76.425295  acc val 73.333333 acc labeled target 97.089947
saving model...
S real T clipart Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.327168 Loss T 0.052867 Method MME

S real T clipart Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.225887 Loss T 0.034016 Method MME

S real T clipart Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.368058 Loss T 0.019343 Method MME

S real T clipart Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.192807 Loss T 0.018596 Method MME

S real T clipart Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.127052 Loss T 0.037743 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1271, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.3458, Accuracy: 14124/18312 F1 (77.1298%)


Val set: Average loss: 1.4215, Accuracy: 262/360 F1 (72.7778%)

best acc test 76.425295  acc val 72.777778 acc labeled target 96.825397
saving model...
S real T clipart Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.395014 Loss T 0.041009 Method MME

S real T clipart Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.402626 Loss T 0.024142 Method MME

S real T clipart Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.335055 Loss T 0.042327 Method MME

S real T clipart Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.481736 Loss T 0.025466 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 0.8888889 0.8888889 1.        1.        1.        0.7777778
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 103, 63, 6, 44, 25, 30, 33, 67, 95, 0, 86, 80, 78, 75, 73, 72, 107, 108, 34, 112, 1, 2, 8, 118, 116, 9, 13, 110, 88, 87, 85, 84, 83, 82, 79, 120, 121, 77, 76, 122, 74, 123, 71, 81, 89, 119, 111, 109, 113, 106, 114, 105, 104, 115, 102, 101, 100, 117, 99, 98, 97, 96, 94, 93, 92, 91, 90, 70, 62, 68, 32, 31, 29, 28, 27, 26, 24, 23, 22, 21, 20, 35, 19, 17, 16, 15, 14, 12, 11, 10, 7, 5, 4, 3, 18, 36, 37, 38, 66, 65, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 43, 42, 41, 40, 39, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.210225 Loss T 0.022633 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1334, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 1.4365, Accuracy: 13871/18312 F1 (75.7481%)


Val set: Average loss: 1.5414, Accuracy: 261/360 F1 (72.5000%)

best acc test 76.425295  acc val 72.500000 acc labeled target 97.001764
saving model...
S real T clipart Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.462734 Loss T 0.031361 Method MME

S real T clipart Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.463032 Loss T 0.025715 Method MME

S real T clipart Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.366633 Loss T 0.020111 Method MME

S real T clipart Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.698200 Loss T 0.029689 Method MME

S real T clipart Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 1.053731 Loss T 0.035113 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1040, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 1.3884, Accuracy: 14159/18312 F1 (77.3209%)


Val set: Average loss: 1.4640, Accuracy: 270/360 F1 (75.0000%)

best acc test 77.320882  acc val 75.000000 acc labeled target 96.913580
saving model...
S real T clipart Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.179708 Loss T 0.035910 Method MME

S real T clipart Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.425075 Loss T 0.030811 Method MME

S real T clipart Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.140289 Loss T 0.039460 Method MME

S real T clipart Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.444066 Loss T 0.042965 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.5555556 0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.7777778 0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.5555556 1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [103, 63, 13, 91, 48, 34, 98, 92, 41, 89, 47, 82, 81, 57, 73, 124, 64, 24, 105, 69, 19, 115, 118, 2, 111, 5, 117, 84, 83, 119, 120, 80, 79, 108, 85, 76, 75, 74, 121, 122, 123, 72, 71, 78, 77, 87, 88, 107, 106, 109, 110, 104, 102, 101, 100, 99, 86, 112, 96, 70, 95, 94, 93, 113, 114, 90, 116, 97, 0, 62, 67, 29, 28, 27, 26, 25, 23, 22, 21, 20, 18, 17, 30, 16, 14, 12, 11, 10, 9, 8, 7, 6, 4, 3, 1, 15, 31, 32, 33, 66, 65, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 46, 45, 44, 43, 42, 40, 39, 38, 37, 36, 35, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2869, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2869, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7131, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7131, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.138804 Loss T 0.040317 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1138, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.4378, Accuracy: 13856/18312 F1 (75.6662%)


Val set: Average loss: 1.6463, Accuracy: 259/360 F1 (71.9444%)

best acc test 77.320882  acc val 71.944444 acc labeled target 97.089947
saving model...
S real T clipart Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.289764 Loss T 0.031807 Method MME

S real T clipart Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.163431 Loss T 0.033520 Method MME

S real T clipart Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.419099 Loss T 0.030142 Method MME

S real T clipart Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.187525 Loss T 0.039005 Method MME

S real T clipart Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.132582 Loss T 0.019572 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1037, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.3559, Accuracy: 14212/18312 F1 (77.6103%)


Val set: Average loss: 1.4151, Accuracy: 272/360 F1 (75.5556%)

best acc test 77.610310  acc val 75.555556 acc labeled target 97.442681
saving model...
S real T clipart Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.329330 Loss T 0.037338 Method MME

S real T clipart Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.483035 Loss T 0.046421 Method MME

S real T clipart Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.396598 Loss T 0.017491 Method MME

S real T clipart Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.294051 Loss T 0.031584 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.6666667 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.5555556 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 0.8888889
 1.        0.7777778 0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 120, 103, 0, 34, 68, 44, 29, 28, 38, 78, 106, 9, 121, 118, 115, 117, 61, 69, 88, 87, 70, 86, 85, 84, 74, 83, 82, 81, 80, 79, 71, 72, 77, 76, 75, 73, 89, 94, 92, 123, 122, 119, 116, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 93, 90, 67, 62, 65, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 27, 30, 31, 32, 64, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 66, 50, 48, 46, 45, 43, 42, 41, 40, 39, 37, 36, 35, 33, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2869, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7131, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.140968 Loss T 0.018099 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1121, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 1.4494, Accuracy: 13847/18312 F1 (75.6171%)


Val set: Average loss: 1.5338, Accuracy: 263/360 F1 (73.0556%)

best acc test 77.610310  acc val 73.055556 acc labeled target 96.913580
saving model...
S real T clipart Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.377075 Loss T 0.041082 Method MME

S real T clipart Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.307363 Loss T 0.027929 Method MME

S real T clipart Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.385693 Loss T 0.025584 Method MME

S real T clipart Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.383976 Loss T 0.025596 Method MME

S real T clipart Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.113429 Loss T 0.024213 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0654, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.4403, Accuracy: 14179/18312 F1 (77.4301%)


Val set: Average loss: 1.5330, Accuracy: 268/360 F1 (74.4444%)

best acc test 77.610310  acc val 74.444444 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.277363 Loss T 0.024326 Method MME

S real T clipart Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.369722 Loss T 0.039273 Method MME

S real T clipart Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.200765 Loss T 0.029165 Method MME

S real T clipart Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.079643 Loss T 0.043593 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 0.8888889 1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889]
Top k classes which perform poorly are:  [63, 91, 103, 125, 75, 44, 34, 105, 24, 23, 107, 113, 67, 3, 118, 5, 2, 9, 6, 116, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 74, 73, 72, 71, 123, 70, 69, 89, 90, 92, 117, 115, 114, 112, 111, 110, 109, 108, 119, 120, 106, 122, 121, 102, 101, 100, 99, 68, 97, 96, 95, 94, 93, 104, 98, 0, 65, 32, 31, 30, 29, 28, 27, 26, 25, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 4, 1, 33, 66, 35, 37, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 43, 42, 41, 40, 39, 38, 36, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.368577 Loss T 0.030245 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1001, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.3946, Accuracy: 14024/18312 F1 (76.5837%)


Val set: Average loss: 1.5346, Accuracy: 263/360 F1 (73.0556%)

best acc test 77.610310  acc val 73.055556 acc labeled target 97.442681
saving model...
S real T clipart Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.240051 Loss T 0.044093 Method MME

S real T clipart Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.251397 Loss T 0.013305 Method MME

S real T clipart Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.218510 Loss T 0.043525 Method MME

S real T clipart Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.038873 Loss T 0.022613 Method MME

S real T clipart Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.374916 Loss T 0.033234 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0883, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 1.4549, Accuracy: 14231/18312 F1 (77.7141%)


Val set: Average loss: 1.5527, Accuracy: 267/360 F1 (74.1667%)

best acc test 77.610310  acc val 74.166667 acc labeled target 97.178131
saving model...
S real T clipart Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.433331 Loss T 0.030810 Method MME

S real T clipart Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.213378 Loss T 0.022943 Method MME

S real T clipart Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.395891 Loss T 0.034727 Method MME

S real T clipart Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.490837 Loss T 0.020915 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.7777778
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [47, 63, 103, 80, 6, 91, 92, 89, 48, 51, 105, 52, 38, 79, 34, 64, 66, 2, 121, 118, 9, 117, 39, 124, 81, 77, 78, 90, 72, 88, 87, 86, 84, 74, 75, 83, 82, 73, 85, 76, 0, 71, 123, 122, 120, 119, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 104, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 70, 62, 68, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 28, 16, 14, 13, 12, 11, 10, 8, 7, 5, 4, 3, 1, 15, 29, 30, 31, 67, 65, 61, 60, 59, 58, 57, 56, 55, 54, 53, 50, 49, 46, 45, 44, 43, 42, 41, 40, 37, 36, 35, 33, 32, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.079984 Loss T 0.031331 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1020, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.4298, Accuracy: 14071/18312 F1 (76.8403%)


Val set: Average loss: 1.5662, Accuracy: 270/360 F1 (75.0000%)

best acc test 77.610310  acc val 75.000000 acc labeled target 97.089947
saving model...
S real T clipart Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.559206 Loss T 0.041373 Method MME

S real T clipart Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.462385 Loss T 0.026384 Method MME

S real T clipart Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.153829 Loss T 0.035342 Method MME

S real T clipart Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.314885 Loss T 0.037830 Method MME

S real T clipart Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.026211 Loss T 0.032374 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0738, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.4247, Accuracy: 14309/18312 F1 (78.1400%)


Val set: Average loss: 1.6393, Accuracy: 268/360 F1 (74.4444%)

best acc test 77.610310  acc val 74.444444 acc labeled target 97.707231
saving model...
S real T clipart Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.242479 Loss T 0.015027 Method MME

S real T clipart Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.161752 Loss T 0.028224 Method MME

S real T clipart Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.243284 Loss T 0.031181 Method MME

S real T clipart Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.074944 Loss T 0.026877 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.6666667 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 91, 63, 9, 106, 37, 28, 44, 14, 43, 88, 74, 60, 69, 121, 3, 35, 116, 89, 87, 90, 86, 85, 0, 83, 82, 81, 79, 78, 77, 76, 75, 73, 72, 71, 70, 84, 80, 95, 93, 123, 122, 120, 119, 118, 117, 115, 114, 113, 112, 111, 110, 92, 109, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 94, 108, 68, 62, 66, 29, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 2, 1, 30, 67, 31, 33, 65, 64, 124, 61, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 42, 41, 40, 39, 38, 36, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.447250 Loss T 0.029689 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1133, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.4913, Accuracy: 14088/18312 F1 (76.9332%)


Val set: Average loss: 1.5498, Accuracy: 268/360 F1 (74.4444%)

best acc test 77.610310  acc val 74.444444 acc labeled target 97.266314
saving model...
S real T clipart Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.200762 Loss T 0.016041 Method MME

S real T clipart Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.161601 Loss T 0.021102 Method MME

S real T clipart Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.188222 Loss T 0.024416 Method MME

S real T clipart Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.468480 Loss T 0.017285 Method MME

S real T clipart Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.061161 Loss T 0.032830 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0727, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.4082, Accuracy: 14332/18312 F1 (78.2656%)


Val set: Average loss: 1.5302, Accuracy: 267/360 F1 (74.1667%)

best acc test 77.610310  acc val 74.166667 acc labeled target 97.707231
saving model...
S real T clipart Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.897060 Loss T 0.032534 Method MME

S real T clipart Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.122186 Loss T 0.026607 Method MME

S real T clipart Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.237705 Loss T 0.030085 Method MME

S real T clipart Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.273475 Loss T 0.019922 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.7777778 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.6666667 1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [91, 63, 103, 74, 98, 124, 47, 20, 96, 9, 86, 46, 29, 122, 53, 100, 44, 24, 90, 89, 87, 88, 84, 85, 0, 81, 80, 79, 78, 77, 76, 75, 73, 72, 71, 70, 83, 82, 95, 93, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 99, 97, 69, 94, 92, 68, 62, 66, 28, 27, 26, 25, 23, 22, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 30, 31, 32, 33, 65, 64, 61, 60, 59, 58, 57, 56, 55, 54, 52, 51, 67, 50, 48, 45, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.091676 Loss T 0.008582 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1054, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 1.4776, Accuracy: 14090/18312 F1 (76.9441%)


Val set: Average loss: 1.5454, Accuracy: 263/360 F1 (73.0556%)

best acc test 77.610310  acc val 73.055556 acc labeled target 97.001764
saving model...
S real T clipart Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.437024 Loss T 0.015901 Method MME

S real T clipart Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.145896 Loss T 0.011310 Method MME

S real T clipart Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.190828 Loss T 0.025704 Method MME

S real T clipart Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.345743 Loss T 0.028514 Method MME

S real T clipart Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.169408 Loss T 0.021052 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0813, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.4942, Accuracy: 14298/18312 F1 (78.0799%)


Val set: Average loss: 1.5625, Accuracy: 270/360 F1 (75.0000%)

best acc test 77.610310  acc val 75.000000 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.163395 Loss T 0.007118 Method MME

S real T clipart Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.454238 Loss T 0.030634 Method MME

S real T clipart Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.287420 Loss T 0.035653 Method MME

S real T clipart Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.200207 Loss T 0.031879 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.5555556 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.5555556 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889]
Top k classes which perform poorly are:  [91, 103, 63, 125, 94, 34, 31, 24, 37, 18, 111, 112, 13, 38, 57, 124, 6, 76, 70, 92, 71, 90, 72, 89, 88, 87, 86, 85, 73, 84, 83, 82, 81, 74, 75, 79, 78, 77, 80, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 69, 93, 68, 0, 66, 29, 28, 27, 26, 25, 23, 22, 21, 20, 19, 17, 16, 15, 14, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 30, 67, 32, 35, 65, 64, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 36, 33, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2869, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2869, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7131, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7131, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.154321 Loss T 0.026523 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1257, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.4516, Accuracy: 14095/18312 F1 (76.9714%)


Val set: Average loss: 1.5086, Accuracy: 274/360 F1 (76.1111%)

best acc test 76.971385  acc val 76.111111 acc labeled target 96.825397
saving model...
S real T clipart Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.201625 Loss T 0.025414 Method MME

S real T clipart Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.430017 Loss T 0.024732 Method MME

S real T clipart Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.491341 Loss T 0.029272 Method MME

S real T clipart Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.476031 Loss T 0.026023 Method MME

S real T clipart Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.329672 Loss T 0.023553 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0796, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.4736, Accuracy: 14349/18312 F1 (78.3585%)


Val set: Average loss: 1.5451, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.971385  acc val 73.888889 acc labeled target 97.530864
saving model...
S real T clipart Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.356767 Loss T 0.016783 Method MME

S real T clipart Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.299839 Loss T 0.039866 Method MME

S real T clipart Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.109282 Loss T 0.032334 Method MME

S real T clipart Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.029465 Loss T 0.031885 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.5555556 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 91, 47, 75, 36, 34, 32, 30, 100, 102, 76, 13, 95, 118, 116, 122, 63, 8, 60, 61, 70, 89, 88, 87, 71, 86, 85, 73, 74, 83, 82, 81, 90, 79, 78, 77, 72, 84, 80, 0, 93, 123, 121, 120, 119, 117, 115, 114, 113, 112, 111, 110, 92, 109, 107, 106, 105, 104, 101, 99, 98, 97, 96, 69, 94, 108, 68, 62, 66, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 28, 29, 31, 33, 65, 64, 124, 59, 58, 57, 56, 55, 54, 53, 52, 51, 67, 50, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2869, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7131, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.313855 Loss T 0.021503 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1145, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.4749, Accuracy: 14132/18312 F1 (77.1734%)


Val set: Average loss: 1.4981, Accuracy: 273/360 F1 (75.8333%)

best acc test 76.971385  acc val 75.833333 acc labeled target 97.089947
saving model...
S real T clipart Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.228116 Loss T 0.020990 Method MME

S real T clipart Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.296625 Loss T 0.022092 Method MME

S real T clipart Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.202705 Loss T 0.016967 Method MME

S real T clipart Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.130806 Loss T 0.029052 Method MME

S real T clipart Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.054811 Loss T 0.022208 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0572, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.4923, Accuracy: 14420/18312 F1 (78.7462%)


Val set: Average loss: 1.4654, Accuracy: 277/360 F1 (76.9444%)

best acc test 78.746177  acc val 76.944444 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.453922 Loss T 0.014128 Method MME

S real T clipart Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.115842 Loss T 0.025354 Method MME

S real T clipart Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.312762 Loss T 0.022132 Method MME

S real T clipart Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.242721 Loss T 0.019876 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 0.7777778 1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 8, 33, 111, 77, 14, 12, 74, 11, 7, 90, 91, 4, 2, 108, 84, 88, 87, 86, 92, 85, 89, 79, 82, 81, 80, 93, 78, 76, 75, 73, 72, 71, 70, 83, 94, 0, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 110, 109, 107, 106, 105, 104, 102, 101, 100, 99, 69, 98, 97, 95, 68, 62, 66, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 10, 9, 6, 5, 3, 1, 34, 35, 36, 37, 65, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 67, 52, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2297,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7703,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.044217 Loss T 0.014700 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0646, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.4543, Accuracy: 14315/18312 F1 (78.1728%)


Val set: Average loss: 1.4826, Accuracy: 273/360 F1 (75.8333%)

best acc test 78.746177  acc val 75.833333 acc labeled target 97.883598
saving model...
S real T clipart Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.192365 Loss T 0.020609 Method MME

S real T clipart Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.099119 Loss T 0.017379 Method MME

S real T clipart Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.030363 Loss T 0.018728 Method MME

S real T clipart Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.347756 Loss T 0.020155 Method MME

S real T clipart Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.623242 Loss T 0.013169 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0707, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.5091, Accuracy: 14424/18312 F1 (78.7680%)


Val set: Average loss: 1.6537, Accuracy: 275/360 F1 (76.3889%)

best acc test 78.746177  acc val 76.388889 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.059090 Loss T 0.021100 Method MME

S real T clipart Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.129632 Loss T 0.013075 Method MME

S real T clipart Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.079580 Loss T 0.021557 Method MME

S real T clipart Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.217035 Loss T 0.013410 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.8888889  1.         1.         1.         1.         1.
 1.         1.         0.8888889  1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.8888889  1.         1.         1.         0.8888889  1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.8888889  0.6666667
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.8888889
 1.         1.         1.         0.44444445 1.         1.
 0.8888889  1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.8888889  1.         1.         0.8888889
 0.8888889  1.         1.         1.         1.         1.
 0.8888889  0.8888889  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.6666667  1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
Top k classes which perform poorly are:  [63, 103, 47, 66, 91, 90, 30, 84, 83, 46, 20, 80, 34, 59, 12, 68, 69, 70, 89, 88, 87, 86, 85, 71, 77, 73, 74, 75, 82, 92, 76, 79, 78, 72, 81, 0, 67, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 94, 62, 64, 27, 26, 25, 24, 23, 22, 21, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 31, 32, 124, 61, 60, 58, 57, 56, 55, 54, 53, 52, 51, 50, 65, 49, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.3206, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.6794, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.226395 Loss T 0.011741 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1019, Accuracy: 1096/1134 F1 (96.6490%)


Test set: Average loss: 1.4315, Accuracy: 14302/18312 F1 (78.1018%)


Val set: Average loss: 1.6235, Accuracy: 267/360 F1 (74.1667%)

best acc test 78.746177  acc val 74.166667 acc labeled target 96.649030
saving model...
S real T clipart Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.075315 Loss T 0.032977 Method MME

S real T clipart Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.112820 Loss T 0.014595 Method MME

S real T clipart Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.066495 Loss T 0.026585 Method MME

S real T clipart Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.294061 Loss T 0.016209 Method MME

S real T clipart Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.207134 Loss T 0.017082 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0676, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.5546, Accuracy: 14413/18312 F1 (78.7080%)


Val set: Average loss: 1.6447, Accuracy: 276/360 F1 (76.6667%)

best acc test 78.746177  acc val 76.666667 acc labeled target 97.707231
saving model...
S real T clipart Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.210442 Loss T 0.017893 Method MME

S real T clipart Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.087668 Loss T 0.011866 Method MME

S real T clipart Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.096431 Loss T 0.017748 Method MME

S real T clipart Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.026833 Loss T 0.022787 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.6666667 0.8888889 1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 94, 68, 41, 29, 28, 99, 86, 46, 106, 82, 92, 67, 122, 4, 116, 73, 5, 78, 89, 88, 69, 87, 70, 71, 72, 85, 84, 83, 74, 75, 76, 80, 79, 77, 81, 0, 93, 123, 121, 120, 119, 118, 117, 115, 114, 113, 112, 111, 90, 110, 108, 107, 105, 104, 103, 102, 101, 100, 98, 97, 95, 109, 96, 62, 65, 30, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 31, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 3, 2, 1, 15, 66, 32, 34, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 33, 51, 49, 48, 45, 44, 43, 42, 40, 39, 38, 37, 36, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.203111 Loss T 0.006401 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1044, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.5017, Accuracy: 14259/18312 F1 (77.8670%)


Val set: Average loss: 1.6067, Accuracy: 266/360 F1 (73.8889%)

best acc test 78.746177  acc val 73.888889 acc labeled target 97.530864
saving model...
S real T clipart Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.391054 Loss T 0.012942 Method MME

S real T clipart Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.145135 Loss T 0.015949 Method MME

S real T clipart Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.276539 Loss T 0.016379 Method MME

S real T clipart Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.350157 Loss T 0.008333 Method MME

S real T clipart Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.072398 Loss T 0.012711 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0902, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.5641, Accuracy: 14443/18312 F1 (78.8718%)


Val set: Average loss: 1.5931, Accuracy: 278/360 F1 (77.2222%)

best acc test 78.871778  acc val 77.222222 acc labeled target 97.442681
saving model...
S real T clipart Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.123645 Loss T 0.016995 Method MME

S real T clipart Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.159483 Loss T 0.011772 Method MME

S real T clipart Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.306232 Loss T 0.027248 Method MME

S real T clipart Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.133390 Loss T 0.017737 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.5555556 1.        1.        1.        0.7777778 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889]
Top k classes which perform poorly are:  [91, 47, 63, 95, 83, 86, 37, 18, 27, 28, 56, 44, 125, 106, 99, 119, 90, 5, 2, 12, 58, 87, 88, 89, 81, 84, 82, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 85, 92, 97, 94, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 98, 70, 96, 93, 69, 0, 67, 31, 30, 29, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 4, 3, 1, 32, 68, 33, 35, 66, 65, 64, 124, 61, 60, 59, 57, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 43, 42, 41, 40, 39, 38, 36, 34, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2869, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7131, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.415710 Loss T 0.015857 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0793, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.5125, Accuracy: 14257/18312 F1 (77.8560%)


Val set: Average loss: 1.6177, Accuracy: 272/360 F1 (75.5556%)

best acc test 78.871778  acc val 75.555556 acc labeled target 97.883598
saving model...
S real T clipart Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.433926 Loss T 0.015068 Method MME

S real T clipart Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.198275 Loss T 0.024690 Method MME

S real T clipart Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.108775 Loss T 0.023471 Method MME

S real T clipart Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.085715 Loss T 0.020073 Method MME

S real T clipart Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.163619 Loss T 0.035657 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0762, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.5327, Accuracy: 14512/18312 F1 (79.2486%)


Val set: Average loss: 1.6548, Accuracy: 275/360 F1 (76.3889%)

best acc test 78.871778  acc val 76.388889 acc labeled target 97.707231
saving model...
S real T clipart Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.317707 Loss T 0.017523 Method MME

S real T clipart Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.028083 Loss T 0.012994 Method MME

S real T clipart Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.065277 Loss T 0.015574 Method MME

S real T clipart Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.305287 Loss T 0.021649 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 0.7777778 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 86, 103, 4, 48, 102, 101, 78, 53, 99, 106, 2, 10, 8, 70, 121, 5, 72, 95, 87, 89, 85, 88, 84, 0, 82, 81, 80, 90, 77, 76, 75, 74, 73, 71, 69, 83, 79, 97, 93, 123, 122, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 100, 98, 68, 96, 94, 92, 67, 62, 65, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 32, 19, 17, 16, 15, 14, 13, 12, 11, 9, 7, 6, 3, 1, 18, 66, 33, 35, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 51, 34, 50, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.310350 Loss T 0.019503 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0745, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.5321, Accuracy: 14324/18312 F1 (78.2219%)


Val set: Average loss: 1.5884, Accuracy: 276/360 F1 (76.6667%)

best acc test 78.871778  acc val 76.666667 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.389284 Loss T 0.022945 Method MME

S real T clipart Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.109761 Loss T 0.019771 Method MME

S real T clipart Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.261391 Loss T 0.013295 Method MME

S real T clipart Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.243885 Loss T 0.025666 Method MME

S real T clipart Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.351142 Loss T 0.019512 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0608, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.5922, Accuracy: 14450/18312 F1 (78.9100%)


Val set: Average loss: 1.6668, Accuracy: 277/360 F1 (76.9444%)

best acc test 78.871778  acc val 76.944444 acc labeled target 98.236332
saving model...
S real T clipart Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.091470 Loss T 0.019915 Method MME

S real T clipart Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.175413 Loss T 0.021328 Method MME

S real T clipart Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.713682 Loss T 0.014765 Method MME

S real T clipart Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.066511 Loss T 0.030348 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 103, 91, 66, 28, 23, 111, 13, 116, 37, 118, 60, 63, 8, 72, 90, 89, 88, 87, 86, 85, 68, 84, 83, 70, 82, 81, 80, 79, 77, 76, 75, 71, 74, 73, 69, 78, 0, 93, 123, 122, 121, 120, 119, 117, 115, 114, 113, 112, 110, 109, 92, 108, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 67, 94, 107, 95, 62, 64, 29, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 30, 31, 32, 33, 124, 61, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 65, 49, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 34, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.139028 Loss T 0.027542 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0700, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.5626, Accuracy: 14323/18312 F1 (78.2165%)


Val set: Average loss: 1.6101, Accuracy: 272/360 F1 (75.5556%)

best acc test 78.871778  acc val 75.555556 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.012631 Loss T 0.015258 Method MME

S real T clipart Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.227096 Loss T 0.023188 Method MME

S real T clipart Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.415757 Loss T 0.016512 Method MME

S real T clipart Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.158222 Loss T 0.013276 Method MME

S real T clipart Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.267475 Loss T 0.009274 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0748, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.6250, Accuracy: 14476/18312 F1 (79.0520%)


Val set: Average loss: 1.7179, Accuracy: 271/360 F1 (75.2778%)

best acc test 78.871778  acc val 75.277778 acc labeled target 97.619048
saving model...
S real T clipart Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.350974 Loss T 0.005445 Method MME

S real T clipart Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.247823 Loss T 0.014446 Method MME

S real T clipart Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.069899 Loss T 0.014049 Method MME

S real T clipart Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.173151 Loss T 0.019853 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.7777778 1.        1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 31, 44, 82, 38, 27, 48, 81, 106, 62, 122, 9, 120, 61, 119, 73, 74, 69, 89, 88, 87, 86, 85, 83, 70, 71, 72, 90, 79, 78, 77, 76, 75, 84, 80, 94, 93, 123, 121, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 92, 108, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 68, 107, 67, 0, 65, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 30, 32, 64, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 66, 50, 46, 45, 43, 42, 41, 40, 39, 37, 36, 35, 34, 33, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.105085 Loss T 0.021163 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1151, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 1.5627, Accuracy: 14377/18312 F1 (78.5114%)


Val set: Average loss: 1.7225, Accuracy: 270/360 F1 (75.0000%)

best acc test 78.871778  acc val 75.000000 acc labeled target 97.178131
saving model...
S real T clipart Train Ep: 28100 lr0.0036669608075000928 	 Loss Classification: 0.217721 Loss T 0.014557 Method MME

S real T clipart Train Ep: 28200 lr0.00365975891867815 	 Loss Classification: 0.194389 Loss T 0.029266 Method MME

S real T clipart Train Ep: 28300 lr0.003652589947415138 	 Loss Classification: 0.026060 Loss T 0.020039 Method MME

S real T clipart Train Ep: 28400 lr0.0036454536578964408 	 Loss Classification: 0.226329 Loss T 0.029715 Method MME

S real T clipart Train Ep: 28500 lr0.0036383498166050877 	 Loss Classification: 0.259347 Loss T 0.024671 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0773, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.6706, Accuracy: 14454/18312 F1 (78.9318%)


Val set: Average loss: 1.8280, Accuracy: 272/360 F1 (75.5556%)

best acc test 78.871778  acc val 75.555556 acc labeled target 97.883598
saving model...
S real T clipart Train Ep: 28600 lr0.0036312781922934662 	 Loss Classification: 0.260953 Loss T 0.014263 Method MME

S real T clipart Train Ep: 28700 lr0.003624238555955462 	 Loss Classification: 0.136144 Loss T 0.019650 Method MME

S real T clipart Train Ep: 28800 lr0.003617230680799007 	 Loss Classification: 0.158297 Loss T 0.017485 Method MME

S real T clipart Train Ep: 28900 lr0.0036102543422190363 	 Loss Classification: 0.193095 Loss T 0.018771 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.7777778 0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.6666667 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [103, 47, 91, 96, 97, 24, 105, 106, 48, 12, 11, 92, 74, 71, 124, 57, 61, 8, 4, 81, 90, 89, 88, 70, 87, 86, 85, 79, 84, 75, 76, 77, 78, 72, 73, 82, 83, 80, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 104, 102, 101, 100, 99, 98, 69, 95, 93, 68, 62, 66, 30, 29, 28, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 10, 9, 7, 6, 5, 3, 2, 1, 31, 32, 33, 34, 65, 64, 63, 60, 59, 58, 56, 55, 54, 53, 52, 51, 67, 50, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 29000 lr0.003603309317770844 	 Loss Classification: 0.059019 Loss T 0.013742 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1029, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 1.5732, Accuracy: 14354/18312 F1 (78.3858%)


Val set: Average loss: 1.6316, Accuracy: 280/360 F1 (77.7778%)

best acc test 78.385758  acc val 77.777778 acc labeled target 97.178131
saving model...
S real T clipart Train Ep: 29100 lr0.0035963953871438275 	 Loss Classification: 0.435375 Loss T 0.021071 Method MME

S real T clipart Train Ep: 29200 lr0.0035895123321356215 	 Loss Classification: 0.310479 Loss T 0.003997 Method MME

S real T clipart Train Ep: 29300 lr0.003582659936626608 	 Loss Classification: 0.313349 Loss T 0.012252 Method MME

S real T clipart Train Ep: 29400 lr0.0035758379865547998 	 Loss Classification: 0.231763 Loss T 0.014314 Method MME

S real T clipart Train Ep: 29500 lr0.0035690462698910875 	 Loss Classification: 0.230820 Loss T 0.007632 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0756, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.6315, Accuracy: 14499/18312 F1 (79.1776%)


Val set: Average loss: 1.6927, Accuracy: 280/360 F1 (77.7778%)

best acc test 79.177588  acc val 77.777778 acc labeled target 98.059965
saving model...
S real T clipart Train Ep: 29600 lr0.0035622845766148485 	 Loss Classification: 0.215537 Loss T 0.018047 Method MME

S real T clipart Train Ep: 29700 lr0.0035555526986899093 	 Loss Classification: 0.249490 Loss T 0.016644 Method MME

S real T clipart Train Ep: 29800 lr0.0035488504300408524 	 Loss Classification: 0.054468 Loss T 0.011167 Method MME

S real T clipart Train Ep: 29900 lr0.0035421775665296674 	 Loss Classification: 0.167915 Loss T 0.019289 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 63, 103, 20, 45, 44, 75, 106, 73, 94, 88, 6, 119, 70, 67, 85, 84, 83, 89, 87, 86, 81, 90, 80, 79, 78, 77, 76, 74, 72, 71, 69, 68, 82, 91, 0, 93, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 92, 110, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 66, 62, 64, 28, 27, 26, 25, 24, 23, 22, 21, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 14, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 30000 lr0.003535533905932738 	 Loss Classification: 0.054205 Loss T 0.011170 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0951, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.5585, Accuracy: 14367/18312 F1 (78.4567%)


Val set: Average loss: 1.6291, Accuracy: 269/360 F1 (74.7222%)

best acc test 79.177588  acc val 74.722222 acc labeled target 97.619048
saving model...
S real T clipart Train Ep: 30100 lr0.0035289192479181558 	 Loss Classification: 0.059686 Loss T 0.014955 Method MME

S real T clipart Train Ep: 30200 lr0.003522333394023364 	 Loss Classification: 0.344820 Loss T 0.015953 Method MME

S real T clipart Train Ep: 30300 lr0.0035157761476331158 	 Loss Classification: 0.117408 Loss T 0.017867 Method MME

S real T clipart Train Ep: 30400 lr0.003509247313957748 	 Loss Classification: 0.302385 Loss T 0.006372 Method MME

S real T clipart Train Ep: 30500 lr0.003502746700011762 	 Loss Classification: 0.026164 Loss T 0.010284 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0635, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.7026, Accuracy: 14465/18312 F1 (78.9919%)


Val set: Average loss: 1.8716, Accuracy: 275/360 F1 (76.3889%)

best acc test 79.177588  acc val 76.388889 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 30600 lr0.003496274114592713 	 Loss Classification: 0.258659 Loss T 0.013939 Method MME

S real T clipart Train Ep: 30700 lr0.0034898293682603908 	 Loss Classification: 0.152275 Loss T 0.023088 Method MME

S real T clipart Train Ep: 30800 lr0.0034834122733162975 	 Loss Classification: 0.022663 Loss T 0.007514 Method MME

S real T clipart Train Ep: 30900 lr0.0034770226437834152 	 Loss Classification: 0.092360 Loss T 0.014159 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        0.7777778 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.7777778 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [91, 103, 63, 12, 67, 95, 69, 29, 47, 57, 13, 39, 10, 9, 123, 2, 6, 90, 70, 89, 88, 87, 71, 86, 72, 85, 84, 83, 82, 81, 80, 92, 78, 77, 73, 76, 75, 74, 79, 0, 94, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 97, 96, 93, 98, 62, 66, 32, 31, 30, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 11, 8, 7, 5, 4, 3, 1, 33, 68, 34, 36, 65, 64, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 38, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 31000 lr0.003470660295386255 	 Loss Classification: 0.247932 Loss T 0.008846 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0916, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.5112, Accuracy: 14377/18312 F1 (78.5114%)


Val set: Average loss: 1.5505, Accuracy: 272/360 F1 (75.5556%)

best acc test 79.177588  acc val 75.555556 acc labeled target 97.089947
saving model...
S real T clipart Train Ep: 31100 lr0.0034643250455311855 	 Loss Classification: 0.054201 Loss T 0.010696 Method MME

S real T clipart Train Ep: 31200 lr0.0034580167132870383 	 Loss Classification: 0.180151 Loss T 0.010176 Method MME

S real T clipart Train Ep: 31300 lr0.00345173511936598 	 Loss Classification: 0.020192 Loss T 0.018611 Method MME

S real T clipart Train Ep: 31400 lr0.0034454800861046533 	 Loss Classification: 0.121121 Loss T 0.014343 Method MME

S real T clipart Train Ep: 31500 lr0.003439251437445577 	 Loss Classification: 0.157781 Loss T 0.021951 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0918, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.6895, Accuracy: 14504/18312 F1 (79.2049%)


Val set: Average loss: 1.8185, Accuracy: 272/360 F1 (75.5556%)

best acc test 79.177588  acc val 75.555556 acc labeled target 97.530864
saving model...
S real T clipart Train Ep: 31600 lr0.0034330489989188046 	 Loss Classification: 0.109931 Loss T 0.023363 Method MME

S real T clipart Train Ep: 31700 lr0.0034268725976238346 	 Loss Classification: 0.124623 Loss T 0.013826 Method MME

S real T clipart Train Ep: 31800 lr0.003420722062211772 	 Loss Classification: 0.289884 Loss T 0.014940 Method MME

S real T clipart Train Ep: 31900 lr0.0034145972228677326 	 Loss Classification: 0.103425 Loss T 0.021992 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.5555556 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.5555556 0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 103, 48, 67, 37, 36, 94, 29, 47, 24, 106, 112, 14, 108, 61, 5, 8, 92, 76, 70, 71, 72, 90, 89, 88, 87, 86, 81, 79, 78, 73, 80, 74, 84, 83, 75, 82, 85, 77, 0, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 93, 111, 109, 107, 105, 104, 102, 101, 100, 99, 98, 97, 69, 110, 96, 62, 66, 30, 28, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 7, 6, 4, 3, 2, 1, 31, 68, 32, 34, 65, 64, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 46, 45, 44, 43, 42, 41, 40, 39, 38, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2869, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2869, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7131, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7131, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 32000 lr0.0034084979112934868 	 Loss Classification: 0.351340 Loss T 0.006594 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0924, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 1.5784, Accuracy: 14399/18312 F1 (78.6315%)


Val set: Average loss: 1.6966, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.177588  acc val 75.833333 acc labeled target 97.001764
saving model...
S real T clipart Train Ep: 32100 lr0.003402423960690348 	 Loss Classification: 0.278710 Loss T 0.011294 Method MME

S real T clipart Train Ep: 32200 lr0.0033963752057422827 	 Loss Classification: 0.091832 Loss T 0.009358 Method MME

S real T clipart Train Ep: 32300 lr0.003390351482599261 	 Loss Classification: 0.062983 Loss T 0.016081 Method MME

S real T clipart Train Ep: 32400 lr0.003384352628860824 	 Loss Classification: 0.062013 Loss T 0.016587 Method MME

S real T clipart Train Ep: 32500 lr0.003378378483559883 	 Loss Classification: 0.054061 Loss T 0.015230 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0753, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.7227, Accuracy: 14505/18312 F1 (79.2104%)


Val set: Average loss: 1.8735, Accuracy: 272/360 F1 (75.5556%)

best acc test 79.177588  acc val 75.555556 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 32600 lr0.0033724288871467283 	 Loss Classification: 0.228033 Loss T 0.010096 Method MME

S real T clipart Train Ep: 32700 lr0.003366503681473259 	 Loss Classification: 0.009122 Loss T 0.007122 Method MME

S real T clipart Train Ep: 32800 lr0.0033606027097774233 	 Loss Classification: 0.101060 Loss T 0.004738 Method MME

S real T clipart Train Ep: 32900 lr0.003354725816667868 	 Loss Classification: 0.221241 Loss T 0.007790 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.6666667 0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 103, 47, 80, 31, 86, 48, 49, 107, 92, 13, 58, 93, 118, 2, 72, 8, 9, 5, 81, 70, 90, 89, 88, 76, 87, 71, 79, 85, 77, 75, 73, 74, 78, 83, 82, 84, 0, 97, 95, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 106, 105, 104, 102, 101, 100, 99, 98, 69, 96, 94, 68, 62, 66, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 7, 6, 4, 3, 1, 32, 33, 34, 35, 65, 64, 63, 124, 61, 60, 59, 57, 56, 55, 54, 53, 67, 52, 50, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 33000 lr0.00334887284810879 	 Loss Classification: 0.044675 Loss T 0.009333 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1073, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.5991, Accuracy: 14347/18312 F1 (78.3475%)


Val set: Average loss: 1.7209, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.177588  acc val 75.277778 acc labeled target 97.530864
saving model...
S real T clipart Train Ep: 33100 lr0.003343043651404997 	 Loss Classification: 0.271347 Loss T 0.017249 Method MME

S real T clipart Train Ep: 33200 lr0.0033372380751871583 	 Loss Classification: 0.181832 Loss T 0.011178 Method MME

S real T clipart Train Ep: 33300 lr0.0033314559693972583 	 Loss Classification: 0.185184 Loss T 0.011473 Method MME

S real T clipart Train Ep: 33400 lr0.0033256971852742394 	 Loss Classification: 0.178557 Loss T 0.017710 Method MME

S real T clipart Train Ep: 33500 lr0.0033199615753398367 	 Loss Classification: 0.070620 Loss T 0.013611 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0696, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.7621, Accuracy: 14511/18312 F1 (79.2431%)


Val set: Average loss: 1.8527, Accuracy: 277/360 F1 (76.9444%)

best acc test 79.177588  acc val 76.944444 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 33600 lr0.0033142489933845978 	 Loss Classification: 0.108586 Loss T 0.004717 Method MME

S real T clipart Train Ep: 33700 lr0.0033085592944540883 	 Loss Classification: 0.051480 Loss T 0.013974 Method MME

S real T clipart Train Ep: 33800 lr0.003302892334835276 	 Loss Classification: 0.089061 Loss T 0.007361 Method MME

S real T clipart Train Ep: 33900 lr0.003297247972043097 	 Loss Classification: 0.161148 Loss T 0.013997 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889]
Top k classes which perform poorly are:  [63, 91, 103, 125, 71, 49, 41, 37, 67, 13, 12, 95, 121, 8, 115, 120, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 122, 70, 69, 68, 123, 88, 89, 90, 119, 116, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 117, 94, 93, 92, 118, 114, 66, 0, 64, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 30, 17, 15, 14, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 16, 65, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 32, 50, 47, 46, 45, 44, 43, 42, 40, 39, 38, 36, 35, 34, 48, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 34000 lr0.0032916260648071937 	 Loss Classification: 0.058357 Loss T 0.014984 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1197, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.5928, Accuracy: 14368/18312 F1 (78.4622%)


Val set: Average loss: 1.7325, Accuracy: 270/360 F1 (75.0000%)

best acc test 79.177588  acc val 75.000000 acc labeled target 97.442681
saving model...
S real T clipart Train Ep: 34100 lr0.0032860264730588296 	 Loss Classification: 0.058807 Loss T 0.005238 Method MME

S real T clipart Train Ep: 34200 lr0.003280449057917969 	 Loss Classification: 0.167810 Loss T 0.006730 Method MME

S real T clipart Train Ep: 34300 lr0.0032748936816805302 	 Loss Classification: 0.129030 Loss T 0.013755 Method MME

S real T clipart Train Ep: 34400 lr0.0032693602078058027 	 Loss Classification: 0.125841 Loss T 0.017802 Method MME

S real T clipart Train Ep: 34500 lr0.0032638485009040203 	 Loss Classification: 0.158688 Loss T 0.010582 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0712, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.7702, Accuracy: 14500/18312 F1 (79.1831%)


Val set: Average loss: 1.9025, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.177588  acc val 75.277778 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 34600 lr0.0032583584267241073 	 Loss Classification: 0.523500 Loss T 0.015943 Method MME

S real T clipart Train Ep: 34700 lr0.0032528898521415684 	 Loss Classification: 0.127820 Loss T 0.008258 Method MME

S real T clipart Train Ep: 34800 lr0.0032474426451465444 	 Loss Classification: 0.050568 Loss T 0.010524 Method MME

S real T clipart Train Ep: 34900 lr0.0032420166748320153 	 Loss Classification: 0.116008 Loss T 0.013505 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.7777778 1.        1.
 0.8888889 1.        0.7777778 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 4, 9, 38, 86, 13, 29, 116, 43, 113, 7, 66, 103, 48, 46, 87, 89, 90, 88, 85, 0, 83, 82, 81, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 84, 80, 96, 93, 123, 122, 121, 120, 119, 118, 117, 115, 114, 112, 111, 110, 92, 109, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 95, 94, 108, 69, 62, 67, 30, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 8, 6, 5, 3, 2, 1, 31, 68, 32, 34, 65, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 45, 44, 42, 41, 40, 39, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 35000 lr0.0032366118113821563 	 Loss Classification: 0.056343 Loss T 0.020222 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0960, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.6272, Accuracy: 14407/18312 F1 (78.6752%)


Val set: Average loss: 1.7831, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.177588  acc val 75.833333 acc labeled target 97.266314
saving model...
S real T clipart Train Ep: 35100 lr0.0032312279260608436 	 Loss Classification: 0.185753 Loss T 0.012606 Method MME

S real T clipart Train Ep: 35200 lr0.0032258648912003012 	 Loss Classification: 0.085532 Loss T 0.018941 Method MME

S real T clipart Train Ep: 35300 lr0.003220522580189901 	 Loss Classification: 0.263940 Loss T 0.020421 Method MME

S real T clipart Train Ep: 35400 lr0.0032152008674650925 	 Loss Classification: 0.061427 Loss T 0.009887 Method MME

S real T clipart Train Ep: 35500 lr0.0032098996284964853 	 Loss Classification: 0.104067 Loss T 0.013120 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0884, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 1.8154, Accuracy: 14492/18312 F1 (79.1394%)


Val set: Average loss: 1.8712, Accuracy: 274/360 F1 (76.1111%)

best acc test 79.177588  acc val 76.111111 acc labeled target 97.354497
saving model...
S real T clipart Train Ep: 35600 lr0.0032046187397790603 	 Loss Classification: 0.219706 Loss T 0.008333 Method MME

S real T clipart Train Ep: 35700 lr0.0031993580788215194 	 Loss Classification: 0.033791 Loss T 0.011792 Method MME

S real T clipart Train Ep: 35800 lr0.0031941175241357693 	 Loss Classification: 0.009345 Loss T 0.010436 Method MME

S real T clipart Train Ep: 35900 lr0.0031888969552265386 	 Loss Classification: 0.173225 Loss T 0.019461 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.7777778 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 63, 47, 29, 106, 44, 67, 76, 17, 16, 27, 13, 34, 116, 10, 8, 6, 95, 120, 121, 94, 66, 114, 89, 87, 86, 85, 84, 88, 78, 82, 81, 80, 79, 77, 75, 74, 73, 72, 71, 83, 90, 0, 92, 123, 122, 119, 118, 117, 115, 113, 112, 111, 110, 109, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 93, 91, 70, 62, 68, 32, 31, 30, 28, 26, 25, 24, 23, 22, 21, 20, 33, 19, 15, 14, 12, 11, 9, 7, 5, 4, 3, 2, 1, 18, 35, 36, 37, 65, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 43, 42, 41, 40, 39, 38, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 36000 lr0.00318369625258112 	 Loss Classification: 0.025165 Loss T 0.009126 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0668, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.6540, Accuracy: 14402/18312 F1 (78.6479%)


Val set: Average loss: 1.7661, Accuracy: 269/360 F1 (74.7222%)

best acc test 79.177588  acc val 74.722222 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 36100 lr0.0031785152976592465 	 Loss Classification: 0.046383 Loss T 0.008593 Method MME

S real T clipart Train Ep: 36200 lr0.0031733539728830895 	 Loss Classification: 0.224879 Loss T 0.006358 Method MME

S real T clipart Train Ep: 36300 lr0.003168212161627382 	 Loss Classification: 0.020693 Loss T 0.009977 Method MME

S real T clipart Train Ep: 36400 lr0.0031630897482096652 	 Loss Classification: 0.059233 Loss T 0.012117 Method MME

S real T clipart Train Ep: 36500 lr0.0031579866178806544 	 Loss Classification: 0.010772 Loss T 0.011763 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0660, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.7795, Accuracy: 14514/18312 F1 (79.2595%)


Val set: Average loss: 1.8451, Accuracy: 272/360 F1 (75.5556%)

best acc test 79.177588  acc val 75.555556 acc labeled target 97.883598
saving model...
S real T clipart Train Ep: 36600 lr0.003152902656814724 	 Loss Classification: 0.012023 Loss T 0.010905 Method MME

S real T clipart Train Ep: 36700 lr0.003147837752100511 	 Loss Classification: 0.135279 Loss T 0.005148 Method MME

S real T clipart Train Ep: 36800 lr0.003142791791731634 	 Loss Classification: 0.059459 Loss T 0.005371 Method MME

S real T clipart Train Ep: 36900 lr0.0031377646645975228 	 Loss Classification: 0.044318 Loss T 0.009853 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.5555556 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 39, 47, 110, 46, 57, 14, 13, 12, 30, 118, 61, 5, 3, 96, 87, 88, 86, 89, 90, 85, 84, 0, 82, 81, 80, 78, 77, 76, 75, 74, 73, 72, 71, 83, 79, 97, 93, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 92, 109, 107, 106, 105, 104, 102, 101, 100, 99, 98, 70, 95, 94, 108, 69, 62, 67, 31, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 11, 10, 9, 8, 7, 6, 4, 2, 1, 32, 68, 33, 35, 66, 65, 64, 124, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 45, 44, 43, 42, 41, 40, 38, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2869, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7131, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 37000 lr0.003132756260474365 	 Loss Classification: 0.134278 Loss T 0.013846 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1017, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.6210, Accuracy: 14399/18312 F1 (78.6315%)


Val set: Average loss: 1.7676, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.177588  acc val 75.833333 acc labeled target 97.530864
saving model...
S real T clipart Train Ep: 37100 lr0.0031277664700161607 	 Loss Classification: 0.194513 Loss T 0.007504 Method MME

S real T clipart Train Ep: 37200 lr0.003122795184745882 	 Loss Classification: 0.071795 Loss T 0.005613 Method MME

S real T clipart Train Ep: 37300 lr0.003117842297046751 	 Loss Classification: 0.134704 Loss T 0.010512 Method MME

S real T clipart Train Ep: 37400 lr0.0031129077001536103 	 Loss Classification: 0.213013 Loss T 0.009752 Method MME

S real T clipart Train Ep: 37500 lr0.00310799128814441 	 Loss Classification: 0.225380 Loss T 0.012136 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0646, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.8176, Accuracy: 14514/18312 F1 (79.2595%)


Val set: Average loss: 1.9532, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.177588  acc val 75.277778 acc labeled target 98.236332
saving model...
S real T clipart Train Ep: 37600 lr0.0031030929559317877 	 Loss Classification: 0.028019 Loss T 0.022093 Method MME

S real T clipart Train Ep: 37700 lr0.003098212599254758 	 Loss Classification: 0.109073 Loss T 0.011810 Method MME

S real T clipart Train Ep: 37800 lr0.003093350114670496 	 Loss Classification: 0.049634 Loss T 0.006428 Method MME

S real T clipart Train Ep: 37900 lr0.003088505399546223 	 Loss Classification: 0.076772 Loss T 0.021639 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 63, 103, 107, 34, 112, 21, 9, 62, 58, 72, 119, 31, 57, 88, 86, 85, 84, 83, 89, 82, 90, 87, 79, 80, 78, 77, 76, 75, 74, 73, 71, 70, 69, 81, 91, 95, 93, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 111, 110, 92, 109, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 68, 94, 108, 67, 0, 65, 28, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 14, 66, 30, 33, 64, 124, 61, 60, 59, 56, 55, 54, 53, 52, 51, 50, 32, 49, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 38000 lr0.0030836783520511884 	 Loss Classification: 0.178984 Loss T 0.013011 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1159, Accuracy: 1095/1134 F1 (96.5608%)


Test set: Average loss: 1.6007, Accuracy: 14412/18312 F1 (78.7025%)


Val set: Average loss: 1.6743, Accuracy: 276/360 F1 (76.6667%)

best acc test 79.177588  acc val 76.666667 acc labeled target 96.560847
saving model...
S real T clipart Train Ep: 38100 lr0.0030788688711487463 	 Loss Classification: 0.086057 Loss T 0.004557 Method MME

S real T clipart Train Ep: 38200 lr0.0030740768565885295 	 Loss Classification: 0.022444 Loss T 0.011999 Method MME

S real T clipart Train Ep: 38300 lr0.0030693022088987133 	 Loss Classification: 0.131111 Loss T 0.008913 Method MME

S real T clipart Train Ep: 38400 lr0.0030645448293783735 	 Loss Classification: 0.031698 Loss T 0.010306 Method MME

S real T clipart Train Ep: 38500 lr0.0030598046200899344 	 Loss Classification: 0.190980 Loss T 0.003109 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0468, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.8160, Accuracy: 14526/18312 F1 (79.3250%)


Val set: Average loss: 1.9238, Accuracy: 274/360 F1 (76.1111%)

best acc test 79.177588  acc val 76.111111 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 38600 lr0.0030550814838517073 	 Loss Classification: 0.026670 Loss T 0.020520 Method MME

S real T clipart Train Ep: 38700 lr0.0030503753242305132 	 Loss Classification: 0.161215 Loss T 0.001625 Method MME

S real T clipart Train Ep: 38800 lr0.003045686045534399 	 Loss Classification: 0.083574 Loss T 0.003855 Method MME

S real T clipart Train Ep: 38900 lr0.003041013552805431 	 Loss Classification: 0.222717 Loss T 0.007928 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [91, 103, 47, 9, 21, 15, 46, 107, 72, 90, 124, 37, 41, 87, 88, 86, 85, 84, 89, 0, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 71, 70, 69, 83, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 68, 93, 67, 62, 65, 29, 28, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 30, 16, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 14, 66, 31, 33, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 32, 51, 49, 48, 45, 44, 43, 42, 40, 39, 38, 36, 35, 34, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 39000 lr0.003036357751812582 	 Loss Classification: 0.034140 Loss T 0.006544 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0820, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.6217, Accuracy: 14449/18312 F1 (78.9045%)


Val set: Average loss: 1.8550, Accuracy: 269/360 F1 (74.7222%)

best acc test 79.177588  acc val 74.722222 acc labeled target 97.619048
saving model...
S real T clipart Train Ep: 39100 lr0.0030317185490446956 	 Loss Classification: 0.032542 Loss T 0.013479 Method MME

S real T clipart Train Ep: 39200 lr0.0030270958517035324 	 Loss Classification: 0.149415 Loss T 0.009654 Method MME

S real T clipart Train Ep: 39300 lr0.003022489567696903 	 Loss Classification: 0.017756 Loss T 0.012134 Method MME

S real T clipart Train Ep: 39400 lr0.0030178996056318755 	 Loss Classification: 0.410410 Loss T 0.008220 Method MME

S real T clipart Train Ep: 39500 lr0.0030133258748080622 	 Loss Classification: 0.038091 Loss T 0.006769 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0708, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.8265, Accuracy: 14520/18312 F1 (79.2923%)


Val set: Average loss: 1.9878, Accuracy: 272/360 F1 (75.5556%)

best acc test 79.177588  acc val 75.555556 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 39600 lr0.0030087682852109887 	 Loss Classification: 0.179710 Loss T 0.002788 Method MME

S real T clipart Train Ep: 39700 lr0.0030042267475055367 	 Loss Classification: 0.038490 Loss T 0.007109 Method MME

S real T clipart Train Ep: 39800 lr0.0029997011730294593 	 Loss Classification: 0.046780 Loss T 0.010010 Method MME

S real T clipart Train Ep: 39900 lr0.0029951914737869757 	 Loss Classification: 0.060008 Loss T 0.003919 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        0.7777778 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 47, 93, 29, 21, 18, 48, 43, 61, 8, 119, 6, 3, 96, 9, 23, 84, 89, 88, 87, 90, 86, 85, 0, 82, 92, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 83, 81, 98, 95, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 70, 97, 109, 69, 62, 67, 32, 31, 30, 28, 27, 26, 25, 24, 22, 20, 19, 33, 17, 15, 14, 13, 12, 11, 10, 7, 5, 4, 2, 1, 16, 34, 35, 36, 66, 65, 64, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 46, 45, 44, 42, 41, 40, 39, 38, 37, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 40000 lr0.0029906975624424408 	 Loss Classification: 0.350947 Loss T 0.008325 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0813, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.6514, Accuracy: 14443/18312 F1 (78.8718%)


Val set: Average loss: 1.7315, Accuracy: 273/360 F1 (75.8333%)

