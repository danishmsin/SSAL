Dataset multi Source painting Target real Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  31502
Unlabelled Target Dataset Size:  69980
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  69980 Source:  31502
Unlabeled Target Data Batches: 1457
S painting T real Train Ep: 0 lr0.01 	 Loss Classification: 5.009888 Loss T 0.472154 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9561, Accuracy: 10/1134 F1 (0.8818%)


Test set: Average loss: 4.9395, Accuracy: 577/69960 F1 (0.8248%)


Val set: Average loss: 4.9652, Accuracy: 2/360 F1 (0.5556%)

best acc test 0.824757  acc val 0.555556 acc labeled target 0.881834
saving model...
S painting T real Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.136786 Loss T 0.271044 Method MME

S painting T real Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.002972 Loss T 0.182601 Method MME

S painting T real Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.161093 Loss T 0.145603 Method MME

S painting T real Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.203149 Loss T 0.110673 Method MME

S painting T real Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.234819 Loss T 0.131846 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1329, Accuracy: 571/1134 F1 (50.3527%)


Test set: Average loss: 1.6510, Accuracy: 42716/69960 F1 (61.0577%)


Val set: Average loss: 1.8571, Accuracy: 199/360 F1 (55.2778%)

best acc test 61.057747  acc val 55.277778 acc labeled target 50.352734
saving model...
S painting T real Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.306820 Loss T 0.139034 Method MME

S painting T real Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.600633 Loss T 0.097626 Method MME

S painting T real Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.863876 Loss T 0.119485 Method MME

S painting T real Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.126883 Loss T 0.119197 Method MME

S painting T real Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.223818 Loss T 0.102650 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8156, Accuracy: 658/1134 F1 (58.0247%)


Test set: Average loss: 1.4550, Accuracy: 46125/69960 F1 (65.9305%)


Val set: Average loss: 1.5563, Accuracy: 229/360 F1 (63.6111%)

best acc test 65.930532  acc val 63.611111 acc labeled target 58.024691
saving model...
S painting T real Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.812530 Loss T 0.098212 Method MME

S painting T real Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.814550 Loss T 0.115283 Method MME

S painting T real Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.441376 Loss T 0.098384 Method MME

S painting T real Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.721509 Loss T 0.092551 Method MME

S painting T real Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.046106 Loss T 0.112335 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8205, Accuracy: 670/1134 F1 (59.0829%)


Test set: Average loss: 1.4324, Accuracy: 47029/69960 F1 (67.2227%)


Val set: Average loss: 1.5832, Accuracy: 233/360 F1 (64.7222%)

best acc test 67.222699  acc val 64.722222 acc labeled target 59.082892
saving model...
S painting T real Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.130325 Loss T 0.090210 Method MME

S painting T real Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.050068 Loss T 0.085085 Method MME

S painting T real Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.317847 Loss T 0.090263 Method MME

S painting T real Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 1.289189 Loss T 0.079706 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 1.         0.7777778  0.33333334 1.
 0.5555556  1.         0.5555556  0.7777778  0.6666667  0.6666667
 0.         0.22222222 0.33333334 0.5555556  0.11111111 1.
 0.         0.7777778  0.33333334 0.11111111 1.         0.22222222
 0.         0.6666667  0.6666667  0.6666667  0.7777778  0.44444445
 0.5555556  0.44444445 1.         0.         0.22222222 0.6666667
 0.         0.8888889  0.22222222 0.8888889  0.6666667  1.
 0.33333334 0.6666667  1.         0.7777778  0.6666667  0.8888889
 0.33333334 1.         0.11111111 0.22222222 0.33333334 0.44444445
 0.11111111 0.6666667  1.         0.7777778  0.33333334 0.33333334
 1.         0.33333334 0.8888889  0.33333334 1.         0.7777778
 0.         0.8888889  0.8888889  1.         0.8888889  0.6666667
 1.         0.6666667  0.22222222 0.8888889  0.6666667  0.33333334
 0.         1.         0.         1.         0.44444445 0.
 0.11111111 1.         1.         0.33333334 0.22222222 0.6666667
 0.11111111 0.6666667  0.7777778  0.5555556  0.6666667  1.
 0.44444445 0.6666667  0.7777778  0.7777778  0.7777778  0.5555556
 0.8888889  0.22222222 0.7777778  0.7777778  0.6666667  0.8888889
 0.22222222 0.6666667  0.6666667  0.11111111 1.         1.
 0.11111111 1.         0.33333334 0.8888889  0.11111111 1.
 0.5555556  0.7777778  0.33333334 0.44444445 0.8888889  1.        ]
Top k classes which perform poorly are:  [33, 36, 83, 78, 24, 66, 18, 80, 12, 111, 21, 84, 118, 16, 114, 90, 50, 54, 23, 34, 74, 88, 38, 51, 13, 103, 108, 87, 42, 48, 116, 63, 61, 52, 59, 14, 1, 58, 4, 122, 20, 77, 123, 53, 31, 82, 96, 29, 15, 120, 8, 6, 93, 101, 30, 76, 73, 110, 71, 106, 94, 55, 10, 11, 97, 25, 89, 27, 26, 40, 43, 46, 91, 35, 109, 105, 92, 98, 99, 100, 104, 45, 3, 65, 121, 9, 19, 28, 57, 102, 37, 39, 117, 70, 47, 124, 107, 67, 68, 75, 62, 115, 113, 119, 112, 0, 86, 2, 5, 7, 17, 22, 32, 41, 44, 49, 56, 60, 64, 69, 72, 79, 81, 85, 95, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.1839, 1.2297, 1.3583, 1.1839, 1.2869, 1.1839, 1.2869,
        1.2297, 1.2567, 1.2567, 1.5000, 1.4004, 1.3583, 1.2869, 1.4474, 1.1839,
        1.5000, 1.2297, 1.3583, 1.4474, 1.1839, 1.4004, 1.5000, 1.2567, 1.2567,
        1.2567, 1.2297, 1.3206, 1.2869, 1.3206, 1.1839, 1.5000, 1.4004, 1.2567,
        1.5000, 1.2056, 1.4004, 1.2056, 1.2567, 1.1839, 1.3583, 1.2567, 1.1839,
        1.2297, 1.2567, 1.2056, 1.3583, 1.1839, 1.4474, 1.4004, 1.3583, 1.3206,
        1.4474, 1.2567, 1.1839, 1.2297, 1.3583, 1.3583, 1.1839, 1.3583, 1.2056,
        1.3583, 1.1839, 1.2297, 1.5000, 1.2056, 1.2056, 1.1839, 1.2056, 1.2567,
        1.1839, 1.2567, 1.4004, 1.2056, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.1839, 1.3206, 1.5000, 1.4474, 1.1839, 1.1839, 1.3583, 1.4004, 1.2567,
        1.4474, 1.2567, 1.2297, 1.2869, 1.2567, 1.1839, 1.3206, 1.2567, 1.2297,
        1.2297, 1.2297, 1.2869, 1.2056, 1.4004, 1.2297, 1.2297, 1.2567, 1.2056,
        1.4004, 1.2567, 1.2567, 1.4474, 1.1839, 1.1839, 1.4474, 1.1839, 1.3583,
        1.2056, 1.4474, 1.1839, 1.2869, 1.2297, 1.3583, 1.3206, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.8161, 0.7703, 0.6417, 0.8161, 0.7131, 0.8161, 0.7131,
        0.7703, 0.7433, 0.7433, 0.5000, 0.5996, 0.6417, 0.7131, 0.5526, 0.8161,
        0.5000, 0.7703, 0.6417, 0.5526, 0.8161, 0.5996, 0.5000, 0.7433, 0.7433,
        0.7433, 0.7703, 0.6794, 0.7131, 0.6794, 0.8161, 0.5000, 0.5996, 0.7433,
        0.5000, 0.7944, 0.5996, 0.7944, 0.7433, 0.8161, 0.6417, 0.7433, 0.8161,
        0.7703, 0.7433, 0.7944, 0.6417, 0.8161, 0.5526, 0.5996, 0.6417, 0.6794,
        0.5526, 0.7433, 0.8161, 0.7703, 0.6417, 0.6417, 0.8161, 0.6417, 0.7944,
        0.6417, 0.8161, 0.7703, 0.5000, 0.7944, 0.7944, 0.8161, 0.7944, 0.7433,
        0.8161, 0.7433, 0.5996, 0.7944, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.8161, 0.6794, 0.5000, 0.5526, 0.8161, 0.8161, 0.6417, 0.5996, 0.7433,
        0.5526, 0.7433, 0.7703, 0.7131, 0.7433, 0.8161, 0.6794, 0.7433, 0.7703,
        0.7703, 0.7703, 0.7131, 0.7944, 0.5996, 0.7703, 0.7703, 0.7433, 0.7944,
        0.5996, 0.7433, 0.7433, 0.5526, 0.8161, 0.8161, 0.5526, 0.8161, 0.6417,
        0.7944, 0.5526, 0.8161, 0.7131, 0.7703, 0.6417, 0.6794, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.973762 Loss T 0.071902 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1296, Accuracy: 608/1134 F1 (53.6155%)


Test set: Average loss: 1.7222, Accuracy: 43514/69960 F1 (62.1984%)


Val set: Average loss: 1.9010, Accuracy: 213/360 F1 (59.1667%)

best acc test 67.222699  acc val 59.166667 acc labeled target 53.615520
saving model...
S painting T real Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.786147 Loss T 0.101623 Method MME

S painting T real Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.677044 Loss T 0.065493 Method MME

S painting T real Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.241630 Loss T 0.098387 Method MME

S painting T real Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.419719 Loss T 0.083150 Method MME

S painting T real Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.529154 Loss T 0.104549 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.6185, Accuracy: 721/1134 F1 (63.5802%)


Test set: Average loss: 1.3093, Accuracy: 49471/69960 F1 (70.7133%)


Val set: Average loss: 1.5235, Accuracy: 236/360 F1 (65.5556%)

best acc test 70.713265  acc val 65.555556 acc labeled target 63.580247
saving model...
S painting T real Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 1.160011 Loss T 0.107949 Method MME

S painting T real Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.028594 Loss T 0.085209 Method MME

S painting T real Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.851202 Loss T 0.101007 Method MME

S painting T real Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.164358 Loss T 0.064907 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.22222222 0.7777778  1.         0.5555556  0.8888889
 0.8888889  0.6666667  0.6666667  0.6666667  0.8888889  0.6666667
 0.         0.         0.6666667  0.6666667  0.5555556  1.
 0.33333334 1.         0.         0.33333334 1.         0.33333334
 0.         1.         0.6666667  0.6666667  0.33333334 0.8888889
 0.7777778  0.44444445 0.8888889  0.11111111 0.33333334 1.
 0.         0.7777778  0.22222222 1.         0.6666667  0.5555556
 0.6666667  0.8888889  1.         1.         0.5555556  0.6666667
 0.7777778  1.         0.6666667  0.44444445 0.6666667  0.5555556
 0.11111111 0.6666667  0.5555556  1.         0.33333334 1.
 0.8888889  0.6666667  1.         0.         0.8888889  0.7777778
 0.         1.         0.6666667  1.         1.         0.8888889
 0.7777778  0.6666667  0.33333334 0.44444445 0.6666667  0.33333334
 0.         1.         0.11111111 0.7777778  0.22222222 0.
 0.         1.         0.6666667  0.33333334 0.33333334 0.5555556
 0.7777778  0.6666667  0.6666667  0.7777778  0.6666667  1.
 0.11111111 0.7777778  1.         1.         0.8888889  0.6666667
 1.         0.44444445 0.6666667  0.8888889  0.6666667  0.8888889
 0.5555556  0.8888889  0.6666667  0.         0.8888889  0.7777778
 0.5555556  1.         0.44444445 0.8888889  0.11111111 0.8888889
 0.33333334 1.         0.6666667  0.6666667  0.5555556  1.        ]
Top k classes which perform poorly are:  [66, 36, 24, 84, 83, 20, 63, 78, 111, 13, 12, 118, 54, 33, 96, 80, 1, 38, 82, 74, 28, 88, 87, 23, 120, 21, 58, 18, 34, 77, 116, 75, 51, 103, 31, 16, 56, 53, 114, 108, 46, 4, 124, 41, 89, 104, 15, 110, 106, 73, 14, 94, 11, 76, 9, 92, 91, 122, 7, 86, 123, 8, 68, 27, 40, 42, 26, 55, 61, 52, 101, 47, 50, 81, 97, 2, 37, 93, 90, 30, 65, 72, 48, 113, 10, 64, 29, 112, 100, 32, 117, 109, 43, 107, 5, 6, 119, 105, 71, 60, 115, 121, 0, 62, 99, 3, 17, 19, 22, 25, 35, 39, 44, 45, 49, 57, 59, 67, 69, 70, 79, 85, 95, 98, 102, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.4004, 1.2297, 1.1839, 1.2869, 1.2056, 1.2056, 1.2567, 1.2567,
        1.2567, 1.2056, 1.2567, 1.5000, 1.5000, 1.2567, 1.2567, 1.2869, 1.1839,
        1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.3583, 1.5000, 1.1839, 1.2567,
        1.2567, 1.3583, 1.2056, 1.2297, 1.3206, 1.2056, 1.4474, 1.3583, 1.1839,
        1.5000, 1.2297, 1.4004, 1.1839, 1.2567, 1.2869, 1.2567, 1.2056, 1.1839,
        1.1839, 1.2869, 1.2567, 1.2297, 1.1839, 1.2567, 1.3206, 1.2567, 1.2869,
        1.4474, 1.2567, 1.2869, 1.1839, 1.3583, 1.1839, 1.2056, 1.2567, 1.1839,
        1.5000, 1.2056, 1.2297, 1.5000, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056,
        1.2297, 1.2567, 1.3583, 1.3206, 1.2567, 1.3583, 1.5000, 1.1839, 1.4474,
        1.2297, 1.4004, 1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.3583, 1.2869,
        1.2297, 1.2567, 1.2567, 1.2297, 1.2567, 1.1839, 1.4474, 1.2297, 1.1839,
        1.1839, 1.2056, 1.2567, 1.1839, 1.3206, 1.2567, 1.2056, 1.2567, 1.2056,
        1.2869, 1.2056, 1.2567, 1.5000, 1.2056, 1.2297, 1.2869, 1.1839, 1.3206,
        1.2056, 1.4474, 1.2056, 1.3583, 1.1839, 1.2567, 1.2567, 1.2869, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5996, 0.7703, 0.8161, 0.7131, 0.7944, 0.7944, 0.7433, 0.7433,
        0.7433, 0.7944, 0.7433, 0.5000, 0.5000, 0.7433, 0.7433, 0.7131, 0.8161,
        0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.6417, 0.5000, 0.8161, 0.7433,
        0.7433, 0.6417, 0.7944, 0.7703, 0.6794, 0.7944, 0.5526, 0.6417, 0.8161,
        0.5000, 0.7703, 0.5996, 0.8161, 0.7433, 0.7131, 0.7433, 0.7944, 0.8161,
        0.8161, 0.7131, 0.7433, 0.7703, 0.8161, 0.7433, 0.6794, 0.7433, 0.7131,
        0.5526, 0.7433, 0.7131, 0.8161, 0.6417, 0.8161, 0.7944, 0.7433, 0.8161,
        0.5000, 0.7944, 0.7703, 0.5000, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944,
        0.7703, 0.7433, 0.6417, 0.6794, 0.7433, 0.6417, 0.5000, 0.8161, 0.5526,
        0.7703, 0.5996, 0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.6417, 0.7131,
        0.7703, 0.7433, 0.7433, 0.7703, 0.7433, 0.8161, 0.5526, 0.7703, 0.8161,
        0.8161, 0.7944, 0.7433, 0.8161, 0.6794, 0.7433, 0.7944, 0.7433, 0.7944,
        0.7131, 0.7944, 0.7433, 0.5000, 0.7944, 0.7703, 0.7131, 0.8161, 0.6794,
        0.7944, 0.5526, 0.7944, 0.6417, 0.8161, 0.7433, 0.7433, 0.7131, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.435630 Loss T 0.060202 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0231, Accuracy: 658/1134 F1 (58.0247%)


Test set: Average loss: 1.6014, Accuracy: 46590/69960 F1 (66.5952%)


Val set: Average loss: 1.7533, Accuracy: 229/360 F1 (63.6111%)

best acc test 70.713265  acc val 63.611111 acc labeled target 58.024691
saving model...
S painting T real Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.311989 Loss T 0.064720 Method MME

S painting T real Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.550681 Loss T 0.045878 Method MME

S painting T real Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 1.197601 Loss T 0.079910 Method MME

S painting T real Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.548211 Loss T 0.072278 Method MME

S painting T real Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.704851 Loss T 0.067231 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.6199, Accuracy: 745/1134 F1 (65.6966%)


Test set: Average loss: 1.2463, Accuracy: 51059/69960 F1 (72.9831%)


Val set: Average loss: 1.4651, Accuracy: 248/360 F1 (68.8889%)

best acc test 72.983133  acc val 68.888889 acc labeled target 65.696649
saving model...
S painting T real Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.495428 Loss T 0.066172 Method MME

S painting T real Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.552536 Loss T 0.049396 Method MME

S painting T real Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.514532 Loss T 0.057219 Method MME

S painting T real Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.803678 Loss T 0.087874 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.44444445 0.6666667  1.         0.44444445 0.6666667
 0.5555556  0.33333334 0.6666667  0.6666667  0.7777778  0.6666667
 0.         0.22222222 0.6666667  0.5555556  0.5555556  1.
 0.5555556  0.7777778  0.         0.5555556  1.         0.33333334
 0.         1.         0.6666667  0.6666667  0.8888889  1.
 0.8888889  0.44444445 0.6666667  0.         0.33333334 0.7777778
 0.         1.         0.33333334 1.         0.6666667  1.
 0.5555556  1.         0.7777778  0.8888889  0.8888889  0.8888889
 0.8888889  1.         0.8888889  0.5555556  0.33333334 0.8888889
 0.22222222 0.7777778  1.         1.         0.33333334 1.
 1.         0.22222222 1.         0.         1.         1.
 0.         1.         0.8888889  0.8888889  1.         1.
 0.8888889  0.6666667  0.22222222 0.7777778  0.5555556  0.33333334
 0.         0.8888889  0.         0.8888889  0.8888889  0.
 0.22222222 1.         0.6666667  0.5555556  0.11111111 0.6666667
 0.33333334 0.6666667  0.7777778  0.8888889  0.6666667  1.
 0.11111111 0.8888889  0.44444445 0.6666667  1.         0.5555556
 1.         0.44444445 0.6666667  0.7777778  1.         0.7777778
 0.6666667  0.8888889  0.7777778  0.44444445 1.         1.
 0.6666667  1.         0.6666667  1.         0.         0.8888889
 0.33333334 0.8888889  0.33333334 0.44444445 0.5555556  1.        ]
Top k classes which perform poorly are:  [80, 33, 24, 83, 36, 66, 63, 118, 20, 78, 12, 88, 96, 74, 84, 54, 61, 13, 122, 38, 52, 7, 23, 120, 34, 77, 90, 58, 111, 31, 103, 98, 1, 123, 4, 76, 6, 124, 87, 15, 51, 16, 101, 18, 21, 42, 94, 32, 27, 2, 73, 26, 5, 108, 104, 99, 9, 8, 11, 14, 40, 89, 114, 91, 86, 116, 10, 44, 75, 92, 105, 35, 107, 110, 19, 55, 81, 97, 93, 82, 0, 72, 121, 28, 119, 30, 45, 46, 79, 48, 47, 53, 109, 68, 69, 50, 113, 112, 115, 117, 106, 102, 62, 95, 3, 17, 22, 25, 29, 37, 39, 41, 43, 100, 49, 57, 59, 60, 64, 65, 67, 70, 71, 85, 56, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.3206, 1.2567, 1.1839, 1.3206, 1.2567, 1.2869, 1.3583, 1.2567,
        1.2567, 1.2297, 1.2567, 1.5000, 1.4004, 1.2567, 1.2869, 1.2869, 1.1839,
        1.2869, 1.2297, 1.5000, 1.2869, 1.1839, 1.3583, 1.5000, 1.1839, 1.2567,
        1.2567, 1.2056, 1.1839, 1.2056, 1.3206, 1.2567, 1.5000, 1.3583, 1.2297,
        1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839, 1.2869, 1.1839, 1.2297,
        1.2056, 1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.2869, 1.3583, 1.2056,
        1.4004, 1.2297, 1.1839, 1.1839, 1.3583, 1.1839, 1.1839, 1.4004, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2567, 1.4004, 1.2297, 1.2869, 1.3583, 1.5000, 1.2056, 1.5000,
        1.2056, 1.2056, 1.5000, 1.4004, 1.1839, 1.2567, 1.2869, 1.4474, 1.2567,
        1.3583, 1.2567, 1.2297, 1.2056, 1.2567, 1.1839, 1.4474, 1.2056, 1.3206,
        1.2567, 1.1839, 1.2869, 1.1839, 1.3206, 1.2567, 1.2297, 1.1839, 1.2297,
        1.2567, 1.2056, 1.2297, 1.3206, 1.1839, 1.1839, 1.2567, 1.1839, 1.2567,
        1.1839, 1.5000, 1.2056, 1.3583, 1.2056, 1.3583, 1.3206, 1.2869, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.6794, 0.7433, 0.8161, 0.6794, 0.7433, 0.7131, 0.6417, 0.7433,
        0.7433, 0.7703, 0.7433, 0.5000, 0.5996, 0.7433, 0.7131, 0.7131, 0.8161,
        0.7131, 0.7703, 0.5000, 0.7131, 0.8161, 0.6417, 0.5000, 0.8161, 0.7433,
        0.7433, 0.7944, 0.8161, 0.7944, 0.6794, 0.7433, 0.5000, 0.6417, 0.7703,
        0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161, 0.7131, 0.8161, 0.7703,
        0.7944, 0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.7131, 0.6417, 0.7944,
        0.5996, 0.7703, 0.8161, 0.8161, 0.6417, 0.8161, 0.8161, 0.5996, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7433, 0.5996, 0.7703, 0.7131, 0.6417, 0.5000, 0.7944, 0.5000,
        0.7944, 0.7944, 0.5000, 0.5996, 0.8161, 0.7433, 0.7131, 0.5526, 0.7433,
        0.6417, 0.7433, 0.7703, 0.7944, 0.7433, 0.8161, 0.5526, 0.7944, 0.6794,
        0.7433, 0.8161, 0.7131, 0.8161, 0.6794, 0.7433, 0.7703, 0.8161, 0.7703,
        0.7433, 0.7944, 0.7703, 0.6794, 0.8161, 0.8161, 0.7433, 0.8161, 0.7433,
        0.8161, 0.5000, 0.7944, 0.6417, 0.7944, 0.6417, 0.6794, 0.7131, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.203847 Loss T 0.056627 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9273, Accuracy: 690/1134 F1 (60.8466%)


Test set: Average loss: 1.5851, Accuracy: 47314/69960 F1 (67.6301%)


Val set: Average loss: 1.8414, Accuracy: 231/360 F1 (64.1667%)

best acc test 72.983133  acc val 64.166667 acc labeled target 60.846561
saving model...
S painting T real Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.823669 Loss T 0.047829 Method MME

S painting T real Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.257632 Loss T 0.064089 Method MME

S painting T real Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.776305 Loss T 0.061898 Method MME

S painting T real Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.701694 Loss T 0.054235 Method MME

S painting T real Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.456815 Loss T 0.062818 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7596, Accuracy: 735/1134 F1 (64.8148%)


Test set: Average loss: 1.3399, Accuracy: 51396/69960 F1 (73.4648%)


Val set: Average loss: 1.6489, Accuracy: 242/360 F1 (67.2222%)

best acc test 72.983133  acc val 67.222222 acc labeled target 64.814815
saving model...
S painting T real Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.599245 Loss T 0.051660 Method MME

S painting T real Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.688894 Loss T 0.067859 Method MME

S painting T real Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.589348 Loss T 0.059661 Method MME

S painting T real Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.785011 Loss T 0.034636 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.22222222 0.8888889  1.         0.44444445 0.8888889
 0.8888889  0.5555556  1.         0.5555556  0.7777778  0.6666667
 0.         0.22222222 0.6666667  0.5555556  0.7777778  1.
 0.11111111 0.6666667  0.11111111 0.6666667  1.         0.11111111
 0.5555556  0.6666667  0.6666667  0.5555556  0.8888889  0.8888889
 0.33333334 0.22222222 1.         0.         0.33333334 0.7777778
 0.         0.8888889  0.11111111 1.         0.6666667  1.
 0.5555556  0.7777778  1.         1.         1.         0.8888889
 0.7777778  1.         0.44444445 0.33333334 0.44444445 0.44444445
 0.33333334 1.         1.         1.         0.33333334 1.
 0.8888889  0.         0.8888889  0.11111111 1.         0.8888889
 0.         1.         0.7777778  1.         1.         1.
 0.6666667  0.5555556  0.7777778  1.         0.6666667  0.33333334
 0.         1.         0.         1.         0.33333334 0.
 0.11111111 1.         0.8888889  0.33333334 0.         0.44444445
 0.44444445 0.8888889  0.7777778  1.         0.6666667  1.
 0.         0.8888889  1.         0.6666667  1.         0.6666667
 1.         0.44444445 0.22222222 0.8888889  0.6666667  0.8888889
 0.33333334 0.44444445 0.6666667  0.22222222 0.8888889  1.
 0.5555556  1.         0.5555556  0.8888889  0.         1.
 0.44444445 1.         0.5555556  0.6666667  1.         1.        ]
Top k classes which perform poorly are:  [96, 61, 78, 118, 80, 36, 66, 83, 88, 12, 33, 84, 18, 63, 20, 38, 23, 31, 13, 104, 1, 111, 58, 51, 30, 77, 108, 87, 54, 82, 34, 89, 4, 53, 50, 52, 109, 103, 90, 120, 7, 9, 73, 15, 122, 114, 116, 42, 24, 27, 110, 72, 11, 123, 76, 94, 101, 40, 99, 26, 25, 21, 19, 14, 106, 92, 68, 74, 48, 35, 10, 16, 43, 2, 5, 91, 6, 86, 28, 29, 65, 105, 37, 117, 47, 97, 112, 60, 107, 62, 119, 115, 121, 102, 113, 98, 100, 0, 93, 3, 8, 17, 22, 32, 39, 41, 44, 45, 46, 49, 55, 56, 57, 59, 124, 64, 67, 69, 70, 71, 75, 79, 81, 85, 95, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.4004, 1.2056, 1.1839, 1.3206, 1.2056, 1.2056, 1.2869, 1.1839,
        1.2869, 1.2297, 1.2567, 1.5000, 1.4004, 1.2567, 1.2869, 1.2297, 1.1839,
        1.4474, 1.2567, 1.4474, 1.2567, 1.1839, 1.4474, 1.2869, 1.2567, 1.2567,
        1.2869, 1.2056, 1.2056, 1.3583, 1.4004, 1.1839, 1.5000, 1.3583, 1.2297,
        1.5000, 1.2056, 1.4474, 1.1839, 1.2567, 1.1839, 1.2869, 1.2297, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.3206, 1.3583, 1.3206, 1.3206,
        1.3583, 1.1839, 1.1839, 1.1839, 1.3583, 1.1839, 1.2056, 1.5000, 1.2056,
        1.4474, 1.1839, 1.2056, 1.5000, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2869, 1.2297, 1.1839, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.1839, 1.3583, 1.5000, 1.4474, 1.1839, 1.2056, 1.3583, 1.5000, 1.3206,
        1.3206, 1.2056, 1.2297, 1.1839, 1.2567, 1.1839, 1.5000, 1.2056, 1.1839,
        1.2567, 1.1839, 1.2567, 1.1839, 1.3206, 1.4004, 1.2056, 1.2567, 1.2056,
        1.3583, 1.3206, 1.2567, 1.4004, 1.2056, 1.1839, 1.2869, 1.1839, 1.2869,
        1.2056, 1.5000, 1.1839, 1.3206, 1.1839, 1.2869, 1.2567, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5996, 0.7944, 0.8161, 0.6794, 0.7944, 0.7944, 0.7131, 0.8161,
        0.7131, 0.7703, 0.7433, 0.5000, 0.5996, 0.7433, 0.7131, 0.7703, 0.8161,
        0.5526, 0.7433, 0.5526, 0.7433, 0.8161, 0.5526, 0.7131, 0.7433, 0.7433,
        0.7131, 0.7944, 0.7944, 0.6417, 0.5996, 0.8161, 0.5000, 0.6417, 0.7703,
        0.5000, 0.7944, 0.5526, 0.8161, 0.7433, 0.8161, 0.7131, 0.7703, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.6794, 0.6417, 0.6794, 0.6794,
        0.6417, 0.8161, 0.8161, 0.8161, 0.6417, 0.8161, 0.7944, 0.5000, 0.7944,
        0.5526, 0.8161, 0.7944, 0.5000, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7131, 0.7703, 0.8161, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.8161, 0.6417, 0.5000, 0.5526, 0.8161, 0.7944, 0.6417, 0.5000, 0.6794,
        0.6794, 0.7944, 0.7703, 0.8161, 0.7433, 0.8161, 0.5000, 0.7944, 0.8161,
        0.7433, 0.8161, 0.7433, 0.8161, 0.6794, 0.5996, 0.7944, 0.7433, 0.7944,
        0.6417, 0.6794, 0.7433, 0.5996, 0.7944, 0.8161, 0.7131, 0.8161, 0.7131,
        0.7944, 0.5000, 0.8161, 0.6794, 0.8161, 0.7131, 0.7433, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.795060 Loss T 0.070705 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0082, Accuracy: 686/1134 F1 (60.4938%)


Test set: Average loss: 1.5958, Accuracy: 47981/69960 F1 (68.5835%)


Val set: Average loss: 1.7000, Accuracy: 238/360 F1 (66.1111%)

best acc test 72.983133  acc val 66.111111 acc labeled target 60.493827
saving model...
S painting T real Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.969041 Loss T 0.058395 Method MME

S painting T real Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.233881 Loss T 0.043802 Method MME

S painting T real Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.501554 Loss T 0.050993 Method MME

S painting T real Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.377935 Loss T 0.060181 Method MME

S painting T real Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.331512 Loss T 0.050019 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8328, Accuracy: 745/1134 F1 (65.6966%)


Test set: Average loss: 1.3536, Accuracy: 52126/69960 F1 (74.5083%)


Val set: Average loss: 1.5467, Accuracy: 257/360 F1 (71.3889%)

best acc test 74.508290  acc val 71.388889 acc labeled target 65.696649
saving model...
S painting T real Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.750083 Loss T 0.044198 Method MME

S painting T real Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.650994 Loss T 0.026613 Method MME

S painting T real Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.714268 Loss T 0.060860 Method MME

S painting T real Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.279235 Loss T 0.045088 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 0.7777778  1.         0.33333334 0.8888889
 0.7777778  0.7777778  1.         0.8888889  0.7777778  0.6666667
 0.         0.33333334 0.6666667  0.5555556  0.7777778  0.8888889
 0.11111111 0.8888889  0.         0.44444445 1.         0.22222222
 0.6666667  0.6666667  0.6666667  0.6666667  0.8888889  0.6666667
 0.7777778  0.7777778  0.6666667  0.         0.33333334 1.
 0.         1.         0.33333334 1.         0.6666667  1.
 0.5555556  1.         1.         0.8888889  0.8888889  0.8888889
 0.8888889  1.         1.         0.44444445 0.5555556  0.6666667
 0.11111111 0.8888889  1.         1.         0.33333334 0.7777778
 1.         0.44444445 1.         0.22222222 1.         1.
 0.         1.         1.         1.         1.         0.7777778
 0.44444445 0.5555556  0.44444445 0.6666667  0.6666667  0.22222222
 0.         0.5555556  0.         0.6666667  0.33333334 0.
 0.22222222 0.8888889  0.6666667  0.33333334 0.         0.33333334
 0.44444445 1.         0.7777778  0.8888889  0.6666667  1.
 0.         0.8888889  0.6666667  0.7777778  1.         0.5555556
 0.7777778  0.33333334 0.44444445 0.7777778  0.6666667  0.7777778
 0.6666667  0.8888889  1.         0.6666667  0.7777778  1.
 0.33333334 1.         0.8888889  0.8888889  0.         1.
 0.         0.8888889  0.5555556  0.8888889  0.6666667  1.        ]
Top k classes which perform poorly are:  [33, 96, 118, 36, 120, 78, 80, 20, 83, 12, 66, 88, 18, 54, 77, 63, 84, 23, 103, 4, 34, 114, 89, 38, 82, 1, 13, 87, 58, 21, 51, 72, 90, 74, 61, 104, 42, 52, 73, 101, 15, 122, 79, 40, 14, 124, 106, 81, 111, 24, 25, 26, 53, 29, 94, 32, 108, 75, 76, 98, 86, 27, 11, 92, 71, 105, 107, 102, 59, 112, 99, 2, 6, 7, 31, 30, 10, 16, 93, 123, 5, 9, 85, 121, 19, 109, 28, 117, 116, 97, 45, 46, 48, 55, 17, 47, 0, 115, 119, 110, 113, 62, 95, 3, 8, 22, 35, 37, 39, 41, 43, 44, 49, 50, 56, 57, 60, 64, 65, 67, 68, 69, 70, 91, 100, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.2297, 1.1839, 1.3583, 1.2056, 1.2297, 1.2297, 1.1839,
        1.2056, 1.2297, 1.2567, 1.5000, 1.3583, 1.2567, 1.2869, 1.2297, 1.2056,
        1.4474, 1.2056, 1.5000, 1.3206, 1.1839, 1.4004, 1.2567, 1.2567, 1.2567,
        1.2567, 1.2056, 1.2567, 1.2297, 1.2297, 1.2567, 1.5000, 1.3583, 1.1839,
        1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839, 1.2869, 1.1839, 1.1839,
        1.2056, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.3206, 1.2869, 1.2567,
        1.4474, 1.2056, 1.1839, 1.1839, 1.3583, 1.2297, 1.1839, 1.3206, 1.1839,
        1.4004, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.3206, 1.2869, 1.3206, 1.2567, 1.2567, 1.4004, 1.5000, 1.2869, 1.5000,
        1.2567, 1.3583, 1.5000, 1.4004, 1.2056, 1.2567, 1.3583, 1.5000, 1.3583,
        1.3206, 1.1839, 1.2297, 1.2056, 1.2567, 1.1839, 1.5000, 1.2056, 1.2567,
        1.2297, 1.1839, 1.2869, 1.2297, 1.3583, 1.3206, 1.2297, 1.2567, 1.2297,
        1.2567, 1.2056, 1.1839, 1.2567, 1.2297, 1.1839, 1.3583, 1.1839, 1.2056,
        1.2056, 1.5000, 1.1839, 1.5000, 1.2056, 1.2869, 1.2056, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.7703, 0.8161, 0.6417, 0.7944, 0.7703, 0.7703, 0.8161,
        0.7944, 0.7703, 0.7433, 0.5000, 0.6417, 0.7433, 0.7131, 0.7703, 0.7944,
        0.5526, 0.7944, 0.5000, 0.6794, 0.8161, 0.5996, 0.7433, 0.7433, 0.7433,
        0.7433, 0.7944, 0.7433, 0.7703, 0.7703, 0.7433, 0.5000, 0.6417, 0.8161,
        0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161, 0.7131, 0.8161, 0.8161,
        0.7944, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.6794, 0.7131, 0.7433,
        0.5526, 0.7944, 0.8161, 0.8161, 0.6417, 0.7703, 0.8161, 0.6794, 0.8161,
        0.5996, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.6794, 0.7131, 0.6794, 0.7433, 0.7433, 0.5996, 0.5000, 0.7131, 0.5000,
        0.7433, 0.6417, 0.5000, 0.5996, 0.7944, 0.7433, 0.6417, 0.5000, 0.6417,
        0.6794, 0.8161, 0.7703, 0.7944, 0.7433, 0.8161, 0.5000, 0.7944, 0.7433,
        0.7703, 0.8161, 0.7131, 0.7703, 0.6417, 0.6794, 0.7703, 0.7433, 0.7703,
        0.7433, 0.7944, 0.8161, 0.7433, 0.7703, 0.8161, 0.6417, 0.8161, 0.7944,
        0.7944, 0.5000, 0.8161, 0.5000, 0.7944, 0.7131, 0.7944, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 1.310529 Loss T 0.047718 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9838, Accuracy: 719/1134 F1 (63.4039%)


Test set: Average loss: 1.5660, Accuracy: 49311/69960 F1 (70.4846%)


Val set: Average loss: 1.7372, Accuracy: 246/360 F1 (68.3333%)

best acc test 74.508290  acc val 68.333333 acc labeled target 63.403880
saving model...
S painting T real Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.364385 Loss T 0.023093 Method MME

S painting T real Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.263995 Loss T 0.045133 Method MME

S painting T real Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.629358 Loss T 0.050460 Method MME

S painting T real Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.196362 Loss T 0.075903 Method MME

S painting T real Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.544037 Loss T 0.039508 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7274, Accuracy: 760/1134 F1 (67.0194%)


Test set: Average loss: 1.3477, Accuracy: 52501/69960 F1 (75.0443%)


Val set: Average loss: 1.5396, Accuracy: 261/360 F1 (72.5000%)

best acc test 75.044311  acc val 72.500000 acc labeled target 67.019400
saving model...
S painting T real Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.134929 Loss T 0.039494 Method MME

S painting T real Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.163145 Loss T 0.056226 Method MME

S painting T real Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.459711 Loss T 0.042768 Method MME

S painting T real Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.221266 Loss T 0.034275 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 0.6666667  1.         0.22222222 1.
 0.7777778  0.7777778  1.         0.8888889  0.8888889  0.6666667
 0.         0.33333334 0.6666667  0.6666667  0.6666667  0.8888889
 0.11111111 0.7777778  0.         0.33333334 1.         0.33333334
 0.5555556  0.7777778  0.5555556  0.6666667  1.         0.8888889
 0.33333334 0.8888889  0.6666667  0.         0.33333334 0.5555556
 0.         1.         0.33333334 1.         0.6666667  1.
 0.5555556  1.         1.         0.8888889  0.7777778  1.
 0.7777778  1.         1.         0.5555556  0.5555556  0.33333334
 0.6666667  1.         0.8888889  1.         0.33333334 0.6666667
 1.         0.         1.         0.22222222 1.         0.8888889
 0.         1.         0.7777778  1.         1.         0.6666667
 0.7777778  0.7777778  0.44444445 1.         0.6666667  0.33333334
 0.         0.8888889  0.         0.8888889  0.33333334 0.
 0.5555556  1.         1.         0.33333334 0.11111111 0.33333334
 0.6666667  0.7777778  0.6666667  0.6666667  0.7777778  1.
 0.         1.         0.33333334 0.8888889  0.5555556  0.5555556
 1.         0.6666667  0.6666667  0.6666667  0.8888889  0.7777778
 0.6666667  1.         0.6666667  0.8888889  1.         1.
 0.5555556  1.         0.8888889  1.         0.         1.
 0.6666667  0.8888889  0.33333334 0.6666667  0.5555556  0.8888889 ]
Top k classes which perform poorly are:  [83, 78, 66, 61, 20, 80, 96, 33, 12, 36, 118, 18, 88, 63, 4, 34, 98, 87, 82, 53, 58, 89, 30, 38, 77, 1, 122, 23, 21, 13, 74, 124, 100, 52, 51, 84, 101, 114, 42, 24, 26, 35, 105, 123, 27, 92, 108, 59, 15, 104, 71, 110, 54, 40, 120, 90, 32, 11, 103, 93, 16, 76, 14, 2, 73, 25, 68, 72, 6, 107, 7, 91, 48, 19, 46, 94, 81, 79, 125, 65, 121, 9, 10, 17, 29, 31, 106, 116, 45, 99, 111, 56, 117, 102, 113, 119, 109, 115, 112, 0, 95, 3, 5, 8, 22, 28, 37, 39, 41, 43, 44, 47, 49, 50, 55, 57, 60, 64, 67, 69, 70, 75, 85, 86, 97, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.2567, 1.1839, 1.4004, 1.1839, 1.2297, 1.2297, 1.1839,
        1.2056, 1.2056, 1.2567, 1.5000, 1.3583, 1.2567, 1.2567, 1.2567, 1.2056,
        1.4474, 1.2297, 1.5000, 1.3583, 1.1839, 1.3583, 1.2869, 1.2297, 1.2869,
        1.2567, 1.1839, 1.2056, 1.3583, 1.2056, 1.2567, 1.5000, 1.3583, 1.2869,
        1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839, 1.2869, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.2297, 1.1839, 1.1839, 1.2869, 1.2869, 1.3583,
        1.2567, 1.1839, 1.2056, 1.1839, 1.3583, 1.2567, 1.1839, 1.5000, 1.1839,
        1.4004, 1.1839, 1.2056, 1.5000, 1.1839, 1.2297, 1.1839, 1.1839, 1.2567,
        1.2297, 1.2297, 1.3206, 1.1839, 1.2567, 1.3583, 1.5000, 1.2056, 1.5000,
        1.2056, 1.3583, 1.5000, 1.2869, 1.1839, 1.1839, 1.3583, 1.4474, 1.3583,
        1.2567, 1.2297, 1.2567, 1.2567, 1.2297, 1.1839, 1.5000, 1.1839, 1.3583,
        1.2056, 1.2869, 1.2869, 1.1839, 1.2567, 1.2567, 1.2567, 1.2056, 1.2297,
        1.2567, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.2869, 1.1839, 1.2056,
        1.1839, 1.5000, 1.1839, 1.2567, 1.2056, 1.3583, 1.2567, 1.2869, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.7433, 0.8161, 0.5996, 0.8161, 0.7703, 0.7703, 0.8161,
        0.7944, 0.7944, 0.7433, 0.5000, 0.6417, 0.7433, 0.7433, 0.7433, 0.7944,
        0.5526, 0.7703, 0.5000, 0.6417, 0.8161, 0.6417, 0.7131, 0.7703, 0.7131,
        0.7433, 0.8161, 0.7944, 0.6417, 0.7944, 0.7433, 0.5000, 0.6417, 0.7131,
        0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161, 0.7131, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.7703, 0.8161, 0.8161, 0.7131, 0.7131, 0.6417,
        0.7433, 0.8161, 0.7944, 0.8161, 0.6417, 0.7433, 0.8161, 0.5000, 0.8161,
        0.5996, 0.8161, 0.7944, 0.5000, 0.8161, 0.7703, 0.8161, 0.8161, 0.7433,
        0.7703, 0.7703, 0.6794, 0.8161, 0.7433, 0.6417, 0.5000, 0.7944, 0.5000,
        0.7944, 0.6417, 0.5000, 0.7131, 0.8161, 0.8161, 0.6417, 0.5526, 0.6417,
        0.7433, 0.7703, 0.7433, 0.7433, 0.7703, 0.8161, 0.5000, 0.8161, 0.6417,
        0.7944, 0.7131, 0.7131, 0.8161, 0.7433, 0.7433, 0.7433, 0.7944, 0.7703,
        0.7433, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.7131, 0.8161, 0.7944,
        0.8161, 0.5000, 0.8161, 0.7433, 0.7944, 0.6417, 0.7433, 0.7131, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.301591 Loss T 0.028117 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9659, Accuracy: 713/1134 F1 (62.8748%)


Test set: Average loss: 1.5819, Accuracy: 48691/69960 F1 (69.5983%)


Val set: Average loss: 1.8047, Accuracy: 242/360 F1 (67.2222%)

best acc test 75.044311  acc val 67.222222 acc labeled target 62.874780
saving model...
S painting T real Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.587684 Loss T 0.027985 Method MME

S painting T real Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.057005 Loss T 0.041062 Method MME

S painting T real Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.696279 Loss T 0.059100 Method MME

S painting T real Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.167323 Loss T 0.036331 Method MME

S painting T real Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.291519 Loss T 0.036470 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7211, Accuracy: 778/1134 F1 (68.6067%)


Test set: Average loss: 1.3335, Accuracy: 52981/69960 F1 (75.7304%)


Val set: Average loss: 1.5901, Accuracy: 263/360 F1 (73.0556%)

best acc test 75.730417  acc val 73.055556 acc labeled target 68.606702
saving model...
S painting T real Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.126232 Loss T 0.041768 Method MME

S painting T real Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.138238 Loss T 0.049575 Method MME

S painting T real Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.429366 Loss T 0.036623 Method MME

S painting T real Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.157069 Loss T 0.030404 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.         0.7777778  1.         0.11111111 0.6666667
 1.         0.8888889  0.8888889  0.7777778  0.7777778  0.6666667
 0.         0.33333334 0.6666667  0.6666667  0.5555556  1.
 0.22222222 0.8888889  0.11111111 0.7777778  1.         0.33333334
 0.22222222 0.6666667  0.5555556  0.6666667  0.8888889  0.8888889
 0.8888889  0.44444445 0.8888889  0.6666667  0.22222222 1.
 0.         1.         0.22222222 1.         0.6666667  1.
 0.6666667  0.8888889  1.         0.8888889  1.         0.8888889
 1.         0.8888889  1.         0.33333334 0.5555556  0.5555556
 0.11111111 0.8888889  0.8888889  1.         0.33333334 0.6666667
 1.         0.33333334 1.         0.11111111 1.         0.8888889
 0.         1.         1.         1.         1.         1.
 0.6666667  0.6666667  0.6666667  1.         0.6666667  0.33333334
 0.         0.8888889  0.         1.         0.33333334 0.
 0.22222222 1.         1.         0.33333334 0.22222222 0.33333334
 0.7777778  0.7777778  0.6666667  0.8888889  0.7777778  1.
 0.11111111 1.         0.44444445 0.7777778  1.         0.6666667
 1.         0.5555556  0.5555556  1.         0.6666667  0.6666667
 0.6666667  0.7777778  0.7777778  0.5555556  1.         1.
 0.5555556  1.         1.         1.         0.         1.
 0.6666667  0.8888889  0.6666667  0.5555556  0.7777778  1.        ]
Top k classes which perform poorly are:  [66, 1, 83, 12, 36, 118, 80, 78, 54, 63, 20, 4, 96, 24, 34, 38, 84, 88, 18, 23, 87, 61, 58, 13, 77, 89, 82, 51, 31, 98, 104, 114, 53, 16, 26, 111, 123, 52, 103, 15, 76, 59, 11, 74, 108, 107, 106, 14, 72, 73, 120, 101, 122, 5, 92, 42, 40, 33, 27, 25, 90, 2, 10, 99, 91, 124, 110, 94, 21, 9, 109, 79, 7, 8, 30, 29, 56, 55, 121, 49, 19, 47, 45, 93, 32, 28, 65, 43, 0, 102, 105, 112, 115, 116, 117, 119, 100, 113, 62, 95, 3, 6, 17, 22, 35, 37, 39, 41, 44, 46, 48, 97, 50, 60, 64, 67, 68, 69, 70, 71, 75, 81, 85, 86, 57, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.5000, 1.2297, 1.1839, 1.4474, 1.2567, 1.1839, 1.2056, 1.2056,
        1.2297, 1.2297, 1.2567, 1.5000, 1.3583, 1.2567, 1.2567, 1.2869, 1.1839,
        1.4004, 1.2056, 1.4474, 1.2297, 1.1839, 1.3583, 1.4004, 1.2567, 1.2869,
        1.2567, 1.2056, 1.2056, 1.2056, 1.3206, 1.2056, 1.2567, 1.4004, 1.1839,
        1.5000, 1.1839, 1.4004, 1.1839, 1.2567, 1.1839, 1.2567, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.3583, 1.2869, 1.2869,
        1.4474, 1.2056, 1.2056, 1.1839, 1.3583, 1.2567, 1.1839, 1.3583, 1.1839,
        1.4474, 1.1839, 1.2056, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2567, 1.2567, 1.1839, 1.2567, 1.3583, 1.5000, 1.2056, 1.5000,
        1.1839, 1.3583, 1.5000, 1.4004, 1.1839, 1.1839, 1.3583, 1.4004, 1.3583,
        1.2297, 1.2297, 1.2567, 1.2056, 1.2297, 1.1839, 1.4474, 1.1839, 1.3206,
        1.2297, 1.1839, 1.2567, 1.1839, 1.2869, 1.2869, 1.1839, 1.2567, 1.2567,
        1.2567, 1.2297, 1.2297, 1.2869, 1.1839, 1.1839, 1.2869, 1.1839, 1.1839,
        1.1839, 1.5000, 1.1839, 1.2567, 1.2056, 1.2567, 1.2869, 1.2297, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5000, 0.7703, 0.8161, 0.5526, 0.7433, 0.8161, 0.7944, 0.7944,
        0.7703, 0.7703, 0.7433, 0.5000, 0.6417, 0.7433, 0.7433, 0.7131, 0.8161,
        0.5996, 0.7944, 0.5526, 0.7703, 0.8161, 0.6417, 0.5996, 0.7433, 0.7131,
        0.7433, 0.7944, 0.7944, 0.7944, 0.6794, 0.7944, 0.7433, 0.5996, 0.8161,
        0.5000, 0.8161, 0.5996, 0.8161, 0.7433, 0.8161, 0.7433, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.6417, 0.7131, 0.7131,
        0.5526, 0.7944, 0.7944, 0.8161, 0.6417, 0.7433, 0.8161, 0.6417, 0.8161,
        0.5526, 0.8161, 0.7944, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7433, 0.7433, 0.8161, 0.7433, 0.6417, 0.5000, 0.7944, 0.5000,
        0.8161, 0.6417, 0.5000, 0.5996, 0.8161, 0.8161, 0.6417, 0.5996, 0.6417,
        0.7703, 0.7703, 0.7433, 0.7944, 0.7703, 0.8161, 0.5526, 0.8161, 0.6794,
        0.7703, 0.8161, 0.7433, 0.8161, 0.7131, 0.7131, 0.8161, 0.7433, 0.7433,
        0.7433, 0.7703, 0.7703, 0.7131, 0.8161, 0.8161, 0.7131, 0.8161, 0.8161,
        0.8161, 0.5000, 0.8161, 0.7433, 0.7944, 0.7433, 0.7131, 0.7703, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.092272 Loss T 0.042145 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9620, Accuracy: 731/1134 F1 (64.4621%)


Test set: Average loss: 1.5346, Accuracy: 50625/69960 F1 (72.3628%)


Val set: Average loss: 1.8143, Accuracy: 248/360 F1 (68.8889%)

best acc test 75.730417  acc val 68.888889 acc labeled target 64.462081
saving model...
S painting T real Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.658459 Loss T 0.050908 Method MME

S painting T real Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.192119 Loss T 0.035946 Method MME

S painting T real Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.259577 Loss T 0.025805 Method MME

S painting T real Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.262492 Loss T 0.049590 Method MME

S painting T real Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.304745 Loss T 0.033326 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1384, Accuracy: 1089/1134 F1 (96.0317%)


Test set: Average loss: 1.0497, Accuracy: 55060/69960 F1 (78.7021%)


Val set: Average loss: 1.2633, Accuracy: 268/360 F1 (74.4444%)

best acc test 78.702115  acc val 74.444444 acc labeled target 96.031746
saving model...
S painting T real Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.293392 Loss T 0.047689 Method MME

S painting T real Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.331602 Loss T 0.042382 Method MME

S painting T real Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.031231 Loss T 0.034643 Method MME

S painting T real Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.415621 Loss T 0.051569 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 0.7777778 0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.7777778 0.8888889 1.        1.
 0.7777778 1.        1.        1.        1.        1.        0.8888889
 0.7777778 1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        0.7777778
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.7777778 0.8888889 0.8888889 1.       ]
Top k classes which perform poorly are:  [77, 122, 29, 84, 90, 104, 73, 101, 28, 30, 33, 38, 43, 44, 50, 26, 52, 53, 54, 61, 124, 83, 67, 96, 108, 74, 23, 1, 123, 4, 6, 7, 11, 15, 115, 114, 12, 21, 103, 87, 86, 85, 106, 111, 121, 82, 81, 110, 80, 79, 78, 107, 76, 88, 89, 120, 119, 113, 100, 99, 98, 97, 112, 116, 102, 117, 94, 93, 92, 109, 91, 105, 118, 95, 0, 62, 72, 35, 34, 32, 31, 27, 25, 24, 22, 20, 19, 18, 17, 16, 14, 13, 10, 9, 8, 5, 3, 2, 36, 37, 39, 40, 71, 70, 69, 68, 66, 65, 64, 63, 60, 59, 75, 58, 56, 55, 51, 49, 48, 47, 46, 45, 42, 41, 57, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2297, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7703, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.201005 Loss T 0.024417 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1651, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 1.3408, Accuracy: 51588/69960 F1 (73.7393%)


Val set: Average loss: 1.4576, Accuracy: 254/360 F1 (70.5556%)

best acc test 78.702115  acc val 70.555556 acc labeled target 95.943563
saving model...
S painting T real Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.441148 Loss T 0.025449 Method MME

S painting T real Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.105716 Loss T 0.043320 Method MME

S painting T real Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.061815 Loss T 0.042441 Method MME

S painting T real Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.345650 Loss T 0.035363 Method MME

S painting T real Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.211818 Loss T 0.041228 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0960, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.0844, Accuracy: 55430/69960 F1 (79.2310%)


Val set: Average loss: 1.2050, Accuracy: 280/360 F1 (77.7778%)

best acc test 79.230989  acc val 77.777778 acc labeled target 97.619048
saving model...
S painting T real Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.564342 Loss T 0.050460 Method MME

S painting T real Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.128684 Loss T 0.028269 Method MME

S painting T real Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.205207 Loss T 0.039114 Method MME

S painting T real Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.083980 Loss T 0.032739 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [61, 91, 52, 104, 82, 24, 54, 99, 109, 79, 18, 68, 101, 36, 113, 11, 10, 117, 38, 88, 5, 65, 2, 41, 115, 30, 86, 87, 85, 89, 84, 0, 81, 90, 78, 77, 76, 75, 74, 73, 72, 71, 83, 80, 97, 93, 123, 122, 121, 120, 119, 118, 116, 114, 112, 111, 92, 110, 107, 106, 105, 103, 102, 100, 98, 96, 95, 94, 108, 70, 62, 67, 31, 29, 28, 27, 26, 25, 23, 22, 21, 20, 19, 32, 17, 15, 14, 13, 12, 9, 8, 7, 6, 4, 3, 1, 16, 69, 33, 35, 66, 64, 63, 124, 60, 59, 58, 57, 56, 55, 53, 34, 51, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 37, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.219486 Loss T 0.029301 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2011, Accuracy: 1087/1134 F1 (95.8554%)


Test set: Average loss: 1.3678, Accuracy: 51906/69960 F1 (74.1938%)


Val set: Average loss: 1.5195, Accuracy: 255/360 F1 (70.8333%)

best acc test 79.230989  acc val 70.833333 acc labeled target 95.855379
saving model...
S painting T real Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.366607 Loss T 0.028121 Method MME

S painting T real Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.128804 Loss T 0.022998 Method MME

S painting T real Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.326318 Loss T 0.032380 Method MME

S painting T real Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.187392 Loss T 0.050880 Method MME

S painting T real Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.418608 Loss T 0.026843 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0892, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.0895, Accuracy: 55798/69960 F1 (79.7570%)


Val set: Average loss: 1.2979, Accuracy: 276/360 F1 (76.6667%)

best acc test 79.230989  acc val 76.666667 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.022042 Loss T 0.018415 Method MME

S painting T real Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.279424 Loss T 0.035817 Method MME

S painting T real Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.409451 Loss T 0.028800 Method MME

S painting T real Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.169999 Loss T 0.036641 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 0.8888889 1.        1.        1.        1.        0.7777778 1.       ]
Top k classes which perform poorly are:  [124, 6, 118, 10, 98, 25, 26, 28, 29, 97, 36, 94, 90, 88, 87, 84, 51, 105, 21, 67, 119, 86, 85, 121, 83, 82, 122, 81, 80, 79, 120, 106, 76, 75, 74, 73, 72, 123, 71, 70, 69, 77, 78, 89, 117, 108, 109, 104, 103, 110, 111, 102, 112, 113, 101, 100, 99, 68, 114, 96, 115, 95, 116, 93, 92, 91, 107, 0, 62, 65, 32, 31, 30, 27, 24, 23, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 5, 4, 3, 2, 1, 33, 66, 34, 37, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.240675 Loss T 0.026858 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2140, Accuracy: 1079/1134 F1 (95.1499%)


Test set: Average loss: 1.3403, Accuracy: 52603/69960 F1 (75.1901%)


Val set: Average loss: 1.5732, Accuracy: 259/360 F1 (71.9444%)

best acc test 79.230989  acc val 71.944444 acc labeled target 95.149912
saving model...
S painting T real Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.038078 Loss T 0.043488 Method MME

S painting T real Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.093424 Loss T 0.021394 Method MME

S painting T real Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.103404 Loss T 0.046230 Method MME

S painting T real Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.255987 Loss T 0.044234 Method MME

S painting T real Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.116696 Loss T 0.025857 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0954, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.1312, Accuracy: 55633/69960 F1 (79.5212%)


Val set: Average loss: 1.3297, Accuracy: 277/360 F1 (76.9444%)

best acc test 79.230989  acc val 76.944444 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.184774 Loss T 0.025413 Method MME

S painting T real Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.147649 Loss T 0.033507 Method MME

S painting T real Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.173242 Loss T 0.015992 Method MME

S painting T real Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.356667 Loss T 0.037805 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.       ]
Top k classes which perform poorly are:  [122, 80, 82, 23, 51, 29, 108, 86, 54, 88, 15, 14, 28, 57, 33, 75, 61, 90, 73, 5, 72, 91, 66, 12, 89, 87, 85, 0, 83, 81, 92, 79, 78, 77, 76, 74, 71, 84, 93, 98, 95, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 107, 106, 105, 104, 103, 102, 101, 100, 99, 70, 97, 96, 109, 69, 62, 67, 31, 30, 27, 26, 25, 24, 22, 21, 20, 19, 18, 32, 17, 13, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 16, 34, 35, 36, 65, 64, 63, 124, 60, 59, 58, 56, 55, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.208678 Loss T 0.035634 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1629, Accuracy: 1094/1134 F1 (96.4727%)


Test set: Average loss: 1.4112, Accuracy: 51673/69960 F1 (73.8608%)


Val set: Average loss: 1.7219, Accuracy: 244/360 F1 (67.7778%)

best acc test 79.230989  acc val 67.777778 acc labeled target 96.472663
saving model...
S painting T real Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.039534 Loss T 0.028798 Method MME

S painting T real Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.098557 Loss T 0.042522 Method MME

S painting T real Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.054848 Loss T 0.028693 Method MME

S painting T real Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.155026 Loss T 0.033776 Method MME

S painting T real Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.088632 Loss T 0.030633 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0993, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.1457, Accuracy: 55728/69960 F1 (79.6569%)


Val set: Average loss: 1.3240, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.230989  acc val 75.277778 acc labeled target 97.619048
saving model...
S painting T real Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.333088 Loss T 0.030442 Method MME

S painting T real Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.217283 Loss T 0.014489 Method MME

S painting T real Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.447074 Loss T 0.041615 Method MME

S painting T real Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.081633 Loss T 0.029091 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        0.7777778 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.7777778 1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.7777778 1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 96, 8, 77, 80, 91, 34, 88, 87, 101, 102, 85, 23, 82, 92, 16, 38, 59, 53, 55, 70, 61, 15, 69, 90, 71, 72, 89, 73, 78, 74, 75, 84, 76, 83, 81, 79, 86, 0, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 100, 99, 98, 97, 93, 68, 62, 65, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 14, 13, 12, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 30, 67, 31, 33, 64, 63, 124, 60, 58, 57, 56, 54, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 35, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.215619 Loss T 0.042966 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1738, Accuracy: 1090/1134 F1 (96.1199%)


Test set: Average loss: 1.3920, Accuracy: 52323/69960 F1 (74.7899%)


Val set: Average loss: 1.6376, Accuracy: 255/360 F1 (70.8333%)

best acc test 79.230989  acc val 70.833333 acc labeled target 96.119929
saving model...
S painting T real Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.200487 Loss T 0.029109 Method MME

S painting T real Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.064313 Loss T 0.025363 Method MME

S painting T real Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.094041 Loss T 0.033703 Method MME

S painting T real Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.118970 Loss T 0.030122 Method MME

S painting T real Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.155911 Loss T 0.028334 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0775, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.1222, Accuracy: 56148/69960 F1 (80.2573%)


Val set: Average loss: 1.2252, Accuracy: 281/360 F1 (78.0556%)

best acc test 80.257290  acc val 78.055556 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.019248 Loss T 0.019955 Method MME

S painting T real Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.187890 Loss T 0.021964 Method MME

S painting T real Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.327733 Loss T 0.016633 Method MME

S painting T real Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.046269 Loss T 0.031869 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 0.7777778 1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 0.8888889 1.       ]
Top k classes which perform poorly are:  [10, 66, 51, 80, 77, 109, 18, 111, 56, 114, 104, 12, 84, 9, 8, 43, 124, 122, 123, 103, 83, 86, 82, 87, 88, 81, 85, 76, 78, 89, 75, 74, 73, 72, 71, 70, 69, 79, 90, 0, 92, 121, 120, 119, 118, 117, 116, 115, 113, 112, 110, 108, 91, 107, 105, 102, 101, 100, 99, 98, 97, 68, 95, 94, 93, 106, 96, 62, 65, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 11, 7, 6, 5, 4, 3, 2, 1, 31, 32, 33, 34, 64, 63, 61, 60, 59, 58, 57, 55, 54, 53, 52, 50, 67, 49, 47, 46, 45, 44, 42, 41, 40, 39, 38, 37, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.091044 Loss T 0.022741 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1869, Accuracy: 1090/1134 F1 (96.1199%)


Test set: Average loss: 1.3877, Accuracy: 52493/69960 F1 (75.0329%)


Val set: Average loss: 1.5168, Accuracy: 263/360 F1 (73.0556%)

best acc test 80.257290  acc val 73.055556 acc labeled target 96.119929
saving model...
S painting T real Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.158555 Loss T 0.016175 Method MME

S painting T real Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.155568 Loss T 0.016088 Method MME

S painting T real Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.115771 Loss T 0.035800 Method MME

S painting T real Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.288559 Loss T 0.040398 Method MME

S painting T real Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.024663 Loss T 0.025979 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0564, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1580, Accuracy: 56216/69960 F1 (80.3545%)


Val set: Average loss: 1.3051, Accuracy: 278/360 F1 (77.2222%)

best acc test 80.257290  acc val 77.222222 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.099758 Loss T 0.030861 Method MME

S painting T real Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.013825 Loss T 0.023829 Method MME

S painting T real Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.168958 Loss T 0.034392 Method MME

S painting T real Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.204744 Loss T 0.024968 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [8, 53, 38, 88, 84, 82, 80, 78, 34, 57, 59, 36, 118, 1, 72, 6, 123, 74, 92, 91, 90, 89, 87, 86, 85, 83, 73, 70, 81, 71, 79, 77, 76, 75, 69, 0, 94, 68, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 93, 67, 62, 65, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 7, 5, 4, 3, 2, 29, 30, 31, 32, 64, 63, 124, 61, 60, 58, 56, 55, 54, 52, 51, 50, 66, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 35, 33, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.123302 Loss T 0.039272 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1190, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 1.3593, Accuracy: 53260/69960 F1 (76.1292%)


Val set: Average loss: 1.6562, Accuracy: 265/360 F1 (73.6111%)

best acc test 80.257290  acc val 73.611111 acc labeled target 97.354497
saving model...
S painting T real Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.097608 Loss T 0.032018 Method MME

S painting T real Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.157858 Loss T 0.038643 Method MME

S painting T real Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.034463 Loss T 0.020254 Method MME

S painting T real Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.117045 Loss T 0.022756 Method MME

S painting T real Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.204170 Loss T 0.031514 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0581, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1579, Accuracy: 56068/69960 F1 (80.1429%)


Val set: Average loss: 1.3633, Accuracy: 280/360 F1 (77.7778%)

best acc test 80.257290  acc val 77.777778 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.246928 Loss T 0.043326 Method MME

S painting T real Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.095114 Loss T 0.031784 Method MME

S painting T real Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.104622 Loss T 0.032712 Method MME

S painting T real Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.053147 Loss T 0.020110 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 13, 19, 94, 52, 82, 83, 12, 85, 23, 114, 116, 88, 61, 38, 21, 87, 84, 89, 90, 91, 86, 79, 80, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 81, 92, 0, 95, 123, 122, 121, 120, 119, 118, 117, 115, 113, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 67, 108, 96, 62, 64, 30, 29, 28, 27, 26, 25, 24, 22, 20, 18, 17, 16, 15, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 32, 33, 34, 63, 124, 60, 59, 58, 57, 56, 55, 54, 53, 51, 50, 65, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.020395 Loss T 0.026612 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1499, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.3778, Accuracy: 53064/69960 F1 (75.8491%)


Val set: Average loss: 1.6097, Accuracy: 249/360 F1 (69.1667%)

best acc test 80.257290  acc val 69.166667 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.070041 Loss T 0.026922 Method MME

S painting T real Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.101281 Loss T 0.039347 Method MME

S painting T real Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.212402 Loss T 0.043734 Method MME

S painting T real Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.237416 Loss T 0.037148 Method MME

S painting T real Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.053168 Loss T 0.017857 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0578, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.1413, Accuracy: 56401/69960 F1 (80.6189%)


Val set: Average loss: 1.2900, Accuracy: 278/360 F1 (77.2222%)

best acc test 80.257290  acc val 77.222222 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.010427 Loss T 0.009428 Method MME

S painting T real Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.075806 Loss T 0.032377 Method MME

S painting T real Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.173689 Loss T 0.021556 Method MME

S painting T real Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.061062 Loss T 0.023272 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [118, 0, 30, 31, 32, 36, 41, 92, 88, 87, 53, 54, 56, 78, 75, 66, 28, 106, 34, 11, 12, 6, 108, 117, 86, 85, 84, 83, 82, 119, 116, 81, 80, 79, 121, 77, 76, 122, 74, 73, 72, 123, 120, 89, 91, 109, 107, 110, 105, 104, 103, 102, 101, 100, 111, 99, 112, 113, 114, 98, 71, 97, 96, 95, 94, 93, 115, 90, 70, 62, 68, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 13, 10, 9, 8, 7, 5, 4, 3, 2, 1, 15, 33, 35, 37, 67, 65, 64, 63, 124, 61, 60, 59, 58, 57, 55, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 38, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.126245 Loss T 0.023187 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1322, Accuracy: 1091/1134 F1 (96.2081%)


Test set: Average loss: 1.3474, Accuracy: 53223/69960 F1 (76.0763%)


Val set: Average loss: 1.6758, Accuracy: 258/360 F1 (71.6667%)

best acc test 80.257290  acc val 71.666667 acc labeled target 96.208113
saving model...
S painting T real Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.080205 Loss T 0.021021 Method MME

S painting T real Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.024873 Loss T 0.021170 Method MME

S painting T real Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.096407 Loss T 0.024204 Method MME

S painting T real Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.073788 Loss T 0.030888 Method MME

S painting T real Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.038683 Loss T 0.021801 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0620, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.1430, Accuracy: 56592/69960 F1 (80.8919%)


Val set: Average loss: 1.3458, Accuracy: 277/360 F1 (76.9444%)

best acc test 80.257290  acc val 76.944444 acc labeled target 98.765432
saving model...
S painting T real Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.021722 Loss T 0.025757 Method MME

S painting T real Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.035979 Loss T 0.018692 Method MME

S painting T real Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.028637 Loss T 0.019174 Method MME

S painting T real Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.116402 Loss T 0.014538 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [100, 81, 2, 40, 71, 98, 6, 30, 118, 89, 46, 26, 52, 15, 85, 0, 87, 88, 90, 86, 84, 80, 82, 91, 79, 78, 77, 76, 75, 74, 73, 72, 70, 69, 83, 92, 97, 94, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 103, 102, 101, 99, 68, 96, 95, 109, 67, 62, 65, 31, 29, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 32, 17, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 1, 16, 66, 33, 35, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 34, 51, 49, 48, 47, 45, 44, 43, 42, 41, 39, 38, 37, 36, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.081274 Loss T 0.028274 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1110, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.3872, Accuracy: 52851/69960 F1 (75.5446%)


Val set: Average loss: 1.5033, Accuracy: 258/360 F1 (71.6667%)

best acc test 80.257290  acc val 71.666667 acc labeled target 97.707231
saving model...
S painting T real Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.221205 Loss T 0.018560 Method MME

S painting T real Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.075010 Loss T 0.024593 Method MME

S painting T real Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.025978 Loss T 0.033486 Method MME

S painting T real Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.156325 Loss T 0.026179 Method MME

S painting T real Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.121710 Loss T 0.036797 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0701, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.1489, Accuracy: 56655/69960 F1 (80.9820%)


Val set: Average loss: 1.3201, Accuracy: 279/360 F1 (77.5000%)

best acc test 80.257290  acc val 77.500000 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.008952 Loss T 0.033723 Method MME

S painting T real Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.095195 Loss T 0.012610 Method MME

S painting T real Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.090208 Loss T 0.012821 Method MME

S painting T real Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.050709 Loss T 0.011782 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [15, 62, 61, 55, 80, 82, 39, 38, 96, 34, 66, 98, 105, 23, 33, 13, 120, 12, 4, 122, 89, 88, 87, 86, 85, 84, 83, 81, 121, 79, 78, 77, 76, 75, 74, 123, 73, 72, 71, 70, 90, 91, 92, 93, 112, 111, 110, 109, 108, 107, 106, 114, 104, 103, 113, 102, 100, 99, 115, 97, 116, 117, 118, 95, 94, 119, 101, 69, 0, 67, 30, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 14, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 31, 68, 32, 36, 65, 64, 63, 124, 60, 59, 58, 57, 56, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.042492 Loss T 0.022136 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1362, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.3175, Accuracy: 53898/69960 F1 (77.0412%)


Val set: Average loss: 1.4534, Accuracy: 267/360 F1 (74.1667%)

best acc test 80.257290  acc val 74.166667 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.079427 Loss T 0.038613 Method MME

S painting T real Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.021920 Loss T 0.020192 Method MME

S painting T real Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.052471 Loss T 0.011744 Method MME

S painting T real Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.052370 Loss T 0.027980 Method MME

S painting T real Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.007122 Loss T 0.024940 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0738, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.1255, Accuracy: 56891/69960 F1 (81.3193%)


Val set: Average loss: 1.2689, Accuracy: 279/360 F1 (77.5000%)

best acc test 80.257290  acc val 77.500000 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.055225 Loss T 0.028202 Method MME

S painting T real Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.135556 Loss T 0.024957 Method MME

S painting T real Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.086541 Loss T 0.028367 Method MME

S painting T real Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.035752 Loss T 0.022578 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 0.8888889 0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [23, 15, 114, 96, 34, 42, 99, 45, 85, 84, 36, 79, 78, 77, 80, 11, 122, 63, 5, 13, 92, 70, 91, 90, 89, 88, 71, 87, 72, 73, 83, 82, 81, 74, 75, 76, 86, 93, 0, 95, 123, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 69, 94, 68, 62, 66, 30, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 14, 12, 10, 9, 8, 7, 6, 4, 3, 2, 1, 31, 32, 33, 35, 65, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 67, 52, 50, 49, 48, 47, 46, 44, 43, 41, 40, 39, 38, 37, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.080954 Loss T 0.025368 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1616, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.3045, Accuracy: 54240/69960 F1 (77.5300%)


Val set: Average loss: 1.4519, Accuracy: 271/360 F1 (75.2778%)

best acc test 80.257290  acc val 75.277778 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.025987 Loss T 0.024727 Method MME

S painting T real Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.141827 Loss T 0.012012 Method MME

S painting T real Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.067104 Loss T 0.029166 Method MME

S painting T real Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.044759 Loss T 0.053214 Method MME

S painting T real Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.052409 Loss T 0.027066 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0430, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.1005, Accuracy: 57026/69960 F1 (81.5123%)


Val set: Average loss: 1.2967, Accuracy: 281/360 F1 (78.0556%)

best acc test 81.512293  acc val 78.055556 acc labeled target 98.941799
saving model...
S painting T real Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.222325 Loss T 0.013404 Method MME

S painting T real Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.034626 Loss T 0.024816 Method MME

S painting T real Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.013211 Loss T 0.029227 Method MME

S painting T real Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.015896 Loss T 0.022524 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 31, 91, 98, 88, 23, 78, 110, 34, 61, 122, 73, 90, 89, 67, 68, 87, 86, 69, 85, 72, 84, 82, 81, 80, 92, 70, 71, 77, 76, 75, 74, 83, 79, 0, 94, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 96, 95, 108, 65, 62, 63, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 64, 30, 33, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.170599 Loss T 0.020373 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1216, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 1.2827, Accuracy: 54167/69960 F1 (77.4257%)


Val set: Average loss: 1.4373, Accuracy: 263/360 F1 (73.0556%)

best acc test 81.512293  acc val 73.055556 acc labeled target 96.913580
saving model...
S painting T real Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.067443 Loss T 0.023646 Method MME

S painting T real Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.012088 Loss T 0.025743 Method MME

S painting T real Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.041468 Loss T 0.015519 Method MME

S painting T real Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.009394 Loss T 0.016971 Method MME

S painting T real Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.012971 Loss T 0.029940 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0687, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.1129, Accuracy: 57032/69960 F1 (81.5209%)


Val set: Average loss: 1.3267, Accuracy: 282/360 F1 (78.3333%)

best acc test 81.520869  acc val 78.333333 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.115896 Loss T 0.023838 Method MME

S painting T real Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.046170 Loss T 0.034806 Method MME

S painting T real Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.024933 Loss T 0.030771 Method MME

S painting T real Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.112985 Loss T 0.039647 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 1.        0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [12, 66, 53, 58, 112, 50, 114, 115, 88, 28, 118, 6, 119, 67, 104, 78, 24, 117, 55, 83, 82, 84, 85, 86, 87, 81, 80, 76, 77, 75, 74, 73, 72, 71, 70, 69, 68, 79, 89, 0, 91, 123, 122, 121, 120, 116, 113, 111, 110, 109, 108, 107, 90, 106, 103, 102, 101, 100, 99, 98, 97, 96, 94, 93, 92, 105, 95, 62, 64, 29, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 30, 31, 32, 33, 63, 124, 61, 60, 59, 57, 56, 54, 52, 51, 49, 48, 65, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.058170 Loss T 0.019324 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1644, Accuracy: 1091/1134 F1 (96.2081%)


Test set: Average loss: 1.3054, Accuracy: 53969/69960 F1 (77.1427%)


Val set: Average loss: 1.4684, Accuracy: 264/360 F1 (73.3333%)

best acc test 81.520869  acc val 73.333333 acc labeled target 96.208113
saving model...
S painting T real Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.031815 Loss T 0.021922 Method MME

S painting T real Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.006878 Loss T 0.024050 Method MME

S painting T real Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.062396 Loss T 0.014271 Method MME

S painting T real Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.060733 Loss T 0.025007 Method MME

S painting T real Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.269839 Loss T 0.033787 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0547, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.1175, Accuracy: 57139/69960 F1 (81.6738%)


Val set: Average loss: 1.3063, Accuracy: 278/360 F1 (77.2222%)

best acc test 81.520869  acc val 77.222222 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.011705 Loss T 0.030434 Method MME

S painting T real Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.013869 Loss T 0.029399 Method MME

S painting T real Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.060611 Loss T 0.020389 Method MME

S painting T real Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.049852 Loss T 0.017580 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [90, 66, 68, 42, 99, 45, 23, 82, 54, 78, 15, 14, 13, 37, 75, 122, 118, 6, 76, 91, 69, 89, 70, 71, 88, 87, 72, 85, 77, 84, 83, 81, 80, 92, 73, 74, 86, 79, 0, 94, 123, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 95, 93, 96, 62, 65, 30, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 31, 32, 33, 34, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 53, 52, 67, 51, 49, 48, 47, 46, 44, 43, 41, 40, 39, 38, 36, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.023645 Loss T 0.014454 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0963, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.2937, Accuracy: 54177/69960 F1 (77.4400%)


Val set: Average loss: 1.4751, Accuracy: 267/360 F1 (74.1667%)

best acc test 81.520869  acc val 74.166667 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.061162 Loss T 0.033484 Method MME

S painting T real Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.035930 Loss T 0.027502 Method MME

S painting T real Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.028106 Loss T 0.024956 Method MME

S painting T real Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.032608 Loss T 0.012478 Method MME

S painting T real Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.034496 Loss T 0.020255 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0662, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1036, Accuracy: 57280/69960 F1 (81.8754%)


Val set: Average loss: 1.3324, Accuracy: 279/360 F1 (77.5000%)

best acc test 81.520869  acc val 77.500000 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.007553 Loss T 0.024063 Method MME

S painting T real Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.011493 Loss T 0.022841 Method MME

S painting T real Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.150749 Loss T 0.025653 Method MME

S painting T real Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.018803 Loss T 0.021861 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [62, 23, 105, 51, 80, 110, 99, 31, 32, 24, 12, 8, 96, 118, 124, 121, 122, 10, 86, 87, 85, 84, 83, 88, 89, 82, 79, 90, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 81, 91, 98, 93, 123, 120, 119, 117, 116, 115, 114, 113, 112, 111, 109, 108, 107, 106, 104, 103, 102, 101, 100, 68, 97, 95, 94, 92, 67, 0, 65, 30, 29, 28, 27, 26, 25, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 9, 7, 6, 5, 4, 3, 2, 1, 33, 34, 35, 36, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 66, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.140278 Loss T 0.026105 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1378, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 1.3341, Accuracy: 53751/69960 F1 (76.8310%)


Val set: Average loss: 1.5512, Accuracy: 264/360 F1 (73.3333%)

best acc test 81.520869  acc val 73.333333 acc labeled target 96.913580
saving model...
S painting T real Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.155539 Loss T 0.021041 Method MME

S painting T real Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.041775 Loss T 0.012603 Method MME

S painting T real Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.012342 Loss T 0.016769 Method MME

S painting T real Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.050347 Loss T 0.018440 Method MME

S painting T real Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.063781 Loss T 0.035841 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0585, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 1.1256, Accuracy: 57262/69960 F1 (81.8496%)


Val set: Average loss: 1.3143, Accuracy: 281/360 F1 (78.0556%)

best acc test 81.520869  acc val 78.055556 acc labeled target 99.029982
saving model...
S painting T real Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.033460 Loss T 0.022800 Method MME

S painting T real Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.042718 Loss T 0.018626 Method MME

S painting T real Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.005456 Loss T 0.032224 Method MME

S painting T real Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.081178 Loss T 0.019315 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [74, 48, 80, 66, 83, 14, 9, 46, 89, 2, 67, 87, 82, 86, 85, 84, 90, 91, 92, 88, 0, 79, 78, 77, 76, 75, 73, 72, 71, 70, 69, 68, 81, 93, 95, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 94, 65, 62, 63, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 30, 17, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 1, 16, 31, 32, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.265323 Loss T 0.019949 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1018, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.2459, Accuracy: 54820/69960 F1 (78.3591%)


Val set: Average loss: 1.4818, Accuracy: 266/360 F1 (73.8889%)

best acc test 81.520869  acc val 73.888889 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.202936 Loss T 0.025216 Method MME

S painting T real Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.011414 Loss T 0.014379 Method MME

S painting T real Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.037126 Loss T 0.029607 Method MME

S painting T real Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.070179 Loss T 0.031010 Method MME

S painting T real Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.067471 Loss T 0.032921 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0660, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1458, Accuracy: 57260/69960 F1 (81.8468%)


Val set: Average loss: 1.4826, Accuracy: 270/360 F1 (75.0000%)

best acc test 81.520869  acc val 75.000000 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.189959 Loss T 0.011653 Method MME

S painting T real Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.007757 Loss T 0.015745 Method MME

S painting T real Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.025697 Loss T 0.018159 Method MME

S painting T real Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.183416 Loss T 0.017122 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [13, 97, 61, 75, 81, 84, 38, 94, 99, 26, 104, 21, 15, 66, 6, 2, 118, 113, 88, 87, 86, 85, 121, 83, 82, 122, 80, 79, 78, 77, 76, 74, 73, 72, 71, 123, 70, 69, 68, 89, 90, 91, 92, 115, 112, 111, 110, 109, 108, 116, 107, 106, 105, 114, 117, 102, 101, 100, 119, 98, 67, 96, 95, 93, 120, 103, 0, 62, 64, 31, 30, 29, 28, 27, 25, 24, 23, 22, 20, 19, 18, 17, 16, 14, 12, 11, 10, 9, 8, 7, 5, 4, 3, 1, 32, 33, 34, 35, 63, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 65, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.073383 Loss T 0.033828 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1431, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.2766, Accuracy: 54582/69960 F1 (78.0189%)


Val set: Average loss: 1.4898, Accuracy: 270/360 F1 (75.0000%)

best acc test 81.520869  acc val 75.000000 acc labeled target 97.089947
saving model...
S painting T real Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.012180 Loss T 0.012347 Method MME

S painting T real Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.229216 Loss T 0.030782 Method MME

S painting T real Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.017857 Loss T 0.038586 Method MME

S painting T real Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.045809 Loss T 0.039307 Method MME

S painting T real Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.280314 Loss T 0.026956 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0489, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.1483, Accuracy: 57261/69960 F1 (81.8482%)


Val set: Average loss: 1.3466, Accuracy: 280/360 F1 (77.7778%)

best acc test 81.520869  acc val 77.777778 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.046447 Loss T 0.031671 Method MME

S painting T real Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.037808 Loss T 0.005100 Method MME

S painting T real Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.185165 Loss T 0.019086 Method MME

S painting T real Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.029762 Loss T 0.023770 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.7777778 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.7777778 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [84, 11, 80, 24, 120, 88, 6, 118, 103, 27, 23, 12, 28, 113, 0, 85, 87, 89, 90, 91, 86, 83, 79, 81, 92, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 82, 93, 99, 95, 123, 122, 121, 119, 117, 116, 115, 114, 112, 111, 110, 94, 109, 107, 106, 105, 104, 102, 101, 100, 67, 98, 97, 96, 108, 66, 62, 64, 33, 32, 31, 30, 29, 26, 25, 22, 21, 20, 19, 18, 34, 17, 15, 14, 13, 10, 9, 8, 7, 5, 4, 3, 2, 1, 16, 65, 35, 37, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 36, 51, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.004037 Loss T 0.035897 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1326, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.2932, Accuracy: 54461/69960 F1 (77.8459%)


Val set: Average loss: 1.3652, Accuracy: 274/360 F1 (76.1111%)

best acc test 81.520869  acc val 76.111111 acc labeled target 97.442681
saving model...
S painting T real Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.015813 Loss T 0.024058 Method MME

S painting T real Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.133845 Loss T 0.025350 Method MME

S painting T real Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.114117 Loss T 0.032615 Method MME

S painting T real Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.050365 Loss T 0.013656 Method MME

S painting T real Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.044518 Loss T 0.015967 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0823, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1575, Accuracy: 57371/69960 F1 (82.0054%)


Val set: Average loss: 1.3461, Accuracy: 281/360 F1 (78.0556%)

best acc test 81.520869  acc val 78.055556 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.014443 Loss T 0.016257 Method MME

S painting T real Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.015545 Loss T 0.019987 Method MME

S painting T real Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.053789 Loss T 0.019196 Method MME

S painting T real Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.029363 Loss T 0.019533 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.7777778 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [122, 19, 37, 48, 29, 83, 108, 21, 15, 12, 11, 41, 123, 8, 2, 118, 121, 72, 91, 90, 89, 88, 87, 86, 85, 84, 82, 73, 81, 71, 80, 79, 92, 78, 77, 76, 75, 74, 70, 0, 99, 94, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 93, 107, 105, 104, 103, 102, 101, 100, 69, 98, 97, 96, 95, 106, 68, 62, 66, 33, 32, 31, 30, 28, 27, 26, 25, 24, 23, 22, 20, 18, 17, 16, 14, 13, 10, 9, 7, 6, 5, 4, 3, 1, 34, 67, 35, 38, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 44, 43, 42, 40, 39, 36, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2297, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7703, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.007077 Loss T 0.032993 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1259, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.2848, Accuracy: 54585/69960 F1 (78.0232%)


Val set: Average loss: 1.4826, Accuracy: 264/360 F1 (73.3333%)

best acc test 81.520869  acc val 73.333333 acc labeled target 97.266314
saving model...
S painting T real Train Ep: 28100 lr0.0036669608075000928 	 Loss Classification: 0.096315 Loss T 0.027446 Method MME

S painting T real Train Ep: 28200 lr0.00365975891867815 	 Loss Classification: 0.007214 Loss T 0.019265 Method MME

S painting T real Train Ep: 28300 lr0.003652589947415138 	 Loss Classification: 0.053433 Loss T 0.025997 Method MME

S painting T real Train Ep: 28400 lr0.0036454536578964408 	 Loss Classification: 0.005972 Loss T 0.023020 Method MME

S painting T real Train Ep: 28500 lr0.0036383498166050877 	 Loss Classification: 0.209280 Loss T 0.011561 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0773, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.1185, Accuracy: 57584/69960 F1 (82.3099%)


Val set: Average loss: 1.3365, Accuracy: 275/360 F1 (76.3889%)

best acc test 81.520869  acc val 76.388889 acc labeled target 97.707231
saving model...
S painting T real Train Ep: 28600 lr0.0036312781922934662 	 Loss Classification: 0.013976 Loss T 0.016791 Method MME

S painting T real Train Ep: 28700 lr0.003624238555955462 	 Loss Classification: 0.029782 Loss T 0.028770 Method MME

S painting T real Train Ep: 28800 lr0.003617230680799007 	 Loss Classification: 0.013337 Loss T 0.018792 Method MME

S painting T real Train Ep: 28900 lr0.0036102543422190363 	 Loss Classification: 0.072957 Loss T 0.017035 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.7777778 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [88, 58, 100, 30, 98, 67, 37, 38, 89, 62, 46, 52, 79, 77, 73, 66, 24, 23, 34, 11, 118, 12, 114, 7, 108, 87, 86, 85, 84, 83, 82, 81, 80, 78, 120, 121, 76, 75, 74, 122, 72, 71, 123, 119, 117, 90, 109, 107, 106, 105, 110, 111, 104, 103, 102, 101, 116, 112, 99, 97, 96, 95, 115, 94, 93, 92, 91, 113, 70, 0, 68, 29, 28, 27, 26, 25, 22, 21, 20, 19, 18, 17, 31, 16, 14, 13, 10, 9, 8, 6, 5, 4, 3, 2, 1, 15, 32, 33, 35, 65, 64, 63, 124, 61, 60, 59, 57, 56, 55, 54, 53, 51, 50, 49, 48, 47, 45, 44, 43, 42, 41, 40, 39, 36, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 29000 lr0.003603309317770844 	 Loss Classification: 0.049605 Loss T 0.017436 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1638, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.2513, Accuracy: 54913/69960 F1 (78.4920%)


Val set: Average loss: 1.4143, Accuracy: 273/360 F1 (75.8333%)

best acc test 81.520869  acc val 75.833333 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 29100 lr0.0035963953871438275 	 Loss Classification: 0.088505 Loss T 0.014501 Method MME

S painting T real Train Ep: 29200 lr0.0035895123321356215 	 Loss Classification: 0.005377 Loss T 0.028266 Method MME

S painting T real Train Ep: 29300 lr0.003582659936626608 	 Loss Classification: 0.009722 Loss T 0.022901 Method MME

S painting T real Train Ep: 29400 lr0.0035758379865547998 	 Loss Classification: 0.012352 Loss T 0.042877 Method MME

S painting T real Train Ep: 29500 lr0.0035690462698910875 	 Loss Classification: 0.011847 Loss T 0.013100 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0669, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.1070, Accuracy: 57675/69960 F1 (82.4400%)


Val set: Average loss: 1.2528, Accuracy: 287/360 F1 (79.7222%)

best acc test 82.439966  acc val 79.722222 acc labeled target 98.236332
saving model...
S painting T real Train Ep: 29600 lr0.0035622845766148485 	 Loss Classification: 0.095020 Loss T 0.017092 Method MME

S painting T real Train Ep: 29700 lr0.0035555526986899093 	 Loss Classification: 0.212708 Loss T 0.017859 Method MME

S painting T real Train Ep: 29800 lr0.0035488504300408524 	 Loss Classification: 0.043473 Loss T 0.041206 Method MME

S painting T real Train Ep: 29900 lr0.0035421775665296674 	 Loss Classification: 0.042999 Loss T 0.016799 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.7777778 1.        0.8888889 1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 0.7777778 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [90, 38, 77, 51, 32, 40, 42, 87, 45, 111, 78, 12, 35, 114, 71, 72, 55, 69, 70, 89, 88, 73, 74, 86, 75, 84, 83, 82, 81, 91, 80, 79, 76, 85, 0, 93, 68, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 110, 109, 92, 108, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 107, 67, 62, 65, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 27, 28, 29, 30, 64, 63, 124, 61, 60, 59, 58, 57, 56, 54, 53, 52, 66, 50, 48, 47, 46, 44, 43, 41, 39, 37, 36, 34, 33, 31, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 30000 lr0.003535533905932738 	 Loss Classification: 0.045047 Loss T 0.012354 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1589, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.2908, Accuracy: 54434/69960 F1 (77.8073%)


Val set: Average loss: 1.4234, Accuracy: 267/360 F1 (74.1667%)

best acc test 82.439966  acc val 74.166667 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 30100 lr0.0035289192479181558 	 Loss Classification: 0.216763 Loss T 0.012573 Method MME

S painting T real Train Ep: 30200 lr0.003522333394023364 	 Loss Classification: 0.010207 Loss T 0.011496 Method MME

S painting T real Train Ep: 30300 lr0.0035157761476331158 	 Loss Classification: 0.019367 Loss T 0.023357 Method MME

S painting T real Train Ep: 30400 lr0.003509247313957748 	 Loss Classification: 0.123622 Loss T 0.023520 Method MME

S painting T real Train Ep: 30500 lr0.003502746700011762 	 Loss Classification: 0.032521 Loss T 0.030738 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0787, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.1477, Accuracy: 57557/69960 F1 (82.2713%)


Val set: Average loss: 1.3649, Accuracy: 279/360 F1 (77.5000%)

best acc test 82.439966  acc val 77.500000 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 30600 lr0.003496274114592713 	 Loss Classification: 0.015012 Loss T 0.023990 Method MME

S painting T real Train Ep: 30700 lr0.0034898293682603908 	 Loss Classification: 0.041206 Loss T 0.020355 Method MME

S painting T real Train Ep: 30800 lr0.0034834122733162975 	 Loss Classification: 0.160867 Loss T 0.023917 Method MME

S painting T real Train Ep: 30900 lr0.0034770226437834152 	 Loss Classification: 0.048570 Loss T 0.020521 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.7777778 1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [112, 66, 36, 94, 96, 29, 100, 81, 78, 20, 89, 16, 108, 11, 123, 72, 121, 117, 118, 6, 74, 68, 88, 87, 86, 85, 69, 70, 82, 83, 73, 80, 79, 71, 77, 76, 75, 84, 90, 0, 92, 122, 120, 119, 116, 115, 114, 113, 111, 110, 109, 91, 107, 105, 104, 103, 102, 101, 99, 98, 67, 95, 93, 106, 97, 62, 64, 31, 30, 28, 27, 26, 25, 24, 23, 22, 21, 19, 18, 32, 17, 14, 13, 12, 10, 9, 8, 7, 5, 4, 3, 2, 1, 15, 33, 34, 35, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 31000 lr0.003470660295386255 	 Loss Classification: 0.088610 Loss T 0.010690 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1173, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.2886, Accuracy: 54583/69960 F1 (78.0203%)


Val set: Average loss: 1.4710, Accuracy: 266/360 F1 (73.8889%)

best acc test 82.439966  acc val 73.888889 acc labeled target 97.266314
saving model...
S painting T real Train Ep: 31100 lr0.0034643250455311855 	 Loss Classification: 0.050626 Loss T 0.014772 Method MME

S painting T real Train Ep: 31200 lr0.0034580167132870383 	 Loss Classification: 0.008258 Loss T 0.033197 Method MME

S painting T real Train Ep: 31300 lr0.00345173511936598 	 Loss Classification: 0.012204 Loss T 0.009527 Method MME

S painting T real Train Ep: 31400 lr0.0034454800861046533 	 Loss Classification: 0.017669 Loss T 0.018485 Method MME

S painting T real Train Ep: 31500 lr0.003439251437445577 	 Loss Classification: 0.077257 Loss T 0.008047 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0613, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.1403, Accuracy: 57616/69960 F1 (82.3556%)


Val set: Average loss: 1.3387, Accuracy: 277/360 F1 (76.9444%)

best acc test 82.439966  acc val 76.944444 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 31600 lr0.0034330489989188046 	 Loss Classification: 0.109835 Loss T 0.027613 Method MME

S painting T real Train Ep: 31700 lr0.0034268725976238346 	 Loss Classification: 0.018096 Loss T 0.024021 Method MME

S painting T real Train Ep: 31800 lr0.003420722062211772 	 Loss Classification: 0.033245 Loss T 0.019815 Method MME

S painting T real Train Ep: 31900 lr0.0034145972228677326 	 Loss Classification: 0.042404 Loss T 0.016672 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [52, 62, 84, 51, 12, 76, 81, 9, 26, 117, 29, 31, 124, 83, 89, 90, 87, 86, 85, 91, 88, 79, 80, 92, 78, 77, 75, 74, 73, 72, 71, 70, 69, 82, 93, 97, 95, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 68, 96, 94, 67, 0, 65, 30, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 32, 16, 14, 13, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 15, 66, 33, 35, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 50, 34, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 32000 lr0.0034084979112934868 	 Loss Classification: 0.140083 Loss T 0.019692 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1122, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.2722, Accuracy: 55074/69960 F1 (78.7221%)


Val set: Average loss: 1.4094, Accuracy: 271/360 F1 (75.2778%)

best acc test 82.439966  acc val 75.277778 acc labeled target 97.266314
saving model...
S painting T real Train Ep: 32100 lr0.003402423960690348 	 Loss Classification: 0.080913 Loss T 0.029808 Method MME

S painting T real Train Ep: 32200 lr0.0033963752057422827 	 Loss Classification: 0.138927 Loss T 0.015335 Method MME

S painting T real Train Ep: 32300 lr0.003390351482599261 	 Loss Classification: 0.034852 Loss T 0.018332 Method MME

S painting T real Train Ep: 32400 lr0.003384352628860824 	 Loss Classification: 0.242063 Loss T 0.013845 Method MME

S painting T real Train Ep: 32500 lr0.003378378483559883 	 Loss Classification: 0.146645 Loss T 0.021717 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0580, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1525, Accuracy: 57600/69960 F1 (82.3328%)


Val set: Average loss: 1.3449, Accuracy: 284/360 F1 (78.8889%)

best acc test 82.439966  acc val 78.888889 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 32600 lr0.0033724288871467283 	 Loss Classification: 0.004889 Loss T 0.024818 Method MME

S painting T real Train Ep: 32700 lr0.003366503681473259 	 Loss Classification: 0.065316 Loss T 0.013252 Method MME

S painting T real Train Ep: 32800 lr0.0033606027097774233 	 Loss Classification: 0.055633 Loss T 0.013728 Method MME

S painting T real Train Ep: 32900 lr0.003354725816667868 	 Loss Classification: 0.018138 Loss T 0.019380 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 61, 58, 55, 76, 77, 84, 40, 37, 98, 26, 110, 111, 94, 13, 12, 122, 87, 86, 85, 118, 83, 82, 81, 80, 79, 78, 119, 112, 75, 121, 74, 73, 72, 71, 123, 70, 69, 68, 88, 120, 117, 90, 113, 109, 108, 107, 106, 105, 104, 103, 102, 101, 89, 114, 99, 115, 97, 96, 95, 67, 93, 92, 91, 116, 100, 0, 62, 64, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 63, 124, 60, 59, 57, 56, 54, 53, 52, 51, 50, 49, 65, 48, 46, 45, 44, 43, 42, 41, 39, 38, 36, 35, 34, 33, 47, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 33000 lr0.00334887284810879 	 Loss Classification: 0.052885 Loss T 0.023780 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1616, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.2778, Accuracy: 54875/69960 F1 (78.4377%)


Val set: Average loss: 1.4389, Accuracy: 265/360 F1 (73.6111%)

best acc test 82.439966  acc val 73.611111 acc labeled target 96.825397
saving model...
S painting T real Train Ep: 33100 lr0.003343043651404997 	 Loss Classification: 0.008509 Loss T 0.016039 Method MME

S painting T real Train Ep: 33200 lr0.0033372380751871583 	 Loss Classification: 0.046578 Loss T 0.010588 Method MME

S painting T real Train Ep: 33300 lr0.0033314559693972583 	 Loss Classification: 0.017160 Loss T 0.009948 Method MME

S painting T real Train Ep: 33400 lr0.0033256971852742394 	 Loss Classification: 0.048043 Loss T 0.021322 Method MME

S painting T real Train Ep: 33500 lr0.0033199615753398367 	 Loss Classification: 0.047484 Loss T 0.014028 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0444, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.1415, Accuracy: 57725/69960 F1 (82.5114%)


Val set: Average loss: 1.3193, Accuracy: 282/360 F1 (78.3333%)

best acc test 82.439966  acc val 78.333333 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 33600 lr0.0033142489933845978 	 Loss Classification: 0.010913 Loss T 0.010712 Method MME

S painting T real Train Ep: 33700 lr0.0033085592944540883 	 Loss Classification: 0.053463 Loss T 0.013422 Method MME

S painting T real Train Ep: 33800 lr0.003302892334835276 	 Loss Classification: 0.056916 Loss T 0.023840 Method MME

S painting T real Train Ep: 33900 lr0.003297247972043097 	 Loss Classification: 0.009365 Loss T 0.011388 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [34, 78, 107, 51, 53, 13, 74, 103, 42, 80, 119, 88, 122, 89, 116, 85, 86, 83, 87, 82, 81, 84, 0, 90, 76, 75, 73, 72, 71, 70, 69, 68, 67, 79, 77, 93, 92, 123, 121, 120, 118, 117, 115, 114, 113, 112, 111, 110, 109, 91, 108, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 94, 66, 106, 65, 62, 63, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 29, 30, 31, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 33, 32, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 34000 lr0.0032916260648071937 	 Loss Classification: 0.012481 Loss T 0.015657 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1288, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 1.2740, Accuracy: 54849/69960 F1 (78.4005%)


Val set: Average loss: 1.4519, Accuracy: 267/360 F1 (74.1667%)

best acc test 82.439966  acc val 74.166667 acc labeled target 97.001764
saving model...
S painting T real Train Ep: 34100 lr0.0032860264730588296 	 Loss Classification: 0.019663 Loss T 0.012319 Method MME

S painting T real Train Ep: 34200 lr0.003280449057917969 	 Loss Classification: 0.020773 Loss T 0.015415 Method MME

S painting T real Train Ep: 34300 lr0.0032748936816805302 	 Loss Classification: 0.010984 Loss T 0.020813 Method MME

S painting T real Train Ep: 34400 lr0.0032693602078058027 	 Loss Classification: 0.011040 Loss T 0.020693 Method MME

S painting T real Train Ep: 34500 lr0.0032638485009040203 	 Loss Classification: 0.021617 Loss T 0.017796 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0558, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.1660, Accuracy: 57643/69960 F1 (82.3942%)


Val set: Average loss: 1.3263, Accuracy: 281/360 F1 (78.0556%)

best acc test 82.439966  acc val 78.055556 acc labeled target 98.765432
saving model...
S painting T real Train Ep: 34600 lr0.0032583584267241073 	 Loss Classification: 0.007015 Loss T 0.016040 Method MME

S painting T real Train Ep: 34700 lr0.0032528898521415684 	 Loss Classification: 0.009434 Loss T 0.018975 Method MME

S painting T real Train Ep: 34800 lr0.0032474426451465444 	 Loss Classification: 0.133821 Loss T 0.021609 Method MME

S painting T real Train Ep: 34900 lr0.0032420166748320153 	 Loss Classification: 0.009542 Loss T 0.008639 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [66, 90, 20, 53, 14, 58, 8, 76, 6, 123, 118, 122, 121, 37, 68, 70, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 71, 72, 77, 69, 91, 75, 74, 73, 78, 0, 93, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 92, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 67, 95, 94, 106, 96, 62, 64, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 19, 18, 31, 17, 15, 13, 12, 11, 10, 9, 7, 5, 4, 3, 2, 1, 16, 65, 32, 34, 63, 124, 61, 60, 59, 57, 56, 55, 54, 52, 51, 50, 33, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 35000 lr0.0032366118113821563 	 Loss Classification: 0.027776 Loss T 0.015798 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0961, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.2679, Accuracy: 55040/69960 F1 (78.6735%)


Val set: Average loss: 1.4446, Accuracy: 277/360 F1 (76.9444%)

best acc test 82.439966  acc val 76.944444 acc labeled target 98.059965
saving model...
S painting T real Train Ep: 35100 lr0.0032312279260608436 	 Loss Classification: 0.004218 Loss T 0.015578 Method MME

S painting T real Train Ep: 35200 lr0.0032258648912003012 	 Loss Classification: 0.004916 Loss T 0.020405 Method MME

S painting T real Train Ep: 35300 lr0.003220522580189901 	 Loss Classification: 0.020280 Loss T 0.023205 Method MME

S painting T real Train Ep: 35400 lr0.0032152008674650925 	 Loss Classification: 0.050585 Loss T 0.015056 Method MME

S painting T real Train Ep: 35500 lr0.0032098996284964853 	 Loss Classification: 0.041570 Loss T 0.020190 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0548, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.1497, Accuracy: 57791/69960 F1 (82.6058%)


Val set: Average loss: 1.2494, Accuracy: 293/360 F1 (81.3889%)

best acc test 82.605775  acc val 81.388889 acc labeled target 98.941799
saving model...
S painting T real Train Ep: 35600 lr0.0032046187397790603 	 Loss Classification: 0.004881 Loss T 0.013749 Method MME

S painting T real Train Ep: 35700 lr0.0031993580788215194 	 Loss Classification: 0.021808 Loss T 0.021469 Method MME

S painting T real Train Ep: 35800 lr0.0031941175241357693 	 Loss Classification: 0.053706 Loss T 0.019160 Method MME

S painting T real Train Ep: 35900 lr0.0031888969552265386 	 Loss Classification: 0.024836 Loss T 0.018997 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [51, 109, 48, 23, 112, 11, 18, 44, 85, 41, 58, 20, 86, 84, 87, 83, 88, 89, 90, 82, 0, 91, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 81, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 68, 93, 67, 62, 65, 29, 28, 27, 26, 25, 24, 22, 21, 19, 17, 16, 15, 14, 13, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 31, 32, 33, 64, 63, 124, 61, 60, 59, 57, 56, 55, 54, 53, 52, 66, 50, 47, 46, 45, 43, 42, 40, 39, 38, 37, 36, 35, 34, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 36000 lr0.00318369625258112 	 Loss Classification: 0.025735 Loss T 0.023145 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1332, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.2625, Accuracy: 55269/69960 F1 (79.0009%)


Val set: Average loss: 1.4227, Accuracy: 271/360 F1 (75.2778%)

best acc test 82.605775  acc val 75.277778 acc labeled target 97.089947
saving model...
S painting T real Train Ep: 36100 lr0.0031785152976592465 	 Loss Classification: 0.033294 Loss T 0.013732 Method MME

S painting T real Train Ep: 36200 lr0.0031733539728830895 	 Loss Classification: 0.020097 Loss T 0.019044 Method MME

S painting T real Train Ep: 36300 lr0.003168212161627382 	 Loss Classification: 0.020611 Loss T 0.021000 Method MME

S painting T real Train Ep: 36400 lr0.0031630897482096652 	 Loss Classification: 0.013393 Loss T 0.027629 Method MME

S painting T real Train Ep: 36500 lr0.0031579866178806544 	 Loss Classification: 0.067545 Loss T 0.018643 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0599, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.1872, Accuracy: 57642/69960 F1 (82.3928%)


Val set: Average loss: 1.3142, Accuracy: 286/360 F1 (79.4444%)

best acc test 82.605775  acc val 79.444444 acc labeled target 98.236332
saving model...
S painting T real Train Ep: 36600 lr0.003152902656814724 	 Loss Classification: 0.151485 Loss T 0.019158 Method MME

S painting T real Train Ep: 36700 lr0.003147837752100511 	 Loss Classification: 0.013040 Loss T 0.019387 Method MME

S painting T real Train Ep: 36800 lr0.003142791791731634 	 Loss Classification: 0.015245 Loss T 0.024544 Method MME

S painting T real Train Ep: 36900 lr0.0031377646645975228 	 Loss Classification: 0.031561 Loss T 0.022516 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 0.8888889 0.8888889 1.
 0.7777778 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [14, 33, 40, 32, 27, 88, 87, 84, 37, 16, 12, 96, 10, 74, 11, 6, 75, 119, 8, 80, 71, 95, 94, 93, 72, 92, 91, 90, 89, 73, 77, 76, 86, 85, 78, 83, 82, 79, 81, 0, 98, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 70, 100, 99, 97, 69, 62, 67, 35, 34, 31, 30, 29, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 15, 13, 9, 7, 5, 4, 3, 2, 1, 36, 68, 38, 41, 66, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 39, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 37000 lr0.003132756260474365 	 Loss Classification: 0.007898 Loss T 0.019673 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1095, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.2880, Accuracy: 55088/69960 F1 (78.7421%)


Val set: Average loss: 1.4617, Accuracy: 267/360 F1 (74.1667%)

best acc test 82.605775  acc val 74.166667 acc labeled target 97.707231
saving model...
S painting T real Train Ep: 37100 lr0.0031277664700161607 	 Loss Classification: 0.005048 Loss T 0.013418 Method MME

S painting T real Train Ep: 37200 lr0.003122795184745882 	 Loss Classification: 0.017467 Loss T 0.022565 Method MME

S painting T real Train Ep: 37300 lr0.003117842297046751 	 Loss Classification: 0.087530 Loss T 0.017996 Method MME

S painting T real Train Ep: 37400 lr0.0031129077001536103 	 Loss Classification: 0.009674 Loss T 0.012729 Method MME

S painting T real Train Ep: 37500 lr0.00310799128814441 	 Loss Classification: 0.018939 Loss T 0.005983 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0456, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 1.1700, Accuracy: 57737/69960 F1 (82.5286%)


Val set: Average loss: 1.3798, Accuracy: 286/360 F1 (79.4444%)

best acc test 82.605775  acc val 79.444444 acc labeled target 98.500882
saving model...
S painting T real Train Ep: 37600 lr0.0031030929559317877 	 Loss Classification: 0.004841 Loss T 0.015499 Method MME

S painting T real Train Ep: 37700 lr0.003098212599254758 	 Loss Classification: 0.029500 Loss T 0.021321 Method MME

S painting T real Train Ep: 37800 lr0.003093350114670496 	 Loss Classification: 0.288247 Loss T 0.022031 Method MME

S painting T real Train Ep: 37900 lr0.003088505399546223 	 Loss Classification: 0.016240 Loss T 0.008666 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [18, 26, 27, 96, 79, 86, 56, 13, 83, 10, 23, 66, 71, 70, 2, 1, 59, 90, 88, 91, 87, 92, 85, 89, 0, 82, 81, 80, 78, 77, 76, 75, 74, 73, 72, 69, 84, 93, 99, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 94, 111, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 110, 68, 62, 65, 33, 32, 31, 30, 29, 28, 25, 24, 22, 21, 20, 19, 17, 16, 15, 14, 12, 11, 9, 8, 7, 6, 5, 4, 3, 34, 67, 35, 37, 64, 63, 124, 61, 60, 58, 57, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 38000 lr0.0030836783520511884 	 Loss Classification: 0.009184 Loss T 0.010323 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1155, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 1.2552, Accuracy: 55516/69960 F1 (79.3539%)


Val set: Average loss: 1.5000, Accuracy: 266/360 F1 (73.8889%)

best acc test 82.605775  acc val 73.888889 acc labeled target 97.354497
saving model...
S painting T real Train Ep: 38100 lr0.0030788688711487463 	 Loss Classification: 0.021488 Loss T 0.015355 Method MME

S painting T real Train Ep: 38200 lr0.0030740768565885295 	 Loss Classification: 0.017114 Loss T 0.011472 Method MME

S painting T real Train Ep: 38300 lr0.0030693022088987133 	 Loss Classification: 0.034805 Loss T 0.023800 Method MME

S painting T real Train Ep: 38400 lr0.0030645448293783735 	 Loss Classification: 0.115226 Loss T 0.015091 Method MME

S painting T real Train Ep: 38500 lr0.0030598046200899344 	 Loss Classification: 0.014514 Loss T 0.021292 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0519, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.1511, Accuracy: 57842/69960 F1 (82.6787%)


Val set: Average loss: 1.2640, Accuracy: 287/360 F1 (79.7222%)

best acc test 82.605775  acc val 79.722222 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 38600 lr0.0030550814838517073 	 Loss Classification: 0.027506 Loss T 0.025951 Method MME

S painting T real Train Ep: 38700 lr0.0030503753242305132 	 Loss Classification: 0.032117 Loss T 0.019360 Method MME

S painting T real Train Ep: 38800 lr0.003045686045534399 	 Loss Classification: 0.072476 Loss T 0.009510 Method MME

S painting T real Train Ep: 38900 lr0.003041013552805431 	 Loss Classification: 0.045830 Loss T 0.019806 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 54, 41, 42, 26, 25, 85, 112, 15, 14, 11, 37, 8, 2, 77, 78, 92, 70, 71, 91, 90, 89, 88, 87, 72, 86, 74, 84, 83, 82, 81, 93, 75, 80, 76, 79, 73, 0, 98, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 96, 109, 69, 62, 67, 32, 31, 30, 29, 28, 27, 24, 23, 22, 21, 20, 19, 18, 17, 16, 13, 12, 10, 9, 7, 6, 5, 4, 3, 1, 33, 68, 34, 36, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 40, 39, 38, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 39000 lr0.003036357751812582 	 Loss Classification: 0.011460 Loss T 0.018874 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1529, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 1.2556, Accuracy: 55406/69960 F1 (79.1967%)


Val set: Average loss: 1.3683, Accuracy: 276/360 F1 (76.6667%)

best acc test 82.605775  acc val 76.666667 acc labeled target 97.178131
saving model...
S painting T real Train Ep: 39100 lr0.0030317185490446956 	 Loss Classification: 0.123333 Loss T 0.011768 Method MME

S painting T real Train Ep: 39200 lr0.0030270958517035324 	 Loss Classification: 0.016596 Loss T 0.027457 Method MME

S painting T real Train Ep: 39300 lr0.003022489567696903 	 Loss Classification: 0.025629 Loss T 0.007186 Method MME

S painting T real Train Ep: 39400 lr0.0030178996056318755 	 Loss Classification: 0.006301 Loss T 0.030991 Method MME

S painting T real Train Ep: 39500 lr0.0030133258748080622 	 Loss Classification: 0.031681 Loss T 0.011534 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0388, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.1571, Accuracy: 57877/69960 F1 (82.7287%)


Val set: Average loss: 1.3748, Accuracy: 285/360 F1 (79.1667%)

best acc test 82.605775  acc val 79.166667 acc labeled target 98.941799
saving model...
S painting T real Train Ep: 39600 lr0.0030087682852109887 	 Loss Classification: 0.006616 Loss T 0.028354 Method MME

S painting T real Train Ep: 39700 lr0.0030042267475055367 	 Loss Classification: 0.015738 Loss T 0.019039 Method MME

S painting T real Train Ep: 39800 lr0.0029997011730294593 	 Loss Classification: 0.057574 Loss T 0.031954 Method MME

S painting T real Train Ep: 39900 lr0.0029951914737869757 	 Loss Classification: 0.148628 Loss T 0.016623 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [66, 123, 89, 38, 118, 51, 99, 78, 52, 11, 13, 0, 82, 83, 86, 85, 87, 88, 84, 81, 77, 79, 90, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 80, 91, 94, 93, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 92, 109, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 95, 108, 65, 62, 63, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 15, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 40000 lr0.0029906975624424408 	 Loss Classification: 0.045819 Loss T 0.018664 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1037, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 1.2419, Accuracy: 55755/69960 F1 (79.6955%)


Val set: Average loss: 1.3794, Accuracy: 281/360 F1 (78.0556%)

best acc test 82.605775  acc val 78.055556 acc labeled target 97.354497
saving model...
S painting T real Train Ep: 40100 lr0.0029862193523140824 	 Loss Classification: 0.019039 Loss T 0.011526 Method MME

S painting T real Train Ep: 40200 lr0.0029817567573678107 	 Loss Classification: 0.247221 Loss T 0.025046 Method MME

S painting T real Train Ep: 40300 lr0.0029773096922111057 	 Loss Classification: 0.019439 Loss T 0.014902 Method MME

S painting T real Train Ep: 40400 lr0.0029728780720869657 	 Loss Classification: 0.053123 Loss T 0.015232 Method MME

S painting T real Train Ep: 40500 lr0.002968461812867928 	 Loss Classification: 0.029203 Loss T 0.019485 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0644, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.1581, Accuracy: 57976/69960 F1 (82.8702%)


Val set: Average loss: 1.2378, Accuracy: 289/360 F1 (80.2778%)

best acc test 82.605775  acc val 80.277778 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 40600 lr0.0029640608310501576 	 Loss Classification: 0.029192 Loss T 0.027855 Method MME

S painting T real Train Ep: 40700 lr0.002959675043747607 	 Loss Classification: 0.030612 Loss T 0.005784 Method MME

S painting T real Train Ep: 40800 lr0.0029553043686862315 	 Loss Classification: 0.039521 Loss T 0.018863 Method MME

S painting T real Train Ep: 40900 lr0.0029509487241982826 	 Loss Classification: 0.128834 Loss T 0.011219 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 34, 43, 87, 85, 24, 23, 21, 36, 110, 78, 12, 94, 71, 69, 2, 118, 70, 11, 93, 92, 91, 90, 89, 88, 86, 77, 73, 84, 83, 82, 74, 75, 80, 79, 76, 72, 81, 0, 96, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 68, 95, 97, 62, 65, 31, 30, 29, 28, 27, 26, 25, 22, 20, 19, 18, 17, 16, 15, 14, 13, 10, 9, 8, 7, 6, 5, 4, 3, 1, 32, 33, 35, 37, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 67, 52, 50, 49, 48, 47, 46, 45, 44, 42, 41, 40, 39, 38, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 41000 lr0.0029466080292166567 	 Loss Classification: 0.014758 Loss T 0.024050 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1118, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.2329, Accuracy: 55804/69960 F1 (79.7656%)


Val set: Average loss: 1.4123, Accuracy: 278/360 F1 (77.2222%)

best acc test 82.605775  acc val 77.222222 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 41100 lr0.0029422822032693125 	 Loss Classification: 0.013051 Loss T 0.012543 Method MME

S painting T real Train Ep: 41200 lr0.002937971166473745 	 Loss Classification: 0.022286 Loss T 0.014404 Method MME

S painting T real Train Ep: 41300 lr0.0029336748395315305 	 Loss Classification: 0.017774 Loss T 0.026814 Method MME

S painting T real Train Ep: 41400 lr0.002929393143722923 	 Loss Classification: 0.058039 Loss T 0.014146 Method MME

S painting T real Train Ep: 41500 lr0.002925126000901522 	 Loss Classification: 0.027787 Loss T 0.028739 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0561, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.1596, Accuracy: 57880/69960 F1 (82.7330%)


Val set: Average loss: 1.4135, Accuracy: 281/360 F1 (78.0556%)

best acc test 82.605775  acc val 78.055556 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 41600 lr0.0029208733334889847 	 Loss Classification: 0.009562 Loss T 0.020015 Method MME

S painting T real Train Ep: 41700 lr0.0029166350644698118 	 Loss Classification: 0.012986 Loss T 0.024488 Method MME

S painting T real Train Ep: 41800 lr0.002912411117386185 	 Loss Classification: 0.048357 Loss T 0.017508 Method MME

S painting T real Train Ep: 41900 lr0.0029082014163328584 	 Loss Classification: 0.018499 Loss T 0.012126 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [38, 80, 101, 76, 15, 114, 13, 58, 48, 10, 11, 88, 89, 6, 34, 63, 122, 31, 104, 90, 87, 86, 91, 85, 0, 83, 82, 81, 92, 78, 77, 75, 74, 73, 72, 71, 70, 84, 79, 97, 94, 123, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 105, 103, 102, 100, 99, 98, 69, 96, 95, 93, 68, 62, 66, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 12, 9, 8, 7, 5, 4, 3, 2, 1, 32, 67, 33, 36, 65, 64, 124, 61, 60, 59, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 42000 lr0.0029040058859521123 	 Loss Classification: 0.023160 Loss T 0.017991 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1328, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 1.2445, Accuracy: 55352/69960 F1 (79.1195%)


Val set: Average loss: 1.5289, Accuracy: 270/360 F1 (75.0000%)

best acc test 82.605775  acc val 75.000000 acc labeled target 97.354497
saving model...
S painting T real Train Ep: 42100 lr0.002899824451428758 	 Loss Classification: 0.041333 Loss T 0.018212 Method MME

S painting T real Train Ep: 42200 lr0.002895657038485203 	 Loss Classification: 0.034029 Loss T 0.014594 Method MME

S painting T real Train Ep: 42300 lr0.0028915035733765655 	 Loss Classification: 0.008666 Loss T 0.011026 Method MME

S painting T real Train Ep: 42400 lr0.0028873639828858417 	 Loss Classification: 0.080860 Loss T 0.022060 Method MME

S painting T real Train Ep: 42500 lr0.0028832381943191343 	 Loss Classification: 0.076935 Loss T 0.021261 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0787, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.1889, Accuracy: 57902/69960 F1 (82.7644%)


Val set: Average loss: 1.2747, Accuracy: 289/360 F1 (80.2778%)

best acc test 82.605775  acc val 80.277778 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 42600 lr0.002879126135500922 	 Loss Classification: 0.005191 Loss T 0.011720 Method MME

S painting T real Train Ep: 42700 lr0.00287502773476939 	 Loss Classification: 0.007858 Loss T 0.011505 Method MME

S painting T real Train Ep: 42800 lr0.0028709429209718045 	 Loss Classification: 0.004113 Loss T 0.026866 Method MME

S painting T real Train Ep: 42900 lr0.0028668716234599434 	 Loss Classification: 0.014753 Loss T 0.012611 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [73, 90, 2, 122, 80, 6, 70, 99, 100, 104, 74, 12, 75, 26, 15, 85, 0, 87, 88, 89, 86, 84, 78, 82, 81, 79, 91, 77, 76, 72, 71, 69, 68, 67, 83, 92, 97, 94, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 103, 102, 101, 98, 66, 96, 95, 93, 65, 62, 63, 31, 30, 29, 28, 27, 25, 24, 23, 22, 21, 20, 19, 32, 18, 16, 14, 13, 11, 10, 9, 8, 7, 5, 4, 3, 1, 17, 33, 34, 35, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 43000 lr0.0028628137720855718 	 Loss Classification: 0.231905 Loss T 0.022254 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1212, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.2447, Accuracy: 55526/69960 F1 (79.3682%)


Val set: Average loss: 1.3994, Accuracy: 277/360 F1 (76.9444%)

best acc test 82.605775  acc val 76.944444 acc labeled target 97.530864
saving model...
S painting T real Train Ep: 43100 lr0.002858769297195967 	 Loss Classification: 0.020208 Loss T 0.020229 Method MME

S painting T real Train Ep: 43200 lr0.0028547381296294984 	 Loss Classification: 0.008785 Loss T 0.019736 Method MME

S painting T real Train Ep: 43300 lr0.0028507202007112434 	 Loss Classification: 0.088637 Loss T 0.018783 Method MME

S painting T real Train Ep: 43400 lr0.002846715442248662 	 Loss Classification: 0.052480 Loss T 0.008856 Method MME

S painting T real Train Ep: 43500 lr0.00284272378652731 	 Loss Classification: 0.060721 Loss T 0.017314 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0786, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.1555, Accuracy: 58056/69960 F1 (82.9846%)


Val set: Average loss: 1.2824, Accuracy: 285/360 F1 (79.1667%)

best acc test 82.605775  acc val 79.166667 acc labeled target 98.059965
saving model...
S painting T real Train Ep: 43600 lr0.002838745166306603 	 Loss Classification: 0.071108 Loss T 0.020971 Method MME

S painting T real Train Ep: 43700 lr0.002834779514815624 	 Loss Classification: 0.018318 Loss T 0.019826 Method MME

S painting T real Train Ep: 43800 lr0.002830826765748974 	 Loss Classification: 0.073456 Loss T 0.012159 Method MME

S painting T real Train Ep: 43900 lr0.0028268868532626687 	 Loss Classification: 0.004582 Loss T 0.017198 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [62, 71, 65, 72, 58, 83, 45, 95, 38, 96, 36, 98, 29, 28, 25, 19, 34, 9, 119, 11, 114, 12, 110, 88, 87, 86, 85, 84, 82, 81, 80, 79, 78, 120, 77, 76, 75, 74, 73, 121, 122, 123, 89, 118, 92, 91, 109, 112, 108, 107, 106, 105, 104, 113, 103, 102, 101, 100, 99, 70, 97, 115, 116, 117, 94, 93, 111, 90, 69, 0, 67, 31, 30, 27, 26, 24, 23, 22, 21, 20, 18, 17, 32, 16, 14, 13, 10, 8, 7, 6, 5, 4, 3, 2, 1, 15, 33, 35, 37, 66, 64, 63, 124, 61, 60, 59, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 41, 40, 39, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 44000 lr0.0028229597119700817 	 Loss Classification: 0.007264 Loss T 0.015349 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0960, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.2007, Accuracy: 56004/69960 F1 (80.0515%)


Val set: Average loss: 1.3861, Accuracy: 273/360 F1 (75.8333%)

best acc test 82.605775  acc val 75.833333 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 44100 lr0.002819045276937925 	 Loss Classification: 0.021786 Loss T 0.015902 Method MME

S painting T real Train Ep: 44200 lr0.002815143483682275 	 Loss Classification: 0.028615 Loss T 0.013619 Method MME

S painting T real Train Ep: 44300 lr0.0028112542681646446 	 Loss Classification: 0.008165 Loss T 0.013803 Method MME

S painting T real Train Ep: 44400 lr0.0028073775667880876 	 Loss Classification: 0.005625 Loss T 0.016154 Method MME

S painting T real Train Ep: 44500 lr0.0028035133163933517 	 Loss Classification: 0.014801 Loss T 0.017670 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0591, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.1591, Accuracy: 58054/69960 F1 (82.9817%)


Val set: Average loss: 1.2858, Accuracy: 288/360 F1 (80.0000%)

best acc test 82.605775  acc val 80.000000 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 44600 lr0.002799661454255073 	 Loss Classification: 0.006880 Loss T 0.030615 Method MME

S painting T real Train Ep: 44700 lr0.0027958219180780008 	 Loss Classification: 0.011212 Loss T 0.023188 Method MME

S painting T real Train Ep: 44800 lr0.002791994645993276 	 Loss Classification: 0.028082 Loss T 0.019659 Method MME

S painting T real Train Ep: 44900 lr0.0027881795765547345 	 Loss Classification: 0.008922 Loss T 0.014119 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [99, 94, 34, 29, 98, 43, 48, 52, 111, 54, 78, 77, 80, 36, 117, 6, 4, 69, 90, 89, 88, 87, 70, 71, 72, 75, 76, 84, 83, 82, 81, 91, 73, 79, 74, 86, 85, 0, 93, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 110, 92, 109, 107, 106, 105, 104, 103, 102, 101, 100, 97, 96, 95, 68, 108, 67, 62, 65, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 3, 2, 1, 28, 30, 31, 32, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 53, 51, 66, 50, 47, 46, 45, 44, 42, 41, 40, 39, 38, 37, 35, 33, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 45000 lr0.0027843766487352603 	 Loss Classification: 0.005344 Loss T 0.018577 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1277, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.2579, Accuracy: 55311/69960 F1 (79.0609%)


Val set: Average loss: 1.4470, Accuracy: 275/360 F1 (76.3889%)

best acc test 82.605775  acc val 76.388889 acc labeled target 97.442681
saving model...
S painting T real Train Ep: 45100 lr0.0027805858019231693 	 Loss Classification: 0.020763 Loss T 0.015605 Method MME

S painting T real Train Ep: 45200 lr0.0027768069759186364 	 Loss Classification: 0.015017 Loss T 0.009999 Method MME

S painting T real Train Ep: 45300 lr0.002773040110930155 	 Loss Classification: 0.187295 Loss T 0.016038 Method MME

S painting T real Train Ep: 45400 lr0.0027692851475710355 	 Loss Classification: 0.021011 Loss T 0.007240 Method MME

S painting T real Train Ep: 45500 lr0.0027655420268559413 	 Loss Classification: 0.018284 Loss T 0.016290 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0524, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.1659, Accuracy: 58020/69960 F1 (82.9331%)


Val set: Average loss: 1.2612, Accuracy: 288/360 F1 (80.0000%)

best acc test 82.605775  acc val 80.000000 acc labeled target 98.853616
saving model...
S painting T real Train Ep: 45600 lr0.0027618106901974556 	 Loss Classification: 0.007956 Loss T 0.016741 Method MME

S painting T real Train Ep: 45700 lr0.002758091079402693 	 Loss Classification: 0.031116 Loss T 0.023684 Method MME

S painting T real Train Ep: 45800 lr0.002754383136669936 	 Loss Classification: 0.028096 Loss T 0.018993 Method MME

S painting T real Train Ep: 45900 lr0.00275068680458531 	 Loss Classification: 0.038917 Loss T 0.012083 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [51, 84, 23, 80, 36, 113, 12, 11, 92, 57, 58, 71, 63, 74, 91, 90, 89, 88, 87, 86, 85, 69, 82, 73, 81, 70, 79, 78, 77, 76, 72, 75, 83, 0, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 68, 108, 67, 62, 65, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 14, 13, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 15, 66, 31, 33, 64, 124, 61, 60, 59, 56, 55, 54, 53, 52, 50, 49, 32, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 34, 47, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 46000 lr0.002747002026119495 	 Loss Classification: 0.025350 Loss T 0.009196 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1038, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.2409, Accuracy: 55679/69960 F1 (79.5869%)


Val set: Average loss: 1.2673, Accuracy: 280/360 F1 (77.7778%)

