Dataset multi Source real Target sketch Labeled num perclass 3 Network alexnet
126 classes in this dataset
Labelled Source Examples:  70358
Unlabelled Target Dataset Size:  23826
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  23826 Source:  70358
Unlabeled Target Data Batches: 372
S real T sketch Train Ep: 0 lr0.01 	 Loss Classification: 4.870662 Loss T 0.481884 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.8433, Accuracy: 10/1134 F1 (0.8818%)


Test set: Average loss: 4.8549, Accuracy: 212/23808 F1 (0.8905%)


Val set: Average loss: 4.8456, Accuracy: 4/352 F1 (1.1364%)

best acc test 0.890457  acc val 1.136364 acc labeled target 0.881834
saving model...
S real T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.386807 Loss T 0.416410 Method MME

S real T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.253950 Loss T 0.350054 Method MME

S real T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.324328 Loss T 0.331176 Method MME

S real T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.432170 Loss T 0.304413 Method MME

S real T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.815064 Loss T 0.281309 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.8669, Accuracy: 216/1134 F1 (19.0476%)


Test set: Average loss: 3.6896, Accuracy: 5707/23808 F1 (23.9709%)


Val set: Average loss: 3.4415, Accuracy: 87/352 F1 (24.7159%)

best acc test 23.970934  acc val 24.715909 acc labeled target 19.047619
saving model...
S real T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.432671 Loss T 0.284076 Method MME

S real T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.800953 Loss T 0.261151 Method MME

S real T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.029511 Loss T 0.278860 Method MME

S real T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.181893 Loss T 0.233699 Method MME

S real T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.582879 Loss T 0.248186 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.6987, Accuracy: 243/1134 F1 (21.4286%)


Test set: Average loss: 3.5072, Accuracy: 6488/23808 F1 (27.2513%)


Val set: Average loss: 3.3159, Accuracy: 109/352 F1 (30.9659%)

best acc test 27.251344  acc val 30.965909 acc labeled target 21.428571
saving model...
S real T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.390133 Loss T 0.273855 Method MME

S real T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.341156 Loss T 0.245600 Method MME

S real T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.925664 Loss T 0.276231 Method MME

S real T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 1.236060 Loss T 0.248834 Method MME

S real T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.154941 Loss T 0.223595 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.7849, Accuracy: 265/1134 F1 (23.3686%)


Test set: Average loss: 3.7134, Accuracy: 6321/23808 F1 (26.5499%)


Val set: Average loss: 3.5916, Accuracy: 94/352 F1 (26.7045%)

best acc test 27.251344  acc val 26.704545 acc labeled target 23.368607
saving model...
S real T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.187363 Loss T 0.223845 Method MME

S real T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.107140 Loss T 0.249747 Method MME

S real T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.212919 Loss T 0.236530 Method MME

S real T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 1.349366 Loss T 0.234471 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         0.         0.         0.         0.
 0.         0.5555556  0.         0.         0.6666667  0.44444445
 0.         0.         0.22222222 0.         0.44444445 0.22222222
 0.         0.22222222 0.5555556  0.         0.44444445 0.
 0.33333334 0.22222222 0.         0.5555556  0.11111111 0.22222222
 0.         0.         0.         0.33333334 0.6666667  0.33333334
 0.         0.         0.22222222 0.         0.33333334 0.11111111
 0.         0.44444445 0.         0.11111111 0.11111111 0.22222222
 0.33333334 0.44444445 0.22222222 0.         0.6666667  0.
 0.44444445 0.         0.         0.5555556  0.11111111 0.
 0.33333334 0.         0.5555556  0.         0.7777778  0.
 0.         0.         0.         1.         0.11111111 0.
 0.6666667  0.22222222 0.7777778  0.         0.11111111 0.11111111
 0.33333334 0.         0.         0.11111111 0.22222222 0.
 0.33333334 0.11111111 0.         0.6666667  0.         0.44444445
 0.33333334 0.         0.         0.33333334 0.44444445 0.22222222
 0.33333334 0.         0.         0.         0.6666667  0.33333334
 0.33333334 0.         0.         0.         0.         0.5555556
 0.         0.44444445 0.33333334 0.22222222 0.33333334 0.22222222
 0.         1.         0.         0.6666667  0.         0.33333334
 0.5555556  0.5555556  0.22222222 0.         0.22222222 1.        ]
Top k classes which perform poorly are:  [105, 98, 97, 36, 37, 39, 42, 44, 92, 51, 104, 53, 91, 55, 32, 56, 61, 63, 88, 65, 66, 67, 68, 71, 86, 108, 75, 79, 80, 59, 31, 83, 4, 12, 9, 13, 8, 118, 30, 15, 18, 6, 5, 21, 103, 3, 116, 99, 106, 23, 114, 26, 123, 2, 28, 81, 58, 45, 70, 85, 77, 76, 46, 41, 122, 73, 29, 47, 113, 25, 38, 82, 95, 124, 111, 50, 19, 17, 14, 101, 96, 102, 93, 90, 60, 78, 24, 33, 35, 40, 84, 48, 112, 119, 110, 54, 94, 89, 109, 22, 16, 11, 49, 43, 107, 121, 62, 57, 27, 20, 7, 120, 87, 72, 52, 34, 10, 117, 100, 74, 64, 0, 69, 1, 115, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.2869, 1.5000,
        1.5000, 1.2567, 1.3206, 1.5000, 1.5000, 1.4004, 1.5000, 1.3206, 1.4004,
        1.5000, 1.4004, 1.2869, 1.5000, 1.3206, 1.5000, 1.3583, 1.4004, 1.5000,
        1.2869, 1.4474, 1.4004, 1.5000, 1.5000, 1.5000, 1.3583, 1.2567, 1.3583,
        1.5000, 1.5000, 1.4004, 1.5000, 1.3583, 1.4474, 1.5000, 1.3206, 1.5000,
        1.4474, 1.4474, 1.4004, 1.3583, 1.3206, 1.4004, 1.5000, 1.2567, 1.5000,
        1.3206, 1.5000, 1.5000, 1.2869, 1.4474, 1.5000, 1.3583, 1.5000, 1.2869,
        1.5000, 1.2297, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.4474, 1.5000,
        1.2567, 1.4004, 1.2297, 1.5000, 1.4474, 1.4474, 1.3583, 1.5000, 1.5000,
        1.4474, 1.4004, 1.5000, 1.3583, 1.4474, 1.5000, 1.2567, 1.5000, 1.3206,
        1.3583, 1.5000, 1.5000, 1.3583, 1.3206, 1.4004, 1.3583, 1.5000, 1.5000,
        1.5000, 1.2567, 1.3583, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.2869,
        1.5000, 1.3206, 1.3583, 1.4004, 1.3583, 1.4004, 1.5000, 1.1839, 1.5000,
        1.2567, 1.5000, 1.3583, 1.2869, 1.2869, 1.4004, 1.5000, 1.4004, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7131, 0.5000,
        0.5000, 0.7433, 0.6794, 0.5000, 0.5000, 0.5996, 0.5000, 0.6794, 0.5996,
        0.5000, 0.5996, 0.7131, 0.5000, 0.6794, 0.5000, 0.6417, 0.5996, 0.5000,
        0.7131, 0.5526, 0.5996, 0.5000, 0.5000, 0.5000, 0.6417, 0.7433, 0.6417,
        0.5000, 0.5000, 0.5996, 0.5000, 0.6417, 0.5526, 0.5000, 0.6794, 0.5000,
        0.5526, 0.5526, 0.5996, 0.6417, 0.6794, 0.5996, 0.5000, 0.7433, 0.5000,
        0.6794, 0.5000, 0.5000, 0.7131, 0.5526, 0.5000, 0.6417, 0.5000, 0.7131,
        0.5000, 0.7703, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.5526, 0.5000,
        0.7433, 0.5996, 0.7703, 0.5000, 0.5526, 0.5526, 0.6417, 0.5000, 0.5000,
        0.5526, 0.5996, 0.5000, 0.6417, 0.5526, 0.5000, 0.7433, 0.5000, 0.6794,
        0.6417, 0.5000, 0.5000, 0.6417, 0.6794, 0.5996, 0.6417, 0.5000, 0.5000,
        0.5000, 0.7433, 0.6417, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.7131,
        0.5000, 0.6794, 0.6417, 0.5996, 0.6417, 0.5996, 0.5000, 0.8161, 0.5000,
        0.7433, 0.5000, 0.6417, 0.7131, 0.7131, 0.5996, 0.5000, 0.5996, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.040561 Loss T 0.241739 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.7536, Accuracy: 264/1134 F1 (23.2804%)


Test set: Average loss: 3.5531, Accuracy: 6744/23808 F1 (28.3266%)


Val set: Average loss: 3.3759, Accuracy: 109/352 F1 (30.9659%)

best acc test 28.326613  acc val 30.965909 acc labeled target 23.280423
saving model...
S real T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.522990 Loss T 0.250455 Method MME

S real T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.837700 Loss T 0.236453 Method MME

S real T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.652482 Loss T 0.218634 Method MME

S real T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.480053 Loss T 0.228698 Method MME

S real T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 1.054724 Loss T 0.193156 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.8974, Accuracy: 290/1134 F1 (25.5732%)


Test set: Average loss: 3.8505, Accuracy: 6467/23808 F1 (27.1631%)


Val set: Average loss: 3.7259, Accuracy: 105/352 F1 (29.8295%)

best acc test 28.326613  acc val 29.829545 acc labeled target 25.573192
saving model...
S real T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.868103 Loss T 0.235067 Method MME

S real T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.076711 Loss T 0.221003 Method MME

S real T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 1.056988 Loss T 0.211234 Method MME

S real T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.815737 Loss T 0.101283 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 1.         0.         0.         0.         0.
 0.         0.6666667  0.         0.         0.44444445 1.
 0.         0.         0.         0.         0.8888889  0.6666667
 0.         0.33333334 0.6666667  0.22222222 0.5555556  0.
 0.22222222 0.33333334 0.         0.5555556  0.33333334 0.22222222
 0.         0.         0.11111111 0.11111111 0.22222222 0.33333334
 0.6666667  0.         0.33333334 0.         0.44444445 0.
 0.33333334 0.         0.11111111 0.33333334 0.         0.
 0.5555556  0.6666667  0.22222222 0.         0.33333334 0.
 0.33333334 0.         0.         1.         0.5555556  0.
 0.5555556  0.11111111 1.         0.33333334 0.33333334 0.22222222
 0.11111111 0.         0.         0.44444445 0.         0.
 0.6666667  0.33333334 0.6666667  0.         0.         0.
 0.         0.33333334 0.         0.11111111 0.33333334 0.
 0.33333334 0.         0.11111111 0.6666667  0.         0.5555556
 0.         0.11111111 0.33333334 0.         0.7777778  0.33333334
 0.5555556  0.         0.22222222 0.         0.6666667  0.33333334
 0.         0.11111111 0.33333334 0.         0.         0.7777778
 0.         0.         0.         0.5555556  0.5555556  0.44444445
 0.         1.         0.         0.5555556  0.         0.33333334
 0.         0.5555556  0.22222222 0.         0.         1.        ]
Top k classes which perform poorly are:  [59, 102, 37, 99, 77, 41, 97, 43, 46, 47, 93, 51, 53, 90, 55, 56, 88, 118, 85, 124, 83, 67, 68, 70, 71, 80, 75, 76, 31, 30, 39, 15, 114, 14, 13, 12, 120, 9, 110, 8, 6, 5, 4, 3, 2, 123, 116, 18, 78, 23, 108, 26, 105, 109, 106, 33, 66, 61, 103, 44, 32, 91, 86, 81, 122, 34, 21, 98, 24, 65, 29, 50, 79, 92, 101, 82, 95, 104, 84, 119, 73, 19, 25, 28, 35, 42, 45, 52, 54, 38, 64, 63, 0, 10, 113, 69, 40, 117, 112, 111, 22, 89, 121, 58, 48, 96, 27, 60, 20, 72, 17, 36, 74, 49, 7, 87, 100, 107, 94, 16, 62, 57, 11, 1, 115, 125]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.2567, 1.5000,
        1.5000, 1.3206, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.2056, 1.2567,
        1.5000, 1.3583, 1.2567, 1.4004, 1.2869, 1.5000, 1.4004, 1.3583, 1.5000,
        1.2869, 1.3583, 1.4004, 1.5000, 1.5000, 1.4474, 1.4474, 1.4004, 1.3583,
        1.2567, 1.5000, 1.3583, 1.5000, 1.3206, 1.5000, 1.3583, 1.5000, 1.4474,
        1.3583, 1.5000, 1.5000, 1.2869, 1.2567, 1.4004, 1.5000, 1.3583, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.2869, 1.5000, 1.2869, 1.4474, 1.1839,
        1.3583, 1.3583, 1.4004, 1.4474, 1.5000, 1.5000, 1.3206, 1.5000, 1.5000,
        1.2567, 1.3583, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583, 1.5000,
        1.4474, 1.3583, 1.5000, 1.3583, 1.5000, 1.4474, 1.2567, 1.5000, 1.2869,
        1.5000, 1.4474, 1.3583, 1.5000, 1.2297, 1.3583, 1.2869, 1.5000, 1.4004,
        1.5000, 1.2567, 1.3583, 1.5000, 1.4474, 1.3583, 1.5000, 1.5000, 1.2297,
        1.5000, 1.5000, 1.5000, 1.2869, 1.2869, 1.3206, 1.5000, 1.1839, 1.5000,
        1.2869, 1.5000, 1.3583, 1.5000, 1.2869, 1.4004, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7433, 0.5000,
        0.5000, 0.6794, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.7944, 0.7433,
        0.5000, 0.6417, 0.7433, 0.5996, 0.7131, 0.5000, 0.5996, 0.6417, 0.5000,
        0.7131, 0.6417, 0.5996, 0.5000, 0.5000, 0.5526, 0.5526, 0.5996, 0.6417,
        0.7433, 0.5000, 0.6417, 0.5000, 0.6794, 0.5000, 0.6417, 0.5000, 0.5526,
        0.6417, 0.5000, 0.5000, 0.7131, 0.7433, 0.5996, 0.5000, 0.6417, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.7131, 0.5000, 0.7131, 0.5526, 0.8161,
        0.6417, 0.6417, 0.5996, 0.5526, 0.5000, 0.5000, 0.6794, 0.5000, 0.5000,
        0.7433, 0.6417, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417, 0.5000,
        0.5526, 0.6417, 0.5000, 0.6417, 0.5000, 0.5526, 0.7433, 0.5000, 0.7131,
        0.5000, 0.5526, 0.6417, 0.5000, 0.7703, 0.6417, 0.7131, 0.5000, 0.5996,
        0.5000, 0.7433, 0.6417, 0.5000, 0.5526, 0.6417, 0.5000, 0.5000, 0.7703,
        0.5000, 0.5000, 0.5000, 0.7131, 0.7131, 0.6794, 0.5000, 0.8161, 0.5000,
        0.7131, 0.5000, 0.6417, 0.5000, 0.7131, 0.5996, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.522569 Loss T 0.217809 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.6243, Accuracy: 300/1134 F1 (26.4550%)


Test set: Average loss: 3.6084, Accuracy: 6934/23808 F1 (29.1247%)


Val set: Average loss: 3.4412, Accuracy: 111/352 F1 (31.5341%)

best acc test 29.124664  acc val 31.534091 acc labeled target 26.455026
saving model...
S real T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 1.088711 Loss T 0.210954 Method MME

S real T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.891605 Loss T 0.210723 Method MME

S real T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.927938 Loss T 0.196854 Method MME

S real T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.662389 Loss T 0.217313 Method MME

S real T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.991395 Loss T 0.192129 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.5563, Accuracy: 312/1134 F1 (27.5132%)


Test set: Average loss: 3.5060, Accuracy: 7495/23808 F1 (31.4810%)


Val set: Average loss: 3.3847, Accuracy: 112/352 F1 (31.8182%)

best acc test 31.481015  acc val 31.818182 acc labeled target 27.513228
saving model...
S real T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.841002 Loss T 0.229813 Method MME

S real T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 1.618501 Loss T 0.129804 Method MME

S real T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.842068 Loss T 0.174468 Method MME

S real T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 1.213203 Loss T 0.212850 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 1.         0.         0.         0.         0.
 0.         0.6666667  0.22222222 0.         0.44444445 0.5555556
 0.         0.         0.         0.         1.         0.8888889
 0.22222222 0.33333334 0.6666667  0.11111111 0.8888889  0.
 0.33333334 0.11111111 0.         0.44444445 0.33333334 0.22222222
 0.         0.         0.         0.22222222 0.11111111 0.33333334
 0.22222222 0.         0.44444445 0.22222222 0.44444445 0.5555556
 0.         0.11111111 0.22222222 0.         0.44444445 0.8888889
 0.44444445 0.8888889  0.33333334 0.         0.6666667  0.
 0.11111111 0.         0.         0.44444445 0.5555556  0.
 0.22222222 0.         0.7777778  0.44444445 0.11111111 0.11111111
 0.         0.6666667  0.11111111 1.         0.11111111 0.
 0.33333334 0.22222222 0.7777778  0.22222222 0.33333334 0.11111111
 0.         0.         0.         0.11111111 0.33333334 0.33333334
 0.33333334 0.         0.22222222 0.6666667  0.         0.33333334
 0.33333334 0.11111111 0.11111111 0.22222222 0.44444445 0.44444445
 0.5555556  0.11111111 0.33333334 0.         0.6666667  0.44444445
 0.11111111 0.11111111 0.33333334 0.         0.         0.44444445
 0.         0.22222222 0.11111111 0.7777778  0.33333334 0.5555556
 0.11111111 1.         0.         0.5555556  0.         0.22222222
 0.33333334 0.22222222 0.         0.         0.         1.        ]
Top k classes which perform poorly are:  [56, 51, 26, 66, 30, 31, 32, 124, 61, 59, 37, 106, 99, 105, 55, 42, 53, 45, 71, 116, 23, 80, 123, 2, 3, 4, 5, 6, 88, 85, 9, 108, 118, 13, 14, 15, 122, 79, 78, 12, 97, 81, 64, 65, 68, 70, 54, 77, 103, 92, 34, 21, 102, 110, 25, 91, 114, 43, 8, 86, 93, 121, 18, 75, 73, 109, 119, 29, 44, 33, 60, 36, 39, 98, 90, 89, 50, 104, 84, 83, 82, 24, 19, 76, 35, 72, 120, 28, 112, 107, 101, 94, 95, 0, 46, 10, 63, 27, 57, 38, 40, 48, 11, 41, 117, 58, 96, 113, 52, 100, 20, 67, 7, 87, 62, 74, 111, 49, 47, 22, 17, 115, 69, 16, 1, 125]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.2567, 1.4004,
        1.5000, 1.3206, 1.2869, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2056,
        1.4004, 1.3583, 1.2567, 1.4474, 1.2056, 1.5000, 1.3583, 1.4474, 1.5000,
        1.3206, 1.3583, 1.4004, 1.5000, 1.5000, 1.5000, 1.4004, 1.4474, 1.3583,
        1.4004, 1.5000, 1.3206, 1.4004, 1.3206, 1.2869, 1.5000, 1.4474, 1.4004,
        1.5000, 1.3206, 1.2056, 1.3206, 1.2056, 1.3583, 1.5000, 1.2567, 1.5000,
        1.4474, 1.5000, 1.5000, 1.3206, 1.2869, 1.5000, 1.4004, 1.5000, 1.2297,
        1.3206, 1.4474, 1.4474, 1.5000, 1.2567, 1.4474, 1.1839, 1.4474, 1.5000,
        1.3583, 1.4004, 1.2297, 1.4004, 1.3583, 1.4474, 1.5000, 1.5000, 1.5000,
        1.4474, 1.3583, 1.3583, 1.3583, 1.5000, 1.4004, 1.2567, 1.5000, 1.3583,
        1.3583, 1.4474, 1.4474, 1.4004, 1.3206, 1.3206, 1.2869, 1.4474, 1.3583,
        1.5000, 1.2567, 1.3206, 1.4474, 1.4474, 1.3583, 1.5000, 1.5000, 1.3206,
        1.5000, 1.4004, 1.4474, 1.2297, 1.3583, 1.2869, 1.4474, 1.1839, 1.5000,
        1.2869, 1.5000, 1.4004, 1.3583, 1.4004, 1.5000, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7433, 0.5996,
        0.5000, 0.6794, 0.7131, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7944,
        0.5996, 0.6417, 0.7433, 0.5526, 0.7944, 0.5000, 0.6417, 0.5526, 0.5000,
        0.6794, 0.6417, 0.5996, 0.5000, 0.5000, 0.5000, 0.5996, 0.5526, 0.6417,
        0.5996, 0.5000, 0.6794, 0.5996, 0.6794, 0.7131, 0.5000, 0.5526, 0.5996,
        0.5000, 0.6794, 0.7944, 0.6794, 0.7944, 0.6417, 0.5000, 0.7433, 0.5000,
        0.5526, 0.5000, 0.5000, 0.6794, 0.7131, 0.5000, 0.5996, 0.5000, 0.7703,
        0.6794, 0.5526, 0.5526, 0.5000, 0.7433, 0.5526, 0.8161, 0.5526, 0.5000,
        0.6417, 0.5996, 0.7703, 0.5996, 0.6417, 0.5526, 0.5000, 0.5000, 0.5000,
        0.5526, 0.6417, 0.6417, 0.6417, 0.5000, 0.5996, 0.7433, 0.5000, 0.6417,
        0.6417, 0.5526, 0.5526, 0.5996, 0.6794, 0.6794, 0.7131, 0.5526, 0.6417,
        0.5000, 0.7433, 0.6794, 0.5526, 0.5526, 0.6417, 0.5000, 0.5000, 0.6794,
        0.5000, 0.5996, 0.5526, 0.7703, 0.6417, 0.7131, 0.5526, 0.8161, 0.5000,
        0.7131, 0.5000, 0.5996, 0.6417, 0.5996, 0.5000, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 1.174601 Loss T 0.185141 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.7661, Accuracy: 314/1134 F1 (27.6896%)


Test set: Average loss: 3.6786, Accuracy: 7307/23808 F1 (30.6914%)


Val set: Average loss: 3.4214, Accuracy: 119/352 F1 (33.8068%)

best acc test 30.691364  acc val 33.806818 acc labeled target 27.689594
saving model...
S real T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 1.211405 Loss T 0.125482 Method MME

S real T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 1.021051 Loss T 0.179610 Method MME

S real T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 1.246386 Loss T 0.212282 Method MME

S real T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.616370 Loss T 0.254000 Method MME

S real T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.880415 Loss T 0.209963 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.6759, Accuracy: 303/1134 F1 (26.7196%)


Test set: Average loss: 3.5804, Accuracy: 7268/23808 F1 (30.5276%)


Val set: Average loss: 3.4275, Accuracy: 119/352 F1 (33.8068%)

best acc test 30.527554  acc val 33.806818 acc labeled target 26.719577
saving model...
S real T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 1.103462 Loss T 0.196935 Method MME

S real T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.702971 Loss T 0.218909 Method MME

S real T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.635583 Loss T 0.201559 Method MME

S real T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.911285 Loss T 0.148928 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.         0.         0.         0.
 0.33333334 0.5555556  0.         0.         0.33333334 1.
 0.         0.33333334 0.         0.         0.44444445 0.33333334
 0.22222222 0.22222222 0.5555556  0.22222222 0.6666667  0.
 0.11111111 0.22222222 0.         0.5555556  0.33333334 0.33333334
 0.         0.         0.         0.11111111 0.44444445 0.22222222
 0.33333334 0.         0.22222222 0.         0.33333334 0.33333334
 0.22222222 0.44444445 0.22222222 0.         0.33333334 0.6666667
 0.44444445 1.         0.11111111 0.         0.8888889  0.
 0.         0.11111111 0.         0.33333334 0.33333334 0.
 0.33333334 0.         0.6666667  0.         0.22222222 0.22222222
 0.         0.         0.         0.6666667  0.         0.
 0.6666667  0.22222222 0.5555556  0.         0.11111111 0.
 0.11111111 0.44444445 0.         0.33333334 0.33333334 0.
 0.33333334 0.22222222 0.22222222 0.         0.         0.44444445
 0.11111111 0.11111111 0.33333334 0.         0.6666667  0.22222222
 0.5555556  0.11111111 0.22222222 0.11111111 0.7777778  0.33333334
 0.         0.11111111 0.5555556  0.         0.         0.6666667
 0.         0.33333334 0.22222222 0.44444445 0.5555556  0.5555556
 0.11111111 1.         0.         0.6666667  0.         0.44444445
 0.5555556  0.7777778  0.44444445 0.         0.         1.        ]
Top k classes which perform poorly are:  [31, 30, 61, 32, 83, 80, 37, 77, 39, 75, 71, 45, 70, 116, 68, 118, 51, 67, 53, 54, 66, 56, 59, 63, 87, 26, 124, 14, 12, 15, 105, 9, 8, 88, 108, 106, 5, 4, 3, 23, 2, 123, 93, 102, 50, 103, 24, 76, 99, 97, 78, 33, 91, 90, 114, 55, 73, 98, 95, 65, 64, 85, 86, 110, 25, 38, 42, 44, 21, 35, 19, 18, 10, 13, 60, 28, 29, 17, 84, 92, 58, 82, 46, 57, 109, 6, 81, 101, 41, 40, 36, 43, 89, 119, 48, 122, 34, 16, 111, 79, 7, 104, 27, 96, 113, 20, 120, 74, 112, 117, 0, 62, 94, 72, 69, 47, 22, 107, 100, 121, 52, 115, 49, 11, 1, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583, 1.2869, 1.5000,
        1.5000, 1.3583, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000, 1.3206, 1.3583,
        1.4004, 1.4004, 1.2869, 1.4004, 1.2567, 1.5000, 1.4474, 1.4004, 1.5000,
        1.2869, 1.3583, 1.3583, 1.5000, 1.5000, 1.5000, 1.4474, 1.3206, 1.4004,
        1.3583, 1.5000, 1.4004, 1.5000, 1.3583, 1.3583, 1.4004, 1.3206, 1.4004,
        1.5000, 1.3583, 1.2567, 1.3206, 1.1839, 1.4474, 1.5000, 1.2056, 1.5000,
        1.5000, 1.4474, 1.5000, 1.3583, 1.3583, 1.5000, 1.3583, 1.5000, 1.2567,
        1.5000, 1.4004, 1.4004, 1.5000, 1.5000, 1.5000, 1.2567, 1.5000, 1.5000,
        1.2567, 1.4004, 1.2869, 1.5000, 1.4474, 1.5000, 1.4474, 1.3206, 1.5000,
        1.3583, 1.3583, 1.5000, 1.3583, 1.4004, 1.4004, 1.5000, 1.5000, 1.3206,
        1.4474, 1.4474, 1.3583, 1.5000, 1.2567, 1.4004, 1.2869, 1.4474, 1.4004,
        1.4474, 1.2297, 1.3583, 1.5000, 1.4474, 1.2869, 1.5000, 1.5000, 1.2567,
        1.5000, 1.3583, 1.4004, 1.3206, 1.2869, 1.2869, 1.4474, 1.1839, 1.5000,
        1.2567, 1.5000, 1.3206, 1.2869, 1.2297, 1.3206, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417, 0.7131, 0.5000,
        0.5000, 0.6417, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000, 0.6794, 0.6417,
        0.5996, 0.5996, 0.7131, 0.5996, 0.7433, 0.5000, 0.5526, 0.5996, 0.5000,
        0.7131, 0.6417, 0.6417, 0.5000, 0.5000, 0.5000, 0.5526, 0.6794, 0.5996,
        0.6417, 0.5000, 0.5996, 0.5000, 0.6417, 0.6417, 0.5996, 0.6794, 0.5996,
        0.5000, 0.6417, 0.7433, 0.6794, 0.8161, 0.5526, 0.5000, 0.7944, 0.5000,
        0.5000, 0.5526, 0.5000, 0.6417, 0.6417, 0.5000, 0.6417, 0.5000, 0.7433,
        0.5000, 0.5996, 0.5996, 0.5000, 0.5000, 0.5000, 0.7433, 0.5000, 0.5000,
        0.7433, 0.5996, 0.7131, 0.5000, 0.5526, 0.5000, 0.5526, 0.6794, 0.5000,
        0.6417, 0.6417, 0.5000, 0.6417, 0.5996, 0.5996, 0.5000, 0.5000, 0.6794,
        0.5526, 0.5526, 0.6417, 0.5000, 0.7433, 0.5996, 0.7131, 0.5526, 0.5996,
        0.5526, 0.7703, 0.6417, 0.5000, 0.5526, 0.7131, 0.5000, 0.5000, 0.7433,
        0.5000, 0.6417, 0.5996, 0.6794, 0.7131, 0.7131, 0.5526, 0.8161, 0.5000,
        0.7433, 0.5000, 0.6794, 0.7131, 0.7703, 0.6794, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.905568 Loss T 0.109139 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 5.8900, Accuracy: 151/1134 F1 (13.3157%)


Test set: Average loss: 5.9577, Accuracy: 3553/23808 F1 (14.9236%)


Val set: Average loss: 5.8245, Accuracy: 55/352 F1 (15.6250%)

best acc test 30.527554  acc val 15.625000 acc labeled target 13.315697
saving model...
S real T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.758877 Loss T 0.168059 Method MME

S real T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.475086 Loss T 0.185375 Method MME

S real T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 1.194332 Loss T 0.151549 Method MME

S real T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.809108 Loss T 0.224494 Method MME

S real T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.952644 Loss T 0.122961 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.9968, Accuracy: 232/1134 F1 (20.4586%)


Test set: Average loss: 5.1452, Accuracy: 5593/23808 F1 (23.4921%)


Val set: Average loss: 5.0232, Accuracy: 83/352 F1 (23.5795%)

best acc test 30.527554  acc val 23.579545 acc labeled target 20.458554
saving model...
S real T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 1.043608 Loss T 0.227705 Method MME

S real T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.424995 Loss T 0.196207 Method MME

S real T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.894081 Loss T 0.210035 Method MME

S real T sketch Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 1.247724 Loss T 0.125385 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.         0.         0.         0.
 0.         0.11111111 0.11111111 0.         0.44444445 0.5555556
 0.         0.         0.11111111 0.         1.         0.11111111
 0.         0.22222222 0.33333334 0.11111111 0.33333334 0.
 0.22222222 0.33333334 0.         0.         0.33333334 0.
 0.         0.11111111 0.         0.22222222 0.         0.11111111
 0.         0.         0.         0.         0.22222222 0.6666667
 0.         0.         0.22222222 0.         0.5555556  0.11111111
 0.33333334 0.44444445 0.33333334 0.         0.33333334 0.
 0.         0.         0.         0.         0.44444445 0.
 0.33333334 0.         0.8888889  0.         0.7777778  0.22222222
 0.11111111 0.6666667  0.         0.22222222 0.11111111 0.
 0.7777778  0.         0.33333334 0.         0.33333334 0.
 0.         0.         0.         0.11111111 0.33333334 0.
 0.33333334 0.11111111 0.11111111 0.8888889  0.         0.22222222
 0.11111111 0.         0.         0.22222222 0.33333334 0.44444445
 0.22222222 0.         0.22222222 0.22222222 0.33333334 0.44444445
 0.         0.33333334 0.33333334 0.         0.         0.6666667
 0.         0.         0.         0.33333334 0.33333334 0.22222222
 0.33333334 1.         0.         0.44444445 0.         0.22222222
 0.33333334 0.5555556  0.22222222 0.         0.         1.        ]
Top k classes which perform poorly are:  [59, 36, 77, 38, 39, 97, 42, 43, 45, 92, 91, 51, 88, 53, 34, 54, 56, 57, 118, 61, 124, 63, 83, 80, 68, 79, 71, 78, 73, 55, 32, 37, 30, 123, 2, 3, 4, 5, 6, 9, 116, 12, 13, 15, 18, 109, 110, 105, 29, 27, 26, 102, 108, 23, 75, 106, 14, 21, 35, 70, 90, 66, 7, 81, 17, 85, 86, 31, 8, 47, 93, 89, 113, 99, 96, 98, 119, 33, 44, 24, 19, 122, 40, 65, 69, 111, 114, 76, 22, 104, 103, 25, 100, 120, 28, 112, 20, 74, 94, 48, 82, 50, 52, 84, 60, 95, 117, 10, 58, 49, 101, 121, 11, 46, 0, 107, 67, 41, 64, 72, 62, 87, 16, 1, 115, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.4474, 1.4474,
        1.5000, 1.3206, 1.2869, 1.5000, 1.5000, 1.4474, 1.5000, 1.1839, 1.4474,
        1.5000, 1.4004, 1.3583, 1.4474, 1.3583, 1.5000, 1.4004, 1.3583, 1.5000,
        1.5000, 1.3583, 1.5000, 1.5000, 1.4474, 1.5000, 1.4004, 1.5000, 1.4474,
        1.5000, 1.5000, 1.5000, 1.5000, 1.4004, 1.2567, 1.5000, 1.5000, 1.4004,
        1.5000, 1.2869, 1.4474, 1.3583, 1.3206, 1.3583, 1.5000, 1.3583, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.3206, 1.5000, 1.3583, 1.5000, 1.2056,
        1.5000, 1.2297, 1.4004, 1.4474, 1.2567, 1.5000, 1.4004, 1.4474, 1.5000,
        1.2297, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000,
        1.4474, 1.3583, 1.5000, 1.3583, 1.4474, 1.4474, 1.2056, 1.5000, 1.4004,
        1.4474, 1.5000, 1.5000, 1.4004, 1.3583, 1.3206, 1.4004, 1.5000, 1.4004,
        1.4004, 1.3583, 1.3206, 1.5000, 1.3583, 1.3583, 1.5000, 1.5000, 1.2567,
        1.5000, 1.5000, 1.5000, 1.3583, 1.3583, 1.4004, 1.3583, 1.1839, 1.5000,
        1.3206, 1.5000, 1.4004, 1.3583, 1.2869, 1.4004, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5526, 0.5526,
        0.5000, 0.6794, 0.7131, 0.5000, 0.5000, 0.5526, 0.5000, 0.8161, 0.5526,
        0.5000, 0.5996, 0.6417, 0.5526, 0.6417, 0.5000, 0.5996, 0.6417, 0.5000,
        0.5000, 0.6417, 0.5000, 0.5000, 0.5526, 0.5000, 0.5996, 0.5000, 0.5526,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5996, 0.7433, 0.5000, 0.5000, 0.5996,
        0.5000, 0.7131, 0.5526, 0.6417, 0.6794, 0.6417, 0.5000, 0.6417, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.6794, 0.5000, 0.6417, 0.5000, 0.7944,
        0.5000, 0.7703, 0.5996, 0.5526, 0.7433, 0.5000, 0.5996, 0.5526, 0.5000,
        0.7703, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5526, 0.6417, 0.5000, 0.6417, 0.5526, 0.5526, 0.7944, 0.5000, 0.5996,
        0.5526, 0.5000, 0.5000, 0.5996, 0.6417, 0.6794, 0.5996, 0.5000, 0.5996,
        0.5996, 0.6417, 0.6794, 0.5000, 0.6417, 0.6417, 0.5000, 0.5000, 0.7433,
        0.5000, 0.5000, 0.5000, 0.6417, 0.6417, 0.5996, 0.6417, 0.8161, 0.5000,
        0.6794, 0.5000, 0.5996, 0.6417, 0.7131, 0.5996, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.636312 Loss T 0.193419 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.0015, Accuracy: 300/1134 F1 (26.4550%)


Test set: Average loss: 3.8510, Accuracy: 7292/23808 F1 (30.6284%)


Val set: Average loss: 3.7895, Accuracy: 107/352 F1 (30.3977%)

best acc test 30.527554  acc val 30.397727 acc labeled target 26.455026
saving model...
S real T sketch Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.764449 Loss T 0.148913 Method MME

S real T sketch Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.698512 Loss T 0.180752 Method MME

S real T sketch Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 1.335486 Loss T 0.216580 Method MME

S real T sketch Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.333171 Loss T 0.165805 Method MME

S real T sketch Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.911793 Loss T 0.180090 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.0308, Accuracy: 280/1134 F1 (24.6914%)


Test set: Average loss: 3.9121, Accuracy: 6962/23808 F1 (29.2423%)


Val set: Average loss: 3.7889, Accuracy: 105/352 F1 (29.8295%)

best acc test 30.527554  acc val 29.829545 acc labeled target 24.691358
saving model...
S real T sketch Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 1.429513 Loss T 0.063242 Method MME

S real T sketch Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.914863 Loss T 0.083772 Method MME

S real T sketch Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.883209 Loss T 0.230267 Method MME

S real T sketch Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.551163 Loss T 0.217944 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.11111111 0.         0.         0.
 0.         0.5555556  0.5555556  0.         0.44444445 0.8888889
 0.         0.         0.         0.         1.         1.
 0.         0.         0.44444445 0.         0.8888889  0.
 0.33333334 0.22222222 0.         0.44444445 0.         0.11111111
 0.         0.22222222 0.         0.11111111 0.33333334 0.
 0.         0.         0.         0.         0.33333334 0.11111111
 0.         0.         0.11111111 0.         0.11111111 0.11111111
 0.33333334 0.6666667  0.33333334 0.         1.         0.
 0.33333334 0.         0.         0.7777778  0.5555556  0.
 0.5555556  0.         0.7777778  0.         0.22222222 0.11111111
 0.         0.7777778  0.         0.44444445 0.         0.
 0.6666667  0.22222222 0.7777778  0.         0.11111111 0.
 0.         0.33333334 0.         0.11111111 0.11111111 0.
 0.22222222 0.22222222 0.11111111 0.6666667  0.         0.5555556
 0.22222222 0.33333334 0.33333334 0.22222222 0.22222222 0.33333334
 0.11111111 0.         0.33333334 0.11111111 0.7777778  0.44444445
 0.         0.22222222 0.5555556  0.         0.         0.5555556
 0.33333334 0.         0.11111111 0.33333334 0.33333334 0.22222222
 0.         1.         0.         0.5555556  0.         0.22222222
 0.11111111 0.8888889  0.22222222 0.         0.         1.        ]
Top k classes which perform poorly are:  [55, 35, 36, 37, 38, 39, 42, 45, 97, 51, 53, 56, 116, 59, 61, 124, 63, 66, 114, 68, 70, 71, 75, 77, 78, 88, 80, 83, 32, 30, 43, 19, 9, 106, 6, 12, 13, 14, 15, 5, 4, 18, 3, 105, 21, 109, 28, 102, 26, 118, 123, 23, 46, 33, 65, 76, 82, 44, 29, 110, 99, 41, 96, 81, 2, 47, 120, 86, 90, 84, 113, 73, 31, 122, 64, 119, 94, 85, 103, 25, 93, 91, 92, 95, 98, 112, 108, 111, 79, 24, 34, 48, 50, 54, 40, 69, 10, 101, 27, 20, 117, 7, 8, 107, 89, 58, 60, 104, 0, 72, 87, 49, 62, 74, 67, 57, 100, 22, 121, 11, 115, 52, 17, 16, 1, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.4474, 1.5000, 1.5000, 1.5000, 1.5000, 1.2869, 1.2869,
        1.5000, 1.3206, 1.2056, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839,
        1.5000, 1.5000, 1.3206, 1.5000, 1.2056, 1.5000, 1.3583, 1.4004, 1.5000,
        1.3206, 1.5000, 1.4474, 1.5000, 1.4004, 1.5000, 1.4474, 1.3583, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.3583, 1.4474, 1.5000, 1.5000, 1.4474,
        1.5000, 1.4474, 1.4474, 1.3583, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.3583, 1.5000, 1.5000, 1.2297, 1.2869, 1.5000, 1.2869, 1.5000, 1.2297,
        1.5000, 1.4004, 1.4474, 1.5000, 1.2297, 1.5000, 1.3206, 1.5000, 1.5000,
        1.2567, 1.4004, 1.2297, 1.5000, 1.4474, 1.5000, 1.5000, 1.3583, 1.5000,
        1.4474, 1.4474, 1.5000, 1.4004, 1.4004, 1.4474, 1.2567, 1.5000, 1.2869,
        1.4004, 1.3583, 1.3583, 1.4004, 1.4004, 1.3583, 1.4474, 1.5000, 1.3583,
        1.4474, 1.2297, 1.3206, 1.5000, 1.4004, 1.2869, 1.5000, 1.5000, 1.2869,
        1.3583, 1.5000, 1.4474, 1.3583, 1.3583, 1.4004, 1.5000, 1.1839, 1.5000,
        1.2869, 1.5000, 1.4004, 1.4474, 1.2056, 1.4004, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.5526, 0.5000, 0.5000, 0.5000, 0.5000, 0.7131, 0.7131,
        0.5000, 0.6794, 0.7944, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161,
        0.5000, 0.5000, 0.6794, 0.5000, 0.7944, 0.5000, 0.6417, 0.5996, 0.5000,
        0.6794, 0.5000, 0.5526, 0.5000, 0.5996, 0.5000, 0.5526, 0.6417, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.6417, 0.5526, 0.5000, 0.5000, 0.5526,
        0.5000, 0.5526, 0.5526, 0.6417, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.6417, 0.5000, 0.5000, 0.7703, 0.7131, 0.5000, 0.7131, 0.5000, 0.7703,
        0.5000, 0.5996, 0.5526, 0.5000, 0.7703, 0.5000, 0.6794, 0.5000, 0.5000,
        0.7433, 0.5996, 0.7703, 0.5000, 0.5526, 0.5000, 0.5000, 0.6417, 0.5000,
        0.5526, 0.5526, 0.5000, 0.5996, 0.5996, 0.5526, 0.7433, 0.5000, 0.7131,
        0.5996, 0.6417, 0.6417, 0.5996, 0.5996, 0.6417, 0.5526, 0.5000, 0.6417,
        0.5526, 0.7703, 0.6794, 0.5000, 0.5996, 0.7131, 0.5000, 0.5000, 0.7131,
        0.6417, 0.5000, 0.5526, 0.6417, 0.6417, 0.5996, 0.5000, 0.8161, 0.5000,
        0.7131, 0.5000, 0.5996, 0.5526, 0.7944, 0.5996, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.718358 Loss T 0.114196 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 5.7116, Accuracy: 206/1134 F1 (18.1658%)


Test set: Average loss: 5.3892, Accuracy: 5500/23808 F1 (23.1015%)


Val set: Average loss: 5.4882, Accuracy: 72/352 F1 (20.4545%)

best acc test 30.527554  acc val 20.454545 acc labeled target 18.165785
saving model...
S real T sketch Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.843672 Loss T 0.124184 Method MME

S real T sketch Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.829119 Loss T 0.120814 Method MME

S real T sketch Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 1.012104 Loss T 0.191180 Method MME

S real T sketch Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.890497 Loss T 0.154387 Method MME

S real T sketch Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.906922 Loss T 0.148984 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.9025, Accuracy: 186/1134 F1 (16.4021%)


Test set: Average loss: 4.7693, Accuracy: 4799/23808 F1 (20.1571%)


Val set: Average loss: 4.6716, Accuracy: 74/352 F1 (21.0227%)

best acc test 30.527554  acc val 21.022727 acc labeled target 16.402116
saving model...
S real T sketch Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.617954 Loss T 0.198271 Method MME

S real T sketch Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.910022 Loss T 0.169337 Method MME

S real T sketch Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.168861 Loss T 0.185501 Method MME

S real T sketch Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.893492 Loss T 0.183752 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  0.6666667  0.         0.         0.         0.
 0.         0.11111111 0.         0.         0.11111111 0.33333334
 0.         0.         0.         0.         0.8888889  0.22222222
 0.         0.         0.44444445 0.         0.         0.
 0.11111111 0.22222222 0.         0.22222222 0.11111111 0.
 0.         0.         0.         0.         0.         0.33333334
 0.         0.         0.         0.         0.33333334 0.
 0.         0.         0.22222222 0.         0.22222222 0.44444445
 0.33333334 0.5555556  0.33333334 0.         1.         0.
 0.         0.         0.         0.         0.5555556  0.
 0.33333334 0.         0.7777778  0.         0.11111111 0.
 0.         0.6666667  0.         0.11111111 0.         0.
 0.7777778  0.33333334 0.11111111 0.         0.11111111 0.
 0.         0.5555556  0.         0.         0.11111111 0.
 0.         0.         0.22222222 0.6666667  0.         0.22222222
 0.         0.         0.33333334 0.         0.33333334 0.33333334
 0.33333334 0.         0.22222222 0.22222222 0.         0.33333334
 0.         0.5555556  0.33333334 0.         0.         0.44444445
 0.22222222 0.         0.         0.44444445 0.33333334 0.22222222
 0.11111111 1.         0.         0.33333334 0.         0.33333334
 0.         0.22222222 0.11111111 0.         0.         0.33333334]
Top k classes which perform poorly are:  [116, 124, 61, 102, 59, 57, 56, 55, 63, 54, 51, 105, 106, 97, 45, 43, 42, 53, 65, 66, 120, 93, 91, 90, 88, 118, 85, 84, 83, 81, 80, 78, 77, 75, 100, 71, 70, 68, 41, 110, 109, 38, 8, 12, 13, 14, 15, 39, 18, 19, 6, 21, 22, 9, 5, 26, 23, 32, 29, 2, 37, 30, 31, 36, 123, 33, 3, 34, 4, 76, 28, 10, 114, 74, 69, 7, 122, 64, 24, 82, 89, 86, 98, 17, 113, 25, 27, 121, 108, 46, 44, 99, 101, 104, 112, 96, 125, 94, 92, 11, 73, 119, 60, 117, 50, 95, 48, 40, 35, 20, 107, 47, 111, 49, 79, 103, 58, 0, 87, 67, 1, 72, 62, 16, 52, 115]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.4474, 1.5000,
        1.5000, 1.4474, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.2056, 1.4004,
        1.5000, 1.5000, 1.3206, 1.5000, 1.5000, 1.5000, 1.4474, 1.4004, 1.5000,
        1.4004, 1.4474, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000, 1.5000, 1.4004,
        1.5000, 1.4004, 1.3206, 1.3583, 1.2869, 1.3583, 1.5000, 1.1839, 1.5000,
        1.5000, 1.5000, 1.5000, 1.5000, 1.2869, 1.5000, 1.3583, 1.5000, 1.2297,
        1.5000, 1.4474, 1.5000, 1.5000, 1.2567, 1.5000, 1.4474, 1.5000, 1.5000,
        1.2297, 1.3583, 1.4474, 1.5000, 1.4474, 1.5000, 1.5000, 1.2869, 1.5000,
        1.5000, 1.4474, 1.5000, 1.5000, 1.5000, 1.4004, 1.2567, 1.5000, 1.4004,
        1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.3583, 1.3583, 1.5000, 1.4004,
        1.4004, 1.5000, 1.3583, 1.5000, 1.2869, 1.3583, 1.5000, 1.5000, 1.3206,
        1.4004, 1.5000, 1.5000, 1.3206, 1.3583, 1.4004, 1.4474, 1.1839, 1.5000,
        1.3583, 1.5000, 1.3583, 1.5000, 1.4004, 1.4474, 1.5000, 1.5000, 1.3583])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5526, 0.5000,
        0.5000, 0.5526, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.7944, 0.5996,
        0.5000, 0.5000, 0.6794, 0.5000, 0.5000, 0.5000, 0.5526, 0.5996, 0.5000,
        0.5996, 0.5526, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000, 0.5000, 0.5996,
        0.5000, 0.5996, 0.6794, 0.6417, 0.7131, 0.6417, 0.5000, 0.8161, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.7131, 0.5000, 0.6417, 0.5000, 0.7703,
        0.5000, 0.5526, 0.5000, 0.5000, 0.7433, 0.5000, 0.5526, 0.5000, 0.5000,
        0.7703, 0.6417, 0.5526, 0.5000, 0.5526, 0.5000, 0.5000, 0.7131, 0.5000,
        0.5000, 0.5526, 0.5000, 0.5000, 0.5000, 0.5996, 0.7433, 0.5000, 0.5996,
        0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.6417, 0.6417, 0.5000, 0.5996,
        0.5996, 0.5000, 0.6417, 0.5000, 0.7131, 0.6417, 0.5000, 0.5000, 0.6794,
        0.5996, 0.5000, 0.5000, 0.6794, 0.6417, 0.5996, 0.5526, 0.8161, 0.5000,
        0.6417, 0.5000, 0.6417, 0.5000, 0.5996, 0.5526, 0.5000, 0.5000, 0.6417])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.907272 Loss T 0.167552 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 3.9545, Accuracy: 300/1134 F1 (26.4550%)


Test set: Average loss: 3.9000, Accuracy: 7246/23808 F1 (30.4351%)


Val set: Average loss: 3.7390, Accuracy: 105/352 F1 (29.8295%)

best acc test 30.527554  acc val 29.829545 acc labeled target 26.455026
saving model...
S real T sketch Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 1.042418 Loss T 0.196565 Method MME

S real T sketch Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.410597 Loss T 0.180369 Method MME

S real T sketch Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.565211 Loss T 0.174912 Method MME

S real T sketch Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.427503 Loss T 0.149285 Method MME

S real T sketch Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.634067 Loss T 0.142323 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1567, Accuracy: 1092/1134 F1 (96.2963%)


Test set: Average loss: 3.1846, Accuracy: 9784/23808 F1 (41.0954%)


Val set: Average loss: 2.8657, Accuracy: 154/352 F1 (43.7500%)

best acc test 41.095430  acc val 43.750000 acc labeled target 96.296296
saving model...
S real T sketch Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.933672 Loss T 0.164155 Method MME

S real T sketch Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 1.577412 Loss T 0.154098 Method MME

S real T sketch Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 1.049744 Loss T 0.142176 Method MME

S real T sketch Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.947674 Loss T 0.138170 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 0.8888889 0.8888889 0.8888889 1.        1.        1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 0.7777778 1.        1.        1.        1.        0.7777778 1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        0.7777778 1.        1.        0.7777778 0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [56, 61, 109, 63, 106, 41, 25, 50, 51, 26, 85, 28, 102, 44, 101, 47, 99, 34, 35, 37, 96, 42, 36, 84, 80, 22, 78, 9, 3, 120, 6, 123, 112, 111, 110, 20, 82, 75, 90, 76, 83, 87, 88, 77, 79, 81, 86, 89, 91, 0, 93, 122, 121, 119, 118, 117, 116, 115, 114, 113, 92, 108, 105, 104, 103, 100, 74, 98, 97, 95, 94, 107, 73, 62, 71, 30, 29, 27, 24, 23, 21, 19, 18, 17, 16, 31, 15, 13, 12, 11, 10, 8, 7, 5, 4, 2, 1, 14, 32, 33, 38, 70, 69, 68, 67, 66, 65, 64, 124, 60, 59, 58, 57, 55, 54, 53, 52, 49, 48, 46, 45, 43, 40, 39, 72, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.2297, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.7703, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.270976 Loss T 0.152993 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1227, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 3.2827, Accuracy: 9884/23808 F1 (41.5155%)


Val set: Average loss: 2.9275, Accuracy: 156/352 F1 (44.3182%)

best acc test 41.515457  acc val 44.318182 acc labeled target 97.001764
saving model...
S real T sketch Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.778820 Loss T 0.126259 Method MME

S real T sketch Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.605084 Loss T 0.155847 Method MME

S real T sketch Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.674736 Loss T 0.131178 Method MME

S real T sketch Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 1.210465 Loss T 0.136585 Method MME

S real T sketch Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.432943 Loss T 0.121113 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1569, Accuracy: 1095/1134 F1 (96.5608%)


Test set: Average loss: 3.2904, Accuracy: 10067/23808 F1 (42.2841%)


Val set: Average loss: 2.9048, Accuracy: 161/352 F1 (45.7386%)

best acc test 42.284106  acc val 45.738636 acc labeled target 96.560847
saving model...
S real T sketch Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.687829 Loss T 0.140206 Method MME

S real T sketch Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.701644 Loss T 0.140972 Method MME

S real T sketch Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.640553 Loss T 0.125134 Method MME

S real T sketch Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.444090 Loss T 0.111017 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 0.8888889 0.7777778 1.       ]
Top k classes which perform poorly are:  [124, 54, 0, 28, 98, 96, 92, 91, 42, 89, 45, 88, 83, 27, 81, 80, 56, 59, 76, 63, 65, 67, 84, 103, 35, 113, 23, 22, 106, 123, 105, 122, 18, 121, 14, 6, 114, 117, 115, 82, 116, 118, 104, 78, 119, 120, 75, 74, 73, 79, 77, 87, 86, 102, 101, 100, 99, 107, 97, 72, 85, 108, 94, 93, 109, 110, 90, 111, 112, 95, 71, 62, 69, 30, 29, 26, 25, 24, 21, 20, 19, 17, 16, 15, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 31, 32, 33, 34, 68, 66, 64, 61, 60, 58, 57, 55, 53, 52, 51, 70, 50, 48, 47, 46, 44, 43, 41, 40, 39, 38, 37, 36, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.2297, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.7703, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.760044 Loss T 0.141159 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1345, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 3.3335, Accuracy: 9915/23808 F1 (41.6457%)


Val set: Average loss: 2.8265, Accuracy: 163/352 F1 (46.3068%)

best acc test 41.645665  acc val 46.306818 acc labeled target 96.913580
saving model...
S real T sketch Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 1.009465 Loss T 0.116734 Method MME

S real T sketch Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.702978 Loss T 0.143123 Method MME

S real T sketch Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.765871 Loss T 0.145150 Method MME

S real T sketch Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.884113 Loss T 0.133451 Method MME

S real T sketch Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.697987 Loss T 0.131794 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1350, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 3.3652, Accuracy: 9959/23808 F1 (41.8305%)


Val set: Average loss: 2.9747, Accuracy: 156/352 F1 (44.3182%)

best acc test 41.645665  acc val 44.318182 acc labeled target 96.737213
saving model...
S real T sketch Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.561095 Loss T 0.103666 Method MME

S real T sketch Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 1.020051 Loss T 0.121884 Method MME

S real T sketch Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.671641 Loss T 0.120636 Method MME

S real T sketch Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.725238 Loss T 0.128401 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        0.8888889 0.8888889
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        0.7777778 1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        0.7777778 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [122, 53, 36, 30, 31, 33, 34, 71, 37, 95, 94, 45, 89, 26, 51, 56, 57, 85, 82, 124, 66, 76, 92, 25, 74, 23, 118, 14, 7, 6, 110, 19, 112, 116, 1, 88, 75, 87, 86, 119, 77, 79, 84, 83, 120, 117, 121, 81, 123, 80, 78, 91, 106, 107, 105, 104, 103, 108, 109, 102, 101, 90, 111, 99, 98, 97, 96, 113, 114, 93, 115, 100, 0, 62, 72, 32, 29, 28, 27, 24, 22, 21, 20, 18, 17, 35, 16, 13, 12, 11, 10, 9, 8, 5, 4, 3, 2, 15, 38, 39, 40, 70, 69, 68, 67, 65, 64, 63, 61, 60, 59, 58, 55, 54, 52, 50, 49, 48, 47, 46, 44, 43, 42, 41, 73, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.332445 Loss T 0.130532 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1240, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 3.3247, Accuracy: 10159/23808 F1 (42.6705%)


Val set: Average loss: 2.8673, Accuracy: 165/352 F1 (46.8750%)

best acc test 42.670531  acc val 46.875000 acc labeled target 97.089947
saving model...
S real T sketch Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.513720 Loss T 0.115839 Method MME

S real T sketch Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.630463 Loss T 0.128461 Method MME

S real T sketch Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.824442 Loss T 0.107533 Method MME

S real T sketch Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.589411 Loss T 0.125948 Method MME

S real T sketch Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.642257 Loss T 0.096503 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1418, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 3.3770, Accuracy: 10181/23808 F1 (42.7629%)


Val set: Average loss: 2.9951, Accuracy: 164/352 F1 (46.5909%)

best acc test 42.670531  acc val 46.590909 acc labeled target 95.943563
saving model...
S real T sketch Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.599379 Loss T 0.108187 Method MME

S real T sketch Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.791385 Loss T 0.115308 Method MME

S real T sketch Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.599889 Loss T 0.119822 Method MME

S real T sketch Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.311224 Loss T 0.142981 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.7777778 1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.7777778 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.7777778 1.        1.        0.7777778 0.8888889 1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        0.8888889 0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 0.7777778 0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [99, 18, 45, 59, 10, 56, 100, 33, 98, 39, 97, 95, 91, 87, 54, 31, 82, 60, 80, 79, 65, 66, 77, 76, 70, 85, 28, 73, 26, 27, 16, 118, 19, 109, 6, 111, 14, 3, 122, 106, 123, 84, 115, 75, 83, 78, 120, 81, 114, 119, 121, 116, 117, 88, 113, 105, 104, 103, 107, 102, 101, 74, 86, 108, 96, 94, 93, 112, 92, 90, 89, 110, 0, 62, 71, 34, 32, 30, 29, 25, 24, 23, 22, 21, 20, 35, 17, 13, 12, 11, 9, 8, 7, 5, 4, 2, 1, 15, 36, 37, 38, 69, 68, 67, 64, 63, 124, 61, 58, 57, 55, 53, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 41, 40, 72, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.558479 Loss T 0.122805 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0886, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 3.4181, Accuracy: 10148/23808 F1 (42.6243%)


Val set: Average loss: 2.9624, Accuracy: 162/352 F1 (46.0227%)

best acc test 42.670531  acc val 46.022727 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.987719 Loss T 0.112515 Method MME

S real T sketch Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.517564 Loss T 0.119019 Method MME

S real T sketch Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.503675 Loss T 0.116508 Method MME

S real T sketch Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.449971 Loss T 0.106346 Method MME

S real T sketch Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.776096 Loss T 0.105715 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1280, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 3.3218, Accuracy: 10408/23808 F1 (43.7164%)


Val set: Average loss: 2.8626, Accuracy: 164/352 F1 (46.5909%)

best acc test 42.670531  acc val 46.590909 acc labeled target 97.266314
saving model...
S real T sketch Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.471025 Loss T 0.137390 Method MME

S real T sketch Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.413568 Loss T 0.114189 Method MME

S real T sketch Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 1.083349 Loss T 0.114911 Method MME

S real T sketch Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.385181 Loss T 0.109253 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 0.8888889 0.8888889 1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        0.8888889 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [98, 118, 62, 32, 96, 37, 38, 39, 94, 42, 92, 44, 88, 83, 81, 59, 124, 75, 67, 28, 23, 34, 106, 122, 3, 109, 110, 13, 14, 105, 86, 85, 84, 119, 82, 120, 78, 79, 87, 121, 77, 76, 74, 73, 72, 123, 80, 117, 91, 90, 107, 104, 103, 102, 101, 108, 100, 99, 89, 97, 111, 95, 112, 113, 93, 114, 115, 116, 71, 70, 0, 68, 29, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 15, 69, 31, 35, 66, 65, 64, 63, 61, 60, 58, 57, 56, 55, 54, 33, 53, 51, 50, 49, 48, 47, 46, 45, 43, 41, 40, 36, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.525280 Loss T 0.129277 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0799, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.3808, Accuracy: 10354/23808 F1 (43.4896%)


Val set: Average loss: 2.8994, Accuracy: 160/352 F1 (45.4545%)

best acc test 42.670531  acc val 45.454545 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.415369 Loss T 0.123058 Method MME

S real T sketch Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.617036 Loss T 0.118219 Method MME

S real T sketch Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.348275 Loss T 0.107014 Method MME

S real T sketch Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.446623 Loss T 0.098434 Method MME

S real T sketch Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.528116 Loss T 0.109759 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1244, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 3.4083, Accuracy: 10421/23808 F1 (43.7710%)


Val set: Average loss: 2.9193, Accuracy: 163/352 F1 (46.3068%)

best acc test 42.670531  acc val 46.306818 acc labeled target 97.089947
saving model...
S real T sketch Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.779297 Loss T 0.134659 Method MME

S real T sketch Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.831751 Loss T 0.103800 Method MME

S real T sketch Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.635581 Loss T 0.100277 Method MME

S real T sketch Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.841732 Loss T 0.105858 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        0.8888889 0.7777778 1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        0.8888889 0.8888889 0.8888889 0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [30, 106, 32, 101, 29, 37, 56, 96, 25, 24, 95, 107, 20, 108, 109, 77, 41, 8, 69, 68, 49, 66, 65, 118, 75, 99, 124, 114, 113, 61, 14, 15, 86, 85, 84, 0, 82, 81, 80, 79, 87, 78, 76, 74, 83, 88, 98, 90, 123, 122, 121, 120, 119, 117, 116, 115, 112, 111, 89, 110, 104, 103, 102, 100, 73, 97, 94, 93, 92, 91, 105, 72, 62, 70, 31, 28, 27, 26, 23, 22, 21, 19, 18, 17, 16, 13, 12, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 33, 71, 34, 36, 67, 64, 63, 60, 59, 58, 57, 55, 54, 53, 52, 51, 50, 48, 47, 46, 45, 44, 43, 42, 40, 39, 38, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.348121 Loss T 0.126770 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1294, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 3.4918, Accuracy: 10301/23808 F1 (43.2670%)


Val set: Average loss: 3.0958, Accuracy: 148/352 F1 (42.0455%)

best acc test 42.670531  acc val 42.045455 acc labeled target 96.737213
saving model...
S real T sketch Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.923887 Loss T 0.131099 Method MME

S real T sketch Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.533913 Loss T 0.098744 Method MME

S real T sketch Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.544309 Loss T 0.117513 Method MME

S real T sketch Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.797174 Loss T 0.126825 Method MME

S real T sketch Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.673399 Loss T 0.114387 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1222, Accuracy: 1099/1134 F1 (96.9136%)


Test set: Average loss: 3.4575, Accuracy: 10423/23808 F1 (43.7794%)


Val set: Average loss: 3.0387, Accuracy: 160/352 F1 (45.4545%)

best acc test 42.670531  acc val 45.454545 acc labeled target 96.913580
saving model...
S real T sketch Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.309489 Loss T 0.079904 Method MME

S real T sketch Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.936284 Loss T 0.115799 Method MME

S real T sketch Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.680718 Loss T 0.123961 Method MME

S real T sketch Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.341086 Loss T 0.105943 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        0.8888889 1.        0.7777778 0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        0.7777778 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        0.7777778 0.8888889 1.
 1.        1.        0.8888889 0.7777778 1.        1.        1.       ]
Top k classes which perform poorly are:  [82, 122, 96, 116, 76, 88, 27, 80, 67, 105, 35, 107, 108, 57, 59, 60, 47, 13, 114, 86, 9, 117, 91, 6, 39, 40, 121, 41, 99, 83, 85, 0, 81, 79, 78, 87, 75, 74, 73, 72, 71, 70, 84, 77, 94, 90, 123, 120, 119, 118, 115, 113, 112, 111, 110, 109, 106, 104, 103, 102, 101, 100, 98, 97, 95, 93, 92, 89, 69, 62, 66, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 12, 11, 10, 8, 7, 5, 4, 3, 2, 1, 15, 30, 31, 32, 65, 64, 63, 124, 61, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 38, 37, 36, 34, 33, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.584305 Loss T 0.121724 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1290, Accuracy: 1094/1134 F1 (96.4727%)


Test set: Average loss: 3.4520, Accuracy: 10501/23808 F1 (44.1070%)


Val set: Average loss: 3.0423, Accuracy: 165/352 F1 (46.8750%)

best acc test 44.107023  acc val 46.875000 acc labeled target 96.472663
saving model...
S real T sketch Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.933088 Loss T 0.108200 Method MME

S real T sketch Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.270877 Loss T 0.107089 Method MME

S real T sketch Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.344016 Loss T 0.100615 Method MME

S real T sketch Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.594705 Loss T 0.079409 Method MME

S real T sketch Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 1.101726 Loss T 0.111205 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1017, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 3.4776, Accuracy: 10466/23808 F1 (43.9600%)


Val set: Average loss: 2.9391, Accuracy: 159/352 F1 (45.1705%)

best acc test 44.107023  acc val 45.170455 acc labeled target 97.530864
saving model...
S real T sketch Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.453017 Loss T 0.088892 Method MME

S real T sketch Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.627896 Loss T 0.095066 Method MME

S real T sketch Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.678684 Loss T 0.092807 Method MME

S real T sketch Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.302303 Loss T 0.087220 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.7777778 1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [37, 9, 0, 98, 96, 94, 36, 39, 42, 89, 45, 46, 47, 88, 49, 51, 82, 81, 67, 26, 24, 95, 123, 108, 14, 21, 105, 118, 119, 87, 120, 86, 85, 84, 83, 122, 80, 79, 78, 77, 76, 75, 74, 73, 72, 121, 117, 115, 114, 104, 106, 103, 107, 102, 101, 100, 99, 97, 109, 71, 110, 111, 93, 112, 92, 91, 113, 90, 116, 70, 62, 68, 29, 28, 27, 25, 23, 22, 20, 19, 18, 17, 16, 30, 15, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 13, 69, 31, 33, 66, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 32, 55, 53, 52, 50, 48, 44, 43, 41, 40, 38, 35, 34, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.337234 Loss T 0.106033 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0832, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.5543, Accuracy: 10524/23808 F1 (44.2036%)


Val set: Average loss: 3.0483, Accuracy: 166/352 F1 (47.1591%)

best acc test 44.203629  acc val 47.159091 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.535989 Loss T 0.089788 Method MME

S real T sketch Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.334241 Loss T 0.100686 Method MME

S real T sketch Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.594153 Loss T 0.082904 Method MME

S real T sketch Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.555349 Loss T 0.095803 Method MME

S real T sketch Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.635792 Loss T 0.071555 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0784, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 3.5418, Accuracy: 10519/23808 F1 (44.1826%)


Val set: Average loss: 3.0156, Accuracy: 158/352 F1 (44.8864%)

best acc test 44.203629  acc val 44.886364 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.904005 Loss T 0.110121 Method MME

S real T sketch Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.441631 Loss T 0.112591 Method MME

S real T sketch Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.128448 Loss T 0.078913 Method MME

S real T sketch Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.626992 Loss T 0.106063 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.7777778 1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [89, 29, 48, 31, 32, 53, 40, 19, 84, 33, 56, 82, 27, 109, 80, 11, 99, 61, 78, 98, 76, 5, 3, 96, 95, 45, 14, 91, 90, 0, 87, 86, 85, 83, 81, 79, 77, 75, 74, 73, 88, 92, 100, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 93, 112, 110, 108, 107, 106, 105, 104, 103, 102, 101, 72, 97, 111, 71, 62, 69, 34, 30, 28, 26, 25, 24, 23, 22, 21, 20, 18, 35, 17, 15, 13, 12, 10, 9, 8, 7, 6, 4, 2, 1, 16, 70, 36, 38, 68, 67, 66, 65, 64, 63, 124, 60, 59, 58, 57, 37, 55, 52, 51, 50, 49, 47, 46, 44, 43, 42, 41, 39, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2297, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7703, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.734237 Loss T 0.096371 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1130, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 3.5337, Accuracy: 10502/23808 F1 (44.1112%)


Val set: Average loss: 3.1397, Accuracy: 160/352 F1 (45.4545%)

best acc test 44.203629  acc val 45.454545 acc labeled target 97.354497
saving model...
S real T sketch Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.594302 Loss T 0.096185 Method MME

S real T sketch Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.431716 Loss T 0.100016 Method MME

S real T sketch Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.692247 Loss T 0.086874 Method MME

S real T sketch Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.716342 Loss T 0.107199 Method MME

S real T sketch Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.578055 Loss T 0.103386 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0942, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 3.5057, Accuracy: 10705/23808 F1 (44.9639%)


Val set: Average loss: 2.9555, Accuracy: 159/352 F1 (45.1705%)

best acc test 44.203629  acc val 45.170455 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.238478 Loss T 0.096446 Method MME

S real T sketch Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.355490 Loss T 0.099556 Method MME

S real T sketch Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.436046 Loss T 0.099607 Method MME

S real T sketch Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.838452 Loss T 0.108171 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        0.6666667 0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [82, 106, 66, 34, 31, 89, 99, 84, 47, 83, 20, 92, 51, 80, 37, 13, 76, 9, 73, 70, 119, 78, 124, 79, 69, 91, 90, 88, 85, 87, 86, 72, 74, 75, 77, 71, 81, 0, 94, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 105, 104, 103, 102, 101, 100, 98, 97, 96, 68, 109, 95, 62, 65, 28, 27, 26, 25, 24, 23, 22, 21, 19, 18, 17, 16, 15, 14, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 32, 33, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 67, 50, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2567, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7433, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.456935 Loss T 0.081769 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1165, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.5752, Accuracy: 10698/23808 F1 (44.9345%)


Val set: Average loss: 3.1274, Accuracy: 158/352 F1 (44.8864%)

best acc test 44.203629  acc val 44.886364 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.447158 Loss T 0.084304 Method MME

S real T sketch Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.341765 Loss T 0.095315 Method MME

S real T sketch Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.469314 Loss T 0.095161 Method MME

S real T sketch Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.568274 Loss T 0.092642 Method MME

S real T sketch Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.240022 Loss T 0.075640 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1065, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 3.5766, Accuracy: 10707/23808 F1 (44.9723%)


Val set: Average loss: 3.0553, Accuracy: 163/352 F1 (46.3068%)

best acc test 44.203629  acc val 46.306818 acc labeled target 97.354497
saving model...
S real T sketch Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.423430 Loss T 0.083634 Method MME

S real T sketch Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.218436 Loss T 0.115073 Method MME

S real T sketch Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.502532 Loss T 0.100035 Method MME

S real T sketch Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.659621 Loss T 0.093445 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 0.8888889 0.8888889 1.        0.8888889 0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [82, 34, 30, 29, 28, 27, 26, 89, 105, 106, 43, 108, 84, 37, 112, 32, 33, 124, 47, 2, 122, 76, 5, 51, 66, 9, 10, 79, 50, 13, 92, 90, 91, 0, 86, 87, 85, 83, 81, 80, 78, 77, 75, 88, 93, 102, 95, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 109, 107, 104, 103, 74, 101, 100, 99, 98, 97, 96, 94, 73, 62, 71, 36, 35, 31, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 8, 7, 6, 4, 3, 1, 38, 72, 39, 41, 70, 69, 68, 67, 65, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 49, 48, 46, 45, 44, 42, 40, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.366199 Loss T 0.083768 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0586, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 3.5639, Accuracy: 10690/23808 F1 (44.9009%)


Val set: Average loss: 2.9997, Accuracy: 159/352 F1 (45.1705%)

best acc test 44.203629  acc val 45.170455 acc labeled target 98.765432
saving model...
S real T sketch Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.253750 Loss T 0.129989 Method MME

S real T sketch Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.520611 Loss T 0.098190 Method MME

S real T sketch Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.367662 Loss T 0.105860 Method MME

S real T sketch Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.436532 Loss T 0.102486 Method MME

S real T sketch Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.320793 Loss T 0.111521 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0826, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 3.5280, Accuracy: 10800/23808 F1 (45.3629%)


Val set: Average loss: 3.1528, Accuracy: 163/352 F1 (46.3068%)

best acc test 44.203629  acc val 46.306818 acc labeled target 97.795414
saving model...
S real T sketch Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.351150 Loss T 0.096275 Method MME

S real T sketch Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.425953 Loss T 0.087912 Method MME

S real T sketch Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.225676 Loss T 0.095473 Method MME

S real T sketch Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.688649 Loss T 0.098182 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [108, 0, 36, 43, 71, 90, 47, 29, 26, 21, 20, 95, 18, 54, 16, 92, 14, 113, 78, 60, 3, 81, 75, 124, 91, 72, 73, 74, 89, 88, 86, 76, 85, 84, 83, 77, 79, 80, 87, 82, 98, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 112, 111, 110, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 96, 93, 70, 62, 68, 32, 31, 30, 28, 27, 25, 24, 23, 22, 19, 17, 33, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 13, 34, 35, 37, 67, 66, 65, 64, 63, 61, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 46, 45, 44, 42, 41, 40, 39, 38, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.538948 Loss T 0.108629 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1019, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 3.5658, Accuracy: 10774/23808 F1 (45.2537%)


Val set: Average loss: 3.1691, Accuracy: 152/352 F1 (43.1818%)

best acc test 44.203629  acc val 43.181818 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.329386 Loss T 0.090697 Method MME

S real T sketch Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.287613 Loss T 0.088108 Method MME

S real T sketch Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.395914 Loss T 0.089295 Method MME

S real T sketch Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.298104 Loss T 0.103045 Method MME

S real T sketch Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.423792 Loss T 0.090667 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1038, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 3.5871, Accuracy: 10794/23808 F1 (45.3377%)


Val set: Average loss: 3.1728, Accuracy: 156/352 F1 (44.3182%)

best acc test 44.203629  acc val 44.318182 acc labeled target 97.266314
saving model...
S real T sketch Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.580842 Loss T 0.097166 Method MME

S real T sketch Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.183769 Loss T 0.106089 Method MME

S real T sketch Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.384742 Loss T 0.082060 Method MME

S real T sketch Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.327403 Loss T 0.094263 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.7777778 1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.7777778
 1.        1.        0.7777778 1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [37, 34, 83, 110, 14, 0, 45, 99, 48, 28, 53, 82, 19, 56, 79, 20, 64, 68, 75, 5, 113, 124, 40, 11, 78, 61, 91, 90, 89, 73, 74, 88, 81, 77, 92, 86, 85, 84, 76, 87, 80, 96, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 112, 111, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 72, 95, 108, 71, 62, 69, 29, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15, 13, 12, 10, 9, 8, 7, 6, 4, 3, 2, 1, 30, 31, 32, 33, 67, 66, 65, 63, 60, 59, 58, 57, 55, 54, 52, 70, 51, 49, 47, 46, 44, 43, 42, 41, 39, 38, 36, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.362298 Loss T 0.095990 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0790, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.5884, Accuracy: 10894/23808 F1 (45.7577%)


Val set: Average loss: 3.0471, Accuracy: 162/352 F1 (46.0227%)

best acc test 44.203629  acc val 46.022727 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.745290 Loss T 0.092977 Method MME

S real T sketch Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.891090 Loss T 0.092432 Method MME

S real T sketch Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.355753 Loss T 0.082395 Method MME

S real T sketch Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.322555 Loss T 0.087321 Method MME

S real T sketch Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.400609 Loss T 0.069077 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0809, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.6532, Accuracy: 10781/23808 F1 (45.2831%)


Val set: Average loss: 3.2384, Accuracy: 162/352 F1 (46.0227%)

best acc test 44.203629  acc val 46.022727 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.450155 Loss T 0.083228 Method MME

S real T sketch Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.539327 Loss T 0.099315 Method MME

S real T sketch Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.518642 Loss T 0.073457 Method MME

S real T sketch Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.181513 Loss T 0.068851 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [19, 76, 37, 36, 92, 95, 96, 44, 48, 102, 50, 105, 107, 41, 18, 40, 2, 114, 57, 124, 75, 110, 81, 71, 72, 89, 88, 73, 74, 85, 86, 77, 84, 83, 78, 79, 80, 82, 87, 0, 94, 91, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 90, 111, 108, 106, 104, 103, 101, 100, 99, 98, 97, 70, 93, 109, 69, 62, 67, 28, 27, 26, 25, 24, 23, 22, 21, 20, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 29, 68, 30, 32, 66, 65, 64, 63, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 49, 47, 46, 45, 43, 42, 39, 38, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.232001 Loss T 0.091961 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0869, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.7513, Accuracy: 10620/23808 F1 (44.6069%)


Val set: Average loss: 3.2818, Accuracy: 156/352 F1 (44.3182%)

best acc test 44.203629  acc val 44.318182 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.588013 Loss T 0.089584 Method MME

S real T sketch Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.341926 Loss T 0.091253 Method MME

S real T sketch Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.445659 Loss T 0.093925 Method MME

S real T sketch Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.292880 Loss T 0.081998 Method MME

S real T sketch Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.195104 Loss T 0.111575 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1098, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.6742, Accuracy: 10884/23808 F1 (45.7157%)


Val set: Average loss: 3.1350, Accuracy: 162/352 F1 (46.0227%)

best acc test 44.203629  acc val 46.022727 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.368949 Loss T 0.071167 Method MME

S real T sketch Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.354722 Loss T 0.114938 Method MME

S real T sketch Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.721373 Loss T 0.089126 Method MME

S real T sketch Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.246670 Loss T 0.084261 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [68, 22, 107, 25, 102, 101, 96, 95, 38, 39, 45, 86, 82, 76, 60, 73, 20, 18, 62, 5, 14, 118, 4, 109, 88, 87, 85, 84, 83, 81, 80, 79, 78, 77, 121, 75, 122, 74, 123, 72, 71, 70, 120, 89, 90, 91, 111, 108, 112, 106, 113, 105, 104, 103, 114, 110, 115, 99, 69, 97, 116, 117, 94, 119, 93, 92, 100, 98, 0, 66, 32, 31, 30, 29, 28, 27, 26, 24, 23, 21, 19, 17, 16, 15, 13, 12, 11, 10, 9, 8, 7, 6, 3, 2, 1, 33, 67, 34, 36, 65, 64, 63, 124, 61, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 41, 40, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.296952 Loss T 0.091217 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0848, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 3.6306, Accuracy: 10925/23808 F1 (45.8879%)


Val set: Average loss: 2.9996, Accuracy: 171/352 F1 (48.5795%)

best acc test 45.887937  acc val 48.579545 acc labeled target 98.412698
saving model...
S real T sketch Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.211257 Loss T 0.079743 Method MME

S real T sketch Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.354815 Loss T 0.098682 Method MME

S real T sketch Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.229735 Loss T 0.097278 Method MME

S real T sketch Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.506415 Loss T 0.080254 Method MME

S real T sketch Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.437946 Loss T 0.071785 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0614, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 3.6682, Accuracy: 10899/23808 F1 (45.7787%)


Val set: Average loss: 3.0690, Accuracy: 159/352 F1 (45.1705%)

best acc test 45.887937  acc val 45.170455 acc labeled target 98.500882
saving model...
S real T sketch Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.514463 Loss T 0.084726 Method MME

S real T sketch Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.516713 Loss T 0.077752 Method MME

S real T sketch Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.555685 Loss T 0.101429 Method MME

S real T sketch Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.439106 Loss T 0.092048 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [118, 97, 32, 44, 29, 26, 49, 106, 82, 56, 59, 38, 9, 121, 5, 4, 74, 91, 90, 89, 70, 88, 71, 87, 86, 84, 75, 83, 72, 73, 81, 92, 79, 78, 77, 76, 85, 80, 0, 94, 123, 122, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 93, 109, 107, 105, 104, 103, 102, 101, 100, 99, 98, 69, 96, 95, 108, 68, 62, 66, 30, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 3, 2, 1, 31, 67, 33, 35, 65, 64, 63, 124, 61, 60, 58, 57, 55, 54, 53, 52, 51, 50, 48, 47, 46, 45, 43, 42, 41, 40, 39, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.368184 Loss T 0.074756 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1275, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 3.6862, Accuracy: 10826/23808 F1 (45.4721%)


Val set: Average loss: 3.1967, Accuracy: 156/352 F1 (44.3182%)

best acc test 45.887937  acc val 44.318182 acc labeled target 96.737213
saving model...
S real T sketch Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.567052 Loss T 0.075505 Method MME

S real T sketch Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.241642 Loss T 0.077113 Method MME

S real T sketch Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.414918 Loss T 0.100788 Method MME

S real T sketch Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.308436 Loss T 0.091091 Method MME

S real T sketch Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.334429 Loss T 0.087773 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0828, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.6948, Accuracy: 10922/23808 F1 (45.8753%)


Val set: Average loss: 2.9981, Accuracy: 171/352 F1 (48.5795%)

best acc test 45.875336  acc val 48.579545 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.098176 Loss T 0.107889 Method MME

S real T sketch Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.335775 Loss T 0.069256 Method MME

S real T sketch Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.172888 Loss T 0.086981 Method MME

S real T sketch Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.610423 Loss T 0.092618 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.7777778 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [53, 66, 91, 89, 68, 97, 98, 99, 84, 46, 82, 106, 37, 18, 39, 64, 63, 121, 10, 8, 118, 77, 88, 87, 86, 69, 70, 71, 76, 83, 72, 81, 80, 73, 74, 78, 75, 85, 79, 0, 92, 123, 122, 120, 119, 117, 116, 115, 114, 113, 112, 111, 90, 110, 108, 107, 105, 104, 103, 102, 101, 100, 96, 95, 93, 109, 94, 62, 65, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 12, 11, 9, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 51, 50, 67, 49, 47, 45, 44, 43, 42, 41, 40, 38, 36, 35, 34, 33, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.276232 Loss T 0.078810 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0820, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 3.7760, Accuracy: 10818/23808 F1 (45.4385%)


Val set: Average loss: 3.1892, Accuracy: 160/352 F1 (45.4545%)

best acc test 45.875336  acc val 45.454545 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.545971 Loss T 0.073660 Method MME

S real T sketch Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.402071 Loss T 0.093267 Method MME

S real T sketch Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.305802 Loss T 0.081280 Method MME

S real T sketch Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.250973 Loss T 0.078540 Method MME

S real T sketch Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.345569 Loss T 0.074384 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0868, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.7504, Accuracy: 10897/23808 F1 (45.7703%)


Val set: Average loss: 3.1255, Accuracy: 159/352 F1 (45.1705%)

best acc test 45.875336  acc val 45.170455 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.538262 Loss T 0.093833 Method MME

S real T sketch Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.171445 Loss T 0.065708 Method MME

S real T sketch Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.150799 Loss T 0.101311 Method MME

S real T sketch Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.516179 Loss T 0.083905 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.7777778 1.        1.       ]
Top k classes which perform poorly are:  [123, 62, 34, 98, 99, 84, 82, 105, 24, 80, 22, 107, 108, 17, 19, 2, 12, 57, 115, 74, 63, 76, 77, 89, 88, 87, 86, 69, 85, 71, 83, 81, 72, 73, 90, 79, 75, 78, 70, 91, 97, 93, 122, 121, 120, 119, 118, 117, 116, 114, 113, 112, 111, 110, 109, 106, 104, 103, 102, 101, 100, 68, 96, 95, 94, 92, 67, 0, 65, 31, 30, 29, 28, 27, 26, 25, 23, 21, 20, 18, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 32, 33, 35, 36, 64, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 66, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.483054 Loss T 0.069984 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0603, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.8129, Accuracy: 10795/23808 F1 (45.3419%)


Val set: Average loss: 3.1160, Accuracy: 172/352 F1 (48.8636%)

best acc test 45.341902  acc val 48.863636 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.313440 Loss T 0.065845 Method MME

S real T sketch Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.796612 Loss T 0.062928 Method MME

S real T sketch Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.481017 Loss T 0.090376 Method MME

S real T sketch Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.123298 Loss T 0.077132 Method MME

S real T sketch Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.171730 Loss T 0.078563 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0802, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.7893, Accuracy: 10905/23808 F1 (45.8039%)


Val set: Average loss: 3.2184, Accuracy: 157/352 F1 (44.6023%)

best acc test 45.341902  acc val 44.602273 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.160620 Loss T 0.081154 Method MME

S real T sketch Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.255268 Loss T 0.074490 Method MME

S real T sketch Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.443125 Loss T 0.080697 Method MME

S real T sketch Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.278956 Loss T 0.071089 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [51, 26, 82, 40, 95, 42, 30, 85, 46, 47, 102, 106, 90, 37, 122, 76, 10, 63, 112, 61, 78, 89, 70, 88, 71, 87, 86, 73, 74, 75, 84, 83, 77, 81, 80, 79, 72, 0, 94, 92, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 91, 109, 107, 105, 104, 103, 101, 100, 99, 98, 97, 96, 69, 93, 108, 68, 62, 66, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 67, 29, 32, 65, 64, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 45, 44, 43, 41, 39, 38, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.280273 Loss T 0.091438 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0814, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 3.8094, Accuracy: 10874/23808 F1 (45.6737%)


Val set: Average loss: 3.1601, Accuracy: 161/352 F1 (45.7386%)

best acc test 45.341902  acc val 45.738636 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.217573 Loss T 0.072610 Method MME

S real T sketch Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.906439 Loss T 0.076670 Method MME

S real T sketch Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.339097 Loss T 0.078430 Method MME

S real T sketch Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.455047 Loss T 0.087061 Method MME

S real T sketch Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.331642 Loss T 0.072531 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0608, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 3.8153, Accuracy: 10891/23808 F1 (45.7451%)


Val set: Average loss: 3.2275, Accuracy: 152/352 F1 (43.1818%)

best acc test 45.341902  acc val 43.181818 acc labeled target 98.500882
saving model...
S real T sketch Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.139418 Loss T 0.065476 Method MME

S real T sketch Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.239509 Loss T 0.091166 Method MME

S real T sketch Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.771711 Loss T 0.071382 Method MME

S real T sketch Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.383138 Loss T 0.077307 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        0.7777778 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [65, 62, 66, 31, 30, 29, 24, 105, 50, 51, 109, 77, 18, 9, 63, 56, 78, 90, 89, 70, 88, 71, 72, 87, 86, 85, 84, 83, 82, 74, 81, 75, 91, 76, 80, 79, 73, 92, 97, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 93, 111, 108, 107, 106, 104, 103, 102, 101, 100, 99, 98, 96, 95, 110, 69, 0, 67, 28, 27, 26, 25, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 32, 68, 33, 35, 64, 124, 61, 60, 59, 58, 57, 55, 54, 53, 52, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.514849 Loss T 0.069510 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1039, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 3.7945, Accuracy: 10985/23808 F1 (46.1400%)


Val set: Average loss: 3.2739, Accuracy: 160/352 F1 (45.4545%)

best acc test 45.341902  acc val 45.454545 acc labeled target 97.530864
saving model...
S real T sketch Train Ep: 28100 lr0.0036669608075000928 	 Loss Classification: 0.169574 Loss T 0.084340 Method MME

S real T sketch Train Ep: 28200 lr0.00365975891867815 	 Loss Classification: 0.256899 Loss T 0.065912 Method MME

S real T sketch Train Ep: 28300 lr0.003652589947415138 	 Loss Classification: 0.274516 Loss T 0.081591 Method MME

S real T sketch Train Ep: 28400 lr0.0036454536578964408 	 Loss Classification: 0.544260 Loss T 0.098494 Method MME

S real T sketch Train Ep: 28500 lr0.0036383498166050877 	 Loss Classification: 0.273616 Loss T 0.069623 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0879, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 3.7342, Accuracy: 10915/23808 F1 (45.8459%)


Val set: Average loss: 3.2910, Accuracy: 160/352 F1 (45.4545%)

best acc test 45.341902  acc val 45.454545 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 28600 lr0.0036312781922934662 	 Loss Classification: 0.131932 Loss T 0.082709 Method MME

S real T sketch Train Ep: 28700 lr0.003624238555955462 	 Loss Classification: 0.327698 Loss T 0.066052 Method MME

S real T sketch Train Ep: 28800 lr0.003617230680799007 	 Loss Classification: 0.109142 Loss T 0.056821 Method MME

S real T sketch Train Ep: 28900 lr0.0036102543422190363 	 Loss Classification: 0.297737 Loss T 0.080729 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.7777778 1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        0.6666667 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        0.7777778
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [29, 41, 3, 72, 46, 48, 36, 69, 34, 26, 25, 108, 23, 109, 96, 19, 21, 44, 14, 13, 12, 75, 76, 8, 83, 73, 94, 74, 93, 77, 78, 92, 84, 90, 88, 87, 79, 80, 81, 86, 82, 85, 91, 89, 0, 97, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 107, 106, 105, 104, 103, 102, 100, 99, 98, 95, 101, 62, 70, 35, 33, 32, 31, 30, 28, 27, 24, 22, 20, 18, 17, 16, 15, 11, 10, 9, 7, 6, 5, 4, 2, 1, 37, 38, 39, 40, 68, 67, 66, 65, 64, 63, 124, 61, 60, 59, 58, 71, 57, 55, 54, 53, 52, 51, 50, 49, 47, 45, 43, 42, 56, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 29000 lr0.003603309317770844 	 Loss Classification: 0.303746 Loss T 0.084662 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0795, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 3.8045, Accuracy: 10985/23808 F1 (46.1400%)


Val set: Average loss: 3.2970, Accuracy: 154/352 F1 (43.7500%)

best acc test 45.341902  acc val 43.750000 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 29100 lr0.0035963953871438275 	 Loss Classification: 0.215248 Loss T 0.073689 Method MME

S real T sketch Train Ep: 29200 lr0.0035895123321356215 	 Loss Classification: 0.211877 Loss T 0.057545 Method MME

S real T sketch Train Ep: 29300 lr0.003582659936626608 	 Loss Classification: 0.318562 Loss T 0.074716 Method MME

S real T sketch Train Ep: 29400 lr0.0035758379865547998 	 Loss Classification: 0.279746 Loss T 0.081425 Method MME

S real T sketch Train Ep: 29500 lr0.0035690462698910875 	 Loss Classification: 0.234788 Loss T 0.058014 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0772, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.8171, Accuracy: 10942/23808 F1 (45.9593%)


Val set: Average loss: 3.1367, Accuracy: 166/352 F1 (47.1591%)

best acc test 45.341902  acc val 47.159091 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 29600 lr0.0035622845766148485 	 Loss Classification: 0.408341 Loss T 0.073999 Method MME

S real T sketch Train Ep: 29700 lr0.0035555526986899093 	 Loss Classification: 0.309865 Loss T 0.063105 Method MME

S real T sketch Train Ep: 29800 lr0.0035488504300408524 	 Loss Classification: 0.191798 Loss T 0.094283 Method MME

S real T sketch Train Ep: 29900 lr0.0035421775665296674 	 Loss Classification: 0.324033 Loss T 0.062766 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        0.7777778 0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [36, 73, 19, 37, 92, 33, 32, 30, 100, 48, 51, 20, 93, 83, 108, 39, 67, 66, 57, 58, 9, 82, 72, 91, 74, 75, 90, 76, 89, 77, 81, 87, 86, 85, 84, 78, 79, 80, 88, 0, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 94, 111, 109, 107, 106, 105, 104, 103, 102, 101, 99, 98, 97, 71, 110, 70, 62, 68, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15, 28, 14, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 13, 69, 29, 34, 65, 64, 63, 124, 61, 60, 59, 56, 55, 54, 53, 31, 52, 49, 47, 46, 45, 44, 43, 42, 41, 40, 38, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2297, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7703, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 30000 lr0.003535533905932738 	 Loss Classification: 0.347122 Loss T 0.079754 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0848, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.8257, Accuracy: 11027/23808 F1 (46.3164%)


Val set: Average loss: 3.1931, Accuracy: 161/352 F1 (45.7386%)

best acc test 45.341902  acc val 45.738636 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 30100 lr0.0035289192479181558 	 Loss Classification: 0.178054 Loss T 0.062602 Method MME

S real T sketch Train Ep: 30200 lr0.003522333394023364 	 Loss Classification: 0.318180 Loss T 0.071929 Method MME

S real T sketch Train Ep: 30300 lr0.0035157761476331158 	 Loss Classification: 0.606932 Loss T 0.073336 Method MME

S real T sketch Train Ep: 30400 lr0.003509247313957748 	 Loss Classification: 0.445061 Loss T 0.069136 Method MME

S real T sketch Train Ep: 30500 lr0.003502746700011762 	 Loss Classification: 0.275500 Loss T 0.095205 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0734, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.8158, Accuracy: 10958/23808 F1 (46.0265%)


Val set: Average loss: 3.3143, Accuracy: 154/352 F1 (43.7500%)

best acc test 45.341902  acc val 43.750000 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 30600 lr0.003496274114592713 	 Loss Classification: 0.265868 Loss T 0.052978 Method MME

S real T sketch Train Ep: 30700 lr0.0034898293682603908 	 Loss Classification: 0.645688 Loss T 0.075915 Method MME

S real T sketch Train Ep: 30800 lr0.0034834122733162975 	 Loss Classification: 0.245443 Loss T 0.042301 Method MME

S real T sketch Train Ep: 30900 lr0.0034770226437834152 	 Loss Classification: 0.475921 Loss T 0.079531 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 0.8888889 0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [67, 92, 95, 44, 30, 104, 20, 41, 77, 56, 111, 75, 19, 39, 65, 9, 122, 118, 3, 121, 120, 60, 89, 88, 87, 86, 85, 84, 74, 81, 80, 79, 78, 70, 71, 76, 72, 73, 83, 82, 0, 91, 123, 119, 117, 116, 115, 114, 113, 112, 110, 109, 108, 90, 107, 105, 103, 102, 101, 100, 99, 98, 97, 69, 94, 93, 106, 96, 62, 66, 29, 28, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 2, 1, 31, 68, 32, 34, 64, 63, 124, 61, 59, 58, 57, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 43, 42, 40, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 31000 lr0.003470660295386255 	 Loss Classification: 0.464276 Loss T 0.060421 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0525, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 3.8657, Accuracy: 10994/23808 F1 (46.1778%)


Val set: Average loss: 3.1603, Accuracy: 163/352 F1 (46.3068%)

best acc test 45.341902  acc val 46.306818 acc labeled target 98.677249
saving model...
S real T sketch Train Ep: 31100 lr0.0034643250455311855 	 Loss Classification: 0.435026 Loss T 0.089438 Method MME

S real T sketch Train Ep: 31200 lr0.0034580167132870383 	 Loss Classification: 0.247424 Loss T 0.065295 Method MME

S real T sketch Train Ep: 31300 lr0.00345173511936598 	 Loss Classification: 0.417811 Loss T 0.066261 Method MME

S real T sketch Train Ep: 31400 lr0.0034454800861046533 	 Loss Classification: 0.216922 Loss T 0.059328 Method MME

S real T sketch Train Ep: 31500 lr0.003439251437445577 	 Loss Classification: 0.257459 Loss T 0.070971 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1224, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 3.8604, Accuracy: 11002/23808 F1 (46.2114%)


Val set: Average loss: 3.2435, Accuracy: 163/352 F1 (46.3068%)

best acc test 45.341902  acc val 46.306818 acc labeled target 97.266314
saving model...
S real T sketch Train Ep: 31600 lr0.0034330489989188046 	 Loss Classification: 0.281829 Loss T 0.081035 Method MME

S real T sketch Train Ep: 31700 lr0.0034268725976238346 	 Loss Classification: 0.199373 Loss T 0.082194 Method MME

S real T sketch Train Ep: 31800 lr0.003420722062211772 	 Loss Classification: 0.219967 Loss T 0.065427 Method MME

S real T sketch Train Ep: 31900 lr0.0034145972228677326 	 Loss Classification: 0.344502 Loss T 0.075720 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [62, 105, 25, 26, 33, 34, 36, 41, 42, 106, 46, 89, 88, 87, 61, 78, 63, 64, 76, 48, 21, 35, 117, 2, 4, 6, 120, 14, 113, 71, 110, 101, 86, 85, 84, 83, 82, 81, 80, 79, 121, 122, 109, 77, 123, 75, 74, 73, 111, 112, 119, 90, 100, 99, 103, 104, 72, 114, 98, 97, 102, 96, 115, 116, 94, 93, 92, 108, 91, 118, 95, 107, 0, 69, 30, 29, 28, 27, 24, 23, 22, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 8, 7, 5, 3, 1, 31, 70, 32, 38, 68, 67, 66, 65, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 45, 44, 43, 40, 39, 37, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 32000 lr0.0034084979112934868 	 Loss Classification: 0.462243 Loss T 0.057238 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0818, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.9656, Accuracy: 10876/23808 F1 (45.6821%)


Val set: Average loss: 3.4136, Accuracy: 162/352 F1 (46.0227%)

best acc test 45.341902  acc val 46.022727 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 32100 lr0.003402423960690348 	 Loss Classification: 0.324768 Loss T 0.072611 Method MME

S real T sketch Train Ep: 32200 lr0.0033963752057422827 	 Loss Classification: 0.442428 Loss T 0.079440 Method MME

S real T sketch Train Ep: 32300 lr0.003390351482599261 	 Loss Classification: 0.141845 Loss T 0.066948 Method MME

S real T sketch Train Ep: 32400 lr0.003384352628860824 	 Loss Classification: 0.254676 Loss T 0.057015 Method MME

S real T sketch Train Ep: 32500 lr0.003378378483559883 	 Loss Classification: 0.350509 Loss T 0.075893 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0893, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 3.8970, Accuracy: 11025/23808 F1 (46.3080%)


Val set: Average loss: 3.3251, Accuracy: 157/352 F1 (44.6023%)

best acc test 45.341902  acc val 44.602273 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 32600 lr0.0033724288871467283 	 Loss Classification: 0.224628 Loss T 0.089480 Method MME

S real T sketch Train Ep: 32700 lr0.003366503681473259 	 Loss Classification: 0.334185 Loss T 0.055885 Method MME

S real T sketch Train Ep: 32800 lr0.0033606027097774233 	 Loss Classification: 0.422735 Loss T 0.085127 Method MME

S real T sketch Train Ep: 32900 lr0.003354725816667868 	 Loss Classification: 0.386552 Loss T 0.083922 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        0.7777778 1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [18, 22, 105, 25, 101, 95, 39, 41, 109, 62, 89, 88, 80, 54, 55, 75, 66, 90, 42, 68, 111, 14, 120, 13, 4, 108, 85, 84, 83, 82, 81, 121, 79, 77, 86, 76, 122, 74, 73, 72, 71, 70, 123, 78, 87, 118, 110, 107, 106, 112, 104, 103, 102, 100, 99, 98, 119, 97, 113, 94, 93, 92, 114, 91, 115, 116, 117, 69, 96, 0, 65, 30, 29, 28, 27, 26, 24, 23, 21, 20, 19, 17, 31, 16, 12, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 15, 32, 33, 34, 64, 63, 124, 61, 60, 59, 58, 57, 56, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 40, 38, 37, 36, 35, 67, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 33000 lr0.00334887284810879 	 Loss Classification: 0.363462 Loss T 0.068160 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0833, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.8389, Accuracy: 11099/23808 F1 (46.6188%)


Val set: Average loss: 3.1739, Accuracy: 170/352 F1 (48.2955%)

best acc test 45.341902  acc val 48.295455 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 33100 lr0.003343043651404997 	 Loss Classification: 0.609872 Loss T 0.049494 Method MME

S real T sketch Train Ep: 33200 lr0.0033372380751871583 	 Loss Classification: 0.278745 Loss T 0.063250 Method MME

S real T sketch Train Ep: 33300 lr0.0033314559693972583 	 Loss Classification: 0.398048 Loss T 0.073065 Method MME

S real T sketch Train Ep: 33400 lr0.0033256971852742394 	 Loss Classification: 0.271447 Loss T 0.063796 Method MME

S real T sketch Train Ep: 33500 lr0.0033199615753398367 	 Loss Classification: 0.333301 Loss T 0.066484 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0861, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.9088, Accuracy: 11018/23808 F1 (46.2786%)


Val set: Average loss: 3.1737, Accuracy: 173/352 F1 (49.1477%)

best acc test 46.278562  acc val 49.147727 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 33600 lr0.0033142489933845978 	 Loss Classification: 0.156155 Loss T 0.080446 Method MME

S real T sketch Train Ep: 33700 lr0.0033085592944540883 	 Loss Classification: 0.181646 Loss T 0.066340 Method MME

S real T sketch Train Ep: 33800 lr0.003302892334835276 	 Loss Classification: 0.321325 Loss T 0.068368 Method MME

S real T sketch Train Ep: 33900 lr0.003297247972043097 	 Loss Classification: 0.367625 Loss T 0.065966 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 1.        0.8888889 0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [99, 80, 86, 51, 28, 30, 56, 76, 113, 31, 32, 60, 88, 124, 6, 5, 120, 89, 35, 90, 116, 83, 85, 87, 0, 82, 81, 91, 79, 78, 77, 75, 74, 73, 72, 71, 70, 84, 92, 97, 94, 123, 122, 121, 119, 118, 117, 115, 114, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 69, 96, 95, 93, 68, 62, 66, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 4, 3, 2, 1, 29, 67, 33, 36, 65, 64, 63, 61, 59, 58, 57, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 34000 lr0.0032916260648071937 	 Loss Classification: 0.345574 Loss T 0.074735 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0902, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 3.9803, Accuracy: 11044/23808 F1 (46.3878%)


Val set: Average loss: 3.3427, Accuracy: 163/352 F1 (46.3068%)

best acc test 46.278562  acc val 46.306818 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 34100 lr0.0032860264730588296 	 Loss Classification: 0.263064 Loss T 0.061896 Method MME

S real T sketch Train Ep: 34200 lr0.003280449057917969 	 Loss Classification: 0.081885 Loss T 0.071871 Method MME

S real T sketch Train Ep: 34300 lr0.0032748936816805302 	 Loss Classification: 0.227218 Loss T 0.062299 Method MME

S real T sketch Train Ep: 34400 lr0.0032693602078058027 	 Loss Classification: 0.230559 Loss T 0.051842 Method MME

S real T sketch Train Ep: 34500 lr0.0032638485009040203 	 Loss Classification: 0.484696 Loss T 0.061423 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0974, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 3.9270, Accuracy: 11006/23808 F1 (46.2282%)


Val set: Average loss: 3.4046, Accuracy: 156/352 F1 (44.3182%)

best acc test 46.278562  acc val 44.318182 acc labeled target 97.530864
saving model...
S real T sketch Train Ep: 34600 lr0.0032583584267241073 	 Loss Classification: 0.236660 Loss T 0.060490 Method MME

S real T sketch Train Ep: 34700 lr0.0032528898521415684 	 Loss Classification: 0.298392 Loss T 0.065468 Method MME

S real T sketch Train Ep: 34800 lr0.0032474426451465444 	 Loss Classification: 0.220651 Loss T 0.065203 Method MME

S real T sketch Train Ep: 34900 lr0.0032420166748320153 	 Loss Classification: 0.426739 Loss T 0.058475 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [62, 28, 98, 68, 96, 36, 38, 41, 45, 89, 85, 51, 53, 54, 82, 78, 65, 73, 27, 107, 97, 19, 6, 110, 120, 20, 15, 14, 108, 86, 117, 118, 84, 119, 83, 81, 80, 121, 77, 76, 75, 74, 122, 123, 72, 79, 87, 115, 116, 106, 105, 104, 103, 109, 102, 101, 100, 99, 111, 112, 95, 113, 94, 93, 114, 92, 91, 90, 88, 71, 0, 69, 31, 30, 29, 26, 25, 24, 23, 22, 21, 18, 17, 32, 16, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 13, 70, 33, 35, 67, 66, 64, 63, 124, 61, 60, 59, 58, 57, 56, 34, 55, 50, 49, 48, 47, 46, 44, 43, 42, 40, 39, 37, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 35000 lr0.0032366118113821563 	 Loss Classification: 0.243797 Loss T 0.074113 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0957, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 3.9682, Accuracy: 11071/23808 F1 (46.5012%)


Val set: Average loss: 3.4686, Accuracy: 154/352 F1 (43.7500%)

best acc test 46.278562  acc val 43.750000 acc labeled target 98.236332
saving model...
S real T sketch Train Ep: 35100 lr0.0032312279260608436 	 Loss Classification: 0.469373 Loss T 0.054444 Method MME

S real T sketch Train Ep: 35200 lr0.0032258648912003012 	 Loss Classification: 0.108684 Loss T 0.082957 Method MME

S real T sketch Train Ep: 35300 lr0.003220522580189901 	 Loss Classification: 0.459382 Loss T 0.072985 Method MME

S real T sketch Train Ep: 35400 lr0.0032152008674650925 	 Loss Classification: 0.157715 Loss T 0.061234 Method MME

S real T sketch Train Ep: 35500 lr0.0032098996284964853 	 Loss Classification: 0.148768 Loss T 0.051015 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0913, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 3.9673, Accuracy: 11011/23808 F1 (46.2492%)


Val set: Average loss: 3.2624, Accuracy: 164/352 F1 (46.5909%)

best acc test 46.278562  acc val 46.590909 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 35600 lr0.0032046187397790603 	 Loss Classification: 0.198086 Loss T 0.053625 Method MME

S real T sketch Train Ep: 35700 lr0.0031993580788215194 	 Loss Classification: 0.168812 Loss T 0.050844 Method MME

S real T sketch Train Ep: 35800 lr0.0031941175241357693 	 Loss Classification: 0.340855 Loss T 0.066306 Method MME

S real T sketch Train Ep: 35900 lr0.0031888969552265386 	 Loss Classification: 0.274876 Loss T 0.048813 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [98, 62, 19, 40, 106, 23, 82, 83, 27, 86, 97, 95, 93, 37, 39, 18, 108, 90, 111, 112, 12, 56, 120, 109, 72, 78, 69, 89, 70, 71, 88, 87, 85, 74, 84, 75, 76, 81, 77, 80, 73, 79, 96, 92, 123, 122, 121, 119, 118, 117, 116, 115, 114, 113, 110, 107, 105, 104, 103, 102, 101, 100, 99, 68, 94, 91, 67, 0, 65, 30, 29, 28, 26, 25, 24, 22, 21, 20, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 32, 33, 34, 64, 63, 124, 61, 60, 59, 58, 57, 55, 54, 53, 52, 66, 51, 49, 48, 47, 46, 45, 44, 43, 42, 41, 38, 36, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 36000 lr0.00318369625258112 	 Loss Classification: 0.207139 Loss T 0.078484 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0715, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 3.9799, Accuracy: 11065/23808 F1 (46.4760%)


Val set: Average loss: 3.3700, Accuracy: 157/352 F1 (44.6023%)

best acc test 46.278562  acc val 44.602273 acc labeled target 98.324515
saving model...
S real T sketch Train Ep: 36100 lr0.0031785152976592465 	 Loss Classification: 0.138665 Loss T 0.080687 Method MME

S real T sketch Train Ep: 36200 lr0.0031733539728830895 	 Loss Classification: 0.465575 Loss T 0.052101 Method MME

S real T sketch Train Ep: 36300 lr0.003168212161627382 	 Loss Classification: 0.288902 Loss T 0.055918 Method MME

S real T sketch Train Ep: 36400 lr0.0031630897482096652 	 Loss Classification: 0.248720 Loss T 0.071077 Method MME

S real T sketch Train Ep: 36500 lr0.0031579866178806544 	 Loss Classification: 0.448915 Loss T 0.065866 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0717, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 3.9899, Accuracy: 11005/23808 F1 (46.2240%)


Val set: Average loss: 3.3674, Accuracy: 163/352 F1 (46.3068%)

best acc test 46.278562  acc val 46.306818 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 36600 lr0.003152902656814724 	 Loss Classification: 0.244369 Loss T 0.065462 Method MME

S real T sketch Train Ep: 36700 lr0.003147837752100511 	 Loss Classification: 0.252104 Loss T 0.050155 Method MME

S real T sketch Train Ep: 36800 lr0.003142791791731634 	 Loss Classification: 0.352399 Loss T 0.054489 Method MME

S real T sketch Train Ep: 36900 lr0.0031377646645975228 	 Loss Classification: 0.144980 Loss T 0.073894 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        0.8888889 0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.7777778 1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [71, 41, 95, 45, 19, 44, 98, 43, 56, 112, 113, 75, 68, 73, 119, 121, 4, 3, 70, 25, 87, 88, 86, 85, 79, 83, 82, 81, 80, 89, 78, 77, 76, 74, 72, 69, 84, 90, 0, 92, 123, 122, 120, 118, 117, 116, 115, 114, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 96, 94, 93, 91, 67, 62, 65, 29, 28, 27, 26, 24, 23, 22, 21, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 2, 1, 30, 31, 32, 33, 64, 63, 124, 61, 60, 59, 58, 57, 55, 54, 53, 52, 66, 51, 49, 48, 47, 46, 42, 40, 39, 38, 37, 36, 35, 34, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2297,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7703,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 37000 lr0.003132756260474365 	 Loss Classification: 0.237336 Loss T 0.058949 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0711, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 3.9655, Accuracy: 11109/23808 F1 (46.6608%)


Val set: Average loss: 3.1998, Accuracy: 171/352 F1 (48.5795%)

best acc test 46.278562  acc val 48.579545 acc labeled target 97.971781
saving model...
S real T sketch Train Ep: 37100 lr0.0031277664700161607 	 Loss Classification: 0.218799 Loss T 0.066642 Method MME

S real T sketch Train Ep: 37200 lr0.003122795184745882 	 Loss Classification: 0.198899 Loss T 0.077103 Method MME

S real T sketch Train Ep: 37300 lr0.003117842297046751 	 Loss Classification: 0.234301 Loss T 0.060377 Method MME

S real T sketch Train Ep: 37400 lr0.0031129077001536103 	 Loss Classification: 0.439981 Loss T 0.052690 Method MME

S real T sketch Train Ep: 37500 lr0.00310799128814441 	 Loss Classification: 0.096185 Loss T 0.059697 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1032, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 3.9902, Accuracy: 11086/23808 F1 (46.5642%)


Val set: Average loss: 3.2978, Accuracy: 168/352 F1 (47.7273%)

best acc test 46.278562  acc val 47.727273 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 37600 lr0.0031030929559317877 	 Loss Classification: 0.181398 Loss T 0.052821 Method MME

S real T sketch Train Ep: 37700 lr0.003098212599254758 	 Loss Classification: 0.061511 Loss T 0.056092 Method MME

S real T sketch Train Ep: 37800 lr0.003093350114670496 	 Loss Classification: 0.147931 Loss T 0.061299 Method MME

S real T sketch Train Ep: 37900 lr0.003088505399546223 	 Loss Classification: 0.195920 Loss T 0.059613 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [35, 84, 23, 105, 25, 50, 89, 30, 47, 33, 98, 97, 37, 45, 39, 95, 56, 18, 85, 82, 123, 76, 115, 11, 80, 9, 42, 14, 60, 81, 73, 74, 75, 92, 91, 87, 79, 90, 83, 86, 88, 78, 77, 0, 94, 122, 121, 120, 119, 118, 117, 116, 114, 113, 112, 111, 93, 110, 108, 107, 106, 104, 103, 102, 101, 100, 99, 72, 96, 109, 71, 62, 69, 29, 28, 27, 26, 24, 22, 21, 20, 19, 17, 16, 15, 13, 12, 10, 8, 7, 6, 5, 4, 3, 2, 1, 31, 32, 34, 36, 68, 67, 66, 65, 64, 63, 124, 61, 59, 58, 57, 70, 55, 53, 52, 51, 49, 48, 46, 44, 43, 41, 40, 38, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 38000 lr0.0030836783520511884 	 Loss Classification: 0.219142 Loss T 0.059149 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0816, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 4.0094, Accuracy: 11086/23808 F1 (46.5642%)


Val set: Average loss: 3.3015, Accuracy: 165/352 F1 (46.8750%)

best acc test 46.278562  acc val 46.875000 acc labeled target 98.324515
saving model...
S real T sketch Train Ep: 38100 lr0.0030788688711487463 	 Loss Classification: 0.324405 Loss T 0.055241 Method MME

S real T sketch Train Ep: 38200 lr0.0030740768565885295 	 Loss Classification: 0.266165 Loss T 0.073393 Method MME

S real T sketch Train Ep: 38300 lr0.0030693022088987133 	 Loss Classification: 0.252466 Loss T 0.060413 Method MME

S real T sketch Train Ep: 38400 lr0.0030645448293783735 	 Loss Classification: 0.128921 Loss T 0.080117 Method MME

S real T sketch Train Ep: 38500 lr0.0030598046200899344 	 Loss Classification: 0.175113 Loss T 0.062526 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0863, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 4.0042, Accuracy: 11061/23808 F1 (46.4592%)


Val set: Average loss: 3.3833, Accuracy: 167/352 F1 (47.4432%)

best acc test 46.278562  acc val 47.443182 acc labeled target 98.236332
saving model...
S real T sketch Train Ep: 38600 lr0.0030550814838517073 	 Loss Classification: 0.515250 Loss T 0.058099 Method MME

S real T sketch Train Ep: 38700 lr0.0030503753242305132 	 Loss Classification: 0.401684 Loss T 0.052014 Method MME

S real T sketch Train Ep: 38800 lr0.003045686045534399 	 Loss Classification: 0.131648 Loss T 0.059981 Method MME

S real T sketch Train Ep: 38900 lr0.003041013552805431 	 Loss Classification: 0.447578 Loss T 0.051309 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        0.7777778 0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [5, 0, 48, 29, 30, 88, 58, 14, 13, 116, 85, 44, 9, 75, 70, 6, 63, 10, 106, 89, 90, 87, 86, 91, 80, 83, 82, 81, 92, 79, 78, 77, 76, 74, 73, 72, 71, 84, 93, 99, 95, 123, 122, 121, 120, 119, 118, 117, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 98, 97, 96, 94, 69, 62, 67, 33, 32, 31, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 12, 11, 8, 7, 4, 3, 2, 1, 34, 68, 35, 37, 66, 65, 64, 124, 61, 60, 59, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 43, 42, 41, 40, 39, 38, 36, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 39000 lr0.003036357751812582 	 Loss Classification: 0.274336 Loss T 0.069625 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0908, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 4.0768, Accuracy: 11011/23808 F1 (46.2492%)


Val set: Average loss: 3.3429, Accuracy: 164/352 F1 (46.5909%)

best acc test 46.278562  acc val 46.590909 acc labeled target 97.707231
saving model...
S real T sketch Train Ep: 39100 lr0.0030317185490446956 	 Loss Classification: 0.291484 Loss T 0.055401 Method MME

S real T sketch Train Ep: 39200 lr0.0030270958517035324 	 Loss Classification: 0.473319 Loss T 0.051950 Method MME

S real T sketch Train Ep: 39300 lr0.003022489567696903 	 Loss Classification: 0.491586 Loss T 0.072942 Method MME

S real T sketch Train Ep: 39400 lr0.0030178996056318755 	 Loss Classification: 0.114356 Loss T 0.043411 Method MME

S real T sketch Train Ep: 39500 lr0.0030133258748080622 	 Loss Classification: 0.433396 Loss T 0.061140 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0701, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 4.0365, Accuracy: 11110/23808 F1 (46.6650%)


Val set: Average loss: 3.2395, Accuracy: 166/352 F1 (47.1591%)

best acc test 46.278562  acc val 47.159091 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 39600 lr0.0030087682852109887 	 Loss Classification: 0.322275 Loss T 0.066457 Method MME

S real T sketch Train Ep: 39700 lr0.0030042267475055367 	 Loss Classification: 0.110686 Loss T 0.053010 Method MME

S real T sketch Train Ep: 39800 lr0.0029997011730294593 	 Loss Classification: 0.311219 Loss T 0.057090 Method MME

S real T sketch Train Ep: 39900 lr0.0029951914737869757 	 Loss Classification: 0.189535 Loss T 0.065203 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 0.7777778 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [19, 113, 0, 73, 86, 42, 37, 34, 98, 25, 107, 110, 112, 33, 3, 122, 118, 5, 6, 89, 88, 87, 85, 84, 83, 82, 81, 115, 79, 78, 77, 76, 75, 74, 123, 72, 71, 70, 69, 90, 80, 92, 114, 116, 111, 117, 109, 108, 119, 106, 105, 104, 120, 91, 103, 101, 100, 99, 97, 68, 96, 95, 121, 94, 93, 102, 67, 62, 65, 30, 29, 28, 27, 26, 24, 23, 22, 21, 20, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 4, 2, 1, 31, 32, 35, 36, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 66, 52, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 40000 lr0.0029906975624424408 	 Loss Classification: 0.120046 Loss T 0.070616 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0807, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 4.0479, Accuracy: 11113/23808 F1 (46.6776%)


Val set: Average loss: 3.2837, Accuracy: 161/352 F1 (45.7386%)

best acc test 46.278562  acc val 45.738636 acc labeled target 97.795414
saving model...
S real T sketch Train Ep: 40100 lr0.0029862193523140824 	 Loss Classification: 0.235139 Loss T 0.057976 Method MME

S real T sketch Train Ep: 40200 lr0.0029817567573678107 	 Loss Classification: 0.240139 Loss T 0.054890 Method MME

S real T sketch Train Ep: 40300 lr0.0029773096922111057 	 Loss Classification: 0.523704 Loss T 0.049932 Method MME

S real T sketch Train Ep: 40400 lr0.0029728780720869657 	 Loss Classification: 0.705209 Loss T 0.043387 Method MME

S real T sketch Train Ep: 40500 lr0.002968461812867928 	 Loss Classification: 0.115957 Loss T 0.095523 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0945, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 4.0885, Accuracy: 11084/23808 F1 (46.5558%)


Val set: Average loss: 3.3120, Accuracy: 171/352 F1 (48.5795%)

best acc test 46.278562  acc val 48.579545 acc labeled target 97.795414
saving model...
S real T sketch Train Ep: 40600 lr0.0029640608310501576 	 Loss Classification: 0.391585 Loss T 0.062378 Method MME

S real T sketch Train Ep: 40700 lr0.002959675043747607 	 Loss Classification: 0.291005 Loss T 0.067751 Method MME

S real T sketch Train Ep: 40800 lr0.0029553043686862315 	 Loss Classification: 0.467146 Loss T 0.056839 Method MME

S real T sketch Train Ep: 40900 lr0.0029509487241982826 	 Loss Classification: 0.353045 Loss T 0.060588 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.7777778 0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [82, 10, 19, 108, 94, 30, 32, 89, 34, 84, 59, 83, 61, 118, 119, 6, 5, 124, 72, 64, 37, 107, 80, 90, 88, 91, 87, 86, 0, 81, 79, 78, 77, 76, 75, 74, 73, 71, 85, 92, 97, 95, 123, 122, 121, 120, 117, 116, 115, 114, 113, 112, 111, 93, 110, 106, 105, 104, 103, 102, 101, 100, 99, 98, 70, 96, 109, 69, 62, 67, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 4, 3, 2, 1, 31, 68, 33, 36, 66, 65, 63, 60, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2297, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7703, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 41000 lr0.0029466080292166567 	 Loss Classification: 0.681990 Loss T 0.062535 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0762, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 4.1168, Accuracy: 11124/23808 F1 (46.7238%)


Val set: Average loss: 3.3515, Accuracy: 173/352 F1 (49.1477%)

best acc test 46.723790  acc val 49.147727 acc labeled target 98.236332
saving model...
S real T sketch Train Ep: 41100 lr0.0029422822032693125 	 Loss Classification: 0.335678 Loss T 0.070162 Method MME

S real T sketch Train Ep: 41200 lr0.002937971166473745 	 Loss Classification: 0.153699 Loss T 0.055651 Method MME

S real T sketch Train Ep: 41300 lr0.0029336748395315305 	 Loss Classification: 0.537181 Loss T 0.069793 Method MME

S real T sketch Train Ep: 41400 lr0.002929393143722923 	 Loss Classification: 0.276827 Loss T 0.060576 Method MME

S real T sketch Train Ep: 41500 lr0.002925126000901522 	 Loss Classification: 0.217031 Loss T 0.092714 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0975, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 4.0541, Accuracy: 11121/23808 F1 (46.7112%)


Val set: Average loss: 3.3868, Accuracy: 161/352 F1 (45.7386%)

best acc test 46.723790  acc val 45.738636 acc labeled target 97.619048
saving model...
S real T sketch Train Ep: 41600 lr0.0029208733334889847 	 Loss Classification: 0.265268 Loss T 0.059739 Method MME

S real T sketch Train Ep: 41700 lr0.0029166350644698118 	 Loss Classification: 0.356278 Loss T 0.058488 Method MME

S real T sketch Train Ep: 41800 lr0.002912411117386185 	 Loss Classification: 0.037222 Loss T 0.062410 Method MME

S real T sketch Train Ep: 41900 lr0.0029082014163328584 	 Loss Classification: 0.487536 Loss T 0.052496 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        0.7777778 0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        0.8888889 1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 0.8888889 1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [83, 89, 18, 0, 19, 20, 107, 106, 104, 68, 98, 36, 96, 85, 73, 30, 110, 33, 112, 3, 118, 12, 66, 14, 109, 86, 84, 122, 82, 81, 80, 79, 87, 78, 76, 75, 74, 123, 72, 71, 70, 69, 77, 88, 121, 90, 114, 105, 115, 103, 102, 101, 116, 100, 99, 117, 113, 97, 119, 120, 95, 94, 93, 92, 111, 108, 91, 62, 65, 32, 31, 29, 28, 27, 26, 25, 24, 23, 22, 21, 17, 16, 15, 13, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 34, 35, 37, 38, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 67, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2297, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7703, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 42000 lr0.0029040058859521123 	 Loss Classification: 0.063130 Loss T 0.061871 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1208, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 4.0873, Accuracy: 11118/23808 F1 (46.6986%)


Val set: Average loss: 3.2487, Accuracy: 165/352 F1 (46.8750%)

best acc test 46.723790  acc val 46.875000 acc labeled target 96.737213
saving model...
S real T sketch Train Ep: 42100 lr0.002899824451428758 	 Loss Classification: 0.143153 Loss T 0.047656 Method MME

S real T sketch Train Ep: 42200 lr0.002895657038485203 	 Loss Classification: 0.165984 Loss T 0.061462 Method MME

S real T sketch Train Ep: 42300 lr0.0028915035733765655 	 Loss Classification: 0.197560 Loss T 0.050953 Method MME

S real T sketch Train Ep: 42400 lr0.0028873639828858417 	 Loss Classification: 0.281024 Loss T 0.063918 Method MME

S real T sketch Train Ep: 42500 lr0.0028832381943191343 	 Loss Classification: 0.239777 Loss T 0.057098 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0611, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 4.1160, Accuracy: 11166/23808 F1 (46.9002%)


Val set: Average loss: 3.2799, Accuracy: 168/352 F1 (47.7273%)

best acc test 46.723790  acc val 47.727273 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 42600 lr0.002879126135500922 	 Loss Classification: 0.289435 Loss T 0.055160 Method MME

S real T sketch Train Ep: 42700 lr0.00287502773476939 	 Loss Classification: 0.228642 Loss T 0.050995 Method MME

S real T sketch Train Ep: 42800 lr0.0028709429209718045 	 Loss Classification: 0.200748 Loss T 0.050349 Method MME

S real T sketch Train Ep: 42900 lr0.0028668716234599434 	 Loss Classification: 0.174785 Loss T 0.067317 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        0.8888889 1.        1.        0.7777778 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [19, 51, 12, 96, 102, 16, 56, 79, 84, 30, 124, 6, 35, 3, 97, 37, 32, 25, 90, 91, 92, 89, 88, 87, 0, 85, 83, 82, 81, 80, 78, 77, 76, 75, 74, 73, 72, 71, 86, 93, 98, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 101, 100, 99, 70, 94, 69, 62, 67, 31, 29, 28, 27, 26, 24, 23, 22, 21, 20, 18, 33, 17, 14, 13, 11, 10, 9, 8, 7, 5, 4, 2, 1, 15, 34, 36, 38, 66, 65, 64, 63, 61, 60, 59, 58, 57, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 43000 lr0.0028628137720855718 	 Loss Classification: 0.463079 Loss T 0.054373 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1080, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 4.1666, Accuracy: 11044/23808 F1 (46.3878%)


Val set: Average loss: 3.5002, Accuracy: 158/352 F1 (44.8864%)

best acc test 46.723790  acc val 44.886364 acc labeled target 97.354497
saving model...
S real T sketch Train Ep: 43100 lr0.002858769297195967 	 Loss Classification: 0.212216 Loss T 0.058250 Method MME

S real T sketch Train Ep: 43200 lr0.0028547381296294984 	 Loss Classification: 0.379043 Loss T 0.055825 Method MME

S real T sketch Train Ep: 43300 lr0.0028507202007112434 	 Loss Classification: 0.387956 Loss T 0.061446 Method MME

S real T sketch Train Ep: 43400 lr0.002846715442248662 	 Loss Classification: 0.248854 Loss T 0.056016 Method MME

S real T sketch Train Ep: 43500 lr0.00284272378652731 	 Loss Classification: 0.130454 Loss T 0.055721 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0829, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 4.1524, Accuracy: 11074/23808 F1 (46.5138%)


Val set: Average loss: 3.4262, Accuracy: 163/352 F1 (46.3068%)

best acc test 46.723790  acc val 46.306818 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 43600 lr0.002838745166306603 	 Loss Classification: 0.397554 Loss T 0.049541 Method MME

S real T sketch Train Ep: 43700 lr0.002834779514815624 	 Loss Classification: 0.200206 Loss T 0.057713 Method MME

S real T sketch Train Ep: 43800 lr0.002830826765748974 	 Loss Classification: 0.273078 Loss T 0.057867 Method MME

S real T sketch Train Ep: 43900 lr0.0028268868532626687 	 Loss Classification: 0.113467 Loss T 0.036234 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [96, 40, 41, 89, 46, 101, 85, 26, 84, 24, 104, 105, 18, 109, 80, 38, 78, 70, 122, 9, 77, 118, 56, 12, 82, 90, 71, 88, 87, 83, 72, 73, 79, 74, 75, 91, 76, 86, 81, 0, 93, 123, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 92, 110, 107, 106, 103, 102, 100, 99, 98, 97, 69, 95, 94, 108, 68, 62, 66, 30, 29, 28, 27, 25, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 31, 32, 33, 34, 65, 64, 63, 124, 61, 60, 59, 58, 57, 55, 54, 53, 67, 52, 50, 49, 48, 47, 45, 44, 43, 42, 39, 37, 36, 35, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 44000 lr0.0028229597119700817 	 Loss Classification: 0.323158 Loss T 0.056730 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0721, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 4.1402, Accuracy: 11136/23808 F1 (46.7742%)


Val set: Average loss: 3.3748, Accuracy: 165/352 F1 (46.8750%)

best acc test 46.723790  acc val 46.875000 acc labeled target 98.412698
saving model...
S real T sketch Train Ep: 44100 lr0.002819045276937925 	 Loss Classification: 0.307953 Loss T 0.054637 Method MME

S real T sketch Train Ep: 44200 lr0.002815143483682275 	 Loss Classification: 0.059927 Loss T 0.057465 Method MME

S real T sketch Train Ep: 44300 lr0.0028112542681646446 	 Loss Classification: 0.197351 Loss T 0.038452 Method MME

S real T sketch Train Ep: 44400 lr0.0028073775667880876 	 Loss Classification: 0.265540 Loss T 0.056233 Method MME

S real T sketch Train Ep: 44500 lr0.0028035133163933517 	 Loss Classification: 0.332275 Loss T 0.044885 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0802, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 4.1561, Accuracy: 11117/23808 F1 (46.6944%)


Val set: Average loss: 3.3948, Accuracy: 157/352 F1 (44.6023%)

best acc test 46.723790  acc val 44.602273 acc labeled target 97.883598
saving model...
S real T sketch Train Ep: 44600 lr0.002799661454255073 	 Loss Classification: 0.199406 Loss T 0.064528 Method MME

S real T sketch Train Ep: 44700 lr0.0027958219180780008 	 Loss Classification: 0.214987 Loss T 0.049959 Method MME

S real T sketch Train Ep: 44800 lr0.002791994645993276 	 Loss Classification: 0.245229 Loss T 0.071646 Method MME

S real T sketch Train Ep: 44900 lr0.0027881795765547345 	 Loss Classification: 0.468106 Loss T 0.049624 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.7777778 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [109, 20, 26, 98, 32, 66, 34, 37, 108, 0, 88, 47, 85, 51, 82, 77, 73, 94, 95, 33, 14, 5, 9, 119, 86, 84, 120, 83, 121, 81, 80, 111, 79, 78, 122, 76, 75, 74, 123, 72, 71, 70, 87, 118, 90, 110, 107, 106, 105, 104, 103, 112, 102, 101, 100, 89, 99, 114, 115, 97, 96, 116, 117, 93, 92, 91, 113, 69, 62, 67, 30, 29, 28, 27, 25, 24, 23, 22, 21, 19, 18, 17, 16, 15, 13, 12, 11, 10, 8, 7, 6, 4, 3, 2, 1, 31, 68, 35, 38, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 36, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 45000 lr0.0027843766487352603 	 Loss Classification: 0.228261 Loss T 0.070541 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0633, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 4.2004, Accuracy: 11111/23808 F1 (46.6692%)


Val set: Average loss: 3.3475, Accuracy: 160/352 F1 (45.4545%)

best acc test 46.723790  acc val 45.454545 acc labeled target 98.324515
saving model...
S real T sketch Train Ep: 45100 lr0.0027805858019231693 	 Loss Classification: 0.275332 Loss T 0.063517 Method MME

S real T sketch Train Ep: 45200 lr0.0027768069759186364 	 Loss Classification: 0.156581 Loss T 0.055262 Method MME

S real T sketch Train Ep: 45300 lr0.002773040110930155 	 Loss Classification: 0.499313 Loss T 0.057234 Method MME

S real T sketch Train Ep: 45400 lr0.0027692851475710355 	 Loss Classification: 0.259653 Loss T 0.050797 Method MME

S real T sketch Train Ep: 45500 lr0.0027655420268559413 	 Loss Classification: 0.350451 Loss T 0.058377 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0843, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 4.1855, Accuracy: 11128/23808 F1 (46.7406%)


Val set: Average loss: 3.2057, Accuracy: 168/352 F1 (47.7273%)

best acc test 46.723790  acc val 47.727273 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 45600 lr0.0027618106901974556 	 Loss Classification: 0.314118 Loss T 0.081969 Method MME

S real T sketch Train Ep: 45700 lr0.002758091079402693 	 Loss Classification: 0.390032 Loss T 0.065818 Method MME

S real T sketch Train Ep: 45800 lr0.002754383136669936 	 Loss Classification: 0.161979 Loss T 0.048733 Method MME

S real T sketch Train Ep: 45900 lr0.00275068680458531 	 Loss Classification: 0.257270 Loss T 0.051913 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [118, 108, 33, 90, 68, 43, 98, 99, 84, 51, 92, 53, 78, 18, 6, 64, 3, 73, 38, 114, 79, 89, 69, 88, 87, 75, 70, 74, 71, 85, 76, 83, 82, 81, 80, 72, 86, 77, 0, 93, 123, 122, 121, 120, 119, 117, 116, 115, 113, 112, 111, 110, 109, 107, 106, 105, 104, 103, 102, 101, 100, 97, 96, 95, 94, 91, 67, 62, 65, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 2, 1, 29, 30, 31, 32, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 50, 66, 49, 47, 46, 45, 44, 42, 41, 40, 39, 37, 36, 35, 34, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 46000 lr0.002747002026119495 	 Loss Classification: 0.099110 Loss T 0.050781 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0775, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 4.1959, Accuracy: 11149/23808 F1 (46.8288%)


Val set: Average loss: 3.5090, Accuracy: 159/352 F1 (45.1705%)

best acc test 46.723790  acc val 45.170455 acc labeled target 98.236332
saving model...
S real T sketch Train Ep: 46100 lr0.00274332874462447 	 Loss Classification: 0.111831 Loss T 0.056341 Method MME

S real T sketch Train Ep: 46200 lr0.0027396669038302853 	 Loss Classification: 0.089727 Loss T 0.039597 Method MME

S real T sketch Train Ep: 46300 lr0.002736016447841875 	 Loss Classification: 0.529649 Loss T 0.060011 Method MME

S real T sketch Train Ep: 46400 lr0.002732377321135899 	 Loss Classification: 0.171847 Loss T 0.055415 Method MME

S real T sketch Train Ep: 46500 lr0.0027287494685576162 	 Loss Classification: 0.318134 Loss T 0.056715 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0832, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 4.1579, Accuracy: 11144/23808 F1 (46.8078%)


Val set: Average loss: 3.3284, Accuracy: 166/352 F1 (47.1591%)

best acc test 46.723790  acc val 47.159091 acc labeled target 97.619048
saving model...
S real T sketch Train Ep: 46600 lr0.0027251328353177914 	 Loss Classification: 0.201544 Loss T 0.056196 Method MME

S real T sketch Train Ep: 46700 lr0.0027215273669896306 	 Loss Classification: 0.231752 Loss T 0.043220 Method MME

S real T sketch Train Ep: 46800 lr0.002717933009505752 	 Loss Classification: 0.320109 Loss T 0.046171 Method MME

S real T sketch Train Ep: 46900 lr0.0027143497091551842 	 Loss Classification: 0.234874 Loss T 0.059660 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [122, 96, 104, 25, 99, 32, 92, 39, 41, 42, 43, 54, 78, 77, 75, 124, 63, 66, 106, 108, 70, 9, 10, 17, 111, 6, 107, 85, 84, 83, 82, 81, 117, 80, 118, 86, 76, 119, 74, 120, 121, 73, 72, 123, 79, 87, 90, 89, 110, 105, 103, 102, 101, 100, 112, 98, 113, 97, 71, 95, 94, 93, 114, 115, 91, 116, 109, 88, 0, 62, 68, 29, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 30, 16, 14, 13, 12, 11, 8, 7, 5, 4, 3, 2, 1, 15, 31, 33, 34, 67, 65, 64, 61, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 40, 38, 37, 36, 35, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 47000 lr0.0027107774125803953 	 Loss Classification: 0.328646 Loss T 0.053211 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0857, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 4.1780, Accuracy: 11184/23808 F1 (46.9758%)


Val set: Average loss: 3.3033, Accuracy: 163/352 F1 (46.3068%)

best acc test 46.723790  acc val 46.306818 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 47100 lr0.0027072160667743496 	 Loss Classification: 0.137755 Loss T 0.060126 Method MME

S real T sketch Train Ep: 47200 lr0.0027036656190776 	 Loss Classification: 0.062681 Loss T 0.062830 Method MME

S real T sketch Train Ep: 47300 lr0.0027001260171754054 	 Loss Classification: 0.508307 Loss T 0.055297 Method MME

S real T sketch Train Ep: 47400 lr0.0026965972090948766 	 Loss Classification: 0.273698 Loss T 0.039214 Method MME

S real T sketch Train Ep: 47500 lr0.00269307914320215 	 Loss Classification: 0.191558 Loss T 0.063874 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0687, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 4.1158, Accuracy: 11175/23808 F1 (46.9380%)


Val set: Average loss: 3.1257, Accuracy: 180/352 F1 (51.1364%)

best acc test 46.938004  acc val 51.136364 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 47600 lr0.002689571768199595 	 Loss Classification: 0.390723 Loss T 0.043024 Method MME

S real T sketch Train Ep: 47700 lr0.0026860750331230425 	 Loss Classification: 0.065306 Loss T 0.043977 Method MME

S real T sketch Train Ep: 47800 lr0.0026825888873390456 	 Loss Classification: 0.059426 Loss T 0.049590 Method MME

S real T sketch Train Ep: 47900 lr0.002679113280542164 	 Loss Classification: 0.151548 Loss T 0.043849 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.7777778 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.7777778 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [37, 73, 48, 88, 50, 39, 28, 111, 98, 32, 57, 70, 75, 95, 61, 124, 2, 71, 10, 25, 87, 90, 89, 91, 0, 85, 84, 83, 81, 80, 79, 78, 77, 76, 74, 72, 86, 82, 96, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 92, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 94, 109, 69, 62, 67, 29, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 5, 4, 3, 1, 30, 68, 31, 34, 66, 65, 64, 63, 60, 59, 58, 56, 55, 54, 53, 52, 51, 49, 47, 46, 45, 44, 43, 42, 41, 40, 38, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 48000 lr0.0026756481627522805 	 Loss Classification: 0.133931 Loss T 0.044937 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1015, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 4.1518, Accuracy: 11161/23808 F1 (46.8792%)


Val set: Average loss: 3.2559, Accuracy: 162/352 F1 (46.0227%)

best acc test 46.938004  acc val 46.022727 acc labeled target 97.795414
saving model...
S real T sketch Train Ep: 48100 lr0.002672193484311935 	 Loss Classification: 0.397104 Loss T 0.051193 Method MME

S real T sketch Train Ep: 48200 lr0.0026687491958836975 	 Loss Classification: 0.192020 Loss T 0.065322 Method MME

S real T sketch Train Ep: 48300 lr0.002665315248447555 	 Loss Classification: 0.241434 Loss T 0.043322 Method MME

S real T sketch Train Ep: 48400 lr0.002661891593298331 	 Loss Classification: 0.035319 Loss T 0.057250 Method MME

S real T sketch Train Ep: 48500 lr0.002658478182043129 	 Loss Classification: 0.383812 Loss T 0.052036 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0787, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 4.2334, Accuracy: 11145/23808 F1 (46.8120%)


Val set: Average loss: 3.3175, Accuracy: 168/352 F1 (47.7273%)

best acc test 46.938004  acc val 47.727273 acc labeled target 98.677249
saving model...
S real T sketch Train Ep: 48600 lr0.0026550749665988005 	 Loss Classification: 0.196707 Loss T 0.053999 Method MME

S real T sketch Train Ep: 48700 lr0.002651681899189436 	 Loss Classification: 0.124609 Loss T 0.052404 Method MME

S real T sketch Train Ep: 48800 lr0.0026482989323438856 	 Loss Classification: 0.265645 Loss T 0.048552 Method MME

S real T sketch Train Ep: 48900 lr0.0026449260188932985 	 Loss Classification: 0.133337 Loss T 0.055548 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 0.8888889 0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [10, 96, 90, 98, 4, 5, 6, 51, 73, 30, 106, 46, 56, 14, 85, 84, 0, 87, 88, 89, 86, 83, 80, 81, 91, 79, 78, 77, 76, 75, 74, 72, 71, 70, 69, 82, 92, 97, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 93, 111, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 68, 95, 110, 67, 62, 65, 31, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 9, 8, 7, 3, 2, 1, 32, 33, 34, 35, 64, 63, 124, 61, 60, 59, 58, 57, 55, 54, 53, 52, 66, 50, 48, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 49000 lr0.0026415631119686904 	 Loss Classification: 0.225258 Loss T 0.059248 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0833, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 4.2503, Accuracy: 11186/23808 F1 (46.9842%)


Val set: Average loss: 3.2582, Accuracy: 167/352 F1 (47.4432%)

best acc test 46.938004  acc val 47.443182 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 49100 lr0.0026382101649985324 	 Loss Classification: 0.223192 Loss T 0.062761 Method MME

S real T sketch Train Ep: 49200 lr0.002634867131706361 	 Loss Classification: 0.238999 Loss T 0.049040 Method MME

S real T sketch Train Ep: 49300 lr0.002631533966108419 	 Loss Classification: 0.199027 Loss T 0.049908 Method MME

S real T sketch Train Ep: 49400 lr0.0026282106225113118 	 Loss Classification: 0.063912 Loss T 0.058169 Method MME

S real T sketch Train Ep: 49500 lr0.0026248970555096873 	 Loss Classification: 0.206180 Loss T 0.073067 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0770, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 4.2217, Accuracy: 11122/23808 F1 (46.7154%)


Val set: Average loss: 3.3130, Accuracy: 167/352 F1 (47.4432%)

best acc test 46.938004  acc val 47.443182 acc labeled target 98.589065
saving model...
S real T sketch Train Ep: 49600 lr0.0026215932199839427 	 Loss Classification: 0.192085 Loss T 0.058303 Method MME

S real T sketch Train Ep: 49700 lr0.002618299071097948 	 Loss Classification: 0.294754 Loss T 0.038483 Method MME

S real T sketch Train Ep: 49800 lr0.002615014564296798 	 Loss Classification: 0.432334 Loss T 0.049118 Method MME

S real T sketch Train Ep: 49900 lr0.0026117396553045746 	 Loss Classification: 0.156205 Loss T 0.054438 Method MME

