Dataset multi Source painting Target real Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  31502
Unlabelled Target Dataset Size:  69980
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  69980 Source:  31502
Unlabeled Target Data Batches: 1457
S painting T real Train Ep: 0 lr0.01 	 Loss Classification: 5.024736 Loss T 0.469390 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 5.0033, Accuracy: 14/1134 F1 (1.2346%)


Test set: Average loss: 4.9468, Accuracy: 1212/69960 F1 (1.7324%)


Val set: Average loss: 4.9636, Accuracy: 8/360 F1 (2.2222%)

best acc test 1.732419  acc val 2.222222 acc labeled target 1.234568
saving model...
S painting T real Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.317132 Loss T 0.275653 Method MME

S painting T real Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 2.148298 Loss T 0.185514 Method MME

S painting T real Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.800351 Loss T 0.169069 Method MME

S painting T real Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.381134 Loss T 0.121144 Method MME

S painting T real Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.802807 Loss T 0.135209 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8408, Accuracy: 636/1134 F1 (56.0847%)


Test set: Average loss: 1.5275, Accuracy: 44326/69960 F1 (63.3591%)


Val set: Average loss: 1.7935, Accuracy: 199/360 F1 (55.2778%)

best acc test 63.359062  acc val 55.277778 acc labeled target 56.084656
saving model...
S painting T real Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.119922 Loss T 0.126992 Method MME

S painting T real Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.596322 Loss T 0.098177 Method MME

S painting T real Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.977512 Loss T 0.122091 Method MME

S painting T real Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.509397 Loss T 0.134203 Method MME

S painting T real Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.848413 Loss T 0.107652 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7940, Accuracy: 678/1134 F1 (59.7884%)


Test set: Average loss: 1.4439, Accuracy: 46206/69960 F1 (66.0463%)


Val set: Average loss: 1.6360, Accuracy: 215/360 F1 (59.7222%)

best acc test 66.046312  acc val 59.722222 acc labeled target 59.788360
saving model...
S painting T real Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.076865 Loss T 0.126326 Method MME

S painting T real Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.338099 Loss T 0.132620 Method MME

S painting T real Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.199235 Loss T 0.100139 Method MME

S painting T real Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.569821 Loss T 0.086145 Method MME

S painting T real Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.997076 Loss T 0.094012 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7045, Accuracy: 690/1134 F1 (60.8466%)


Test set: Average loss: 1.3915, Accuracy: 47386/69960 F1 (67.7330%)


Val set: Average loss: 1.4489, Accuracy: 242/360 F1 (67.2222%)

best acc test 67.732990  acc val 67.222222 acc labeled target 60.846561
saving model...
S painting T real Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.257629 Loss T 0.095360 Method MME

S painting T real Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.341030 Loss T 0.074747 Method MME

S painting T real Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.896047 Loss T 0.101594 Method MME

S painting T real Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 1.614046 Loss T 0.105711 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.44444445 1.         0.7777778  0.44444445 0.8888889
 0.7777778  0.33333334 0.6666667  0.8888889  0.6666667  0.6666667
 0.         0.33333334 0.6666667  0.6666667  0.5555556  1.
 0.         0.6666667  0.         0.6666667  1.         0.33333334
 0.         0.6666667  0.5555556  0.6666667  0.7777778  0.6666667
 0.8888889  0.44444445 0.8888889  0.         0.44444445 0.6666667
 0.         1.         0.22222222 1.         0.6666667  1.
 0.33333334 0.6666667  1.         1.         0.8888889  0.8888889
 0.33333334 1.         0.44444445 0.5555556  0.5555556  0.44444445
 0.11111111 0.5555556  0.6666667  1.         0.33333334 0.8888889
 1.         0.         0.8888889  0.         1.         0.8888889
 0.         1.         0.7777778  1.         1.         0.6666667
 0.7777778  0.5555556  0.         0.6666667  0.6666667  0.33333334
 0.         0.5555556  0.         1.         0.         0.
 0.11111111 1.         0.5555556  0.33333334 0.         0.6666667
 0.11111111 1.         0.8888889  0.7777778  0.6666667  0.6666667
 0.         1.         1.         1.         1.         0.6666667
 0.7777778  0.22222222 0.44444445 0.8888889  0.6666667  1.
 0.         0.6666667  0.6666667  0.5555556  1.         1.
 0.5555556  1.         0.6666667  1.         0.11111111 1.
 0.33333334 1.         0.33333334 0.22222222 0.6666667  1.        ]
Top k classes which perform poorly are:  [61, 20, 18, 33, 82, 88, 74, 108, 83, 80, 12, 36, 96, 63, 78, 66, 24, 90, 54, 118, 84, 103, 123, 38, 120, 122, 87, 42, 13, 48, 7, 58, 23, 77, 53, 50, 31, 1, 4, 104, 34, 114, 55, 52, 51, 111, 79, 73, 16, 86, 26, 110, 71, 94, 89, 95, 75, 76, 124, 109, 106, 101, 43, 15, 14, 25, 27, 11, 29, 10, 35, 40, 21, 19, 116, 8, 56, 72, 93, 6, 68, 102, 3, 28, 92, 105, 5, 9, 59, 30, 32, 46, 47, 65, 62, 121, 113, 119, 117, 115, 112, 107, 0, 99, 2, 17, 22, 37, 39, 41, 44, 45, 49, 100, 57, 64, 67, 69, 70, 81, 85, 91, 97, 98, 60, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3206, 1.1839, 1.2297, 1.3206, 1.2056, 1.2297, 1.3583, 1.2567,
        1.2056, 1.2567, 1.2567, 1.5000, 1.3583, 1.2567, 1.2567, 1.2869, 1.1839,
        1.5000, 1.2567, 1.5000, 1.2567, 1.1839, 1.3583, 1.5000, 1.2567, 1.2869,
        1.2567, 1.2297, 1.2567, 1.2056, 1.3206, 1.2056, 1.5000, 1.3206, 1.2567,
        1.5000, 1.1839, 1.4004, 1.1839, 1.2567, 1.1839, 1.3583, 1.2567, 1.1839,
        1.1839, 1.2056, 1.2056, 1.3583, 1.1839, 1.3206, 1.2869, 1.2869, 1.3206,
        1.4474, 1.2869, 1.2567, 1.1839, 1.3583, 1.2056, 1.1839, 1.5000, 1.2056,
        1.5000, 1.1839, 1.2056, 1.5000, 1.1839, 1.2297, 1.1839, 1.1839, 1.2567,
        1.2297, 1.2869, 1.5000, 1.2567, 1.2567, 1.3583, 1.5000, 1.2869, 1.5000,
        1.1839, 1.5000, 1.5000, 1.4474, 1.1839, 1.2869, 1.3583, 1.5000, 1.2567,
        1.4474, 1.1839, 1.2056, 1.2297, 1.2567, 1.2567, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2297, 1.4004, 1.3206, 1.2056, 1.2567, 1.1839,
        1.5000, 1.2567, 1.2567, 1.2869, 1.1839, 1.1839, 1.2869, 1.1839, 1.2567,
        1.1839, 1.4474, 1.1839, 1.3583, 1.1839, 1.3583, 1.4004, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6794, 0.8161, 0.7703, 0.6794, 0.7944, 0.7703, 0.6417, 0.7433,
        0.7944, 0.7433, 0.7433, 0.5000, 0.6417, 0.7433, 0.7433, 0.7131, 0.8161,
        0.5000, 0.7433, 0.5000, 0.7433, 0.8161, 0.6417, 0.5000, 0.7433, 0.7131,
        0.7433, 0.7703, 0.7433, 0.7944, 0.6794, 0.7944, 0.5000, 0.6794, 0.7433,
        0.5000, 0.8161, 0.5996, 0.8161, 0.7433, 0.8161, 0.6417, 0.7433, 0.8161,
        0.8161, 0.7944, 0.7944, 0.6417, 0.8161, 0.6794, 0.7131, 0.7131, 0.6794,
        0.5526, 0.7131, 0.7433, 0.8161, 0.6417, 0.7944, 0.8161, 0.5000, 0.7944,
        0.5000, 0.8161, 0.7944, 0.5000, 0.8161, 0.7703, 0.8161, 0.8161, 0.7433,
        0.7703, 0.7131, 0.5000, 0.7433, 0.7433, 0.6417, 0.5000, 0.7131, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5526, 0.8161, 0.7131, 0.6417, 0.5000, 0.7433,
        0.5526, 0.8161, 0.7944, 0.7703, 0.7433, 0.7433, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7703, 0.5996, 0.6794, 0.7944, 0.7433, 0.8161,
        0.5000, 0.7433, 0.7433, 0.7131, 0.8161, 0.8161, 0.7131, 0.8161, 0.7433,
        0.8161, 0.5526, 0.8161, 0.6417, 0.8161, 0.6417, 0.5996, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.386799 Loss T 0.073298 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9759, Accuracy: 666/1134 F1 (58.7302%)


Test set: Average loss: 1.5930, Accuracy: 45167/69960 F1 (64.5612%)


Val set: Average loss: 1.7369, Accuracy: 219/360 F1 (60.8333%)

best acc test 67.732990  acc val 60.833333 acc labeled target 58.730159
saving model...
S painting T real Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.593053 Loss T 0.094396 Method MME

S painting T real Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 1.869609 Loss T 0.087380 Method MME

S painting T real Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.888186 Loss T 0.067792 Method MME

S painting T real Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.727671 Loss T 0.067028 Method MME

S painting T real Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.825348 Loss T 0.056153 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7055, Accuracy: 732/1134 F1 (64.5503%)


Test set: Average loss: 1.3231, Accuracy: 49848/69960 F1 (71.2521%)


Val set: Average loss: 1.4488, Accuracy: 253/360 F1 (70.2778%)

best acc test 71.252144  acc val 70.277778 acc labeled target 64.550265
saving model...
S painting T real Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.528036 Loss T 0.073595 Method MME

S painting T real Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.166104 Loss T 0.076874 Method MME

S painting T real Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.744099 Loss T 0.067570 Method MME

S painting T real Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.464916 Loss T 0.066115 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.44444445 0.7777778  0.5555556  0.22222222 0.5555556
 1.         0.44444445 0.5555556  0.6666667  0.5555556  0.6666667
 0.         0.22222222 0.6666667  0.6666667  0.6666667  1.
 0.         1.         0.22222222 0.33333334 1.         0.33333334
 0.44444445 0.6666667  0.6666667  0.6666667  0.7777778  0.7777778
 0.8888889  0.33333334 1.         0.22222222 0.33333334 0.6666667
 0.         0.8888889  0.33333334 1.         0.6666667  1.
 0.44444445 0.7777778  1.         1.         0.6666667  1.
 0.33333334 1.         0.7777778  0.5555556  0.33333334 0.33333334
 0.22222222 0.5555556  0.8888889  0.8888889  0.33333334 0.6666667
 0.8888889  0.8888889  1.         0.11111111 1.         1.
 0.         1.         1.         1.         1.         0.6666667
 0.6666667  0.6666667  0.5555556  0.5555556  0.6666667  0.33333334
 0.         0.8888889  0.         0.8888889  0.5555556  0.
 0.33333334 1.         1.         0.33333334 0.11111111 0.6666667
 0.22222222 0.8888889  0.6666667  1.         0.6666667  1.
 0.11111111 1.         0.8888889  1.         1.         0.6666667
 0.5555556  0.44444445 0.22222222 1.         0.7777778  0.8888889
 0.44444445 0.7777778  0.6666667  0.33333334 1.         1.
 0.6666667  1.         0.6666667  1.         0.         1.
 0.33333334 1.         0.6666667  0.6666667  0.6666667  1.        ]
Top k classes which perform poorly are:  [118, 36, 66, 78, 18, 80, 12, 83, 96, 88, 63, 33, 90, 20, 104, 13, 54, 4, 34, 31, 53, 84, 77, 111, 120, 21, 52, 38, 87, 48, 23, 58, 24, 7, 42, 103, 1, 108, 51, 55, 75, 3, 74, 5, 8, 102, 82, 10, 72, 89, 92, 71, 76, 59, 110, 73, 124, 101, 94, 40, 25, 26, 27, 15, 14, 35, 11, 16, 122, 116, 46, 114, 9, 123, 43, 106, 29, 50, 2, 109, 28, 56, 79, 57, 30, 37, 107, 98, 61, 60, 81, 91, 0, 112, 115, 117, 119, 121, 105, 113, 62, 99, 6, 17, 19, 22, 32, 39, 41, 44, 45, 47, 100, 49, 65, 67, 68, 69, 70, 85, 86, 93, 95, 97, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3206, 1.2297, 1.2869, 1.4004, 1.2869, 1.1839, 1.3206, 1.2869,
        1.2567, 1.2869, 1.2567, 1.5000, 1.4004, 1.2567, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.4004, 1.3583, 1.1839, 1.3583, 1.3206, 1.2567, 1.2567,
        1.2567, 1.2297, 1.2297, 1.2056, 1.3583, 1.1839, 1.4004, 1.3583, 1.2567,
        1.5000, 1.2056, 1.3583, 1.1839, 1.2567, 1.1839, 1.3206, 1.2297, 1.1839,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.2297, 1.2869, 1.3583, 1.3583,
        1.4004, 1.2869, 1.2056, 1.2056, 1.3583, 1.2567, 1.2056, 1.2056, 1.1839,
        1.4474, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.2567,
        1.2567, 1.2567, 1.2869, 1.2869, 1.2567, 1.3583, 1.5000, 1.2056, 1.5000,
        1.2056, 1.2869, 1.5000, 1.3583, 1.1839, 1.1839, 1.3583, 1.4474, 1.2567,
        1.4004, 1.2056, 1.2567, 1.1839, 1.2567, 1.1839, 1.4474, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2567, 1.2869, 1.3206, 1.4004, 1.1839, 1.2297, 1.2056,
        1.3206, 1.2297, 1.2567, 1.3583, 1.1839, 1.1839, 1.2567, 1.1839, 1.2567,
        1.1839, 1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.2567, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6794, 0.7703, 0.7131, 0.5996, 0.7131, 0.8161, 0.6794, 0.7131,
        0.7433, 0.7131, 0.7433, 0.5000, 0.5996, 0.7433, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.5996, 0.6417, 0.8161, 0.6417, 0.6794, 0.7433, 0.7433,
        0.7433, 0.7703, 0.7703, 0.7944, 0.6417, 0.8161, 0.5996, 0.6417, 0.7433,
        0.5000, 0.7944, 0.6417, 0.8161, 0.7433, 0.8161, 0.6794, 0.7703, 0.8161,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.7703, 0.7131, 0.6417, 0.6417,
        0.5996, 0.7131, 0.7944, 0.7944, 0.6417, 0.7433, 0.7944, 0.7944, 0.8161,
        0.5526, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.7433,
        0.7433, 0.7433, 0.7131, 0.7131, 0.7433, 0.6417, 0.5000, 0.7944, 0.5000,
        0.7944, 0.7131, 0.5000, 0.6417, 0.8161, 0.8161, 0.6417, 0.5526, 0.7433,
        0.5996, 0.7944, 0.7433, 0.8161, 0.7433, 0.8161, 0.5526, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7433, 0.7131, 0.6794, 0.5996, 0.8161, 0.7703, 0.7944,
        0.6794, 0.7703, 0.7433, 0.6417, 0.8161, 0.8161, 0.7433, 0.8161, 0.7433,
        0.8161, 0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.7433, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.454115 Loss T 0.072286 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9747, Accuracy: 666/1134 F1 (58.7302%)


Test set: Average loss: 1.6001, Accuracy: 46678/69960 F1 (66.7210%)


Val set: Average loss: 1.8810, Accuracy: 219/360 F1 (60.8333%)

best acc test 71.252144  acc val 60.833333 acc labeled target 58.730159
saving model...
S painting T real Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.213704 Loss T 0.078877 Method MME

S painting T real Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.432179 Loss T 0.079037 Method MME

S painting T real Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.464721 Loss T 0.045039 Method MME

S painting T real Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.741600 Loss T 0.082206 Method MME

S painting T real Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.843932 Loss T 0.067597 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9340, Accuracy: 718/1134 F1 (63.3157%)


Test set: Average loss: 1.4659, Accuracy: 49805/69960 F1 (71.1907%)


Val set: Average loss: 1.6935, Accuracy: 241/360 F1 (66.9444%)

best acc test 71.252144  acc val 66.944444 acc labeled target 63.315697
saving model...
S painting T real Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.865668 Loss T 0.049386 Method MME

S painting T real Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.855146 Loss T 0.057662 Method MME

S painting T real Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.719759 Loss T 0.054698 Method MME

S painting T real Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 1.030030 Loss T 0.062138 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.22222222 0.7777778  0.8888889  0.44444445 0.7777778
 0.8888889  0.33333334 0.6666667  0.6666667  0.6666667  0.6666667
 0.         0.         0.6666667  0.6666667  0.5555556  1.
 0.         1.         0.22222222 0.33333334 1.         0.33333334
 0.33333334 0.6666667  0.6666667  0.6666667  0.7777778  1.
 0.5555556  0.33333334 1.         0.         0.33333334 0.6666667
 0.         1.         0.22222222 1.         0.6666667  1.
 0.33333334 0.8888889  1.         1.         0.8888889  0.7777778
 0.         1.         0.7777778  0.44444445 0.5555556  0.44444445
 0.11111111 0.6666667  1.         1.         0.33333334 0.7777778
 1.         0.44444445 0.7777778  0.22222222 1.         1.
 0.         1.         0.8888889  1.         1.         0.22222222
 0.8888889  0.5555556  0.44444445 0.7777778  0.6666667  0.33333334
 0.         0.8888889  0.22222222 0.8888889  0.44444445 0.
 0.33333334 1.         0.7777778  0.33333334 0.         0.6666667
 0.         0.6666667  1.         0.8888889  0.5555556  1.
 0.33333334 0.7777778  0.44444445 0.7777778  1.         0.6666667
 1.         0.5555556  0.33333334 0.8888889  0.6666667  1.
 0.6666667  0.6666667  0.6666667  0.6666667  1.         0.8888889
 0.33333334 0.8888889  0.5555556  1.         0.         1.
 0.33333334 1.         0.6666667  0.7777778  0.6666667  1.        ]
Top k classes which perform poorly are:  [36, 88, 118, 33, 90, 48, 83, 66, 18, 78, 12, 13, 54, 38, 80, 20, 1, 63, 71, 96, 114, 34, 104, 31, 84, 120, 58, 42, 7, 24, 23, 21, 87, 77, 82, 51, 4, 74, 98, 53, 61, 52, 73, 94, 30, 103, 16, 116, 40, 106, 76, 8, 108, 109, 9, 124, 10, 110, 11, 14, 15, 55, 122, 91, 25, 26, 27, 89, 35, 111, 101, 86, 75, 97, 62, 50, 2, 59, 5, 99, 123, 47, 28, 3, 6, 93, 72, 105, 46, 113, 81, 79, 68, 115, 43, 117, 119, 121, 112, 102, 107, 0, 95, 17, 19, 22, 29, 32, 37, 39, 41, 44, 45, 49, 56, 57, 60, 64, 65, 67, 69, 70, 85, 92, 100, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.4004, 1.2297, 1.2056, 1.3206, 1.2297, 1.2056, 1.3583, 1.2567,
        1.2567, 1.2567, 1.2567, 1.5000, 1.5000, 1.2567, 1.2567, 1.2869, 1.1839,
        1.5000, 1.1839, 1.4004, 1.3583, 1.1839, 1.3583, 1.3583, 1.2567, 1.2567,
        1.2567, 1.2297, 1.1839, 1.2869, 1.3583, 1.1839, 1.5000, 1.3583, 1.2567,
        1.5000, 1.1839, 1.4004, 1.1839, 1.2567, 1.1839, 1.3583, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2297, 1.5000, 1.1839, 1.2297, 1.3206, 1.2869, 1.3206,
        1.4474, 1.2567, 1.1839, 1.1839, 1.3583, 1.2297, 1.1839, 1.3206, 1.2297,
        1.4004, 1.1839, 1.1839, 1.5000, 1.1839, 1.2056, 1.1839, 1.1839, 1.4004,
        1.2056, 1.2869, 1.3206, 1.2297, 1.2567, 1.3583, 1.5000, 1.2056, 1.4004,
        1.2056, 1.3206, 1.5000, 1.3583, 1.1839, 1.2297, 1.3583, 1.5000, 1.2567,
        1.5000, 1.2567, 1.1839, 1.2056, 1.2869, 1.1839, 1.3583, 1.2297, 1.3206,
        1.2297, 1.1839, 1.2567, 1.1839, 1.2869, 1.3583, 1.2056, 1.2567, 1.1839,
        1.2567, 1.2567, 1.2567, 1.2567, 1.1839, 1.2056, 1.3583, 1.2056, 1.2869,
        1.1839, 1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.2297, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5996, 0.7703, 0.7944, 0.6794, 0.7703, 0.7944, 0.6417, 0.7433,
        0.7433, 0.7433, 0.7433, 0.5000, 0.5000, 0.7433, 0.7433, 0.7131, 0.8161,
        0.5000, 0.8161, 0.5996, 0.6417, 0.8161, 0.6417, 0.6417, 0.7433, 0.7433,
        0.7433, 0.7703, 0.8161, 0.7131, 0.6417, 0.8161, 0.5000, 0.6417, 0.7433,
        0.5000, 0.8161, 0.5996, 0.8161, 0.7433, 0.8161, 0.6417, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7703, 0.5000, 0.8161, 0.7703, 0.6794, 0.7131, 0.6794,
        0.5526, 0.7433, 0.8161, 0.8161, 0.6417, 0.7703, 0.8161, 0.6794, 0.7703,
        0.5996, 0.8161, 0.8161, 0.5000, 0.8161, 0.7944, 0.8161, 0.8161, 0.5996,
        0.7944, 0.7131, 0.6794, 0.7703, 0.7433, 0.6417, 0.5000, 0.7944, 0.5996,
        0.7944, 0.6794, 0.5000, 0.6417, 0.8161, 0.7703, 0.6417, 0.5000, 0.7433,
        0.5000, 0.7433, 0.8161, 0.7944, 0.7131, 0.8161, 0.6417, 0.7703, 0.6794,
        0.7703, 0.8161, 0.7433, 0.8161, 0.7131, 0.6417, 0.7944, 0.7433, 0.8161,
        0.7433, 0.7433, 0.7433, 0.7433, 0.8161, 0.7944, 0.6417, 0.7944, 0.7131,
        0.8161, 0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.7703, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.261779 Loss T 0.062092 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0037, Accuracy: 693/1134 F1 (61.1111%)


Test set: Average loss: 1.6268, Accuracy: 47431/69960 F1 (67.7973%)


Val set: Average loss: 1.6880, Accuracy: 232/360 F1 (64.4444%)

best acc test 71.252144  acc val 64.444444 acc labeled target 61.111111
saving model...
S painting T real Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.180814 Loss T 0.050527 Method MME

S painting T real Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.644748 Loss T 0.037090 Method MME

S painting T real Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.474195 Loss T 0.058432 Method MME

S painting T real Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.665967 Loss T 0.049276 Method MME

S painting T real Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.203642 Loss T 0.049435 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7134, Accuracy: 759/1134 F1 (66.9312%)


Test set: Average loss: 1.3784, Accuracy: 51015/69960 F1 (72.9202%)


Val set: Average loss: 1.4411, Accuracy: 255/360 F1 (70.8333%)

best acc test 72.920240  acc val 70.833333 acc labeled target 66.931217
saving model...
S painting T real Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.354536 Loss T 0.067161 Method MME

S painting T real Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.861273 Loss T 0.053665 Method MME

S painting T real Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.301576 Loss T 0.066407 Method MME

S painting T real Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.276148 Loss T 0.064442 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.22222222 1.         1.         0.33333334 0.7777778
 0.8888889  0.6666667  0.6666667  1.         0.7777778  0.6666667
 0.         0.         0.6666667  0.5555556  0.44444445 1.
 0.         0.7777778  0.22222222 0.33333334 1.         0.33333334
 0.6666667  1.         0.6666667  0.6666667  1.         1.
 1.         0.44444445 0.33333334 0.11111111 0.33333334 0.7777778
 0.         0.8888889  0.33333334 1.         0.6666667  0.7777778
 0.33333334 0.6666667  0.8888889  1.         0.8888889  0.6666667
 0.         1.         1.         0.33333334 0.6666667  0.7777778
 0.22222222 0.8888889  1.         1.         0.44444445 1.
 1.         0.33333334 1.         0.         1.         1.
 0.         1.         0.6666667  1.         1.         0.5555556
 1.         0.5555556  0.11111111 0.7777778  0.6666667  0.33333334
 0.         1.         0.         0.8888889  0.5555556  0.
 0.22222222 1.         1.         0.33333334 0.         0.6666667
 0.33333334 1.         0.6666667  1.         0.6666667  1.
 0.33333334 1.         0.6666667  0.8888889  1.         0.6666667
 1.         0.33333334 0.33333334 0.8888889  1.         1.
 0.6666667  0.7777778  0.7777778  0.8888889  1.         1.
 0.5555556  1.         0.8888889  0.8888889  0.         0.8888889
 0.5555556  0.8888889  0.6666667  0.6666667  1.         1.        ]
Top k classes which perform poorly are:  [118, 78, 80, 18, 36, 13, 83, 66, 12, 88, 63, 48, 33, 74, 84, 54, 20, 1, 42, 32, 38, 103, 61, 34, 104, 51, 90, 77, 87, 23, 21, 4, 96, 58, 31, 16, 114, 82, 71, 73, 15, 120, 92, 108, 76, 98, 52, 68, 101, 89, 47, 94, 43, 26, 24, 8, 7, 40, 122, 27, 11, 123, 14, 5, 19, 75, 41, 109, 10, 110, 53, 35, 81, 99, 119, 117, 116, 37, 105, 6, 44, 46, 55, 111, 121, 97, 112, 115, 102, 106, 107, 113, 95, 100, 0, 62, 91, 2, 3, 9, 17, 22, 25, 28, 29, 30, 39, 45, 49, 50, 56, 57, 59, 60, 124, 64, 65, 67, 69, 70, 72, 79, 85, 86, 93, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.4004, 1.1839, 1.1839, 1.3583, 1.2297, 1.2056, 1.2567, 1.2567,
        1.1839, 1.2297, 1.2567, 1.5000, 1.5000, 1.2567, 1.2869, 1.3206, 1.1839,
        1.5000, 1.2297, 1.4004, 1.3583, 1.1839, 1.3583, 1.2567, 1.1839, 1.2567,
        1.2567, 1.1839, 1.1839, 1.1839, 1.3206, 1.3583, 1.4474, 1.3583, 1.2297,
        1.5000, 1.2056, 1.3583, 1.1839, 1.2567, 1.2297, 1.3583, 1.2567, 1.2056,
        1.1839, 1.2056, 1.2567, 1.5000, 1.1839, 1.1839, 1.3583, 1.2567, 1.2297,
        1.4004, 1.2056, 1.1839, 1.1839, 1.3206, 1.1839, 1.1839, 1.3583, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839, 1.1839, 1.2869,
        1.1839, 1.2869, 1.4474, 1.2297, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.2056, 1.2869, 1.5000, 1.4004, 1.1839, 1.1839, 1.3583, 1.5000, 1.2567,
        1.3583, 1.1839, 1.2567, 1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.2567,
        1.2056, 1.1839, 1.2567, 1.1839, 1.3583, 1.3583, 1.2056, 1.1839, 1.1839,
        1.2567, 1.2297, 1.2297, 1.2056, 1.1839, 1.1839, 1.2869, 1.1839, 1.2056,
        1.2056, 1.5000, 1.2056, 1.2869, 1.2056, 1.2567, 1.2567, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5996, 0.8161, 0.8161, 0.6417, 0.7703, 0.7944, 0.7433, 0.7433,
        0.8161, 0.7703, 0.7433, 0.5000, 0.5000, 0.7433, 0.7131, 0.6794, 0.8161,
        0.5000, 0.7703, 0.5996, 0.6417, 0.8161, 0.6417, 0.7433, 0.8161, 0.7433,
        0.7433, 0.8161, 0.8161, 0.8161, 0.6794, 0.6417, 0.5526, 0.6417, 0.7703,
        0.5000, 0.7944, 0.6417, 0.8161, 0.7433, 0.7703, 0.6417, 0.7433, 0.7944,
        0.8161, 0.7944, 0.7433, 0.5000, 0.8161, 0.8161, 0.6417, 0.7433, 0.7703,
        0.5996, 0.7944, 0.8161, 0.8161, 0.6794, 0.8161, 0.8161, 0.6417, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161, 0.8161, 0.7131,
        0.8161, 0.7131, 0.5526, 0.7703, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.7944, 0.7131, 0.5000, 0.5996, 0.8161, 0.8161, 0.6417, 0.5000, 0.7433,
        0.6417, 0.8161, 0.7433, 0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.7433,
        0.7944, 0.8161, 0.7433, 0.8161, 0.6417, 0.6417, 0.7944, 0.8161, 0.8161,
        0.7433, 0.7703, 0.7703, 0.7944, 0.8161, 0.8161, 0.7131, 0.8161, 0.7944,
        0.7944, 0.5000, 0.7944, 0.7131, 0.7944, 0.7433, 0.7433, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.387807 Loss T 0.071562 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2134, Accuracy: 659/1134 F1 (58.1129%)


Test set: Average loss: 1.7946, Accuracy: 46323/69960 F1 (66.2136%)


Val set: Average loss: 1.9926, Accuracy: 223/360 F1 (61.9444%)

best acc test 72.920240  acc val 61.944444 acc labeled target 58.112875
saving model...
S painting T real Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.423127 Loss T 0.055956 Method MME

S painting T real Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.605230 Loss T 0.049758 Method MME

S painting T real Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.426346 Loss T 0.068448 Method MME

S painting T real Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.304432 Loss T 0.039189 Method MME

S painting T real Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.518588 Loss T 0.035521 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7315, Accuracy: 755/1134 F1 (66.5785%)


Test set: Average loss: 1.3785, Accuracy: 51617/69960 F1 (73.7807%)


Val set: Average loss: 1.5760, Accuracy: 249/360 F1 (69.1667%)

best acc test 72.920240  acc val 69.166667 acc labeled target 66.578483
saving model...
S painting T real Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.446563 Loss T 0.055032 Method MME

S painting T real Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.595556 Loss T 0.059252 Method MME

S painting T real Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.333014 Loss T 0.047849 Method MME

S painting T real Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.557270 Loss T 0.051994 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 1.         1.         0.33333334 0.7777778
 0.8888889  0.6666667  0.6666667  0.8888889  0.8888889  0.6666667
 0.         0.11111111 0.6666667  0.33333334 0.6666667  1.
 0.44444445 1.         0.11111111 0.33333334 1.         0.22222222
 0.44444445 1.         0.6666667  0.6666667  1.         1.
 0.33333334 0.22222222 0.6666667  0.44444445 0.33333334 0.7777778
 0.         1.         0.33333334 1.         0.6666667  0.7777778
 0.33333334 0.6666667  1.         1.         1.         1.
 0.         1.         1.         0.8888889  0.6666667  0.7777778
 0.22222222 0.6666667  1.         1.         0.33333334 1.
 1.         0.5555556  1.         0.22222222 1.         1.
 0.         1.         1.         1.         1.         0.22222222
 1.         0.6666667  0.7777778  0.8888889  0.6666667  0.33333334
 0.         0.7777778  0.         1.         0.44444445 0.
 0.         1.         1.         0.33333334 0.33333334 0.5555556
 0.22222222 0.6666667  0.7777778  0.8888889  0.6666667  1.
 0.22222222 1.         0.6666667  0.6666667  1.         0.6666667
 0.8888889  0.33333334 0.22222222 0.7777778  0.6666667  0.7777778
 0.6666667  0.8888889  0.6666667  0.6666667  0.8888889  0.6666667
 0.6666667  1.         0.6666667  1.         0.         1.
 0.5555556  1.         0.33333334 0.5555556  0.8888889  1.        ]
Top k classes which perform poorly are:  [84, 83, 36, 80, 66, 118, 78, 12, 48, 13, 20, 90, 96, 54, 104, 31, 23, 63, 71, 1, 42, 21, 87, 15, 38, 58, 4, 103, 122, 30, 77, 34, 88, 18, 33, 82, 24, 123, 89, 120, 61, 98, 73, 106, 55, 99, 101, 52, 108, 111, 116, 91, 7, 8, 11, 14, 16, 26, 27, 94, 110, 76, 114, 40, 43, 113, 32, 35, 105, 74, 79, 107, 41, 53, 5, 92, 93, 6, 102, 124, 51, 109, 112, 9, 75, 10, 97, 121, 95, 117, 115, 100, 119, 0, 62, 85, 2, 3, 17, 19, 22, 25, 28, 29, 37, 39, 44, 45, 46, 86, 47, 50, 56, 57, 59, 60, 64, 65, 67, 68, 69, 70, 72, 81, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.1839, 1.1839, 1.3583, 1.2297, 1.2056, 1.2567, 1.2567,
        1.2056, 1.2056, 1.2567, 1.5000, 1.4474, 1.2567, 1.3583, 1.2567, 1.1839,
        1.3206, 1.1839, 1.4474, 1.3583, 1.1839, 1.4004, 1.3206, 1.1839, 1.2567,
        1.2567, 1.1839, 1.1839, 1.3583, 1.4004, 1.2567, 1.3206, 1.3583, 1.2297,
        1.5000, 1.1839, 1.3583, 1.1839, 1.2567, 1.2297, 1.3583, 1.2567, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.2056, 1.2567, 1.2297,
        1.4004, 1.2567, 1.1839, 1.1839, 1.3583, 1.1839, 1.1839, 1.2869, 1.1839,
        1.4004, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.4004,
        1.1839, 1.2567, 1.2297, 1.2056, 1.2567, 1.3583, 1.5000, 1.2297, 1.5000,
        1.1839, 1.3206, 1.5000, 1.5000, 1.1839, 1.1839, 1.3583, 1.3583, 1.2869,
        1.4004, 1.2567, 1.2297, 1.2056, 1.2567, 1.1839, 1.4004, 1.1839, 1.2567,
        1.2567, 1.1839, 1.2567, 1.2056, 1.3583, 1.4004, 1.2297, 1.2567, 1.2297,
        1.2567, 1.2056, 1.2567, 1.2567, 1.2056, 1.2567, 1.2567, 1.1839, 1.2567,
        1.1839, 1.5000, 1.1839, 1.2869, 1.1839, 1.3583, 1.2869, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.8161, 0.8161, 0.6417, 0.7703, 0.7944, 0.7433, 0.7433,
        0.7944, 0.7944, 0.7433, 0.5000, 0.5526, 0.7433, 0.6417, 0.7433, 0.8161,
        0.6794, 0.8161, 0.5526, 0.6417, 0.8161, 0.5996, 0.6794, 0.8161, 0.7433,
        0.7433, 0.8161, 0.8161, 0.6417, 0.5996, 0.7433, 0.6794, 0.6417, 0.7703,
        0.5000, 0.8161, 0.6417, 0.8161, 0.7433, 0.7703, 0.6417, 0.7433, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.7944, 0.7433, 0.7703,
        0.5996, 0.7433, 0.8161, 0.8161, 0.6417, 0.8161, 0.8161, 0.7131, 0.8161,
        0.5996, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5996,
        0.8161, 0.7433, 0.7703, 0.7944, 0.7433, 0.6417, 0.5000, 0.7703, 0.5000,
        0.8161, 0.6794, 0.5000, 0.5000, 0.8161, 0.8161, 0.6417, 0.6417, 0.7131,
        0.5996, 0.7433, 0.7703, 0.7944, 0.7433, 0.8161, 0.5996, 0.8161, 0.7433,
        0.7433, 0.8161, 0.7433, 0.7944, 0.6417, 0.5996, 0.7703, 0.7433, 0.7703,
        0.7433, 0.7944, 0.7433, 0.7433, 0.7944, 0.7433, 0.7433, 0.8161, 0.7433,
        0.8161, 0.5000, 0.8161, 0.7131, 0.8161, 0.6417, 0.7131, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.598331 Loss T 0.056279 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0749, Accuracy: 701/1134 F1 (61.8166%)


Test set: Average loss: 1.7103, Accuracy: 47874/69960 F1 (68.4305%)


Val set: Average loss: 1.9770, Accuracy: 233/360 F1 (64.7222%)

best acc test 72.920240  acc val 64.722222 acc labeled target 61.816578
saving model...
S painting T real Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.715016 Loss T 0.060757 Method MME

S painting T real Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.199655 Loss T 0.037657 Method MME

S painting T real Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 1.019247 Loss T 0.050110 Method MME

S painting T real Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.100123 Loss T 0.053368 Method MME

S painting T real Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.485276 Loss T 0.067809 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.7905, Accuracy: 763/1134 F1 (67.2840%)


Test set: Average loss: 1.4590, Accuracy: 51698/69960 F1 (73.8965%)


Val set: Average loss: 1.6672, Accuracy: 250/360 F1 (69.4444%)

best acc test 72.920240  acc val 69.444444 acc labeled target 67.283951
saving model...
S painting T real Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.187333 Loss T 0.056172 Method MME

S painting T real Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.164849 Loss T 0.034458 Method MME

S painting T real Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.277896 Loss T 0.043424 Method MME

S painting T real Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.192505 Loss T 0.061371 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 0.6666667  1.         0.44444445 1.
 0.6666667  0.6666667  1.         0.8888889  0.6666667  0.6666667
 0.         0.33333334 0.6666667  0.44444445 0.6666667  1.
 0.33333334 0.6666667  0.22222222 0.5555556  1.         0.33333334
 0.22222222 0.8888889  0.33333334 0.6666667  0.8888889  1.
 0.8888889  0.         0.44444445 0.6666667  0.33333334 0.6666667
 0.         0.8888889  0.33333334 1.         0.6666667  1.
 0.33333334 0.8888889  1.         0.7777778  0.7777778  0.8888889
 0.         1.         1.         0.44444445 0.6666667  0.44444445
 0.5555556  0.7777778  0.8888889  1.         0.5555556  0.6666667
 1.         0.         1.         0.6666667  1.         1.
 0.         1.         0.7777778  1.         1.         0.5555556
 0.8888889  0.6666667  0.6666667  0.8888889  0.6666667  0.33333334
 0.         1.         0.         1.         0.6666667  0.
 0.22222222 1.         0.6666667  0.33333334 0.11111111 0.6666667
 0.8888889  0.6666667  0.7777778  1.         0.5555556  1.
 0.44444445 0.8888889  0.6666667  0.6666667  0.8888889  0.6666667
 1.         0.44444445 0.5555556  0.7777778  1.         0.7777778
 0.5555556  0.8888889  1.         0.6666667  1.         1.
 0.6666667  0.8888889  0.7777778  1.         0.         0.8888889
 0.5555556  0.8888889  0.44444445 0.6666667  0.6666667  1.        ]
Top k classes which perform poorly are:  [78, 31, 118, 83, 80, 48, 12, 36, 66, 61, 88, 24, 84, 20, 34, 42, 26, 87, 23, 1, 18, 13, 38, 77, 122, 15, 51, 96, 53, 32, 103, 4, 58, 54, 108, 104, 94, 71, 120, 21, 76, 74, 91, 59, 111, 7, 124, 63, 6, 73, 123, 2, 89, 10, 11, 52, 14, 99, 114, 16, 19, 82, 27, 86, 40, 98, 33, 35, 101, 105, 46, 68, 55, 92, 45, 107, 116, 121, 90, 9, 119, 25, 28, 30, 43, 115, 47, 56, 75, 97, 109, 72, 37, 100, 0, 106, 110, 112, 117, 102, 113, 62, 93, 3, 5, 8, 17, 22, 29, 39, 41, 44, 49, 50, 57, 60, 64, 65, 67, 69, 70, 79, 81, 85, 95, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.2567, 1.1839, 1.3206, 1.1839, 1.2567, 1.2567, 1.1839,
        1.2056, 1.2567, 1.2567, 1.5000, 1.3583, 1.2567, 1.3206, 1.2567, 1.1839,
        1.3583, 1.2567, 1.4004, 1.2869, 1.1839, 1.3583, 1.4004, 1.2056, 1.3583,
        1.2567, 1.2056, 1.1839, 1.2056, 1.5000, 1.3206, 1.2567, 1.3583, 1.2567,
        1.5000, 1.2056, 1.3583, 1.1839, 1.2567, 1.1839, 1.3583, 1.2056, 1.1839,
        1.2297, 1.2297, 1.2056, 1.5000, 1.1839, 1.1839, 1.3206, 1.2567, 1.3206,
        1.2869, 1.2297, 1.2056, 1.1839, 1.2869, 1.2567, 1.1839, 1.5000, 1.1839,
        1.2567, 1.1839, 1.1839, 1.5000, 1.1839, 1.2297, 1.1839, 1.1839, 1.2869,
        1.2056, 1.2567, 1.2567, 1.2056, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.1839, 1.2567, 1.5000, 1.4004, 1.1839, 1.2567, 1.3583, 1.4474, 1.2567,
        1.2056, 1.2567, 1.2297, 1.1839, 1.2869, 1.1839, 1.3206, 1.2056, 1.2567,
        1.2567, 1.2056, 1.2567, 1.1839, 1.3206, 1.2869, 1.2297, 1.1839, 1.2297,
        1.2869, 1.2056, 1.1839, 1.2567, 1.1839, 1.1839, 1.2567, 1.2056, 1.2297,
        1.1839, 1.5000, 1.2056, 1.2869, 1.2056, 1.3206, 1.2567, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.7433, 0.8161, 0.6794, 0.8161, 0.7433, 0.7433, 0.8161,
        0.7944, 0.7433, 0.7433, 0.5000, 0.6417, 0.7433, 0.6794, 0.7433, 0.8161,
        0.6417, 0.7433, 0.5996, 0.7131, 0.8161, 0.6417, 0.5996, 0.7944, 0.6417,
        0.7433, 0.7944, 0.8161, 0.7944, 0.5000, 0.6794, 0.7433, 0.6417, 0.7433,
        0.5000, 0.7944, 0.6417, 0.8161, 0.7433, 0.8161, 0.6417, 0.7944, 0.8161,
        0.7703, 0.7703, 0.7944, 0.5000, 0.8161, 0.8161, 0.6794, 0.7433, 0.6794,
        0.7131, 0.7703, 0.7944, 0.8161, 0.7131, 0.7433, 0.8161, 0.5000, 0.8161,
        0.7433, 0.8161, 0.8161, 0.5000, 0.8161, 0.7703, 0.8161, 0.8161, 0.7131,
        0.7944, 0.7433, 0.7433, 0.7944, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.8161, 0.7433, 0.5000, 0.5996, 0.8161, 0.7433, 0.6417, 0.5526, 0.7433,
        0.7944, 0.7433, 0.7703, 0.8161, 0.7131, 0.8161, 0.6794, 0.7944, 0.7433,
        0.7433, 0.7944, 0.7433, 0.8161, 0.6794, 0.7131, 0.7703, 0.8161, 0.7703,
        0.7131, 0.7944, 0.8161, 0.7433, 0.8161, 0.8161, 0.7433, 0.7944, 0.7703,
        0.8161, 0.5000, 0.7944, 0.7131, 0.7944, 0.6794, 0.7433, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.282382 Loss T 0.045296 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9891, Accuracy: 731/1134 F1 (64.4621%)


Test set: Average loss: 1.7020, Accuracy: 48133/69960 F1 (68.8007%)


Val set: Average loss: 1.9630, Accuracy: 237/360 F1 (65.8333%)

best acc test 72.920240  acc val 65.833333 acc labeled target 64.462081
saving model...
S painting T real Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.154098 Loss T 0.047528 Method MME

S painting T real Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.129677 Loss T 0.043720 Method MME

S painting T real Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.411457 Loss T 0.038358 Method MME

S painting T real Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.340026 Loss T 0.043402 Method MME

S painting T real Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.558722 Loss T 0.030356 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8177, Accuracy: 778/1134 F1 (68.6067%)


Test set: Average loss: 1.5172, Accuracy: 51756/69960 F1 (73.9794%)


Val set: Average loss: 1.6883, Accuracy: 247/360 F1 (68.6111%)

best acc test 72.920240  acc val 68.611111 acc labeled target 68.606702
saving model...
S painting T real Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.293794 Loss T 0.030976 Method MME

S painting T real Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.357520 Loss T 0.034273 Method MME

S painting T real Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.508508 Loss T 0.022904 Method MME

S painting T real Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.164103 Loss T 0.035620 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 0.8888889  1.         0.33333334 0.8888889
 0.8888889  0.8888889  0.8888889  0.7777778  1.         0.6666667
 0.         0.         0.6666667  0.5555556  0.5555556  1.
 0.22222222 1.         0.         0.33333334 1.         0.33333334
 0.6666667  0.7777778  0.44444445 0.6666667  0.8888889  1.
 0.8888889  0.22222222 0.33333334 0.11111111 0.6666667  0.6666667
 0.         0.8888889  0.33333334 1.         0.6666667  1.
 0.6666667  1.         0.8888889  0.8888889  0.8888889  0.6666667
 0.         1.         1.         0.6666667  0.6666667  0.5555556
 0.44444445 1.         1.         1.         0.33333334 0.8888889
 1.         0.11111111 1.         0.7777778  1.         1.
 0.         1.         0.8888889  0.8888889  1.         1.
 1.         0.5555556  0.33333334 1.         0.6666667  0.33333334
 0.         0.7777778  0.         1.         0.5555556  0.
 0.22222222 1.         1.         0.33333334 0.22222222 0.6666667
 0.6666667  0.6666667  0.8888889  1.         0.7777778  1.
 0.         0.6666667  0.6666667  0.8888889  0.7777778  0.6666667
 0.7777778  0.44444445 1.         0.7777778  0.7777778  0.8888889
 0.6666667  0.8888889  0.8888889  0.8888889  1.         1.
 0.5555556  1.         0.6666667  1.         0.         1.
 0.44444445 0.8888889  0.5555556  0.5555556  0.7777778  1.        ]
Top k classes which perform poorly are:  [48, 83, 80, 78, 66, 36, 118, 20, 13, 12, 96, 33, 61, 31, 84, 18, 88, 77, 74, 1, 23, 32, 87, 38, 4, 58, 21, 120, 26, 103, 54, 73, 122, 53, 123, 82, 16, 15, 114, 51, 101, 89, 108, 90, 91, 98, 52, 76, 11, 47, 35, 97, 27, 40, 116, 24, 42, 34, 14, 106, 94, 9, 79, 105, 25, 124, 63, 102, 100, 92, 99, 28, 2, 121, 6, 8, 7, 37, 5, 69, 68, 46, 107, 109, 59, 110, 30, 111, 45, 44, 113, 119, 112, 117, 104, 115, 0, 62, 93, 3, 10, 17, 19, 22, 29, 39, 41, 43, 49, 50, 55, 56, 57, 60, 64, 65, 67, 70, 71, 72, 75, 81, 85, 86, 95, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.3583, 1.2056, 1.1839, 1.3583, 1.2056, 1.2056, 1.2056, 1.2056,
        1.2297, 1.1839, 1.2567, 1.5000, 1.5000, 1.2567, 1.2869, 1.2869, 1.1839,
        1.4004, 1.1839, 1.5000, 1.3583, 1.1839, 1.3583, 1.2567, 1.2297, 1.3206,
        1.2567, 1.2056, 1.1839, 1.2056, 1.4004, 1.3583, 1.4474, 1.2567, 1.2567,
        1.5000, 1.2056, 1.3583, 1.1839, 1.2567, 1.1839, 1.2567, 1.1839, 1.2056,
        1.2056, 1.2056, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.2869,
        1.3206, 1.1839, 1.1839, 1.1839, 1.3583, 1.2056, 1.1839, 1.4474, 1.1839,
        1.2297, 1.1839, 1.1839, 1.5000, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2869, 1.3583, 1.1839, 1.2567, 1.3583, 1.5000, 1.2297, 1.5000,
        1.1839, 1.2869, 1.5000, 1.4004, 1.1839, 1.1839, 1.3583, 1.4004, 1.2567,
        1.2567, 1.2567, 1.2056, 1.1839, 1.2297, 1.1839, 1.5000, 1.2567, 1.2567,
        1.2056, 1.2297, 1.2567, 1.2297, 1.3206, 1.1839, 1.2297, 1.2297, 1.2056,
        1.2567, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2869, 1.1839, 1.2567,
        1.1839, 1.5000, 1.1839, 1.3206, 1.2056, 1.2869, 1.2869, 1.2297, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.6417, 0.7944, 0.8161, 0.6417, 0.7944, 0.7944, 0.7944, 0.7944,
        0.7703, 0.8161, 0.7433, 0.5000, 0.5000, 0.7433, 0.7131, 0.7131, 0.8161,
        0.5996, 0.8161, 0.5000, 0.6417, 0.8161, 0.6417, 0.7433, 0.7703, 0.6794,
        0.7433, 0.7944, 0.8161, 0.7944, 0.5996, 0.6417, 0.5526, 0.7433, 0.7433,
        0.5000, 0.7944, 0.6417, 0.8161, 0.7433, 0.8161, 0.7433, 0.8161, 0.7944,
        0.7944, 0.7944, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.7131,
        0.6794, 0.8161, 0.8161, 0.8161, 0.6417, 0.7944, 0.8161, 0.5526, 0.8161,
        0.7703, 0.8161, 0.8161, 0.5000, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7131, 0.6417, 0.8161, 0.7433, 0.6417, 0.5000, 0.7703, 0.5000,
        0.8161, 0.7131, 0.5000, 0.5996, 0.8161, 0.8161, 0.6417, 0.5996, 0.7433,
        0.7433, 0.7433, 0.7944, 0.8161, 0.7703, 0.8161, 0.5000, 0.7433, 0.7433,
        0.7944, 0.7703, 0.7433, 0.7703, 0.6794, 0.8161, 0.7703, 0.7703, 0.7944,
        0.7433, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7131, 0.8161, 0.7433,
        0.8161, 0.5000, 0.8161, 0.6794, 0.7944, 0.7131, 0.7131, 0.7703, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.323089 Loss T 0.040005 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0270, Accuracy: 728/1134 F1 (64.1975%)


Test set: Average loss: 1.6280, Accuracy: 49836/69960 F1 (71.2350%)


Val set: Average loss: 1.8553, Accuracy: 240/360 F1 (66.6667%)

best acc test 72.920240  acc val 66.666667 acc labeled target 64.197531
saving model...
S painting T real Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.183848 Loss T 0.058446 Method MME

S painting T real Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.117092 Loss T 0.044142 Method MME

S painting T real Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.232441 Loss T 0.044462 Method MME

S painting T real Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.058775 Loss T 0.025205 Method MME

S painting T real Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.196983 Loss T 0.025653 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0440, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 1.0998, Accuracy: 54760/69960 F1 (78.2733%)


Val set: Average loss: 1.1920, Accuracy: 276/360 F1 (76.6667%)

best acc test 78.273299  acc val 76.666667 acc labeled target 99.029982
saving model...
S painting T real Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.192400 Loss T 0.037815 Method MME

S painting T real Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.589613 Loss T 0.049892 Method MME

S painting T real Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.489269 Loss T 0.023103 Method MME

S painting T real Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.079341 Loss T 0.039519 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [23, 94, 84, 12, 10, 106, 55, 26, 73, 36, 89, 90, 87, 91, 86, 92, 85, 88, 83, 0, 93, 80, 79, 78, 77, 76, 75, 74, 72, 71, 70, 69, 68, 82, 81, 96, 67, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 95, 111, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 110, 66, 62, 64, 30, 29, 28, 27, 25, 24, 22, 21, 20, 19, 18, 17, 31, 16, 14, 13, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 15, 32, 33, 34, 63, 124, 61, 60, 59, 58, 57, 56, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.405796 Loss T 0.035062 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1266, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 1.3934, Accuracy: 51671/69960 F1 (73.8579%)


Val set: Average loss: 1.5514, Accuracy: 249/360 F1 (69.1667%)

best acc test 78.273299  acc val 69.166667 acc labeled target 96.737213
saving model...
S painting T real Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.110137 Loss T 0.037412 Method MME

S painting T real Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.034717 Loss T 0.028323 Method MME

S painting T real Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.131102 Loss T 0.033543 Method MME

S painting T real Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.125603 Loss T 0.040834 Method MME

S painting T real Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.331891 Loss T 0.028982 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0367, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 1.1436, Accuracy: 54981/69960 F1 (78.5892%)


Val set: Average loss: 1.3006, Accuracy: 273/360 F1 (75.8333%)

best acc test 78.273299  acc val 75.833333 acc labeled target 99.118166
saving model...
S painting T real Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.090273 Loss T 0.034023 Method MME

S painting T real Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.360963 Loss T 0.027984 Method MME

S painting T real Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.396879 Loss T 0.038429 Method MME

S painting T real Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.257129 Loss T 0.038767 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 38, 26, 25, 104, 116, 57, 34, 61, 2, 91, 68, 90, 89, 88, 87, 69, 86, 85, 84, 72, 71, 82, 81, 92, 79, 78, 77, 76, 75, 74, 73, 70, 83, 80, 0, 94, 123, 122, 121, 120, 119, 118, 117, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 103, 102, 101, 100, 99, 98, 97, 96, 67, 93, 95, 62, 64, 29, 28, 27, 24, 23, 22, 21, 20, 19, 18, 17, 16, 30, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 14, 65, 31, 33, 63, 124, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 32, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.290809 Loss T 0.041370 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0794, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.4236, Accuracy: 51887/69960 F1 (74.1667%)


Val set: Average loss: 1.5835, Accuracy: 254/360 F1 (70.5556%)

best acc test 78.273299  acc val 70.555556 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.044689 Loss T 0.028842 Method MME

S painting T real Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.177108 Loss T 0.026486 Method MME

S painting T real Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.540278 Loss T 0.027922 Method MME

S painting T real Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.028992 Loss T 0.030845 Method MME

S painting T real Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.374313 Loss T 0.028615 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0326, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 1.1711, Accuracy: 55173/69960 F1 (78.8636%)


Val set: Average loss: 1.4161, Accuracy: 263/360 F1 (73.0556%)

best acc test 78.273299  acc val 73.055556 acc labeled target 99.206349
saving model...
S painting T real Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.633719 Loss T 0.019759 Method MME

S painting T real Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.403007 Loss T 0.024648 Method MME

S painting T real Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.089219 Loss T 0.028269 Method MME

S painting T real Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.390638 Loss T 0.030394 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [19, 122, 89, 51, 82, 118, 57, 80, 12, 81, 83, 0, 85, 87, 88, 90, 84, 86, 77, 78, 91, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 92, 95, 94, 123, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 66, 93, 65, 62, 63, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.204446 Loss T 0.036482 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1049, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.4433, Accuracy: 51765/69960 F1 (73.9923%)


Val set: Average loss: 1.6141, Accuracy: 253/360 F1 (70.2778%)

best acc test 78.273299  acc val 70.277778 acc labeled target 97.530864
saving model...
S painting T real Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.300960 Loss T 0.025910 Method MME

S painting T real Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.100490 Loss T 0.037236 Method MME

S painting T real Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.016755 Loss T 0.032279 Method MME

S painting T real Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.087464 Loss T 0.027328 Method MME

S painting T real Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.059345 Loss T 0.031969 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0174, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 1.1615, Accuracy: 55474/69960 F1 (79.2939%)


Val set: Average loss: 1.4169, Accuracy: 268/360 F1 (74.4444%)

best acc test 78.273299  acc val 74.444444 acc labeled target 99.647266
saving model...
S painting T real Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.005126 Loss T 0.031171 Method MME

S painting T real Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 1.194307 Loss T 0.028674 Method MME

S painting T real Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.326694 Loss T 0.031036 Method MME

S painting T real Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.068355 Loss T 0.031972 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [54, 12, 53, 23, 82, 83, 84, 85, 0, 86, 87, 88, 89, 90, 91, 81, 80, 78, 92, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 93, 95, 66, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 63, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.074858 Loss T 0.037621 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0785, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.4448, Accuracy: 52309/69960 F1 (74.7699%)


Val set: Average loss: 1.7715, Accuracy: 246/360 F1 (68.3333%)

best acc test 78.273299  acc val 68.333333 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.108862 Loss T 0.023213 Method MME

S painting T real Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.125465 Loss T 0.038895 Method MME

S painting T real Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.237445 Loss T 0.042648 Method MME

S painting T real Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.040317 Loss T 0.034128 Method MME

S painting T real Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.165957 Loss T 0.027604 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0470, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.2405, Accuracy: 55410/69960 F1 (79.2024%)


Val set: Average loss: 1.5491, Accuracy: 264/360 F1 (73.3333%)

best acc test 78.273299  acc val 73.333333 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.042158 Loss T 0.032164 Method MME

S painting T real Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.095244 Loss T 0.035720 Method MME

S painting T real Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.043237 Loss T 0.023509 Method MME

S painting T real Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.156749 Loss T 0.028321 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [78, 12, 0, 37, 84, 23, 104, 107, 34, 53, 80, 36, 123, 10, 92, 91, 90, 89, 88, 87, 86, 85, 68, 76, 83, 82, 71, 81, 72, 79, 73, 74, 77, 75, 70, 69, 95, 94, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 106, 105, 103, 102, 101, 100, 99, 98, 97, 96, 67, 109, 66, 62, 64, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 14, 13, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 15, 65, 31, 33, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 51, 32, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 35, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.052306 Loss T 0.022119 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0749, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.4049, Accuracy: 52727/69960 F1 (75.3674%)


Val set: Average loss: 1.7033, Accuracy: 261/360 F1 (72.5000%)

best acc test 78.273299  acc val 72.500000 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.105982 Loss T 0.029898 Method MME

S painting T real Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.100057 Loss T 0.011986 Method MME

S painting T real Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.063071 Loss T 0.022405 Method MME

S painting T real Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.284220 Loss T 0.019042 Method MME

S painting T real Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.094347 Loss T 0.017185 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0189, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.2192, Accuracy: 55614/69960 F1 (79.4940%)


Val set: Average loss: 1.5076, Accuracy: 269/360 F1 (74.7222%)

best acc test 78.273299  acc val 74.722222 acc labeled target 99.294533
saving model...
S painting T real Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.096629 Loss T 0.040289 Method MME

S painting T real Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.121897 Loss T 0.017406 Method MME

S painting T real Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.018949 Loss T 0.047495 Method MME

S painting T real Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.091749 Loss T 0.020191 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [78, 82, 12, 84, 87, 6, 40, 69, 81, 86, 85, 89, 90, 83, 91, 88, 80, 0, 92, 77, 76, 75, 74, 73, 72, 71, 70, 68, 67, 66, 79, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 30, 63, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.177655 Loss T 0.017651 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0761, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.4144, Accuracy: 52700/69960 F1 (75.3288%)


Val set: Average loss: 1.7930, Accuracy: 254/360 F1 (70.5556%)

best acc test 78.273299  acc val 70.555556 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.287639 Loss T 0.035822 Method MME

S painting T real Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.090711 Loss T 0.027356 Method MME

S painting T real Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.153051 Loss T 0.030497 Method MME

S painting T real Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.179064 Loss T 0.034460 Method MME

S painting T real Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.170689 Loss T 0.013049 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0095, Accuracy: 1132/1134 F1 (99.8236%)


Test set: Average loss: 1.2151, Accuracy: 55706/69960 F1 (79.6255%)


Val set: Average loss: 1.6274, Accuracy: 260/360 F1 (72.2222%)

best acc test 78.273299  acc val 72.222222 acc labeled target 99.823633
saving model...
S painting T real Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.201768 Loss T 0.025773 Method MME

S painting T real Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.430934 Loss T 0.028613 Method MME

S painting T real Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.072683 Loss T 0.032284 Method MME

S painting T real Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.055285 Loss T 0.011429 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [10, 0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 92, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 63, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.058223 Loss T 0.022333 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0806, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.4268, Accuracy: 52788/69960 F1 (75.4545%)


Val set: Average loss: 1.7461, Accuracy: 258/360 F1 (71.6667%)

best acc test 78.273299  acc val 71.666667 acc labeled target 98.059965
saving model...
S painting T real Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.047393 Loss T 0.028038 Method MME

S painting T real Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.358336 Loss T 0.026275 Method MME

S painting T real Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.264064 Loss T 0.019994 Method MME

S painting T real Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.309945 Loss T 0.021458 Method MME

S painting T real Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.078753 Loss T 0.024065 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0170, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 1.2169, Accuracy: 55828/69960 F1 (79.7999%)


Val set: Average loss: 1.4691, Accuracy: 274/360 F1 (76.1111%)

best acc test 78.273299  acc val 76.111111 acc labeled target 99.647266
saving model...
S painting T real Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.040306 Loss T 0.018562 Method MME

S painting T real Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.092911 Loss T 0.016502 Method MME

S painting T real Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.012571 Loss T 0.015874 Method MME

S painting T real Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.060883 Loss T 0.027561 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [97, 36, 75, 80, 0, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 79, 78, 77, 76, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 91, 92, 93, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 96, 95, 109, 63, 62, 61, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 30, 31, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 34, 33, 32, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.087159 Loss T 0.031044 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0675, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.3744, Accuracy: 53582/69960 F1 (76.5895%)


Val set: Average loss: 1.6958, Accuracy: 256/360 F1 (71.1111%)

best acc test 78.273299  acc val 71.111111 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.069362 Loss T 0.026288 Method MME

S painting T real Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.033649 Loss T 0.024997 Method MME

S painting T real Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.020251 Loss T 0.020002 Method MME

S painting T real Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.075606 Loss T 0.022066 Method MME

S painting T real Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.046152 Loss T 0.016077 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0189, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 1.2525, Accuracy: 55837/69960 F1 (79.8128%)


Val set: Average loss: 1.5354, Accuracy: 270/360 F1 (75.0000%)

best acc test 78.273299  acc val 75.000000 acc labeled target 99.559083
saving model...
S painting T real Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.044549 Loss T 0.029462 Method MME

S painting T real Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.112635 Loss T 0.012906 Method MME

S painting T real Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.004579 Loss T 0.025334 Method MME

S painting T real Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.019452 Loss T 0.028529 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 59, 106, 33, 101, 0, 82, 83, 84, 85, 86, 88, 89, 90, 91, 87, 81, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 80, 92, 93, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 100, 99, 98, 97, 96, 95, 65, 64, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 30, 31, 61, 60, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.606293 Loss T 0.020955 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0626, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.3844, Accuracy: 53580/69960 F1 (76.5866%)


Val set: Average loss: 1.5982, Accuracy: 267/360 F1 (74.1667%)

best acc test 78.273299  acc val 74.166667 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.063096 Loss T 0.020951 Method MME

S painting T real Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.310281 Loss T 0.024077 Method MME

S painting T real Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.096671 Loss T 0.015203 Method MME

S painting T real Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.390976 Loss T 0.024459 Method MME

S painting T real Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.081383 Loss T 0.025419 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0228, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.2788, Accuracy: 55769/69960 F1 (79.7156%)


Val set: Average loss: 1.4451, Accuracy: 280/360 F1 (77.7778%)

best acc test 79.715552  acc val 77.777778 acc labeled target 99.294533
saving model...
S painting T real Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.122375 Loss T 0.037151 Method MME

S painting T real Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.031324 Loss T 0.029529 Method MME

S painting T real Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.054947 Loss T 0.021663 Method MME

S painting T real Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.148830 Loss T 0.017549 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [95, 78, 121, 99, 100, 26, 13, 12, 0, 83, 84, 87, 86, 82, 88, 89, 90, 85, 81, 79, 91, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 92, 96, 94, 123, 122, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 98, 97, 65, 93, 64, 62, 124, 30, 29, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 63, 32, 34, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.065949 Loss T 0.024635 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0456, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.3586, Accuracy: 53743/69960 F1 (76.8196%)


Val set: Average loss: 1.5950, Accuracy: 263/360 F1 (73.0556%)

best acc test 79.715552  acc val 73.055556 acc labeled target 98.853616
saving model...
S painting T real Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.015354 Loss T 0.021638 Method MME

S painting T real Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.024583 Loss T 0.012897 Method MME

S painting T real Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.064270 Loss T 0.033693 Method MME

S painting T real Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.017556 Loss T 0.013673 Method MME

S painting T real Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.020692 Loss T 0.013251 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0172, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 1.2012, Accuracy: 56283/69960 F1 (80.4503%)


Val set: Average loss: 1.4791, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.715552  acc val 75.833333 acc labeled target 99.470899
saving model...
S painting T real Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.054744 Loss T 0.026314 Method MME

S painting T real Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.015791 Loss T 0.018326 Method MME

S painting T real Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.014942 Loss T 0.025614 Method MME

S painting T real Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.018996 Loss T 0.026429 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [108, 36, 45, 114, 41, 90, 80, 81, 82, 0, 85, 86, 87, 88, 89, 83, 84, 79, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 78, 91, 93, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 92, 109, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 107, 64, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 63, 29, 31, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 40, 39, 38, 37, 35, 34, 33, 32, 30, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.017445 Loss T 0.026164 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0632, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.3222, Accuracy: 54234/69960 F1 (77.5214%)


Val set: Average loss: 1.5568, Accuracy: 263/360 F1 (73.0556%)

best acc test 79.715552  acc val 73.055556 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.097465 Loss T 0.020458 Method MME

S painting T real Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.056770 Loss T 0.015923 Method MME

S painting T real Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.039991 Loss T 0.027077 Method MME

S painting T real Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.174787 Loss T 0.030526 Method MME

S painting T real Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.024270 Loss T 0.023073 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0106, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 1.1855, Accuracy: 56329/69960 F1 (80.5160%)


Val set: Average loss: 1.3755, Accuracy: 274/360 F1 (76.1111%)

best acc test 79.715552  acc val 76.111111 acc labeled target 99.647266
saving model...
S painting T real Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.210705 Loss T 0.024097 Method MME

S painting T real Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.043479 Loss T 0.026966 Method MME

S painting T real Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.035710 Loss T 0.024654 Method MME

S painting T real Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.014026 Loss T 0.021118 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 12, 74, 73, 0, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 81, 80, 78, 92, 77, 76, 75, 72, 71, 70, 69, 68, 67, 65, 79, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 63, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.004666 Loss T 0.018394 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0532, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 1.4131, Accuracy: 53437/69960 F1 (76.3822%)


Val set: Average loss: 1.6802, Accuracy: 264/360 F1 (73.3333%)

best acc test 79.715552  acc val 73.333333 acc labeled target 99.029982
saving model...
S painting T real Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.029184 Loss T 0.025523 Method MME

S painting T real Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.063094 Loss T 0.022711 Method MME

S painting T real Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.019812 Loss T 0.021825 Method MME

S painting T real Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.029567 Loss T 0.019517 Method MME

S painting T real Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.049062 Loss T 0.018599 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0181, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.2159, Accuracy: 56562/69960 F1 (80.8491%)


Val set: Average loss: 1.5448, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.715552  acc val 75.277778 acc labeled target 99.294533
saving model...
S painting T real Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.070952 Loss T 0.029222 Method MME

S painting T real Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.076430 Loss T 0.017095 Method MME

S painting T real Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.003140 Loss T 0.014747 Method MME

S painting T real Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.045725 Loss T 0.013133 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [17, 66, 36, 15, 106, 78, 40, 114, 83, 84, 0, 82, 87, 88, 89, 90, 85, 86, 80, 91, 79, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 81, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 93, 110, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 63, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 39, 38, 37, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.184273 Loss T 0.025037 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0579, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.3583, Accuracy: 54075/69960 F1 (77.2942%)


Val set: Average loss: 1.6754, Accuracy: 263/360 F1 (73.0556%)

best acc test 79.715552  acc val 73.055556 acc labeled target 98.765432
saving model...
S painting T real Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.033671 Loss T 0.009786 Method MME

S painting T real Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.061257 Loss T 0.019690 Method MME

S painting T real Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.191242 Loss T 0.019353 Method MME

S painting T real Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.003733 Loss T 0.027519 Method MME

S painting T real Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.131286 Loss T 0.022164 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0088, Accuracy: 1131/1134 F1 (99.7355%)


Test set: Average loss: 1.2097, Accuracy: 56566/69960 F1 (80.8548%)


Val set: Average loss: 1.6237, Accuracy: 263/360 F1 (73.0556%)

best acc test 79.715552  acc val 73.055556 acc labeled target 99.735450
saving model...
S painting T real Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.162301 Loss T 0.022816 Method MME

S painting T real Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.107201 Loss T 0.019801 Method MME

S painting T real Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.022113 Loss T 0.017253 Method MME

S painting T real Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.088495 Loss T 0.022985 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [37, 6, 12, 0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 78, 92, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 30, 63, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.016882 Loss T 0.028798 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0561, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.4060, Accuracy: 53768/69960 F1 (76.8553%)


Val set: Average loss: 1.6028, Accuracy: 266/360 F1 (73.8889%)

best acc test 79.715552  acc val 73.888889 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.089739 Loss T 0.019247 Method MME

S painting T real Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.069123 Loss T 0.015483 Method MME

S painting T real Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.003864 Loss T 0.016449 Method MME

S painting T real Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.009098 Loss T 0.026700 Method MME

S painting T real Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.009816 Loss T 0.018137 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0261, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.2027, Accuracy: 56556/69960 F1 (80.8405%)


Val set: Average loss: 1.5668, Accuracy: 268/360 F1 (74.4444%)

best acc test 79.715552  acc val 74.444444 acc labeled target 99.294533
saving model...
S painting T real Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.006005 Loss T 0.028245 Method MME

S painting T real Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.025791 Loss T 0.027007 Method MME

S painting T real Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.077383 Loss T 0.032692 Method MME

S painting T real Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.024440 Loss T 0.017412 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [79, 30, 76, 88, 82, 51, 114, 108, 81, 0, 85, 86, 87, 89, 90, 91, 83, 84, 78, 77, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 92, 94, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 93, 64, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 31, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.048839 Loss T 0.013880 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0467, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.3729, Accuracy: 53979/69960 F1 (77.1569%)


Val set: Average loss: 1.7160, Accuracy: 262/360 F1 (72.7778%)

best acc test 79.715552  acc val 72.777778 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.081642 Loss T 0.015086 Method MME

S painting T real Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.243203 Loss T 0.022588 Method MME

S painting T real Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.052345 Loss T 0.016617 Method MME

S painting T real Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.035270 Loss T 0.028372 Method MME

S painting T real Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.045224 Loss T 0.014560 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0247, Accuracy: 1127/1134 F1 (99.3827%)


Test set: Average loss: 1.2293, Accuracy: 56579/69960 F1 (80.8734%)


Val set: Average loss: 1.5699, Accuracy: 275/360 F1 (76.3889%)

best acc test 79.715552  acc val 76.388889 acc labeled target 99.382716
saving model...
S painting T real Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.092056 Loss T 0.017135 Method MME

S painting T real Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.061670 Loss T 0.010572 Method MME

S painting T real Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.011185 Loss T 0.011147 Method MME

S painting T real Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.056070 Loss T 0.007259 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [79, 2, 121, 12, 71, 23, 41, 83, 84, 85, 87, 82, 88, 89, 90, 91, 86, 81, 0, 92, 78, 77, 76, 75, 74, 73, 72, 70, 69, 68, 67, 80, 93, 96, 95, 123, 122, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 66, 94, 65, 62, 63, 30, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 31, 64, 32, 34, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.044729 Loss T 0.028643 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0362, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 1.3533, Accuracy: 54201/69960 F1 (77.4743%)


Val set: Average loss: 1.6426, Accuracy: 271/360 F1 (75.2778%)

best acc test 79.715552  acc val 75.277778 acc labeled target 99.206349
saving model...
S painting T real Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.044696 Loss T 0.020509 Method MME

S painting T real Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.012605 Loss T 0.029066 Method MME

S painting T real Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.008200 Loss T 0.011370 Method MME

S painting T real Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.089744 Loss T 0.042754 Method MME

S painting T real Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.023140 Loss T 0.027296 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0212, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 1.2530, Accuracy: 56764/69960 F1 (81.1378%)


Val set: Average loss: 1.5952, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.715552  acc val 75.833333 acc labeled target 99.470899
saving model...
S painting T real Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.092848 Loss T 0.026055 Method MME

S painting T real Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.009074 Loss T 0.043270 Method MME

S painting T real Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.170200 Loss T 0.021023 Method MME

S painting T real Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.035435 Loss T 0.040213 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [61, 66, 121, 65, 6, 10, 0, 82, 83, 84, 85, 87, 81, 88, 89, 90, 91, 86, 80, 77, 78, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 92, 95, 94, 123, 122, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 93, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 5, 4, 3, 2, 1, 30, 63, 31, 33, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.042494 Loss T 0.025943 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0664, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.3579, Accuracy: 54393/69960 F1 (77.7487%)


Val set: Average loss: 1.6690, Accuracy: 270/360 F1 (75.0000%)

best acc test 79.715552  acc val 75.000000 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.036149 Loss T 0.020491 Method MME

S painting T real Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.046631 Loss T 0.023068 Method MME

S painting T real Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.022369 Loss T 0.018899 Method MME

S painting T real Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.005934 Loss T 0.018120 Method MME

S painting T real Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.021901 Loss T 0.023012 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0254, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.2370, Accuracy: 56697/69960 F1 (81.0420%)


Val set: Average loss: 1.5197, Accuracy: 276/360 F1 (76.6667%)

best acc test 79.715552  acc val 76.666667 acc labeled target 99.294533
saving model...
S painting T real Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.096441 Loss T 0.036987 Method MME

S painting T real Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.014951 Loss T 0.010110 Method MME

S painting T real Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.041471 Loss T 0.013940 Method MME

S painting T real Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.015774 Loss T 0.020230 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.7777778 0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [79, 80, 1, 113, 84, 71, 23, 81, 82, 83, 0, 87, 88, 89, 90, 91, 85, 86, 78, 77, 76, 75, 74, 73, 72, 70, 69, 68, 67, 66, 92, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 94, 64, 62, 124, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 30, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 63, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 47, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.018849 Loss T 0.018507 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0505, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.3789, Accuracy: 54343/69960 F1 (77.6772%)


Val set: Average loss: 1.6859, Accuracy: 262/360 F1 (72.7778%)

best acc test 79.715552  acc val 72.777778 acc labeled target 98.765432
saving model...
S painting T real Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.009131 Loss T 0.018835 Method MME

S painting T real Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.060508 Loss T 0.019006 Method MME

S painting T real Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.003525 Loss T 0.019506 Method MME

S painting T real Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.132431 Loss T 0.025213 Method MME

S painting T real Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.033342 Loss T 0.017653 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0199, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 1.2386, Accuracy: 56745/69960 F1 (81.1106%)


Val set: Average loss: 1.4584, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.715552  acc val 75.833333 acc labeled target 99.647266
saving model...
S painting T real Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.040390 Loss T 0.022040 Method MME

S painting T real Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.036008 Loss T 0.013909 Method MME

S painting T real Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.016206 Loss T 0.024563 Method MME

S painting T real Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.189154 Loss T 0.017998 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [42, 51, 12, 108, 0, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 78, 91, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 92, 94, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 109, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.049452 Loss T 0.026567 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0536, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.3511, Accuracy: 54399/69960 F1 (77.7573%)


Val set: Average loss: 1.6743, Accuracy: 266/360 F1 (73.8889%)

best acc test 79.715552  acc val 73.888889 acc labeled target 98.941799
saving model...
S painting T real Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.099870 Loss T 0.032414 Method MME

S painting T real Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.071340 Loss T 0.013903 Method MME

S painting T real Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.003749 Loss T 0.014895 Method MME

S painting T real Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.098699 Loss T 0.017630 Method MME

S painting T real Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.013870 Loss T 0.020703 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0176, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 1.2370, Accuracy: 56884/69960 F1 (81.3093%)


Val set: Average loss: 1.6448, Accuracy: 269/360 F1 (74.7222%)

best acc test 79.715552  acc val 74.722222 acc labeled target 99.559083
saving model...
S painting T real Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.017812 Loss T 0.010781 Method MME

S painting T real Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.025961 Loss T 0.013134 Method MME

S painting T real Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.026176 Loss T 0.031000 Method MME

S painting T real Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.189293 Loss T 0.010461 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [16, 13, 114, 23, 54, 87, 86, 85, 81, 89, 90, 84, 83, 91, 82, 88, 80, 0, 92, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 93, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 66, 94, 65, 62, 63, 30, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 64, 32, 34, 124, 61, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.077479 Loss T 0.022682 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0325, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 1.3302, Accuracy: 54676/69960 F1 (78.1532%)


Val set: Average loss: 1.6460, Accuracy: 268/360 F1 (74.4444%)

