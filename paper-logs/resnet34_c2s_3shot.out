Dataset multi Source clipart Target sketch Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  18703
Unlabelled Target Dataset Size:  23826
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  23826 Source:  18703
Unlabeled Target Data Batches: 496
S clipart T sketch Train Ep: 0 lr0.01 	 Loss Classification: 4.864226 Loss T 0.468158 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9570, Accuracy: 9/1134 F1 (0.7937%)


Test set: Average loss: 4.9859, Accuracy: 270/23808 F1 (1.1341%)


Val set: Average loss: 4.9790, Accuracy: 3/360 F1 (0.8333%)

best acc test 1.134073  acc val 0.833333 acc labeled target 0.793651
saving model...
S clipart T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.331077 Loss T 0.314463 Method MME

S clipart T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.880017 Loss T 0.253450 Method MME

S clipart T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.401780 Loss T 0.212456 Method MME

S clipart T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 0.995963 Loss T 0.186642 Method MME

S clipart T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.690515 Loss T 0.185167 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4729, Accuracy: 512/1134 F1 (45.1499%)


Test set: Average loss: 2.4050, Accuracy: 11365/23808 F1 (47.7361%)


Val set: Average loss: 2.3516, Accuracy: 168/360 F1 (46.6667%)

best acc test 47.736055  acc val 46.666667 acc labeled target 45.149912
saving model...
S clipart T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.765242 Loss T 0.147401 Method MME

S clipart T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.078225 Loss T 0.157348 Method MME

S clipart T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.045228 Loss T 0.144824 Method MME

S clipart T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.781802 Loss T 0.138963 Method MME

S clipart T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.720218 Loss T 0.132321 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3427, Accuracy: 574/1134 F1 (50.6173%)


Test set: Average loss: 2.3608, Accuracy: 12354/23808 F1 (51.8901%)


Val set: Average loss: 2.2132, Accuracy: 188/360 F1 (52.2222%)

best acc test 51.890121  acc val 52.222222 acc labeled target 50.617284
saving model...
S clipart T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.474477 Loss T 0.128611 Method MME

S clipart T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.257568 Loss T 0.139529 Method MME

S clipart T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.646841 Loss T 0.127283 Method MME

S clipart T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 1.064172 Loss T 0.108475 Method MME

S clipart T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.400784 Loss T 0.116495 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3095, Accuracy: 576/1134 F1 (50.7937%)


Test set: Average loss: 2.1757, Accuracy: 13191/23808 F1 (55.4057%)


Val set: Average loss: 2.2428, Accuracy: 189/360 F1 (52.5000%)

best acc test 55.405746  acc val 52.500000 acc labeled target 50.793651
saving model...
S clipart T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.353199 Loss T 0.113392 Method MME

S clipart T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.447532 Loss T 0.120074 Method MME

S clipart T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.576391 Loss T 0.114635 Method MME

S clipart T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.668856 Loss T 0.095049 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.22222222 0.6666667  0.         0.
 0.         1.         1.         0.33333334 0.44444445 0.8888889
 0.         0.         0.33333334 0.8888889  1.         0.8888889
 0.33333334 0.22222222 0.8888889  0.8888889  0.6666667  0.6666667
 0.5555556  0.33333334 0.         0.11111111 0.         0.22222222
 0.5555556  0.         0.         0.33333334 0.8888889  0.
 0.5555556  0.         0.7777778  0.5555556  0.8888889  0.22222222
 0.44444445 0.6666667  0.44444445 0.5555556  1.         0.22222222
 0.44444445 1.         0.33333334 0.33333334 0.8888889  0.5555556
 0.33333334 0.5555556  0.6666667  0.6666667  1.         0.7777778
 0.7777778  0.33333334 1.         0.33333334 0.7777778  0.6666667
 0.11111111 0.33333334 0.         0.22222222 0.         0.33333334
 0.7777778  0.6666667  0.33333334 0.         0.33333334 0.11111111
 1.         0.11111111 0.         0.8888889  0.         0.
 0.22222222 0.         1.         0.6666667  0.         0.
 0.11111111 0.8888889  0.8888889  0.6666667  0.6666667  0.5555556
 0.5555556  1.         0.6666667  0.         0.8888889  0.6666667
 0.6666667  0.8888889  0.8888889  0.22222222 0.44444445 0.8888889
 0.7777778  0.6666667  0.5555556  0.44444445 1.         1.
 0.44444445 1.         0.44444445 0.6666667  0.22222222 0.44444445
 0.44444445 0.6666667  0.7777778  0.5555556  0.44444445 1.        ]
Top k classes which perform poorly are:  [85, 26, 68, 31, 70, 32, 35, 99, 37, 80, 82, 13, 28, 83, 6, 5, 4, 75, 89, 88, 12, 27, 79, 90, 66, 77, 41, 47, 118, 29, 105, 69, 2, 84, 19, 51, 63, 9, 54, 61, 25, 14, 18, 71, 67, 33, 76, 74, 50, 111, 124, 44, 106, 119, 42, 10, 120, 114, 48, 116, 39, 55, 123, 110, 96, 30, 95, 24, 45, 53, 36, 94, 87, 93, 98, 101, 102, 109, 0, 56, 23, 3, 65, 121, 22, 117, 57, 73, 43, 122, 108, 38, 72, 64, 60, 59, 40, 81, 107, 11, 104, 103, 15, 17, 100, 20, 21, 52, 34, 91, 92, 115, 113, 62, 97, 86, 78, 58, 49, 46, 16, 8, 7, 1, 112, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.4004, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839,
        1.3583, 1.3206, 1.2056, 1.5000, 1.5000, 1.3583, 1.2056, 1.1839, 1.2056,
        1.3583, 1.4004, 1.2056, 1.2056, 1.2567, 1.2567, 1.2869, 1.3583, 1.5000,
        1.4474, 1.5000, 1.4004, 1.2869, 1.5000, 1.5000, 1.3583, 1.2056, 1.5000,
        1.2869, 1.5000, 1.2297, 1.2869, 1.2056, 1.4004, 1.3206, 1.2567, 1.3206,
        1.2869, 1.1839, 1.4004, 1.3206, 1.1839, 1.3583, 1.3583, 1.2056, 1.2869,
        1.3583, 1.2869, 1.2567, 1.2567, 1.1839, 1.2297, 1.2297, 1.3583, 1.1839,
        1.3583, 1.2297, 1.2567, 1.4474, 1.3583, 1.5000, 1.4004, 1.5000, 1.3583,
        1.2297, 1.2567, 1.3583, 1.5000, 1.3583, 1.4474, 1.1839, 1.4474, 1.5000,
        1.2056, 1.5000, 1.5000, 1.4004, 1.5000, 1.1839, 1.2567, 1.5000, 1.5000,
        1.4474, 1.2056, 1.2056, 1.2567, 1.2567, 1.2869, 1.2869, 1.1839, 1.2567,
        1.5000, 1.2056, 1.2567, 1.2567, 1.2056, 1.2056, 1.4004, 1.3206, 1.2056,
        1.2297, 1.2567, 1.2869, 1.3206, 1.1839, 1.1839, 1.3206, 1.1839, 1.3206,
        1.2567, 1.4004, 1.3206, 1.3206, 1.2567, 1.2297, 1.2869, 1.3206, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.5996, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161,
        0.6417, 0.6794, 0.7944, 0.5000, 0.5000, 0.6417, 0.7944, 0.8161, 0.7944,
        0.6417, 0.5996, 0.7944, 0.7944, 0.7433, 0.7433, 0.7131, 0.6417, 0.5000,
        0.5526, 0.5000, 0.5996, 0.7131, 0.5000, 0.5000, 0.6417, 0.7944, 0.5000,
        0.7131, 0.5000, 0.7703, 0.7131, 0.7944, 0.5996, 0.6794, 0.7433, 0.6794,
        0.7131, 0.8161, 0.5996, 0.6794, 0.8161, 0.6417, 0.6417, 0.7944, 0.7131,
        0.6417, 0.7131, 0.7433, 0.7433, 0.8161, 0.7703, 0.7703, 0.6417, 0.8161,
        0.6417, 0.7703, 0.7433, 0.5526, 0.6417, 0.5000, 0.5996, 0.5000, 0.6417,
        0.7703, 0.7433, 0.6417, 0.5000, 0.6417, 0.5526, 0.8161, 0.5526, 0.5000,
        0.7944, 0.5000, 0.5000, 0.5996, 0.5000, 0.8161, 0.7433, 0.5000, 0.5000,
        0.5526, 0.7944, 0.7944, 0.7433, 0.7433, 0.7131, 0.7131, 0.8161, 0.7433,
        0.5000, 0.7944, 0.7433, 0.7433, 0.7944, 0.7944, 0.5996, 0.6794, 0.7944,
        0.7703, 0.7433, 0.7131, 0.6794, 0.8161, 0.8161, 0.6794, 0.8161, 0.6794,
        0.7433, 0.5996, 0.6794, 0.6794, 0.7433, 0.7703, 0.7131, 0.6794, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.387326 Loss T 0.084854 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5827, Accuracy: 576/1134 F1 (50.7937%)


Test set: Average loss: 2.5186, Accuracy: 12622/23808 F1 (53.0158%)


Val set: Average loss: 2.4685, Accuracy: 189/360 F1 (52.5000%)

best acc test 53.015793  acc val 52.500000 acc labeled target 50.793651
saving model...
S clipart T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.507514 Loss T 0.096811 Method MME

S clipart T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.625576 Loss T 0.107467 Method MME

S clipart T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.706355 Loss T 0.087599 Method MME

S clipart T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.225121 Loss T 0.102697 Method MME

S clipart T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.166682 Loss T 0.087737 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3573, Accuracy: 614/1134 F1 (54.1446%)


Test set: Average loss: 2.3002, Accuracy: 13793/23808 F1 (57.9343%)


Val set: Average loss: 2.2959, Accuracy: 206/360 F1 (57.2222%)

best acc test 57.934308  acc val 57.222222 acc labeled target 54.144621
saving model...
S clipart T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.625326 Loss T 0.094968 Method MME

S clipart T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.250249 Loss T 0.065991 Method MME

S clipart T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.477786 Loss T 0.095365 Method MME

S clipart T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.616861 Loss T 0.085137 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.         0.6666667  0.11111111 0.
 0.22222222 1.         1.         0.22222222 0.5555556  1.
 0.         0.         0.5555556  1.         1.         0.6666667
 0.7777778  0.         0.6666667  1.         0.33333334 1.
 0.33333334 0.         0.         0.11111111 0.         0.5555556
 0.5555556  0.5555556  0.5555556  0.6666667  1.         0.11111111
 0.11111111 0.         0.6666667  0.6666667  0.5555556  0.22222222
 0.44444445 0.7777778  0.5555556  0.6666667  0.8888889  1.
 0.33333334 1.         0.33333334 0.33333334 1.         0.6666667
 0.6666667  0.5555556  0.5555556  0.6666667  1.         1.
 1.         0.33333334 0.6666667  0.11111111 0.7777778  0.7777778
 0.5555556  0.33333334 0.11111111 0.11111111 0.33333334 0.6666667
 0.8888889  0.44444445 0.22222222 0.         0.         0.44444445
 0.6666667  0.22222222 0.         1.         0.         0.11111111
 0.11111111 0.         1.         0.6666667  0.         0.
 0.         0.8888889  0.5555556  1.         0.8888889  0.5555556
 0.5555556  1.         0.6666667  0.33333334 1.         0.6666667
 0.6666667  0.8888889  0.8888889  0.11111111 0.6666667  0.8888889
 0.8888889  0.6666667  0.5555556  0.22222222 1.         0.7777778
 1.         0.8888889  0.5555556  0.6666667  0.         1.
 0.22222222 0.6666667  1.         0.5555556  0.33333334 1.        ]
Top k classes which perform poorly are:  [37, 26, 25, 90, 89, 19, 88, 85, 28, 13, 12, 82, 118, 75, 2, 76, 5, 80, 4, 27, 36, 35, 69, 68, 84, 83, 63, 105, 41, 79, 74, 111, 6, 120, 9, 51, 70, 99, 24, 50, 67, 48, 22, 61, 124, 42, 77, 73, 10, 66, 14, 123, 116, 56, 31, 0, 110, 30, 32, 92, 44, 95, 29, 55, 40, 96, 121, 101, 102, 78, 106, 117, 109, 98, 87, 62, 71, 20, 33, 38, 39, 45, 53, 54, 17, 57, 3, 18, 113, 43, 64, 65, 91, 72, 94, 104, 107, 103, 108, 46, 115, 16, 7, 1, 122, 15, 11, 8, 119, 112, 114, 100, 23, 34, 97, 93, 47, 49, 52, 86, 58, 81, 59, 60, 21, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.5000, 1.2567, 1.4474, 1.5000, 1.4004, 1.1839, 1.1839,
        1.4004, 1.2869, 1.1839, 1.5000, 1.5000, 1.2869, 1.1839, 1.1839, 1.2567,
        1.2297, 1.5000, 1.2567, 1.1839, 1.3583, 1.1839, 1.3583, 1.5000, 1.5000,
        1.4474, 1.5000, 1.2869, 1.2869, 1.2869, 1.2869, 1.2567, 1.1839, 1.4474,
        1.4474, 1.5000, 1.2567, 1.2567, 1.2869, 1.4004, 1.3206, 1.2297, 1.2869,
        1.2567, 1.2056, 1.1839, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.2567,
        1.2567, 1.2869, 1.2869, 1.2567, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.4474, 1.2297, 1.2297, 1.2869, 1.3583, 1.4474, 1.4474, 1.3583, 1.2567,
        1.2056, 1.3206, 1.4004, 1.5000, 1.5000, 1.3206, 1.2567, 1.4004, 1.5000,
        1.1839, 1.5000, 1.4474, 1.4474, 1.5000, 1.1839, 1.2567, 1.5000, 1.5000,
        1.5000, 1.2056, 1.2869, 1.1839, 1.2056, 1.2869, 1.2869, 1.1839, 1.2567,
        1.3583, 1.1839, 1.2567, 1.2567, 1.2056, 1.2056, 1.4474, 1.2567, 1.2056,
        1.2056, 1.2567, 1.2869, 1.4004, 1.1839, 1.2297, 1.1839, 1.2056, 1.2869,
        1.2567, 1.5000, 1.1839, 1.4004, 1.2567, 1.1839, 1.2869, 1.3583, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.5000, 0.7433, 0.5526, 0.5000, 0.5996, 0.8161, 0.8161,
        0.5996, 0.7131, 0.8161, 0.5000, 0.5000, 0.7131, 0.8161, 0.8161, 0.7433,
        0.7703, 0.5000, 0.7433, 0.8161, 0.6417, 0.8161, 0.6417, 0.5000, 0.5000,
        0.5526, 0.5000, 0.7131, 0.7131, 0.7131, 0.7131, 0.7433, 0.8161, 0.5526,
        0.5526, 0.5000, 0.7433, 0.7433, 0.7131, 0.5996, 0.6794, 0.7703, 0.7131,
        0.7433, 0.7944, 0.8161, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.7433,
        0.7433, 0.7131, 0.7131, 0.7433, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.5526, 0.7703, 0.7703, 0.7131, 0.6417, 0.5526, 0.5526, 0.6417, 0.7433,
        0.7944, 0.6794, 0.5996, 0.5000, 0.5000, 0.6794, 0.7433, 0.5996, 0.5000,
        0.8161, 0.5000, 0.5526, 0.5526, 0.5000, 0.8161, 0.7433, 0.5000, 0.5000,
        0.5000, 0.7944, 0.7131, 0.8161, 0.7944, 0.7131, 0.7131, 0.8161, 0.7433,
        0.6417, 0.8161, 0.7433, 0.7433, 0.7944, 0.7944, 0.5526, 0.7433, 0.7944,
        0.7944, 0.7433, 0.7131, 0.5996, 0.8161, 0.7703, 0.8161, 0.7944, 0.7131,
        0.7433, 0.5000, 0.8161, 0.5996, 0.7433, 0.8161, 0.7131, 0.6417, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.788361 Loss T 0.082812 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5612, Accuracy: 578/1134 F1 (50.9700%)


Test set: Average loss: 2.4658, Accuracy: 13185/23808 F1 (55.3805%)


Val set: Average loss: 2.3572, Accuracy: 195/360 F1 (54.1667%)

best acc test 57.934308  acc val 54.166667 acc labeled target 50.970018
saving model...
S clipart T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.969270 Loss T 0.072515 Method MME

S clipart T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.174069 Loss T 0.069143 Method MME

S clipart T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.298082 Loss T 0.093479 Method MME

S clipart T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.840985 Loss T 0.068772 Method MME

S clipart T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.501003 Loss T 0.069900 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4356, Accuracy: 609/1134 F1 (53.7037%)


Test set: Average loss: 2.3319, Accuracy: 13949/23808 F1 (58.5896%)


Val set: Average loss: 2.2241, Accuracy: 210/360 F1 (58.3333%)

best acc test 58.589550  acc val 58.333333 acc labeled target 53.703704
saving model...
S clipart T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.162617 Loss T 0.102078 Method MME

S clipart T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.330467 Loss T 0.092454 Method MME

S clipart T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.222519 Loss T 0.062645 Method MME

S clipart T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.171456 Loss T 0.071350 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.         0.6666667  0.11111111 0.
 0.22222222 1.         1.         0.33333334 0.5555556  1.
 0.7777778  0.         0.44444445 0.6666667  1.         0.6666667
 0.8888889  0.         0.7777778  1.         0.44444445 1.
 0.33333334 0.22222222 0.         0.11111111 0.         0.8888889
 0.33333334 0.33333334 0.22222222 0.33333334 1.         0.
 0.6666667  0.         0.6666667  0.7777778  0.7777778  0.22222222
 0.33333334 0.7777778  0.44444445 0.33333334 1.         0.11111111
 0.33333334 1.         0.33333334 0.33333334 1.         0.5555556
 0.6666667  0.5555556  0.7777778  0.6666667  1.         0.7777778
 0.8888889  0.33333334 0.7777778  0.22222222 0.7777778  0.5555556
 0.44444445 0.33333334 0.         0.         0.44444445 0.44444445
 0.8888889  0.5555556  0.33333334 0.         0.         0.22222222
 0.6666667  0.33333334 0.         1.         0.         0.
 0.         0.         1.         0.6666667  0.         0.33333334
 0.         0.8888889  0.7777778  1.         1.         0.6666667
 0.5555556  1.         0.6666667  0.22222222 1.         0.5555556
 0.6666667  1.         1.         0.22222222 0.5555556  0.44444445
 1.         0.5555556  0.8888889  0.33333334 0.7777778  0.6666667
 0.5555556  0.7777778  0.5555556  0.6666667  0.11111111 1.
 0.6666667  0.6666667  0.8888889  0.7777778  0.33333334 1.        ]
Top k classes which perform poorly are:  [28, 35, 69, 37, 68, 19, 75, 76, 85, 80, 13, 88, 82, 5, 83, 2, 84, 90, 26, 118, 27, 47, 4, 99, 63, 41, 32, 105, 6, 77, 25, 61, 124, 9, 79, 51, 50, 48, 45, 74, 42, 111, 89, 67, 33, 24, 31, 30, 107, 44, 22, 66, 14, 71, 70, 65, 73, 96, 0, 55, 53, 101, 10, 106, 109, 116, 114, 95, 3, 121, 120, 117, 78, 15, 17, 113, 57, 36, 38, 102, 54, 98, 87, 112, 92, 123, 115, 62, 40, 39, 64, 43, 20, 12, 59, 56, 18, 29, 110, 122, 60, 91, 72, 7, 11, 16, 1, 21, 23, 8, 119, 81, 108, 86, 104, 103, 46, 49, 100, 52, 97, 58, 94, 93, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.5000, 1.2567, 1.4474, 1.5000, 1.4004, 1.1839, 1.1839,
        1.3583, 1.2869, 1.1839, 1.2297, 1.5000, 1.3206, 1.2567, 1.1839, 1.2567,
        1.2056, 1.5000, 1.2297, 1.1839, 1.3206, 1.1839, 1.3583, 1.4004, 1.5000,
        1.4474, 1.5000, 1.2056, 1.3583, 1.3583, 1.4004, 1.3583, 1.1839, 1.5000,
        1.2567, 1.5000, 1.2567, 1.2297, 1.2297, 1.4004, 1.3583, 1.2297, 1.3206,
        1.3583, 1.1839, 1.4474, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.2869,
        1.2567, 1.2869, 1.2297, 1.2567, 1.1839, 1.2297, 1.2056, 1.3583, 1.2297,
        1.4004, 1.2297, 1.2869, 1.3206, 1.3583, 1.5000, 1.5000, 1.3206, 1.3206,
        1.2056, 1.2869, 1.3583, 1.5000, 1.5000, 1.4004, 1.2567, 1.3583, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.5000, 1.2056, 1.2297, 1.1839, 1.1839, 1.2567, 1.2869, 1.1839, 1.2567,
        1.4004, 1.1839, 1.2869, 1.2567, 1.1839, 1.1839, 1.4004, 1.2869, 1.3206,
        1.1839, 1.2869, 1.2056, 1.3583, 1.2297, 1.2567, 1.2869, 1.2297, 1.2869,
        1.2567, 1.4474, 1.1839, 1.2567, 1.2567, 1.2056, 1.2297, 1.3583, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.5000, 0.7433, 0.5526, 0.5000, 0.5996, 0.8161, 0.8161,
        0.6417, 0.7131, 0.8161, 0.7703, 0.5000, 0.6794, 0.7433, 0.8161, 0.7433,
        0.7944, 0.5000, 0.7703, 0.8161, 0.6794, 0.8161, 0.6417, 0.5996, 0.5000,
        0.5526, 0.5000, 0.7944, 0.6417, 0.6417, 0.5996, 0.6417, 0.8161, 0.5000,
        0.7433, 0.5000, 0.7433, 0.7703, 0.7703, 0.5996, 0.6417, 0.7703, 0.6794,
        0.6417, 0.8161, 0.5526, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.7131,
        0.7433, 0.7131, 0.7703, 0.7433, 0.8161, 0.7703, 0.7944, 0.6417, 0.7703,
        0.5996, 0.7703, 0.7131, 0.6794, 0.6417, 0.5000, 0.5000, 0.6794, 0.6794,
        0.7944, 0.7131, 0.6417, 0.5000, 0.5000, 0.5996, 0.7433, 0.6417, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.5000, 0.7944, 0.7703, 0.8161, 0.8161, 0.7433, 0.7131, 0.8161, 0.7433,
        0.5996, 0.8161, 0.7131, 0.7433, 0.8161, 0.8161, 0.5996, 0.7131, 0.6794,
        0.8161, 0.7131, 0.7944, 0.6417, 0.7703, 0.7433, 0.7131, 0.7703, 0.7131,
        0.7433, 0.5526, 0.8161, 0.7433, 0.7433, 0.7944, 0.7703, 0.6417, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.079018 Loss T 0.094318 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6288, Accuracy: 591/1134 F1 (52.1164%)


Test set: Average loss: 2.5702, Accuracy: 13442/23808 F1 (56.4600%)


Val set: Average loss: 2.6528, Accuracy: 194/360 F1 (53.8889%)

best acc test 58.589550  acc val 53.888889 acc labeled target 52.116402
saving model...
S clipart T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.375366 Loss T 0.037288 Method MME

S clipart T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.489126 Loss T 0.109897 Method MME

S clipart T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.494683 Loss T 0.080668 Method MME

S clipart T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.213170 Loss T 0.070640 Method MME

S clipart T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.420509 Loss T 0.068358 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4282, Accuracy: 645/1134 F1 (56.8783%)


Test set: Average loss: 2.4173, Accuracy: 14246/23808 F1 (59.8370%)


Val set: Average loss: 2.3410, Accuracy: 211/360 F1 (58.6111%)

best acc test 59.837030  acc val 58.611111 acc labeled target 56.878307
saving model...
S clipart T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.467036 Loss T 0.062330 Method MME

S clipart T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.324205 Loss T 0.052271 Method MME

S clipart T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.198587 Loss T 0.071923 Method MME

S clipart T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.405548 Loss T 0.060887 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 1.         0.         0.6666667  0.         0.
 0.22222222 0.8888889  1.         0.11111111 1.         1.
 0.         0.         0.33333334 1.         1.         0.8888889
 1.         0.         0.8888889  1.         0.44444445 0.8888889
 0.22222222 0.         0.22222222 0.         0.         0.33333334
 0.6666667  0.5555556  0.33333334 0.5555556  1.         0.
 0.6666667  0.         0.         0.7777778  1.         0.22222222
 0.5555556  0.7777778  0.33333334 0.5555556  1.         0.8888889
 0.33333334 1.         0.5555556  0.33333334 1.         0.7777778
 0.7777778  0.8888889  1.         0.6666667  0.8888889  1.
 0.7777778  0.33333334 0.6666667  0.33333334 0.8888889  0.6666667
 0.7777778  0.         0.22222222 0.22222222 0.7777778  0.7777778
 1.         0.22222222 0.33333334 0.         0.         0.7777778
 0.8888889  0.33333334 0.         1.         0.         0.11111111
 0.         0.         0.8888889  0.6666667  0.         0.33333334
 0.44444445 0.8888889  0.8888889  1.         0.7777778  0.5555556
 0.5555556  1.         0.6666667  0.33333334 1.         0.5555556
 0.6666667  0.8888889  1.         0.11111111 0.44444445 0.6666667
 1.         0.5555556  0.6666667  0.6666667  0.8888889  0.6666667
 0.33333334 0.7777778  0.6666667  0.6666667  0.11111111 1.
 0.7777778  0.7777778  1.         0.7777778  0.22222222 1.        ]
Top k classes which perform poorly are:  [67, 88, 85, 38, 37, 35, 84, 28, 27, 25, 82, 19, 76, 75, 80, 13, 12, 5, 2, 4, 118, 83, 105, 9, 73, 69, 24, 6, 124, 41, 26, 68, 51, 48, 29, 99, 14, 63, 114, 89, 79, 61, 74, 32, 44, 0, 90, 106, 22, 42, 109, 45, 101, 33, 96, 50, 95, 31, 98, 107, 87, 110, 111, 113, 116, 117, 102, 62, 65, 3, 30, 57, 36, 60, 123, 121, 120, 115, 66, 39, 94, 43, 53, 70, 77, 54, 71, 78, 7, 64, 103, 55, 20, 92, 91, 58, 112, 47, 86, 17, 23, 10, 52, 11, 1, 119, 122, 59, 8, 15, 104, 108, 18, 21, 100, 72, 34, 97, 56, 93, 40, 81, 46, 49, 16, 125]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.4004, 1.2056, 1.1839,
        1.4474, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.1839, 1.2056,
        1.1839, 1.5000, 1.2056, 1.1839, 1.3206, 1.2056, 1.4004, 1.5000, 1.4004,
        1.5000, 1.5000, 1.3583, 1.2567, 1.2869, 1.3583, 1.2869, 1.1839, 1.5000,
        1.2567, 1.5000, 1.5000, 1.2297, 1.1839, 1.4004, 1.2869, 1.2297, 1.3583,
        1.2869, 1.1839, 1.2056, 1.3583, 1.1839, 1.2869, 1.3583, 1.1839, 1.2297,
        1.2297, 1.2056, 1.1839, 1.2567, 1.2056, 1.1839, 1.2297, 1.3583, 1.2567,
        1.3583, 1.2056, 1.2567, 1.2297, 1.5000, 1.4004, 1.4004, 1.2297, 1.2297,
        1.1839, 1.4004, 1.3583, 1.5000, 1.5000, 1.2297, 1.2056, 1.3583, 1.5000,
        1.1839, 1.5000, 1.4474, 1.5000, 1.5000, 1.2056, 1.2567, 1.5000, 1.3583,
        1.3206, 1.2056, 1.2056, 1.1839, 1.2297, 1.2869, 1.2869, 1.1839, 1.2567,
        1.3583, 1.1839, 1.2869, 1.2567, 1.2056, 1.1839, 1.4474, 1.3206, 1.2567,
        1.1839, 1.2869, 1.2567, 1.2567, 1.2056, 1.2567, 1.3583, 1.2297, 1.2567,
        1.2567, 1.4474, 1.1839, 1.2297, 1.2297, 1.1839, 1.2297, 1.4004, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5996, 0.7944, 0.8161,
        0.5526, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.8161, 0.7944,
        0.8161, 0.5000, 0.7944, 0.8161, 0.6794, 0.7944, 0.5996, 0.5000, 0.5996,
        0.5000, 0.5000, 0.6417, 0.7433, 0.7131, 0.6417, 0.7131, 0.8161, 0.5000,
        0.7433, 0.5000, 0.5000, 0.7703, 0.8161, 0.5996, 0.7131, 0.7703, 0.6417,
        0.7131, 0.8161, 0.7944, 0.6417, 0.8161, 0.7131, 0.6417, 0.8161, 0.7703,
        0.7703, 0.7944, 0.8161, 0.7433, 0.7944, 0.8161, 0.7703, 0.6417, 0.7433,
        0.6417, 0.7944, 0.7433, 0.7703, 0.5000, 0.5996, 0.5996, 0.7703, 0.7703,
        0.8161, 0.5996, 0.6417, 0.5000, 0.5000, 0.7703, 0.7944, 0.6417, 0.5000,
        0.8161, 0.5000, 0.5526, 0.5000, 0.5000, 0.7944, 0.7433, 0.5000, 0.6417,
        0.6794, 0.7944, 0.7944, 0.8161, 0.7703, 0.7131, 0.7131, 0.8161, 0.7433,
        0.6417, 0.8161, 0.7131, 0.7433, 0.7944, 0.8161, 0.5526, 0.6794, 0.7433,
        0.8161, 0.7131, 0.7433, 0.7433, 0.7944, 0.7433, 0.6417, 0.7703, 0.7433,
        0.7433, 0.5526, 0.8161, 0.7703, 0.7703, 0.8161, 0.7703, 0.5996, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.356209 Loss T 0.053653 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7023, Accuracy: 597/1134 F1 (52.6455%)


Test set: Average loss: 2.6240, Accuracy: 13610/23808 F1 (57.1657%)


Val set: Average loss: 2.5671, Accuracy: 194/360 F1 (53.8889%)

best acc test 59.837030  acc val 53.888889 acc labeled target 52.645503
saving model...
S clipart T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.216848 Loss T 0.071649 Method MME

S clipart T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.374751 Loss T 0.076499 Method MME

S clipart T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.356316 Loss T 0.064527 Method MME

S clipart T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.177527 Loss T 0.039669 Method MME

S clipart T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.164233 Loss T 0.045712 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5642, Accuracy: 633/1134 F1 (55.8201%)


Test set: Average loss: 2.5475, Accuracy: 14150/23808 F1 (59.4338%)


Val set: Average loss: 2.5265, Accuracy: 194/360 F1 (53.8889%)

best acc test 59.837030  acc val 53.888889 acc labeled target 55.820106
saving model...
S clipart T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.207945 Loss T 0.063974 Method MME

S clipart T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.304740 Loss T 0.055936 Method MME

S clipart T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.160061 Loss T 0.046475 Method MME

S clipart T sketch Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.107464 Loss T 0.068535 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 1.         0.         0.6666667  0.11111111 0.
 0.5555556  0.7777778  1.         0.         1.         1.
 0.         0.         0.33333334 0.7777778  1.         1.
 1.         0.11111111 0.7777778  0.8888889  0.44444445 1.
 0.44444445 0.22222222 0.11111111 0.         0.         0.5555556
 0.5555556  0.6666667  0.22222222 0.6666667  1.         0.
 0.5555556  0.11111111 0.11111111 1.         0.6666667  0.33333334
 0.33333334 0.5555556  0.7777778  0.5555556  1.         0.44444445
 0.33333334 1.         0.44444445 0.33333334 0.8888889  0.44444445
 0.11111111 0.7777778  0.8888889  0.6666667  0.8888889  1.
 1.         0.22222222 0.8888889  0.44444445 1.         0.7777778
 0.5555556  0.33333334 0.         0.         0.33333334 0.6666667
 0.8888889  0.22222222 0.33333334 0.         0.         1.
 1.         0.33333334 0.         1.         0.         0.11111111
 0.         0.         1.         0.6666667  0.         0.33333334
 0.33333334 1.         0.8888889  1.         0.8888889  0.5555556
 0.33333334 1.         0.6666667  0.22222222 1.         0.6666667
 0.6666667  1.         1.         0.33333334 0.5555556  0.5555556
 1.         0.6666667  0.5555556  0.5555556  0.8888889  0.6666667
 0.44444445 1.         0.6666667  0.6666667  0.22222222 0.5555556
 1.         0.5555556  0.5555556  0.6666667  0.33333334 1.        ]
Top k classes which perform poorly are:  [69, 75, 76, 27, 28, 13, 35, 80, 9, 12, 84, 5, 85, 2, 88, 82, 68, 83, 37, 4, 19, 54, 26, 38, 99, 118, 73, 32, 25, 61, 41, 105, 42, 51, 90, 67, 89, 70, 74, 96, 14, 79, 124, 48, 63, 53, 50, 0, 114, 22, 47, 24, 110, 6, 122, 121, 119, 95, 29, 66, 30, 45, 36, 43, 106, 107, 111, 33, 123, 87, 3, 109, 40, 116, 117, 98, 71, 57, 102, 101, 31, 113, 15, 55, 44, 7, 65, 20, 112, 94, 92, 62, 52, 56, 58, 21, 72, 86, 23, 115, 18, 17, 16, 11, 120, 10, 8, 1, 34, 39, 108, 49, 91, 104, 103, 59, 60, 100, 64, 97, 77, 78, 81, 93, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.1839, 1.5000, 1.2567, 1.4474, 1.5000, 1.2869, 1.2297, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.2297, 1.1839, 1.1839,
        1.1839, 1.4474, 1.2297, 1.2056, 1.3206, 1.1839, 1.3206, 1.4004, 1.4474,
        1.5000, 1.5000, 1.2869, 1.2869, 1.2567, 1.4004, 1.2567, 1.1839, 1.5000,
        1.2869, 1.4474, 1.4474, 1.1839, 1.2567, 1.3583, 1.3583, 1.2869, 1.2297,
        1.2869, 1.1839, 1.3206, 1.3583, 1.1839, 1.3206, 1.3583, 1.2056, 1.3206,
        1.4474, 1.2297, 1.2056, 1.2567, 1.2056, 1.1839, 1.1839, 1.4004, 1.2056,
        1.3206, 1.1839, 1.2297, 1.2869, 1.3583, 1.5000, 1.5000, 1.3583, 1.2567,
        1.2056, 1.4004, 1.3583, 1.5000, 1.5000, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.5000, 1.4474, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.3583, 1.1839, 1.2056, 1.1839, 1.2056, 1.2869, 1.3583, 1.1839, 1.2567,
        1.4004, 1.1839, 1.2567, 1.2567, 1.1839, 1.1839, 1.3583, 1.2869, 1.2869,
        1.1839, 1.2567, 1.2869, 1.2869, 1.2056, 1.2567, 1.3206, 1.1839, 1.2567,
        1.2567, 1.4004, 1.2869, 1.1839, 1.2869, 1.2869, 1.2567, 1.3583, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.8161, 0.5000, 0.7433, 0.5526, 0.5000, 0.7131, 0.7703, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.7703, 0.8161, 0.8161,
        0.8161, 0.5526, 0.7703, 0.7944, 0.6794, 0.8161, 0.6794, 0.5996, 0.5526,
        0.5000, 0.5000, 0.7131, 0.7131, 0.7433, 0.5996, 0.7433, 0.8161, 0.5000,
        0.7131, 0.5526, 0.5526, 0.8161, 0.7433, 0.6417, 0.6417, 0.7131, 0.7703,
        0.7131, 0.8161, 0.6794, 0.6417, 0.8161, 0.6794, 0.6417, 0.7944, 0.6794,
        0.5526, 0.7703, 0.7944, 0.7433, 0.7944, 0.8161, 0.8161, 0.5996, 0.7944,
        0.6794, 0.8161, 0.7703, 0.7131, 0.6417, 0.5000, 0.5000, 0.6417, 0.7433,
        0.7944, 0.5996, 0.6417, 0.5000, 0.5000, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.5000, 0.5526, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.6417, 0.8161, 0.7944, 0.8161, 0.7944, 0.7131, 0.6417, 0.8161, 0.7433,
        0.5996, 0.8161, 0.7433, 0.7433, 0.8161, 0.8161, 0.6417, 0.7131, 0.7131,
        0.8161, 0.7433, 0.7131, 0.7131, 0.7944, 0.7433, 0.6794, 0.8161, 0.7433,
        0.7433, 0.5996, 0.7131, 0.8161, 0.7131, 0.7131, 0.7433, 0.6417, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.243298 Loss T 0.051260 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8662, Accuracy: 595/1134 F1 (52.4691%)


Test set: Average loss: 2.7945, Accuracy: 13489/23808 F1 (56.6574%)


Val set: Average loss: 2.8567, Accuracy: 191/360 F1 (53.0556%)

best acc test 59.837030  acc val 53.055556 acc labeled target 52.469136
saving model...
S clipart T sketch Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.053244 Loss T 0.059904 Method MME

S clipart T sketch Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.295449 Loss T 0.048238 Method MME

S clipart T sketch Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.110192 Loss T 0.043884 Method MME

S clipart T sketch Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.207319 Loss T 0.071371 Method MME

S clipart T sketch Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.363618 Loss T 0.055940 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4859, Accuracy: 651/1134 F1 (57.4074%)


Test set: Average loss: 2.4873, Accuracy: 14403/23808 F1 (60.4965%)


Val set: Average loss: 2.3988, Accuracy: 211/360 F1 (58.6111%)

best acc test 60.496472  acc val 58.611111 acc labeled target 57.407407
saving model...
S clipart T sketch Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.133049 Loss T 0.052460 Method MME

S clipart T sketch Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.170955 Loss T 0.056089 Method MME

S clipart T sketch Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.096781 Loss T 0.046974 Method MME

S clipart T sketch Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.217256 Loss T 0.047357 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         0.         0.6666667  0.22222222 0.
 0.44444445 1.         1.         0.33333334 1.         1.
 0.         0.         0.22222222 1.         1.         0.8888889
 1.         0.         0.8888889  0.7777778  0.44444445 1.
 0.22222222 0.11111111 0.         0.         0.         0.6666667
 0.5555556  0.5555556  0.33333334 0.6666667  1.         0.
 0.6666667  0.11111111 0.33333334 0.8888889  0.44444445 0.5555556
 0.22222222 0.7777778  0.7777778  0.44444445 1.         0.5555556
 0.33333334 1.         0.6666667  0.22222222 1.         0.7777778
 0.6666667  0.7777778  1.         0.6666667  1.         1.
 1.         0.33333334 0.8888889  0.22222222 0.8888889  0.7777778
 0.6666667  0.         0.         0.         0.33333334 0.44444445
 0.8888889  0.22222222 0.33333334 0.         0.         1.
 1.         0.6666667  0.         1.         0.         0.
 0.         0.         1.         0.6666667  0.         0.33333334
 0.33333334 1.         0.6666667  0.6666667  0.8888889  0.44444445
 0.5555556  1.         0.5555556  0.33333334 1.         0.6666667
 0.6666667  1.         1.         0.33333334 0.5555556  0.6666667
 1.         0.6666667  0.5555556  0.44444445 0.6666667  0.7777778
 0.33333334 1.         0.6666667  0.6666667  0.11111111 1.
 0.6666667  0.7777778  1.         0.7777778  0.33333334 1.        ]
Top k classes which perform poorly are:  [88, 80, 75, 76, 84, 13, 12, 26, 19, 27, 69, 68, 67, 5, 83, 82, 2, 35, 28, 85, 25, 37, 118, 51, 24, 14, 73, 4, 42, 63, 74, 70, 105, 61, 38, 124, 48, 99, 32, 90, 114, 89, 9, 71, 6, 111, 95, 45, 40, 22, 47, 98, 106, 30, 31, 96, 41, 110, 101, 79, 92, 102, 87, 93, 66, 112, 33, 117, 120, 29, 36, 50, 54, 116, 57, 109, 107, 3, 53, 55, 113, 43, 121, 65, 123, 21, 44, 17, 94, 64, 39, 72, 20, 62, 103, 119, 115, 104, 122, 108, 0, 97, 1, 7, 8, 10, 11, 15, 16, 18, 23, 34, 100, 46, 52, 56, 58, 59, 60, 77, 78, 81, 86, 91, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.5000, 1.2567, 1.4004, 1.5000, 1.3206, 1.1839, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.5000, 1.4004, 1.1839, 1.1839, 1.2056,
        1.1839, 1.5000, 1.2056, 1.2297, 1.3206, 1.1839, 1.4004, 1.4474, 1.5000,
        1.5000, 1.5000, 1.2567, 1.2869, 1.2869, 1.3583, 1.2567, 1.1839, 1.5000,
        1.2567, 1.4474, 1.3583, 1.2056, 1.3206, 1.2869, 1.4004, 1.2297, 1.2297,
        1.3206, 1.1839, 1.2869, 1.3583, 1.1839, 1.2567, 1.4004, 1.1839, 1.2297,
        1.2567, 1.2297, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.3583, 1.2056,
        1.4004, 1.2056, 1.2297, 1.2567, 1.5000, 1.5000, 1.5000, 1.3583, 1.3206,
        1.2056, 1.4004, 1.3583, 1.5000, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.3583, 1.1839, 1.2567, 1.2567, 1.2056, 1.3206, 1.2869, 1.1839, 1.2869,
        1.3583, 1.1839, 1.2567, 1.2567, 1.1839, 1.1839, 1.3583, 1.2869, 1.2567,
        1.1839, 1.2567, 1.2869, 1.3206, 1.2567, 1.2297, 1.3583, 1.1839, 1.2567,
        1.2567, 1.4474, 1.1839, 1.2567, 1.2297, 1.1839, 1.2297, 1.3583, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.5000, 0.7433, 0.5996, 0.5000, 0.6794, 0.8161, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.5000, 0.5996, 0.8161, 0.8161, 0.7944,
        0.8161, 0.5000, 0.7944, 0.7703, 0.6794, 0.8161, 0.5996, 0.5526, 0.5000,
        0.5000, 0.5000, 0.7433, 0.7131, 0.7131, 0.6417, 0.7433, 0.8161, 0.5000,
        0.7433, 0.5526, 0.6417, 0.7944, 0.6794, 0.7131, 0.5996, 0.7703, 0.7703,
        0.6794, 0.8161, 0.7131, 0.6417, 0.8161, 0.7433, 0.5996, 0.8161, 0.7703,
        0.7433, 0.7703, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.6417, 0.7944,
        0.5996, 0.7944, 0.7703, 0.7433, 0.5000, 0.5000, 0.5000, 0.6417, 0.6794,
        0.7944, 0.5996, 0.6417, 0.5000, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.6417, 0.8161, 0.7433, 0.7433, 0.7944, 0.6794, 0.7131, 0.8161, 0.7131,
        0.6417, 0.8161, 0.7433, 0.7433, 0.8161, 0.8161, 0.6417, 0.7131, 0.7433,
        0.8161, 0.7433, 0.7131, 0.6794, 0.7433, 0.7703, 0.6417, 0.8161, 0.7433,
        0.7433, 0.5526, 0.8161, 0.7433, 0.7703, 0.8161, 0.7703, 0.6417, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.117900 Loss T 0.039615 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8487, Accuracy: 621/1134 F1 (54.7619%)


Test set: Average loss: 2.7437, Accuracy: 13808/23808 F1 (57.9973%)


Val set: Average loss: 2.8340, Accuracy: 186/360 F1 (51.6667%)

best acc test 60.496472  acc val 51.666667 acc labeled target 54.761905
saving model...
S clipart T sketch Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.136945 Loss T 0.059954 Method MME

S clipart T sketch Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.190928 Loss T 0.043241 Method MME

S clipart T sketch Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.215502 Loss T 0.052441 Method MME

S clipart T sketch Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.274547 Loss T 0.065322 Method MME

S clipart T sketch Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.359452 Loss T 0.039781 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7169, Accuracy: 636/1134 F1 (56.0847%)


Test set: Average loss: 2.6648, Accuracy: 14256/23808 F1 (59.8790%)


Val set: Average loss: 2.6818, Accuracy: 200/360 F1 (55.5556%)

best acc test 60.496472  acc val 55.555556 acc labeled target 56.084656
saving model...
S clipart T sketch Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.027613 Loss T 0.056335 Method MME

S clipart T sketch Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.182439 Loss T 0.040759 Method MME

S clipart T sketch Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.050532 Loss T 0.054443 Method MME

S clipart T sketch Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.125909 Loss T 0.054078 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.         0.6666667  0.         0.
 0.33333334 1.         1.         0.         1.         1.
 0.         0.         0.22222222 1.         1.         0.6666667
 0.6666667  0.33333334 1.         0.8888889  0.22222222 1.
 0.33333334 0.         0.         0.11111111 0.         0.33333334
 0.44444445 0.33333334 0.33333334 0.44444445 0.7777778  0.
 0.8888889  0.         0.22222222 0.6666667  0.7777778  0.44444445
 0.22222222 0.6666667  0.8888889  0.44444445 1.         0.6666667
 0.33333334 1.         0.44444445 0.33333334 1.         0.8888889
 1.         0.6666667  0.8888889  0.6666667  1.         1.
 0.8888889  0.33333334 1.         0.33333334 1.         0.8888889
 0.7777778  0.         0.         0.         0.33333334 0.7777778
 0.7777778  0.33333334 0.22222222 0.11111111 0.         0.6666667
 1.         0.5555556  0.         1.         0.         0.
 0.         0.         1.         0.6666667  0.         0.33333334
 0.11111111 0.8888889  0.7777778  1.         1.         0.33333334
 0.5555556  1.         0.5555556  0.33333334 1.         0.6666667
 0.6666667  1.         1.         0.22222222 0.5555556  0.5555556
 0.8888889  0.6666667  0.44444445 0.33333334 0.6666667  0.6666667
 0.6666667  1.         1.         0.7777778  0.         1.
 0.5555556  0.8888889  1.         0.6666667  0.33333334 1.        ]
Top k classes which perform poorly are:  [118, 28, 26, 25, 84, 85, 37, 88, 80, 13, 12, 76, 83, 82, 2, 67, 4, 68, 5, 69, 35, 9, 90, 75, 27, 105, 22, 42, 14, 74, 38, 31, 99, 73, 111, 70, 63, 48, 51, 124, 19, 32, 6, 95, 89, 24, 61, 29, 110, 33, 45, 41, 30, 50, 106, 120, 107, 96, 79, 98, 77, 87, 102, 0, 101, 39, 43, 114, 47, 17, 112, 113, 55, 3, 57, 109, 123, 18, 72, 92, 66, 40, 34, 117, 71, 121, 91, 108, 21, 60, 44, 53, 56, 65, 36, 115, 119, 104, 103, 122, 116, 62, 97, 1, 7, 8, 10, 11, 15, 16, 20, 23, 46, 49, 52, 54, 58, 59, 64, 78, 81, 86, 93, 94, 100, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.3583, 1.1839, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.4004, 1.1839, 1.1839, 1.2567,
        1.2567, 1.3583, 1.1839, 1.2056, 1.4004, 1.1839, 1.3583, 1.5000, 1.5000,
        1.4474, 1.5000, 1.3583, 1.3206, 1.3583, 1.3583, 1.3206, 1.2297, 1.5000,
        1.2056, 1.5000, 1.4004, 1.2567, 1.2297, 1.3206, 1.4004, 1.2567, 1.2056,
        1.3206, 1.1839, 1.2567, 1.3583, 1.1839, 1.3206, 1.3583, 1.1839, 1.2056,
        1.1839, 1.2567, 1.2056, 1.2567, 1.1839, 1.1839, 1.2056, 1.3583, 1.1839,
        1.3583, 1.1839, 1.2056, 1.2297, 1.5000, 1.5000, 1.5000, 1.3583, 1.2297,
        1.2297, 1.3583, 1.4004, 1.4474, 1.5000, 1.2567, 1.1839, 1.2869, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.4474, 1.2056, 1.2297, 1.1839, 1.1839, 1.3583, 1.2869, 1.1839, 1.2869,
        1.3583, 1.1839, 1.2567, 1.2567, 1.1839, 1.1839, 1.4004, 1.2869, 1.2869,
        1.2056, 1.2567, 1.3206, 1.3583, 1.2567, 1.2567, 1.2567, 1.1839, 1.1839,
        1.2297, 1.5000, 1.1839, 1.2869, 1.2056, 1.1839, 1.2567, 1.3583, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.6417, 0.8161, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.5996, 0.8161, 0.8161, 0.7433,
        0.7433, 0.6417, 0.8161, 0.7944, 0.5996, 0.8161, 0.6417, 0.5000, 0.5000,
        0.5526, 0.5000, 0.6417, 0.6794, 0.6417, 0.6417, 0.6794, 0.7703, 0.5000,
        0.7944, 0.5000, 0.5996, 0.7433, 0.7703, 0.6794, 0.5996, 0.7433, 0.7944,
        0.6794, 0.8161, 0.7433, 0.6417, 0.8161, 0.6794, 0.6417, 0.8161, 0.7944,
        0.8161, 0.7433, 0.7944, 0.7433, 0.8161, 0.8161, 0.7944, 0.6417, 0.8161,
        0.6417, 0.8161, 0.7944, 0.7703, 0.5000, 0.5000, 0.5000, 0.6417, 0.7703,
        0.7703, 0.6417, 0.5996, 0.5526, 0.5000, 0.7433, 0.8161, 0.7131, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.5526, 0.7944, 0.7703, 0.8161, 0.8161, 0.6417, 0.7131, 0.8161, 0.7131,
        0.6417, 0.8161, 0.7433, 0.7433, 0.8161, 0.8161, 0.5996, 0.7131, 0.7131,
        0.7944, 0.7433, 0.6794, 0.6417, 0.7433, 0.7433, 0.7433, 0.8161, 0.8161,
        0.7703, 0.5000, 0.8161, 0.7131, 0.7944, 0.8161, 0.7433, 0.6417, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.088692 Loss T 0.051396 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6674, Accuracy: 621/1134 F1 (54.7619%)


Test set: Average loss: 2.6961, Accuracy: 14153/23808 F1 (59.4464%)


Val set: Average loss: 2.5763, Accuracy: 203/360 F1 (56.3889%)

best acc test 60.496472  acc val 56.388889 acc labeled target 54.761905
saving model...
S clipart T sketch Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.340241 Loss T 0.071225 Method MME

S clipart T sketch Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.113918 Loss T 0.063658 Method MME

S clipart T sketch Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.105001 Loss T 0.062623 Method MME

S clipart T sketch Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.470239 Loss T 0.049433 Method MME

S clipart T sketch Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.139696 Loss T 0.048137 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0632, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 2.1001, Accuracy: 15405/23808 F1 (64.7051%)


Val set: Average loss: 1.6843, Accuracy: 233/360 F1 (64.7222%)

best acc test 64.705141  acc val 64.722222 acc labeled target 98.589065
saving model...
S clipart T sketch Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.127432 Loss T 0.061931 Method MME

S clipart T sketch Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.266248 Loss T 0.041267 Method MME

S clipart T sketch Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.052608 Loss T 0.037211 Method MME

S clipart T sketch Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.022201 Loss T 0.033931 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.7777778 1.        1.        1.        0.8888889
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [79, 86, 9, 91, 83, 14, 53, 123, 67, 75, 29, 5, 18, 87, 88, 89, 85, 84, 90, 82, 0, 80, 92, 78, 77, 76, 74, 73, 72, 71, 70, 69, 68, 81, 93, 97, 95, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 96, 109, 66, 62, 64, 31, 30, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 32, 17, 15, 13, 12, 11, 10, 8, 7, 6, 4, 3, 2, 1, 16, 33, 34, 35, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.017668 Loss T 0.039697 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0908, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 2.2725, Accuracy: 15146/23808 F1 (63.6173%)


Val set: Average loss: 1.8315, Accuracy: 231/360 F1 (64.1667%)

best acc test 64.705141  acc val 64.166667 acc labeled target 98.059965
saving model...
S clipart T sketch Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.084134 Loss T 0.051514 Method MME

S clipart T sketch Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.188216 Loss T 0.031190 Method MME

S clipart T sketch Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.201398 Loss T 0.050138 Method MME

S clipart T sketch Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.197288 Loss T 0.063057 Method MME

S clipart T sketch Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.175150 Loss T 0.053588 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0389, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 2.1447, Accuracy: 15696/23808 F1 (65.9274%)


Val set: Average loss: 1.7232, Accuracy: 246/360 F1 (68.3333%)

best acc test 65.927419  acc val 68.333333 acc labeled target 99.118166
saving model...
S clipart T sketch Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.071544 Loss T 0.059825 Method MME

S clipart T sketch Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.050562 Loss T 0.050475 Method MME

S clipart T sketch Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.062564 Loss T 0.048462 Method MME

S clipart T sketch Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.051961 Loss T 0.042382 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [118, 36, 37, 69, 83, 28, 106, 9, 44, 0, 84, 85, 88, 87, 89, 90, 86, 82, 80, 91, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 68, 67, 81, 92, 94, 66, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 93, 65, 62, 63, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 14, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 43, 42, 41, 40, 39, 38, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.248625 Loss T 0.033412 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0964, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 2.3354, Accuracy: 15265/23808 F1 (64.1171%)


Val set: Average loss: 1.9901, Accuracy: 233/360 F1 (64.7222%)

best acc test 65.927419  acc val 64.722222 acc labeled target 97.971781
saving model...
S clipart T sketch Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.044581 Loss T 0.025447 Method MME

S clipart T sketch Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.045955 Loss T 0.042053 Method MME

S clipart T sketch Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.074574 Loss T 0.036008 Method MME

S clipart T sketch Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.157934 Loss T 0.045487 Method MME

S clipart T sketch Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.085941 Loss T 0.036313 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0509, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 2.3293, Accuracy: 15524/23808 F1 (65.2050%)


Val set: Average loss: 1.9470, Accuracy: 232/360 F1 (64.4444%)

best acc test 65.927419  acc val 64.444444 acc labeled target 98.853616
saving model...
S clipart T sketch Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.020732 Loss T 0.037868 Method MME

S clipart T sketch Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.238294 Loss T 0.033131 Method MME

S clipart T sketch Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.127702 Loss T 0.040136 Method MME

S clipart T sketch Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.144821 Loss T 0.036219 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [32, 28, 85, 103, 21, 106, 48, 80, 79, 13, 108, 74, 61, 77, 91, 90, 89, 88, 68, 87, 86, 84, 69, 83, 70, 82, 71, 81, 92, 72, 73, 75, 78, 76, 93, 0, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 94, 111, 109, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 67, 110, 66, 62, 64, 29, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 16, 30, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 31, 33, 34, 63, 124, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.019903 Loss T 0.039875 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0881, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 2.3639, Accuracy: 15497/23808 F1 (65.0916%)


Val set: Average loss: 2.0379, Accuracy: 233/360 F1 (64.7222%)

best acc test 65.927419  acc val 64.722222 acc labeled target 97.971781
saving model...
S clipart T sketch Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.016914 Loss T 0.040459 Method MME

S clipart T sketch Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.137382 Loss T 0.049241 Method MME

S clipart T sketch Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.261330 Loss T 0.033174 Method MME

S clipart T sketch Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.082553 Loss T 0.056684 Method MME

S clipart T sketch Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.188536 Loss T 0.042845 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0303, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 2.2894, Accuracy: 15744/23808 F1 (66.1290%)


Val set: Average loss: 1.9160, Accuracy: 229/360 F1 (63.6111%)

best acc test 65.927419  acc val 63.611111 acc labeled target 99.294533
saving model...
S clipart T sketch Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.241763 Loss T 0.043749 Method MME

S clipart T sketch Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.189646 Loss T 0.045061 Method MME

S clipart T sketch Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.040590 Loss T 0.036803 Method MME

S clipart T sketch Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.174381 Loss T 0.029021 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [35, 14, 26, 5, 101, 37, 89, 109, 90, 88, 91, 81, 87, 86, 85, 84, 83, 82, 0, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 80, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 108, 107, 106, 105, 104, 103, 102, 100, 99, 98, 97, 96, 66, 93, 65, 62, 63, 29, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 30, 16, 13, 12, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 15, 31, 32, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 34, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.027527 Loss T 0.032367 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0717, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 2.3781, Accuracy: 15535/23808 F1 (65.2512%)


Val set: Average loss: 1.9896, Accuracy: 230/360 F1 (63.8889%)

best acc test 65.927419  acc val 63.888889 acc labeled target 98.412698
saving model...
S clipart T sketch Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.136316 Loss T 0.035610 Method MME

S clipart T sketch Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.209558 Loss T 0.032859 Method MME

S clipart T sketch Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.172888 Loss T 0.047463 Method MME

S clipart T sketch Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.108470 Loss T 0.043904 Method MME

S clipart T sketch Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.040898 Loss T 0.033139 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0417, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 2.2836, Accuracy: 15873/23808 F1 (66.6709%)


Val set: Average loss: 1.8544, Accuracy: 240/360 F1 (66.6667%)

best acc test 65.927419  acc val 66.666667 acc labeled target 99.206349
saving model...
S clipart T sketch Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.059670 Loss T 0.047530 Method MME

S clipart T sketch Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.103356 Loss T 0.037647 Method MME

S clipart T sketch Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.234385 Loss T 0.037049 Method MME

S clipart T sketch Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.157722 Loss T 0.032223 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [25, 93, 111, 75, 73, 106, 105, 68, 118, 86, 85, 87, 84, 88, 89, 83, 82, 90, 81, 0, 78, 79, 77, 76, 74, 72, 71, 70, 69, 67, 66, 65, 80, 91, 94, 64, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 110, 109, 108, 107, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 92, 63, 62, 61, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.033189 Loss T 0.034018 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0642, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 2.3318, Accuracy: 15811/23808 F1 (66.4105%)


Val set: Average loss: 1.9947, Accuracy: 238/360 F1 (66.1111%)

best acc test 65.927419  acc val 66.111111 acc labeled target 98.677249
saving model...
S clipart T sketch Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.009473 Loss T 0.026960 Method MME

S clipart T sketch Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.310317 Loss T 0.031088 Method MME

S clipart T sketch Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.013399 Loss T 0.035448 Method MME

S clipart T sketch Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.063337 Loss T 0.021883 Method MME

S clipart T sketch Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.056338 Loss T 0.037414 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0353, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 2.3519, Accuracy: 15846/23808 F1 (66.5575%)


Val set: Average loss: 1.9836, Accuracy: 241/360 F1 (66.9444%)

best acc test 65.927419  acc val 66.944444 acc labeled target 99.294533
saving model...
S clipart T sketch Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.247129 Loss T 0.040082 Method MME

S clipart T sketch Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.243536 Loss T 0.030497 Method MME

S clipart T sketch Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.079232 Loss T 0.029109 Method MME

S clipart T sketch Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.017668 Loss T 0.021371 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.7777778 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [70, 123, 35, 4, 120, 37, 75, 83, 84, 85, 86, 0, 88, 82, 89, 90, 87, 81, 78, 79, 91, 77, 76, 74, 73, 72, 71, 69, 68, 67, 66, 80, 92, 94, 65, 122, 121, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 93, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.027555 Loss T 0.030765 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0585, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 2.3761, Accuracy: 15694/23808 F1 (65.9190%)


Val set: Average loss: 2.0091, Accuracy: 237/360 F1 (65.8333%)

best acc test 65.927419  acc val 65.833333 acc labeled target 98.236332
saving model...
S clipart T sketch Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.014825 Loss T 0.028104 Method MME

S clipart T sketch Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.024244 Loss T 0.022539 Method MME

S clipart T sketch Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.006047 Loss T 0.028628 Method MME

S clipart T sketch Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.045399 Loss T 0.049199 Method MME

S clipart T sketch Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.155888 Loss T 0.040824 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0249, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 2.2782, Accuracy: 16030/23808 F1 (67.3303%)


Val set: Average loss: 1.9188, Accuracy: 233/360 F1 (64.7222%)

best acc test 65.927419  acc val 64.722222 acc labeled target 99.470899
saving model...
S clipart T sketch Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.064659 Loss T 0.034173 Method MME

S clipart T sketch Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.028947 Loss T 0.037122 Method MME

S clipart T sketch Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.046120 Loss T 0.029522 Method MME

S clipart T sketch Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.051021 Loss T 0.034261 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [59, 86, 103, 75, 20, 83, 0, 91, 90, 89, 88, 87, 85, 84, 82, 81, 79, 92, 78, 77, 76, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 65, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 61, 60, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.057310 Loss T 0.032263 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0552, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 2.3948, Accuracy: 15789/23808 F1 (66.3180%)


Val set: Average loss: 2.0048, Accuracy: 234/360 F1 (65.0000%)

best acc test 65.927419  acc val 65.000000 acc labeled target 99.118166
saving model...
S clipart T sketch Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.056962 Loss T 0.026384 Method MME

S clipart T sketch Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.116468 Loss T 0.028483 Method MME

S clipart T sketch Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.015143 Loss T 0.026363 Method MME

S clipart T sketch Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.020258 Loss T 0.021771 Method MME

S clipart T sketch Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.120312 Loss T 0.038003 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0206, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 2.4306, Accuracy: 15922/23808 F1 (66.8767%)


Val set: Average loss: 2.0146, Accuracy: 238/360 F1 (66.1111%)

best acc test 65.927419  acc val 66.111111 acc labeled target 99.559083
saving model...
S clipart T sketch Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.223084 Loss T 0.024501 Method MME

S clipart T sketch Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.239500 Loss T 0.027246 Method MME

S clipart T sketch Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.229180 Loss T 0.035754 Method MME

S clipart T sketch Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.019881 Loss T 0.034295 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [35, 3, 38, 25, 84, 0, 91, 90, 89, 88, 87, 86, 85, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 93, 95, 66, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 63, 29, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 37, 36, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.134921 Loss T 0.032620 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0553, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 2.3753, Accuracy: 15856/23808 F1 (66.5995%)


Val set: Average loss: 2.0663, Accuracy: 231/360 F1 (64.1667%)

best acc test 65.927419  acc val 64.166667 acc labeled target 99.118166
saving model...
S clipart T sketch Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.006498 Loss T 0.029213 Method MME

S clipart T sketch Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.031216 Loss T 0.031631 Method MME

S clipart T sketch Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.013737 Loss T 0.041955 Method MME

S clipart T sketch Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.210927 Loss T 0.040889 Method MME

S clipart T sketch Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.047983 Loss T 0.039355 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0161, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 2.3777, Accuracy: 15995/23808 F1 (67.1833%)


Val set: Average loss: 2.0498, Accuracy: 242/360 F1 (67.2222%)

best acc test 65.927419  acc val 67.222222 acc labeled target 99.470899
saving model...
S clipart T sketch Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.038007 Loss T 0.029207 Method MME

S clipart T sketch Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.168735 Loss T 0.017357 Method MME

S clipart T sketch Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.035726 Loss T 0.016554 Method MME

S clipart T sketch Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.083682 Loss T 0.022480 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [26, 83, 28, 5, 12, 118, 84, 85, 86, 87, 0, 82, 89, 90, 91, 92, 88, 81, 79, 93, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 80, 94, 97, 96, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 95, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 66, 109, 65, 62, 63, 31, 30, 29, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 32, 64, 33, 35, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.015105 Loss T 0.047383 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0543, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 2.4497, Accuracy: 15899/23808 F1 (66.7801%)


Val set: Average loss: 1.9604, Accuracy: 236/360 F1 (65.5556%)

best acc test 65.927419  acc val 65.555556 acc labeled target 99.029982
saving model...
S clipart T sketch Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.016288 Loss T 0.024512 Method MME

S clipart T sketch Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.041806 Loss T 0.033928 Method MME

S clipart T sketch Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.026735 Loss T 0.019132 Method MME

S clipart T sketch Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.020969 Loss T 0.026083 Method MME

S clipart T sketch Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.012733 Loss T 0.029438 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0237, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 2.4186, Accuracy: 16129/23808 F1 (67.7461%)


Val set: Average loss: 1.9638, Accuracy: 245/360 F1 (68.0556%)

best acc test 65.927419  acc val 68.055556 acc labeled target 99.647266
saving model...
S clipart T sketch Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.016674 Loss T 0.035958 Method MME

S clipart T sketch Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.007343 Loss T 0.027742 Method MME

S clipart T sketch Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.187721 Loss T 0.041148 Method MME

S clipart T sketch Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.174966 Loss T 0.023279 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [28, 36, 37, 25, 0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 93, 95, 66, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 63, 29, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.080047 Loss T 0.024273 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0567, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 2.4241, Accuracy: 15932/23808 F1 (66.9187%)


Val set: Average loss: 1.9476, Accuracy: 233/360 F1 (64.7222%)

best acc test 65.927419  acc val 64.722222 acc labeled target 98.500882
saving model...
S clipart T sketch Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.121604 Loss T 0.040625 Method MME

S clipart T sketch Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.063142 Loss T 0.036027 Method MME

S clipart T sketch Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.011949 Loss T 0.038103 Method MME

S clipart T sketch Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.071037 Loss T 0.030903 Method MME

S clipart T sketch Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.062397 Loss T 0.033845 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0375, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 2.3960, Accuracy: 16209/23808 F1 (68.0822%)


Val set: Average loss: 2.0311, Accuracy: 242/360 F1 (67.2222%)

best acc test 65.927419  acc val 67.222222 acc labeled target 99.206349
saving model...
S clipart T sketch Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.020428 Loss T 0.025500 Method MME

S clipart T sketch Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.035219 Loss T 0.024659 Method MME

S clipart T sketch Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.104759 Loss T 0.021694 Method MME

S clipart T sketch Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.071134 Loss T 0.028533 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [62, 28, 26, 106, 95, 16, 111, 13, 17, 75, 92, 91, 90, 89, 88, 67, 87, 68, 86, 85, 84, 74, 83, 82, 81, 80, 70, 71, 79, 72, 73, 78, 77, 76, 69, 93, 97, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 66, 94, 65, 0, 63, 31, 30, 29, 27, 25, 24, 23, 22, 21, 20, 19, 18, 32, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 33, 34, 35, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.005441 Loss T 0.025889 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0521, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 2.4129, Accuracy: 16042/23808 F1 (67.3807%)


Val set: Average loss: 1.9481, Accuracy: 244/360 F1 (67.7778%)

best acc test 65.927419  acc val 67.777778 acc labeled target 98.941799
saving model...
S clipart T sketch Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.124824 Loss T 0.027982 Method MME

S clipart T sketch Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.055296 Loss T 0.040639 Method MME

S clipart T sketch Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.024198 Loss T 0.021706 Method MME

S clipart T sketch Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.154555 Loss T 0.033875 Method MME

S clipart T sketch Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.009117 Loss T 0.023234 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0433, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 2.4677, Accuracy: 16157/23808 F1 (67.8637%)


Val set: Average loss: 1.9303, Accuracy: 243/360 F1 (67.5000%)

best acc test 65.927419  acc val 67.500000 acc labeled target 99.118166
saving model...
S clipart T sketch Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.024303 Loss T 0.021639 Method MME

S clipart T sketch Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.018840 Loss T 0.034507 Method MME

S clipart T sketch Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.151827 Loss T 0.023459 Method MME

S clipart T sketch Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.233329 Loss T 0.020730 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [64, 37, 111, 7, 6, 9, 120, 68, 96, 106, 88, 81, 87, 86, 85, 84, 83, 82, 90, 89, 77, 79, 78, 76, 75, 74, 73, 72, 71, 70, 69, 67, 66, 80, 91, 0, 93, 123, 122, 121, 119, 118, 117, 116, 115, 114, 113, 112, 110, 92, 109, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 65, 94, 108, 95, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 30, 17, 15, 14, 13, 12, 11, 10, 8, 5, 4, 3, 2, 1, 16, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 35, 34, 63, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.003919 Loss T 0.024642 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0568, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 2.4881, Accuracy: 16037/23808 F1 (67.3597%)


Val set: Average loss: 2.0914, Accuracy: 231/360 F1 (64.1667%)

