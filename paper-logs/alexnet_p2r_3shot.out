Dataset multi Source painting Target real Labeled num perclass 3 Network alexnet
126 classes in this dataset
Labelled Source Examples:  31502
Unlabelled Target Dataset Size:  69980
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  69980 Source:  31502
Unlabeled Target Data Batches: 1093
S painting T real Train Ep: 0 lr0.01 	 Loss Classification: 4.854565 Loss T 0.481848 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 4.8536, Accuracy: 10/1134 F1 (0.8818%)


Test set: Average loss: 4.8511, Accuracy: 547/69952 F1 (0.7820%)


Val set: Average loss: 4.8531, Accuracy: 2/352 F1 (0.5682%)

best acc test 0.781965  acc val 0.568182 acc labeled target 0.881834
saving model...
S painting T real Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 3.244153 Loss T 0.381040 Method MME

S painting T real Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 2.196549 Loss T 0.309384 Method MME

S painting T real Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 2.682752 Loss T 0.290802 Method MME

S painting T real Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 2.297412 Loss T 0.274455 Method MME

S painting T real Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 2.481914 Loss T 0.242178 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.8052, Accuracy: 400/1134 F1 (35.2734%)


Test set: Average loss: 2.4409, Accuracy: 29354/69952 F1 (41.9631%)


Val set: Average loss: 2.5389, Accuracy: 133/352 F1 (37.7841%)

best acc test 41.963060  acc val 37.784091 acc labeled target 35.273369
saving model...
S painting T real Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.801578 Loss T 0.242585 Method MME

S painting T real Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.807433 Loss T 0.213084 Method MME

S painting T real Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 2.208296 Loss T 0.223394 Method MME

S painting T real Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.202193 Loss T 0.249576 Method MME

S painting T real Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.554158 Loss T 0.215523 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.5889, Accuracy: 412/1134 F1 (36.3316%)


Test set: Average loss: 2.2775, Accuracy: 31663/69952 F1 (45.2639%)


Val set: Average loss: 2.3505, Accuracy: 154/352 F1 (43.7500%)

best acc test 45.263895  acc val 43.750000 acc labeled target 36.331570
saving model...
S painting T real Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.188338 Loss T 0.204756 Method MME

S painting T real Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.287062 Loss T 0.221185 Method MME

S painting T real Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 2.144727 Loss T 0.199275 Method MME

S painting T real Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 1.443213 Loss T 0.224964 Method MME

S painting T real Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.865826 Loss T 0.209374 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.5827, Accuracy: 467/1134 F1 (41.1817%)


Test set: Average loss: 2.2036, Accuracy: 33465/69952 F1 (47.8399%)


Val set: Average loss: 2.2742, Accuracy: 161/352 F1 (45.7386%)

best acc test 47.839947  acc val 45.738636 acc labeled target 41.181658
saving model...
S painting T real Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.560603 Loss T 0.201203 Method MME

S painting T real Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.973404 Loss T 0.192018 Method MME

S painting T real Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.473498 Loss T 0.176832 Method MME

S painting T real Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 1.603366 Loss T 0.195820 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.         0.6666667  0.11111111 0.5555556  0.11111111
 0.33333334 0.11111111 0.33333334 0.6666667  0.8888889  0.6666667
 0.         0.         0.44444445 0.33333334 0.         1.
 0.         0.6666667  0.         0.22222222 0.5555556  0.
 0.         0.33333334 0.6666667  0.6666667  0.44444445 0.11111111
 0.33333334 0.         0.44444445 0.22222222 0.33333334 0.8888889
 0.         0.5555556  0.44444445 0.6666667  0.6666667  0.6666667
 0.22222222 0.22222222 0.7777778  0.33333334 0.33333334 0.6666667
 0.         0.6666667  0.11111111 0.33333334 0.22222222 0.33333334
 0.         0.         0.7777778  0.5555556  0.7777778  0.44444445
 0.8888889  0.         0.7777778  0.         1.         0.33333334
 0.         0.7777778  0.6666667  0.5555556  0.44444445 0.11111111
 0.         0.33333334 0.         0.44444445 0.7777778  0.33333334
 0.         0.5555556  0.         1.         0.33333334 0.
 0.         0.7777778  0.11111111 0.33333334 0.33333334 0.33333334
 0.         0.7777778  0.8888889  0.33333334 0.5555556  1.
 0.         0.7777778  0.33333334 0.6666667  0.22222222 0.22222222
 0.33333334 0.44444445 0.         0.8888889  0.6666667  0.44444445
 0.         0.6666667  0.6666667  0.         0.7777778  0.8888889
 0.22222222 0.8888889  0.6666667  1.         0.         1.
 0.44444445 0.5555556  0.         0.         0.5555556  1.        ]
Top k classes which perform poorly are:  [20, 66, 108, 31, 24, 23, 72, 74, 61, 78, 18, 122, 16, 80, 83, 13, 12, 84, 123, 111, 90, 55, 104, 54, 36, 48, 96, 1, 118, 63, 50, 71, 86, 7, 5, 3, 29, 43, 114, 52, 100, 42, 101, 21, 33, 87, 25, 65, 88, 30, 6, 73, 77, 93, 34, 53, 15, 51, 89, 82, 102, 98, 46, 45, 8, 107, 75, 14, 70, 28, 103, 32, 120, 59, 38, 94, 124, 4, 57, 121, 79, 37, 69, 22, 2, 99, 40, 106, 11, 116, 19, 41, 68, 26, 27, 109, 49, 39, 47, 110, 9, 62, 56, 91, 85, 76, 67, 58, 44, 97, 112, 115, 113, 0, 92, 60, 35, 10, 105, 95, 81, 117, 64, 119, 17, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.5000, 1.2567, 1.4474, 1.2869, 1.4474, 1.3583, 1.4474, 1.3583,
        1.2567, 1.2056, 1.2567, 1.5000, 1.5000, 1.3206, 1.3583, 1.5000, 1.1839,
        1.5000, 1.2567, 1.5000, 1.4004, 1.2869, 1.5000, 1.5000, 1.3583, 1.2567,
        1.2567, 1.3206, 1.4474, 1.3583, 1.5000, 1.3206, 1.4004, 1.3583, 1.2056,
        1.5000, 1.2869, 1.3206, 1.2567, 1.2567, 1.2567, 1.4004, 1.4004, 1.2297,
        1.3583, 1.3583, 1.2567, 1.5000, 1.2567, 1.4474, 1.3583, 1.4004, 1.3583,
        1.5000, 1.5000, 1.2297, 1.2869, 1.2297, 1.3206, 1.2056, 1.5000, 1.2297,
        1.5000, 1.1839, 1.3583, 1.5000, 1.2297, 1.2567, 1.2869, 1.3206, 1.4474,
        1.5000, 1.3583, 1.5000, 1.3206, 1.2297, 1.3583, 1.5000, 1.2869, 1.5000,
        1.1839, 1.3583, 1.5000, 1.5000, 1.2297, 1.4474, 1.3583, 1.3583, 1.3583,
        1.5000, 1.2297, 1.2056, 1.3583, 1.2869, 1.1839, 1.5000, 1.2297, 1.3583,
        1.2567, 1.4004, 1.4004, 1.3583, 1.3206, 1.5000, 1.2056, 1.2567, 1.3206,
        1.5000, 1.2567, 1.2567, 1.5000, 1.2297, 1.2056, 1.4004, 1.2056, 1.2567,
        1.1839, 1.5000, 1.1839, 1.3206, 1.2869, 1.5000, 1.5000, 1.2869, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.5000, 0.7433, 0.5526, 0.7131, 0.5526, 0.6417, 0.5526, 0.6417,
        0.7433, 0.7944, 0.7433, 0.5000, 0.5000, 0.6794, 0.6417, 0.5000, 0.8161,
        0.5000, 0.7433, 0.5000, 0.5996, 0.7131, 0.5000, 0.5000, 0.6417, 0.7433,
        0.7433, 0.6794, 0.5526, 0.6417, 0.5000, 0.6794, 0.5996, 0.6417, 0.7944,
        0.5000, 0.7131, 0.6794, 0.7433, 0.7433, 0.7433, 0.5996, 0.5996, 0.7703,
        0.6417, 0.6417, 0.7433, 0.5000, 0.7433, 0.5526, 0.6417, 0.5996, 0.6417,
        0.5000, 0.5000, 0.7703, 0.7131, 0.7703, 0.6794, 0.7944, 0.5000, 0.7703,
        0.5000, 0.8161, 0.6417, 0.5000, 0.7703, 0.7433, 0.7131, 0.6794, 0.5526,
        0.5000, 0.6417, 0.5000, 0.6794, 0.7703, 0.6417, 0.5000, 0.7131, 0.5000,
        0.8161, 0.6417, 0.5000, 0.5000, 0.7703, 0.5526, 0.6417, 0.6417, 0.6417,
        0.5000, 0.7703, 0.7944, 0.6417, 0.7131, 0.8161, 0.5000, 0.7703, 0.6417,
        0.7433, 0.5996, 0.5996, 0.6417, 0.6794, 0.5000, 0.7944, 0.7433, 0.6794,
        0.5000, 0.7433, 0.7433, 0.5000, 0.7703, 0.7944, 0.5996, 0.7944, 0.7433,
        0.8161, 0.5000, 0.8161, 0.6794, 0.7131, 0.5000, 0.5000, 0.7131, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.071588 Loss T 0.169401 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.5280, Accuracy: 455/1134 F1 (40.1235%)


Test set: Average loss: 2.1511, Accuracy: 34340/69952 F1 (49.0908%)


Val set: Average loss: 2.3201, Accuracy: 153/352 F1 (43.4659%)

best acc test 47.839947  acc val 43.465909 acc labeled target 40.123457
saving model...
S painting T real Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.510593 Loss T 0.170435 Method MME

S painting T real Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 1.457091 Loss T 0.203370 Method MME

S painting T real Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 1.303066 Loss T 0.167216 Method MME

S painting T real Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.444652 Loss T 0.178957 Method MME

S painting T real Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.884927 Loss T 0.176258 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.4388, Accuracy: 494/1134 F1 (43.5626%)


Test set: Average loss: 2.0934, Accuracy: 35982/69952 F1 (51.4381%)


Val set: Average loss: 2.2271, Accuracy: 165/352 F1 (46.8750%)

best acc test 51.438129  acc val 46.875000 acc labeled target 43.562610
saving model...
S painting T real Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 1.436969 Loss T 0.139579 Method MME

S painting T real Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.752901 Loss T 0.180350 Method MME

S painting T real Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 1.020907 Loss T 0.184806 Method MME

S painting T real Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 1.020344 Loss T 0.177714 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  0.         0.6666667  0.22222222 0.44444445 0.33333334
 0.5555556  0.11111111 0.11111111 0.6666667  0.5555556  0.33333334
 0.         0.11111111 0.6666667  0.6666667  0.         1.
 0.         0.5555556  0.33333334 0.         0.33333334 0.22222222
 0.         0.6666667  0.6666667  0.6666667  0.5555556  0.22222222
 0.5555556  0.         0.33333334 0.22222222 0.11111111 0.8888889
 0.         0.6666667  0.7777778  0.44444445 0.6666667  0.7777778
 0.22222222 0.22222222 0.8888889  0.33333334 0.33333334 0.6666667
 0.         0.8888889  0.11111111 0.44444445 0.22222222 0.44444445
 0.         0.11111111 0.7777778  0.6666667  0.7777778  0.7777778
 0.8888889  0.11111111 0.8888889  0.         1.         0.33333334
 0.         1.         0.6666667  0.6666667  0.33333334 0.33333334
 0.         0.33333334 0.22222222 1.         0.6666667  0.33333334
 0.         1.         0.         1.         0.         0.
 0.11111111 0.8888889  0.22222222 0.33333334 0.33333334 0.6666667
 0.         0.6666667  0.6666667  1.         0.6666667  0.5555556
 0.         0.33333334 0.6666667  0.5555556  0.44444445 0.33333334
 0.22222222 0.6666667  0.33333334 0.7777778  0.6666667  0.7777778
 0.33333334 0.44444445 0.5555556  0.11111111 0.44444445 0.44444445
 0.         1.         0.33333334 0.8888889  0.         0.6666667
 0.33333334 0.5555556  0.22222222 0.11111111 0.11111111 1.        ]
Top k classes which perform poorly are:  [36, 24, 96, 90, 31, 83, 82, 21, 48, 80, 114, 78, 63, 118, 66, 54, 18, 72, 16, 1, 12, 124, 61, 7, 50, 8, 123, 84, 34, 55, 111, 13, 29, 23, 33, 122, 74, 86, 102, 52, 42, 43, 3, 88, 5, 77, 108, 65, 97, 116, 73, 70, 20, 104, 45, 101, 11, 32, 120, 71, 87, 46, 22, 39, 112, 109, 100, 4, 53, 113, 51, 99, 95, 110, 30, 6, 10, 19, 28, 121, 68, 94, 26, 25, 15, 14, 9, 103, 106, 2, 98, 27, 92, 91, 76, 119, 69, 47, 57, 40, 37, 89, 0, 56, 38, 58, 59, 105, 107, 41, 117, 62, 85, 60, 49, 44, 35, 81, 79, 115, 75, 67, 64, 17, 93, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.5000, 1.2567, 1.4004, 1.3206, 1.3583, 1.2869, 1.4474, 1.4474,
        1.2567, 1.2869, 1.3583, 1.5000, 1.4474, 1.2567, 1.2567, 1.5000, 1.1839,
        1.5000, 1.2869, 1.3583, 1.5000, 1.3583, 1.4004, 1.5000, 1.2567, 1.2567,
        1.2567, 1.2869, 1.4004, 1.2869, 1.5000, 1.3583, 1.4004, 1.4474, 1.2056,
        1.5000, 1.2567, 1.2297, 1.3206, 1.2567, 1.2297, 1.4004, 1.4004, 1.2056,
        1.3583, 1.3583, 1.2567, 1.5000, 1.2056, 1.4474, 1.3206, 1.4004, 1.3206,
        1.5000, 1.4474, 1.2297, 1.2567, 1.2297, 1.2297, 1.2056, 1.4474, 1.2056,
        1.5000, 1.1839, 1.3583, 1.5000, 1.1839, 1.2567, 1.2567, 1.3583, 1.3583,
        1.5000, 1.3583, 1.4004, 1.1839, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.4474, 1.2056, 1.4004, 1.3583, 1.3583, 1.2567,
        1.5000, 1.2567, 1.2567, 1.1839, 1.2567, 1.2869, 1.5000, 1.3583, 1.2567,
        1.2869, 1.3206, 1.3583, 1.4004, 1.2567, 1.3583, 1.2297, 1.2567, 1.2297,
        1.3583, 1.3206, 1.2869, 1.4474, 1.3206, 1.3206, 1.5000, 1.1839, 1.3583,
        1.2056, 1.5000, 1.2567, 1.3583, 1.2869, 1.4004, 1.4474, 1.4474, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.5000, 0.7433, 0.5996, 0.6794, 0.6417, 0.7131, 0.5526, 0.5526,
        0.7433, 0.7131, 0.6417, 0.5000, 0.5526, 0.7433, 0.7433, 0.5000, 0.8161,
        0.5000, 0.7131, 0.6417, 0.5000, 0.6417, 0.5996, 0.5000, 0.7433, 0.7433,
        0.7433, 0.7131, 0.5996, 0.7131, 0.5000, 0.6417, 0.5996, 0.5526, 0.7944,
        0.5000, 0.7433, 0.7703, 0.6794, 0.7433, 0.7703, 0.5996, 0.5996, 0.7944,
        0.6417, 0.6417, 0.7433, 0.5000, 0.7944, 0.5526, 0.6794, 0.5996, 0.6794,
        0.5000, 0.5526, 0.7703, 0.7433, 0.7703, 0.7703, 0.7944, 0.5526, 0.7944,
        0.5000, 0.8161, 0.6417, 0.5000, 0.8161, 0.7433, 0.7433, 0.6417, 0.6417,
        0.5000, 0.6417, 0.5996, 0.8161, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5526, 0.7944, 0.5996, 0.6417, 0.6417, 0.7433,
        0.5000, 0.7433, 0.7433, 0.8161, 0.7433, 0.7131, 0.5000, 0.6417, 0.7433,
        0.7131, 0.6794, 0.6417, 0.5996, 0.7433, 0.6417, 0.7703, 0.7433, 0.7703,
        0.6417, 0.6794, 0.7131, 0.5526, 0.6794, 0.6794, 0.5000, 0.8161, 0.6417,
        0.7944, 0.5000, 0.7433, 0.6417, 0.7131, 0.5996, 0.5526, 0.5526, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 1.430504 Loss T 0.152088 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.3752, Accuracy: 534/1134 F1 (47.0899%)


Test set: Average loss: 2.0498, Accuracy: 36906/69952 F1 (52.7590%)


Val set: Average loss: 2.1662, Accuracy: 171/352 F1 (48.5795%)

best acc test 52.759035  acc val 48.579545 acc labeled target 47.089947
saving model...
S painting T real Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 1.087990 Loss T 0.160534 Method MME

S painting T real Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 1.587581 Loss T 0.151792 Method MME

S painting T real Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 1.393284 Loss T 0.159171 Method MME

S painting T real Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 1.421400 Loss T 0.139155 Method MME

S painting T real Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 1.001665 Loss T 0.165284 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.3366, Accuracy: 535/1134 F1 (47.1781%)


Test set: Average loss: 2.0205, Accuracy: 37670/69952 F1 (53.8512%)


Val set: Average loss: 2.0629, Accuracy: 188/352 F1 (53.4091%)

best acc test 53.851212  acc val 53.409091 acc labeled target 47.178131
saving model...
S painting T real Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.867865 Loss T 0.138667 Method MME

S painting T real Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 1.414250 Loss T 0.162652 Method MME

S painting T real Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 1.077372 Loss T 0.167241 Method MME

S painting T real Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 1.172612 Loss T 0.136650 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  0.11111111 0.6666667  0.         0.6666667  0.22222222
 0.44444445 0.44444445 0.22222222 0.6666667  0.6666667  0.5555556
 0.         0.11111111 0.5555556  0.44444445 0.         1.
 0.         0.7777778  0.22222222 0.11111111 0.33333334 0.22222222
 0.         0.33333334 0.6666667  0.6666667  0.7777778  0.5555556
 0.33333334 0.         0.5555556  0.22222222 0.33333334 0.6666667
 0.         0.6666667  0.44444445 0.6666667  0.6666667  0.8888889
 0.33333334 0.6666667  0.8888889  0.33333334 0.44444445 0.6666667
 0.         0.7777778  0.33333334 0.44444445 0.22222222 0.6666667
 0.11111111 0.11111111 0.6666667  0.7777778  0.5555556  0.8888889
 0.8888889  0.11111111 0.8888889  0.         0.8888889  0.7777778
 0.         1.         1.         0.7777778  0.7777778  0.6666667
 0.33333334 0.33333334 0.11111111 0.5555556  0.5555556  0.33333334
 0.         0.6666667  0.         1.         0.         0.
 0.11111111 0.8888889  0.22222222 0.33333334 0.22222222 0.33333334
 0.         0.6666667  0.6666667  1.         0.5555556  0.8888889
 0.         0.7777778  0.5555556  0.5555556  0.33333334 0.33333334
 0.33333334 0.6666667  0.33333334 0.7777778  0.6666667  0.6666667
 0.22222222 0.44444445 0.5555556  0.11111111 0.44444445 1.
 0.         0.6666667  0.6666667  1.         0.         0.7777778
 0.6666667  0.7777778  0.11111111 0.22222222 0.8888889  1.        ]
Top k classes which perform poorly are:  [31, 18, 114, 16, 118, 78, 12, 80, 66, 82, 24, 48, 90, 3, 96, 36, 83, 63, 55, 61, 122, 54, 13, 84, 111, 1, 21, 74, 33, 52, 86, 88, 108, 20, 23, 8, 123, 5, 30, 73, 22, 77, 25, 87, 50, 89, 72, 104, 45, 34, 101, 42, 102, 100, 38, 46, 112, 51, 6, 15, 109, 7, 76, 75, 110, 99, 98, 94, 14, 11, 0, 29, 58, 32, 71, 106, 35, 103, 37, 39, 40, 2, 43, 47, 92, 91, 4, 27, 53, 107, 56, 9, 10, 79, 115, 26, 120, 116, 49, 69, 105, 19, 28, 119, 97, 57, 121, 65, 70, 62, 85, 64, 124, 60, 59, 44, 41, 95, 93, 81, 113, 68, 67, 117, 17, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.4474, 1.2567, 1.5000, 1.2567, 1.4004, 1.3206, 1.3206, 1.4004,
        1.2567, 1.2567, 1.2869, 1.5000, 1.4474, 1.2869, 1.3206, 1.5000, 1.1839,
        1.5000, 1.2297, 1.4004, 1.4474, 1.3583, 1.4004, 1.5000, 1.3583, 1.2567,
        1.2567, 1.2297, 1.2869, 1.3583, 1.5000, 1.2869, 1.4004, 1.3583, 1.2567,
        1.5000, 1.2567, 1.3206, 1.2567, 1.2567, 1.2056, 1.3583, 1.2567, 1.2056,
        1.3583, 1.3206, 1.2567, 1.5000, 1.2297, 1.3583, 1.3206, 1.4004, 1.2567,
        1.4474, 1.4474, 1.2567, 1.2297, 1.2869, 1.2056, 1.2056, 1.4474, 1.2056,
        1.5000, 1.2056, 1.2297, 1.5000, 1.1839, 1.1839, 1.2297, 1.2297, 1.2567,
        1.3583, 1.3583, 1.4474, 1.2869, 1.2869, 1.3583, 1.5000, 1.2567, 1.5000,
        1.1839, 1.5000, 1.5000, 1.4474, 1.2056, 1.4004, 1.3583, 1.4004, 1.3583,
        1.5000, 1.2567, 1.2567, 1.1839, 1.2869, 1.2056, 1.5000, 1.2297, 1.2869,
        1.2869, 1.3583, 1.3583, 1.3583, 1.2567, 1.3583, 1.2297, 1.2567, 1.2567,
        1.4004, 1.3206, 1.2869, 1.4474, 1.3206, 1.1839, 1.5000, 1.2567, 1.2567,
        1.1839, 1.5000, 1.2297, 1.2567, 1.2297, 1.4474, 1.4004, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.5526, 0.7433, 0.5000, 0.7433, 0.5996, 0.6794, 0.6794, 0.5996,
        0.7433, 0.7433, 0.7131, 0.5000, 0.5526, 0.7131, 0.6794, 0.5000, 0.8161,
        0.5000, 0.7703, 0.5996, 0.5526, 0.6417, 0.5996, 0.5000, 0.6417, 0.7433,
        0.7433, 0.7703, 0.7131, 0.6417, 0.5000, 0.7131, 0.5996, 0.6417, 0.7433,
        0.5000, 0.7433, 0.6794, 0.7433, 0.7433, 0.7944, 0.6417, 0.7433, 0.7944,
        0.6417, 0.6794, 0.7433, 0.5000, 0.7703, 0.6417, 0.6794, 0.5996, 0.7433,
        0.5526, 0.5526, 0.7433, 0.7703, 0.7131, 0.7944, 0.7944, 0.5526, 0.7944,
        0.5000, 0.7944, 0.7703, 0.5000, 0.8161, 0.8161, 0.7703, 0.7703, 0.7433,
        0.6417, 0.6417, 0.5526, 0.7131, 0.7131, 0.6417, 0.5000, 0.7433, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5526, 0.7944, 0.5996, 0.6417, 0.5996, 0.6417,
        0.5000, 0.7433, 0.7433, 0.8161, 0.7131, 0.7944, 0.5000, 0.7703, 0.7131,
        0.7131, 0.6417, 0.6417, 0.6417, 0.7433, 0.6417, 0.7703, 0.7433, 0.7433,
        0.5996, 0.6794, 0.7131, 0.5526, 0.6794, 0.8161, 0.5000, 0.7433, 0.7433,
        0.8161, 0.5000, 0.7703, 0.7433, 0.7703, 0.5526, 0.5996, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.699899 Loss T 0.138179 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.4813, Accuracy: 511/1134 F1 (45.0617%)


Test set: Average loss: 2.1116, Accuracy: 37012/69952 F1 (52.9106%)


Val set: Average loss: 2.1915, Accuracy: 185/352 F1 (52.5568%)

best acc test 53.851212  acc val 52.556818 acc labeled target 45.061728
saving model...
S painting T real Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 1.085361 Loss T 0.135538 Method MME

S painting T real Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.695015 Loss T 0.113387 Method MME

S painting T real Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.783131 Loss T 0.106101 Method MME

S painting T real Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.809720 Loss T 0.162160 Method MME

S painting T real Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.805220 Loss T 0.126439 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.3730, Accuracy: 545/1134 F1 (48.0600%)


Test set: Average loss: 2.0993, Accuracy: 37904/69952 F1 (54.1857%)


Val set: Average loss: 2.3405, Accuracy: 171/352 F1 (48.5795%)

best acc test 53.851212  acc val 48.579545 acc labeled target 48.059965
saving model...
S painting T real Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 1.007390 Loss T 0.138429 Method MME

S painting T real Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 1.224690 Loss T 0.137535 Method MME

S painting T real Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.574910 Loss T 0.149618 Method MME

S painting T real Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.850305 Loss T 0.130307 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.         0.6666667  0.11111111 0.6666667  0.5555556
 0.44444445 0.22222222 0.11111111 0.7777778  1.         0.44444445
 0.         0.         0.5555556  0.11111111 0.         1.
 0.         0.5555556  0.         0.11111111 0.7777778  0.44444445
 0.         0.44444445 0.6666667  0.6666667  0.7777778  0.6666667
 0.6666667  0.         0.8888889  0.33333334 0.22222222 0.5555556
 0.         0.6666667  0.44444445 0.33333334 0.6666667  0.7777778
 0.5555556  0.44444445 0.8888889  0.44444445 0.5555556  0.6666667
 0.         0.8888889  0.44444445 0.33333334 0.5555556  1.
 0.33333334 0.22222222 0.7777778  1.         0.33333334 0.8888889
 1.         0.22222222 0.7777778  0.         1.         0.6666667
 0.         1.         1.         0.6666667  0.6666667  0.5555556
 0.22222222 0.33333334 0.         1.         0.5555556  0.33333334
 0.         0.7777778  0.         1.         0.         0.
 0.         0.8888889  0.11111111 0.33333334 0.22222222 0.5555556
 0.         0.6666667  0.6666667  0.7777778  0.44444445 0.6666667
 0.         0.44444445 0.5555556  0.5555556  0.44444445 0.33333334
 0.5555556  0.5555556  0.11111111 0.8888889  0.6666667  0.44444445
 0.22222222 0.33333334 0.6666667  0.         0.7777778  0.8888889
 0.         0.8888889  0.6666667  1.         0.         1.
 0.33333334 0.7777778  0.22222222 0.         0.44444445 1.        ]
Top k classes which perform poorly are:  [118, 96, 36, 83, 31, 63, 82, 24, 114, 90, 66, 18, 16, 80, 20, 84, 12, 1, 48, 123, 74, 111, 78, 13, 3, 104, 86, 15, 8, 21, 55, 7, 108, 34, 122, 61, 72, 88, 120, 58, 101, 77, 39, 33, 87, 109, 54, 73, 51, 124, 97, 100, 94, 23, 6, 11, 25, 107, 38, 45, 50, 43, 42, 98, 5, 71, 46, 14, 19, 52, 102, 89, 35, 76, 99, 103, 91, 92, 47, 69, 116, 65, 95, 106, 40, 37, 30, 29, 27, 26, 110, 4, 2, 70, 62, 56, 79, 9, 22, 28, 112, 121, 93, 41, 85, 32, 49, 105, 59, 115, 44, 113, 119, 117, 0, 75, 68, 67, 64, 60, 57, 53, 17, 10, 81, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.5000, 1.2567, 1.4474, 1.2567, 1.2869, 1.3206, 1.4004, 1.4474,
        1.2297, 1.1839, 1.3206, 1.5000, 1.5000, 1.2869, 1.4474, 1.5000, 1.1839,
        1.5000, 1.2869, 1.5000, 1.4474, 1.2297, 1.3206, 1.5000, 1.3206, 1.2567,
        1.2567, 1.2297, 1.2567, 1.2567, 1.5000, 1.2056, 1.3583, 1.4004, 1.2869,
        1.5000, 1.2567, 1.3206, 1.3583, 1.2567, 1.2297, 1.2869, 1.3206, 1.2056,
        1.3206, 1.2869, 1.2567, 1.5000, 1.2056, 1.3206, 1.3583, 1.2869, 1.1839,
        1.3583, 1.4004, 1.2297, 1.1839, 1.3583, 1.2056, 1.1839, 1.4004, 1.2297,
        1.5000, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.2869,
        1.4004, 1.3583, 1.5000, 1.1839, 1.2869, 1.3583, 1.5000, 1.2297, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.2056, 1.4474, 1.3583, 1.4004, 1.2869,
        1.5000, 1.2567, 1.2567, 1.2297, 1.3206, 1.2567, 1.5000, 1.3206, 1.2869,
        1.2869, 1.3206, 1.3583, 1.2869, 1.2869, 1.4474, 1.2056, 1.2567, 1.3206,
        1.4004, 1.3583, 1.2567, 1.5000, 1.2297, 1.2056, 1.5000, 1.2056, 1.2567,
        1.1839, 1.5000, 1.1839, 1.3583, 1.2297, 1.4004, 1.5000, 1.3206, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5000, 0.7433, 0.5526, 0.7433, 0.7131, 0.6794, 0.5996, 0.5526,
        0.7703, 0.8161, 0.6794, 0.5000, 0.5000, 0.7131, 0.5526, 0.5000, 0.8161,
        0.5000, 0.7131, 0.5000, 0.5526, 0.7703, 0.6794, 0.5000, 0.6794, 0.7433,
        0.7433, 0.7703, 0.7433, 0.7433, 0.5000, 0.7944, 0.6417, 0.5996, 0.7131,
        0.5000, 0.7433, 0.6794, 0.6417, 0.7433, 0.7703, 0.7131, 0.6794, 0.7944,
        0.6794, 0.7131, 0.7433, 0.5000, 0.7944, 0.6794, 0.6417, 0.7131, 0.8161,
        0.6417, 0.5996, 0.7703, 0.8161, 0.6417, 0.7944, 0.8161, 0.5996, 0.7703,
        0.5000, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.7131,
        0.5996, 0.6417, 0.5000, 0.8161, 0.7131, 0.6417, 0.5000, 0.7703, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.7944, 0.5526, 0.6417, 0.5996, 0.7131,
        0.5000, 0.7433, 0.7433, 0.7703, 0.6794, 0.7433, 0.5000, 0.6794, 0.7131,
        0.7131, 0.6794, 0.6417, 0.7131, 0.7131, 0.5526, 0.7944, 0.7433, 0.6794,
        0.5996, 0.6417, 0.7433, 0.5000, 0.7703, 0.7944, 0.5000, 0.7944, 0.7433,
        0.8161, 0.5000, 0.8161, 0.6417, 0.7703, 0.5996, 0.5000, 0.6794, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.804907 Loss T 0.137249 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.3669, Accuracy: 546/1134 F1 (48.1481%)


Test set: Average loss: 2.0914, Accuracy: 38295/69952 F1 (54.7447%)


Val set: Average loss: 2.3074, Accuracy: 176/352 F1 (50.0000%)

best acc test 53.851212  acc val 50.000000 acc labeled target 48.148148
saving model...
S painting T real Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.738360 Loss T 0.109016 Method MME

S painting T real Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.618152 Loss T 0.129760 Method MME

S painting T real Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.836045 Loss T 0.120737 Method MME

S painting T real Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 1.273891 Loss T 0.126135 Method MME

S painting T real Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.888725 Loss T 0.154862 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.4587, Accuracy: 537/1134 F1 (47.3545%)


Test set: Average loss: 2.1144, Accuracy: 38548/69952 F1 (55.1064%)


Val set: Average loss: 2.2898, Accuracy: 176/352 F1 (50.0000%)

best acc test 53.851212  acc val 50.000000 acc labeled target 47.354497
saving model...
S painting T real Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.868926 Loss T 0.145494 Method MME

S painting T real Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.943143 Loss T 0.131366 Method MME

S painting T real Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.438506 Loss T 0.122083 Method MME

S painting T real Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.691259 Loss T 0.131711 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  0.22222222 0.5555556  0.         0.6666667  0.22222222
 0.22222222 0.33333334 0.         0.7777778  0.8888889  0.5555556
 0.         0.         0.33333334 0.11111111 0.         0.8888889
 0.         0.7777778  0.         0.         0.6666667  0.22222222
 0.         0.5555556  0.6666667  0.6666667  0.5555556  0.5555556
 0.5555556  0.11111111 1.         0.33333334 0.33333334 0.6666667
 0.         0.6666667  0.33333334 0.8888889  0.6666667  0.7777778
 0.5555556  0.11111111 1.         0.33333334 0.33333334 0.6666667
 0.         0.8888889  0.6666667  0.5555556  0.33333334 0.5555556
 0.11111111 0.         1.         0.8888889  0.33333334 1.
 1.         0.22222222 1.         0.         0.8888889  0.33333334
 0.         0.7777778  0.5555556  0.5555556  1.         0.7777778
 0.22222222 0.33333334 0.         0.44444445 0.6666667  0.33333334
 0.         0.7777778  0.         1.         0.22222222 0.
 0.         1.         0.33333334 0.33333334 0.11111111 0.44444445
 0.         0.6666667  0.6666667  0.7777778  0.5555556  0.6666667
 0.         1.         0.33333334 0.44444445 0.6666667  0.33333334
 0.6666667  0.44444445 0.22222222 1.         0.6666667  0.6666667
 0.44444445 0.6666667  0.6666667  0.11111111 0.7777778  0.6666667
 0.         1.         0.6666667  0.7777778  0.         1.
 0.5555556  0.8888889  0.         0.         0.5555556  1.        ]
Top k classes which perform poorly are:  [84, 74, 123, 114, 36, 24, 118, 21, 20, 83, 18, 16, 122, 63, 12, 90, 78, 66, 48, 80, 8, 96, 13, 3, 55, 54, 88, 43, 31, 111, 15, 72, 104, 1, 82, 5, 6, 61, 23, 38, 33, 58, 65, 34, 52, 86, 98, 7, 45, 14, 77, 87, 101, 73, 46, 108, 89, 75, 103, 99, 69, 68, 42, 29, 120, 2, 94, 53, 51, 30, 124, 28, 25, 11, 116, 110, 109, 91, 106, 102, 100, 95, 92, 107, 0, 113, 76, 4, 22, 26, 27, 35, 50, 37, 40, 47, 79, 9, 19, 41, 112, 93, 67, 71, 117, 39, 49, 57, 64, 17, 10, 121, 115, 119, 62, 97, 85, 81, 70, 60, 59, 56, 44, 32, 105, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.4004, 1.2869, 1.5000, 1.2567, 1.4004, 1.4004, 1.3583, 1.5000,
        1.2297, 1.2056, 1.2869, 1.5000, 1.5000, 1.3583, 1.4474, 1.5000, 1.2056,
        1.5000, 1.2297, 1.5000, 1.5000, 1.2567, 1.4004, 1.5000, 1.2869, 1.2567,
        1.2567, 1.2869, 1.2869, 1.2869, 1.4474, 1.1839, 1.3583, 1.3583, 1.2567,
        1.5000, 1.2567, 1.3583, 1.2056, 1.2567, 1.2297, 1.2869, 1.4474, 1.1839,
        1.3583, 1.3583, 1.2567, 1.5000, 1.2056, 1.2567, 1.2869, 1.3583, 1.2869,
        1.4474, 1.5000, 1.1839, 1.2056, 1.3583, 1.1839, 1.1839, 1.4004, 1.1839,
        1.5000, 1.2056, 1.3583, 1.5000, 1.2297, 1.2869, 1.2869, 1.1839, 1.2297,
        1.4004, 1.3583, 1.5000, 1.3206, 1.2567, 1.3583, 1.5000, 1.2297, 1.5000,
        1.1839, 1.4004, 1.5000, 1.5000, 1.1839, 1.3583, 1.3583, 1.4474, 1.3206,
        1.5000, 1.2567, 1.2567, 1.2297, 1.2869, 1.2567, 1.5000, 1.1839, 1.3583,
        1.3206, 1.2567, 1.3583, 1.2567, 1.3206, 1.4004, 1.1839, 1.2567, 1.2567,
        1.3206, 1.2567, 1.2567, 1.4474, 1.2297, 1.2567, 1.5000, 1.1839, 1.2567,
        1.2297, 1.5000, 1.1839, 1.2869, 1.2056, 1.5000, 1.5000, 1.2869, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.5996, 0.7131, 0.5000, 0.7433, 0.5996, 0.5996, 0.6417, 0.5000,
        0.7703, 0.7944, 0.7131, 0.5000, 0.5000, 0.6417, 0.5526, 0.5000, 0.7944,
        0.5000, 0.7703, 0.5000, 0.5000, 0.7433, 0.5996, 0.5000, 0.7131, 0.7433,
        0.7433, 0.7131, 0.7131, 0.7131, 0.5526, 0.8161, 0.6417, 0.6417, 0.7433,
        0.5000, 0.7433, 0.6417, 0.7944, 0.7433, 0.7703, 0.7131, 0.5526, 0.8161,
        0.6417, 0.6417, 0.7433, 0.5000, 0.7944, 0.7433, 0.7131, 0.6417, 0.7131,
        0.5526, 0.5000, 0.8161, 0.7944, 0.6417, 0.8161, 0.8161, 0.5996, 0.8161,
        0.5000, 0.7944, 0.6417, 0.5000, 0.7703, 0.7131, 0.7131, 0.8161, 0.7703,
        0.5996, 0.6417, 0.5000, 0.6794, 0.7433, 0.6417, 0.5000, 0.7703, 0.5000,
        0.8161, 0.5996, 0.5000, 0.5000, 0.8161, 0.6417, 0.6417, 0.5526, 0.6794,
        0.5000, 0.7433, 0.7433, 0.7703, 0.7131, 0.7433, 0.5000, 0.8161, 0.6417,
        0.6794, 0.7433, 0.6417, 0.7433, 0.6794, 0.5996, 0.8161, 0.7433, 0.7433,
        0.6794, 0.7433, 0.7433, 0.5526, 0.7703, 0.7433, 0.5000, 0.8161, 0.7433,
        0.7703, 0.5000, 0.8161, 0.7131, 0.7944, 0.5000, 0.5000, 0.7131, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.602818 Loss T 0.119803 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.3896, Accuracy: 569/1134 F1 (50.1764%)


Test set: Average loss: 2.1490, Accuracy: 38681/69952 F1 (55.2965%)


Val set: Average loss: 2.2630, Accuracy: 187/352 F1 (53.1250%)

best acc test 53.851212  acc val 53.125000 acc labeled target 50.176367
saving model...
S painting T real Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.700599 Loss T 0.129133 Method MME

S painting T real Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.653962 Loss T 0.110394 Method MME

S painting T real Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.580811 Loss T 0.130745 Method MME

S painting T real Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.528573 Loss T 0.120389 Method MME

S painting T real Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.456459 Loss T 0.127810 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.4637, Accuracy: 562/1134 F1 (49.5591%)


Test set: Average loss: 2.1500, Accuracy: 39048/69952 F1 (55.8211%)


Val set: Average loss: 2.3679, Accuracy: 184/352 F1 (52.2727%)

best acc test 53.851212  acc val 52.272727 acc labeled target 49.559083
saving model...
S painting T real Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.530651 Loss T 0.126438 Method MME

S painting T real Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 1.102235 Loss T 0.095227 Method MME

S painting T real Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.531940 Loss T 0.108202 Method MME

S painting T real Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.682850 Loss T 0.100528 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.         0.6666667  0.33333334 0.5555556  0.6666667
 0.22222222 0.22222222 0.         0.6666667  0.8888889  0.44444445
 0.         0.         0.6666667  0.6666667  0.33333334 1.
 0.22222222 0.33333334 0.         0.         0.33333334 0.11111111
 0.         0.7777778  0.6666667  0.6666667  0.5555556  0.5555556
 0.6666667  0.22222222 0.7777778  0.11111111 0.33333334 0.6666667
 0.         0.6666667  0.5555556  0.7777778  0.6666667  0.6666667
 0.44444445 0.         1.         0.33333334 0.33333334 0.6666667
 0.         0.6666667  0.6666667  0.5555556  0.33333334 0.6666667
 0.         0.         0.6666667  1.         0.33333334 1.
 1.         0.         1.         0.         1.         0.33333334
 0.         1.         0.8888889  0.8888889  0.8888889  0.5555556
 0.         0.33333334 0.11111111 0.8888889  0.6666667  0.33333334
 0.         1.         0.11111111 0.8888889  0.6666667  0.
 0.         0.6666667  0.22222222 0.33333334 0.33333334 0.6666667
 0.         0.6666667  0.5555556  1.         0.44444445 0.7777778
 0.         1.         0.5555556  0.5555556  0.6666667  0.22222222
 0.8888889  0.6666667  0.22222222 1.         0.6666667  0.8888889
 0.11111111 0.6666667  0.6666667  0.         0.5555556  0.7777778
 0.         1.         0.8888889  1.         0.         0.7777778
 0.         0.8888889  0.33333334 0.         0.8888889  1.        ]
Top k classes which perform poorly are:  [111, 20, 120, 24, 66, 55, 118, 48, 63, 96, 36, 83, 61, 84, 90, 114, 123, 21, 8, 1, 54, 72, 12, 43, 13, 78, 74, 23, 108, 33, 80, 31, 7, 6, 86, 104, 101, 18, 88, 87, 46, 52, 45, 58, 65, 34, 22, 19, 16, 77, 3, 73, 122, 42, 11, 94, 71, 112, 51, 4, 28, 29, 98, 99, 92, 38, 91, 85, 82, 100, 103, 106, 109, 89, 110, 76, 56, 37, 27, 30, 35, 15, 40, 41, 26, 49, 50, 47, 14, 9, 5, 2, 53, 119, 113, 39, 95, 32, 25, 10, 107, 102, 70, 121, 124, 81, 68, 116, 69, 75, 115, 117, 0, 62, 97, 93, 79, 67, 64, 60, 59, 57, 44, 17, 105, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.5000, 1.2567, 1.3583, 1.2869, 1.2567, 1.4004, 1.4004, 1.5000,
        1.2567, 1.2056, 1.3206, 1.5000, 1.5000, 1.2567, 1.2567, 1.3583, 1.1839,
        1.4004, 1.3583, 1.5000, 1.5000, 1.3583, 1.4474, 1.5000, 1.2297, 1.2567,
        1.2567, 1.2869, 1.2869, 1.2567, 1.4004, 1.2297, 1.4474, 1.3583, 1.2567,
        1.5000, 1.2567, 1.2869, 1.2297, 1.2567, 1.2567, 1.3206, 1.5000, 1.1839,
        1.3583, 1.3583, 1.2567, 1.5000, 1.2567, 1.2567, 1.2869, 1.3583, 1.2567,
        1.5000, 1.5000, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.3583, 1.5000, 1.1839, 1.2056, 1.2056, 1.2056, 1.2869,
        1.5000, 1.3583, 1.4474, 1.2056, 1.2567, 1.3583, 1.5000, 1.1839, 1.4474,
        1.2056, 1.2567, 1.5000, 1.5000, 1.2567, 1.4004, 1.3583, 1.3583, 1.2567,
        1.5000, 1.2567, 1.2869, 1.1839, 1.3206, 1.2297, 1.5000, 1.1839, 1.2869,
        1.2869, 1.2567, 1.4004, 1.2056, 1.2567, 1.4004, 1.1839, 1.2567, 1.2056,
        1.4474, 1.2567, 1.2567, 1.5000, 1.2869, 1.2297, 1.5000, 1.1839, 1.2056,
        1.1839, 1.5000, 1.2297, 1.5000, 1.2056, 1.3583, 1.5000, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.5000, 0.7433, 0.6417, 0.7131, 0.7433, 0.5996, 0.5996, 0.5000,
        0.7433, 0.7944, 0.6794, 0.5000, 0.5000, 0.7433, 0.7433, 0.6417, 0.8161,
        0.5996, 0.6417, 0.5000, 0.5000, 0.6417, 0.5526, 0.5000, 0.7703, 0.7433,
        0.7433, 0.7131, 0.7131, 0.7433, 0.5996, 0.7703, 0.5526, 0.6417, 0.7433,
        0.5000, 0.7433, 0.7131, 0.7703, 0.7433, 0.7433, 0.6794, 0.5000, 0.8161,
        0.6417, 0.6417, 0.7433, 0.5000, 0.7433, 0.7433, 0.7131, 0.6417, 0.7433,
        0.5000, 0.5000, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.6417, 0.5000, 0.8161, 0.7944, 0.7944, 0.7944, 0.7131,
        0.5000, 0.6417, 0.5526, 0.7944, 0.7433, 0.6417, 0.5000, 0.8161, 0.5526,
        0.7944, 0.7433, 0.5000, 0.5000, 0.7433, 0.5996, 0.6417, 0.6417, 0.7433,
        0.5000, 0.7433, 0.7131, 0.8161, 0.6794, 0.7703, 0.5000, 0.8161, 0.7131,
        0.7131, 0.7433, 0.5996, 0.7944, 0.7433, 0.5996, 0.8161, 0.7433, 0.7944,
        0.5526, 0.7433, 0.7433, 0.5000, 0.7131, 0.7703, 0.5000, 0.8161, 0.7944,
        0.8161, 0.5000, 0.7703, 0.5000, 0.7944, 0.6417, 0.5000, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.352414 Loss T 0.111875 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.4330, Accuracy: 579/1134 F1 (51.0582%)


Test set: Average loss: 2.1621, Accuracy: 39662/69952 F1 (56.6989%)


Val set: Average loss: 2.3827, Accuracy: 190/352 F1 (53.9773%)

best acc test 56.698879  acc val 53.977273 acc labeled target 51.058201
saving model...
S painting T real Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.868676 Loss T 0.124501 Method MME

S painting T real Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.477916 Loss T 0.093824 Method MME

S painting T real Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.501562 Loss T 0.102996 Method MME

S painting T real Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.448301 Loss T 0.117478 Method MME

S painting T real Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.688240 Loss T 0.112381 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.5210, Accuracy: 566/1134 F1 (49.9118%)


Test set: Average loss: 2.1834, Accuracy: 39645/69952 F1 (56.6746%)


Val set: Average loss: 2.3542, Accuracy: 192/352 F1 (54.5455%)

best acc test 56.674577  acc val 54.545455 acc labeled target 49.911817
saving model...
S painting T real Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.669098 Loss T 0.117638 Method MME

S painting T real Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.439935 Loss T 0.100997 Method MME

S painting T real Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.618470 Loss T 0.109758 Method MME

S painting T real Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.475931 Loss T 0.110582 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.         0.6666667  0.44444445 0.6666667  0.44444445
 0.5555556  0.33333334 0.         0.7777778  0.7777778  0.6666667
 0.         0.         0.6666667  0.33333334 0.         0.7777778
 0.         0.7777778  0.         0.         0.33333334 0.11111111
 0.         0.5555556  0.6666667  0.6666667  0.6666667  0.5555556
 0.8888889  0.33333334 1.         0.22222222 0.33333334 0.5555556
 0.         0.6666667  0.44444445 0.8888889  0.6666667  0.6666667
 0.44444445 0.6666667  1.         0.44444445 0.33333334 0.7777778
 0.         0.8888889  0.6666667  0.6666667  0.33333334 0.8888889
 0.33333334 0.11111111 0.6666667  1.         1.         1.
 1.         0.         0.8888889  0.         1.         0.33333334
 0.         1.         0.8888889  0.7777778  0.6666667  0.5555556
 0.         0.33333334 0.         0.7777778  0.6666667  0.33333334
 0.         1.         0.         0.8888889  0.         0.
 0.         0.8888889  0.22222222 0.33333334 0.33333334 0.44444445
 0.         0.5555556  0.6666667  0.8888889  0.5555556  0.6666667
 0.         0.8888889  0.33333334 0.5555556  0.6666667  0.33333334
 0.6666667  0.33333334 0.33333334 1.         0.6666667  0.5555556
 0.33333334 0.5555556  0.7777778  0.         0.5555556  0.7777778
 0.11111111 1.         0.6666667  1.         0.         0.8888889
 0.33333334 0.8888889  0.11111111 0.         0.6666667  1.        ]
Top k classes which perform poorly are:  [36, 24, 82, 123, 21, 20, 83, 18, 80, 16, 48, 118, 13, 96, 61, 78, 8, 63, 111, 84, 66, 72, 74, 1, 12, 90, 122, 55, 23, 114, 33, 86, 52, 54, 120, 108, 65, 77, 46, 101, 73, 88, 15, 87, 7, 104, 22, 98, 31, 103, 34, 5, 89, 45, 38, 42, 3, 109, 99, 6, 71, 94, 107, 25, 91, 29, 35, 112, 95, 92, 76, 100, 106, 51, 102, 40, 11, 14, 26, 27, 28, 37, 70, 41, 43, 4, 2, 50, 56, 116, 124, 9, 113, 19, 17, 110, 69, 10, 47, 75, 121, 119, 0, 62, 93, 30, 85, 81, 68, 39, 49, 53, 97, 32, 44, 117, 58, 115, 59, 60, 64, 67, 79, 105, 57, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.5000, 1.2567, 1.3206, 1.2567, 1.3206, 1.2869, 1.3583, 1.5000,
        1.2297, 1.2297, 1.2567, 1.5000, 1.5000, 1.2567, 1.3583, 1.5000, 1.2297,
        1.5000, 1.2297, 1.5000, 1.5000, 1.3583, 1.4474, 1.5000, 1.2869, 1.2567,
        1.2567, 1.2567, 1.2869, 1.2056, 1.3583, 1.1839, 1.4004, 1.3583, 1.2869,
        1.5000, 1.2567, 1.3206, 1.2056, 1.2567, 1.2567, 1.3206, 1.2567, 1.1839,
        1.3206, 1.3583, 1.2297, 1.5000, 1.2056, 1.2567, 1.2567, 1.3583, 1.2056,
        1.3583, 1.4474, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2056,
        1.5000, 1.1839, 1.3583, 1.5000, 1.1839, 1.2056, 1.2297, 1.2567, 1.2869,
        1.5000, 1.3583, 1.5000, 1.2297, 1.2567, 1.3583, 1.5000, 1.1839, 1.5000,
        1.2056, 1.5000, 1.5000, 1.5000, 1.2056, 1.4004, 1.3583, 1.3583, 1.3206,
        1.5000, 1.2869, 1.2567, 1.2056, 1.2869, 1.2567, 1.5000, 1.2056, 1.3583,
        1.2869, 1.2567, 1.3583, 1.2567, 1.3583, 1.3583, 1.1839, 1.2567, 1.2869,
        1.3583, 1.2869, 1.2297, 1.5000, 1.2869, 1.2297, 1.4474, 1.1839, 1.2567,
        1.1839, 1.5000, 1.2056, 1.3583, 1.2056, 1.4474, 1.5000, 1.2567, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.5000, 0.7433, 0.6794, 0.7433, 0.6794, 0.7131, 0.6417, 0.5000,
        0.7703, 0.7703, 0.7433, 0.5000, 0.5000, 0.7433, 0.6417, 0.5000, 0.7703,
        0.5000, 0.7703, 0.5000, 0.5000, 0.6417, 0.5526, 0.5000, 0.7131, 0.7433,
        0.7433, 0.7433, 0.7131, 0.7944, 0.6417, 0.8161, 0.5996, 0.6417, 0.7131,
        0.5000, 0.7433, 0.6794, 0.7944, 0.7433, 0.7433, 0.6794, 0.7433, 0.8161,
        0.6794, 0.6417, 0.7703, 0.5000, 0.7944, 0.7433, 0.7433, 0.6417, 0.7944,
        0.6417, 0.5526, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7944,
        0.5000, 0.8161, 0.6417, 0.5000, 0.8161, 0.7944, 0.7703, 0.7433, 0.7131,
        0.5000, 0.6417, 0.5000, 0.7703, 0.7433, 0.6417, 0.5000, 0.8161, 0.5000,
        0.7944, 0.5000, 0.5000, 0.5000, 0.7944, 0.5996, 0.6417, 0.6417, 0.6794,
        0.5000, 0.7131, 0.7433, 0.7944, 0.7131, 0.7433, 0.5000, 0.7944, 0.6417,
        0.7131, 0.7433, 0.6417, 0.7433, 0.6417, 0.6417, 0.8161, 0.7433, 0.7131,
        0.6417, 0.7131, 0.7703, 0.5000, 0.7131, 0.7703, 0.5526, 0.8161, 0.7433,
        0.8161, 0.5000, 0.7944, 0.6417, 0.7944, 0.5526, 0.5000, 0.7433, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.652593 Loss T 0.112470 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 2.5188, Accuracy: 568/1134 F1 (50.0882%)


Test set: Average loss: 2.2401, Accuracy: 39497/69952 F1 (56.4630%)


Val set: Average loss: 2.3987, Accuracy: 188/352 F1 (53.4091%)

best acc test 56.674577  acc val 53.409091 acc labeled target 50.088183
saving model...
S painting T real Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.558835 Loss T 0.108713 Method MME

S painting T real Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.426508 Loss T 0.121597 Method MME

S painting T real Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.592064 Loss T 0.113819 Method MME

S painting T real Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.294010 Loss T 0.115368 Method MME

S painting T real Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.588257 Loss T 0.106633 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1049, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.7600, Accuracy: 43430/69952 F1 (62.0854%)


Val set: Average loss: 1.8778, Accuracy: 206/352 F1 (58.5227%)

best acc test 62.085430  acc val 58.522727 acc labeled target 97.089947
saving model...
S painting T real Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.422580 Loss T 0.090925 Method MME

S painting T real Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.458152 Loss T 0.087297 Method MME

S painting T real Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.589558 Loss T 0.082633 Method MME

S painting T real Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.140674 Loss T 0.089273 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        0.7777778 0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        0.8888889 0.8888889 1.        1.        0.8888889 1.
 1.        0.7777778 1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 0.7777778 1.        0.8888889 1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [71, 84, 51, 31, 100, 36, 91, 90, 45, 46, 86, 52, 54, 55, 80, 61, 77, 64, 65, 68, 28, 24, 62, 97, 14, 11, 111, 3, 6, 2, 76, 74, 85, 123, 117, 118, 119, 120, 83, 81, 116, 79, 121, 75, 78, 122, 82, 87, 106, 115, 108, 105, 104, 103, 109, 102, 101, 110, 99, 107, 98, 112, 96, 95, 94, 93, 92, 113, 114, 89, 73, 88, 0, 70, 30, 29, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 10, 9, 8, 7, 5, 4, 1, 32, 72, 33, 35, 69, 67, 66, 63, 124, 60, 59, 58, 57, 56, 53, 50, 49, 48, 47, 44, 43, 42, 41, 40, 39, 38, 37, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.509676 Loss T 0.098447 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0634, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.8423, Accuracy: 43177/69952 F1 (61.7238%)


Val set: Average loss: 2.0707, Accuracy: 207/352 F1 (58.8068%)

best acc test 61.723753  acc val 58.806818 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.610472 Loss T 0.067289 Method MME

S painting T real Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.292298 Loss T 0.077871 Method MME

S painting T real Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.719161 Loss T 0.072821 Method MME

S painting T real Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.495499 Loss T 0.090070 Method MME

S painting T real Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.649469 Loss T 0.099660 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1020, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.9070, Accuracy: 43116/69952 F1 (61.6366%)


Val set: Average loss: 2.1877, Accuracy: 204/352 F1 (57.9545%)

best acc test 61.723753  acc val 57.954545 acc labeled target 97.707231
saving model...
S painting T real Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.663029 Loss T 0.088160 Method MME

S painting T real Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.357104 Loss T 0.080326 Method MME

S painting T real Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.742249 Loss T 0.083175 Method MME

S painting T real Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.339430 Loss T 0.070786 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        0.7777778
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [80, 111, 79, 26, 32, 23, 22, 21, 40, 19, 18, 108, 109, 99, 48, 96, 114, 75, 95, 61, 65, 122, 123, 57, 85, 87, 88, 89, 86, 0, 83, 82, 81, 78, 77, 76, 74, 73, 72, 71, 84, 90, 98, 92, 121, 120, 119, 118, 117, 116, 115, 113, 112, 110, 91, 107, 105, 104, 103, 102, 101, 100, 70, 97, 94, 93, 106, 69, 62, 67, 31, 30, 29, 28, 27, 25, 24, 20, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 33, 68, 34, 36, 66, 64, 63, 124, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 44, 43, 42, 41, 39, 38, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.596657 Loss T 0.087349 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0713, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.8875, Accuracy: 43637/69952 F1 (62.3813%)


Val set: Average loss: 2.0691, Accuracy: 202/352 F1 (57.3864%)

best acc test 61.723753  acc val 57.386364 acc labeled target 97.795414
saving model...
S painting T real Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.359494 Loss T 0.099383 Method MME

S painting T real Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.572492 Loss T 0.089214 Method MME

S painting T real Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.435619 Loss T 0.104448 Method MME

S painting T real Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.440320 Loss T 0.086653 Method MME

S painting T real Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.527916 Loss T 0.064588 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0877, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.9330, Accuracy: 43351/69952 F1 (61.9725%)


Val set: Average loss: 2.1420, Accuracy: 203/352 F1 (57.6705%)

best acc test 61.723753  acc val 57.670455 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.783934 Loss T 0.075818 Method MME

S painting T real Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.858861 Loss T 0.083255 Method MME

S painting T real Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.434611 Loss T 0.085463 Method MME

S painting T real Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.362056 Loss T 0.097623 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 0.7777778 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [58, 0, 23, 100, 31, 68, 90, 88, 87, 42, 83, 80, 78, 52, 57, 71, 106, 107, 96, 67, 6, 120, 10, 85, 84, 118, 82, 81, 79, 119, 77, 75, 74, 121, 122, 73, 72, 123, 70, 69, 76, 86, 109, 116, 110, 105, 104, 111, 103, 102, 101, 112, 99, 108, 98, 113, 114, 95, 94, 93, 92, 91, 115, 89, 97, 117, 62, 65, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 14, 13, 12, 11, 9, 8, 7, 5, 4, 3, 2, 1, 15, 66, 32, 34, 64, 63, 124, 61, 60, 59, 56, 55, 54, 53, 51, 50, 33, 49, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.457498 Loss T 0.075182 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0861, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.9311, Accuracy: 43612/69952 F1 (62.3456%)


Val set: Average loss: 2.0590, Accuracy: 203/352 F1 (57.6705%)

best acc test 61.723753  acc val 57.670455 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.519953 Loss T 0.092878 Method MME

S painting T real Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.236493 Loss T 0.069754 Method MME

S painting T real Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.320651 Loss T 0.082363 Method MME

S painting T real Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.499635 Loss T 0.084310 Method MME

S painting T real Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.270170 Loss T 0.097688 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1044, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 1.9204, Accuracy: 43785/69952 F1 (62.5929%)


Val set: Average loss: 2.1833, Accuracy: 203/352 F1 (57.6705%)

best acc test 61.723753  acc val 57.670455 acc labeled target 97.530864
saving model...
S painting T real Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.602001 Loss T 0.087982 Method MME

S painting T real Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.576701 Loss T 0.074606 Method MME

S painting T real Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.305309 Loss T 0.096349 Method MME

S painting T real Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.302895 Loss T 0.069283 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        0.7777778 1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.6666667 1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [78, 16, 23, 90, 105, 21, 83, 107, 97, 31, 98, 66, 45, 36, 89, 29, 26, 41, 80, 110, 57, 122, 119, 53, 70, 88, 71, 72, 73, 87, 86, 85, 75, 84, 76, 77, 82, 79, 74, 81, 0, 92, 123, 121, 120, 118, 117, 116, 115, 114, 113, 112, 111, 91, 109, 106, 104, 103, 102, 101, 100, 99, 96, 95, 94, 93, 108, 69, 62, 67, 30, 28, 27, 25, 24, 22, 20, 19, 18, 17, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 32, 68, 33, 35, 65, 64, 63, 124, 61, 60, 59, 58, 56, 55, 54, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 40, 39, 38, 37, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.258514 Loss T 0.081317 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0515, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.9564, Accuracy: 43659/69952 F1 (62.4128%)


Val set: Average loss: 2.0490, Accuracy: 203/352 F1 (57.6705%)

best acc test 61.723753  acc val 57.670455 acc labeled target 98.765432
saving model...
S painting T real Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.309387 Loss T 0.068659 Method MME

S painting T real Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.555197 Loss T 0.074171 Method MME

S painting T real Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.446907 Loss T 0.084030 Method MME

S painting T real Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.590718 Loss T 0.073690 Method MME

S painting T real Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.253361 Loss T 0.067070 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0685, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.9408, Accuracy: 43864/69952 F1 (62.7059%)


Val set: Average loss: 2.1406, Accuracy: 205/352 F1 (58.2386%)

best acc test 61.723753  acc val 58.238636 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.646562 Loss T 0.095990 Method MME

S painting T real Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.617331 Loss T 0.091903 Method MME

S painting T real Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.502325 Loss T 0.088115 Method MME

S painting T real Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.293936 Loss T 0.079033 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [42, 92, 51, 15, 76, 13, 58, 10, 31, 89, 63, 67, 65, 123, 1, 32, 23, 83, 90, 88, 87, 86, 85, 84, 0, 81, 80, 91, 78, 77, 75, 74, 73, 72, 71, 70, 82, 79, 97, 94, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 96, 95, 93, 69, 62, 66, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 30, 17, 14, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 16, 33, 34, 35, 64, 124, 61, 60, 59, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.303690 Loss T 0.073455 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0796, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.9502, Accuracy: 43964/69952 F1 (62.8488%)


Val set: Average loss: 2.1259, Accuracy: 210/352 F1 (59.6591%)

best acc test 62.848811  acc val 59.659091 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.259809 Loss T 0.076861 Method MME

S painting T real Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.382126 Loss T 0.081096 Method MME

S painting T real Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.288537 Loss T 0.088128 Method MME

S painting T real Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.431702 Loss T 0.048079 Method MME

S painting T real Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.594579 Loss T 0.069006 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0999, Accuracy: 1102/1134 F1 (97.1781%)


Test set: Average loss: 2.0161, Accuracy: 43957/69952 F1 (62.8388%)


Val set: Average loss: 2.1477, Accuracy: 218/352 F1 (61.9318%)

best acc test 62.838804  acc val 61.931818 acc labeled target 97.178131
saving model...
S painting T real Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.232537 Loss T 0.091795 Method MME

S painting T real Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.370240 Loss T 0.086468 Method MME

S painting T real Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.309293 Loss T 0.066466 Method MME

S painting T real Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.476139 Loss T 0.066257 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.7777778 0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.7777778 0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        0.7777778
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [82, 15, 32, 61, 90, 52, 83, 23, 84, 26, 107, 100, 33, 96, 44, 37, 94, 86, 101, 42, 55, 111, 57, 12, 10, 120, 77, 72, 73, 74, 89, 75, 87, 88, 81, 78, 79, 85, 80, 76, 0, 97, 92, 123, 122, 121, 119, 118, 117, 116, 115, 114, 113, 112, 91, 110, 108, 106, 105, 104, 103, 102, 99, 98, 71, 95, 93, 109, 70, 62, 68, 29, 28, 27, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 13, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 31, 34, 35, 67, 66, 65, 64, 63, 124, 60, 59, 58, 56, 54, 53, 51, 50, 49, 48, 47, 46, 45, 43, 41, 40, 39, 38, 36, 69, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.384909 Loss T 0.076669 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0902, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.9853, Accuracy: 44219/69952 F1 (63.2133%)


Val set: Average loss: 2.2638, Accuracy: 208/352 F1 (59.0909%)

best acc test 62.838804  acc val 59.090909 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.514072 Loss T 0.055439 Method MME

S painting T real Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.224271 Loss T 0.106526 Method MME

S painting T real Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.371502 Loss T 0.066153 Method MME

S painting T real Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.434417 Loss T 0.067539 Method MME

S painting T real Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.427905 Loss T 0.063221 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0825, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.9668, Accuracy: 44455/69952 F1 (63.5507%)


Val set: Average loss: 2.2985, Accuracy: 205/352 F1 (58.2386%)

best acc test 62.838804  acc val 58.238636 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.301090 Loss T 0.052636 Method MME

S painting T real Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.198241 Loss T 0.088129 Method MME

S painting T real Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.368929 Loss T 0.080279 Method MME

S painting T real Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.414694 Loss T 0.097644 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [15, 62, 69, 74, 55, 80, 81, 48, 42, 87, 36, 97, 25, 108, 66, 111, 123, 2, 122, 119, 118, 86, 85, 84, 83, 82, 120, 121, 112, 117, 77, 76, 75, 73, 72, 71, 70, 68, 79, 78, 88, 90, 110, 109, 113, 107, 106, 105, 104, 103, 102, 114, 89, 101, 99, 98, 115, 96, 67, 94, 93, 92, 116, 91, 100, 95, 0, 64, 29, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 30, 16, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 14, 65, 31, 33, 63, 124, 61, 60, 59, 58, 57, 56, 54, 53, 52, 51, 32, 50, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 35, 34, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.295020 Loss T 0.077391 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0850, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.9680, Accuracy: 44381/69952 F1 (63.4449%)


Val set: Average loss: 2.0976, Accuracy: 212/352 F1 (60.2273%)

best acc test 62.838804  acc val 60.227273 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.186198 Loss T 0.085715 Method MME

S painting T real Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.441873 Loss T 0.070724 Method MME

S painting T real Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.208909 Loss T 0.065781 Method MME

S painting T real Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.272897 Loss T 0.077930 Method MME

S painting T real Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.242917 Loss T 0.084901 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0868, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 1.9941, Accuracy: 44495/69952 F1 (63.6079%)


Val set: Average loss: 2.2015, Accuracy: 209/352 F1 (59.3750%)

best acc test 62.838804  acc val 59.375000 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.367207 Loss T 0.066377 Method MME

S painting T real Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.213458 Loss T 0.072377 Method MME

S painting T real Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.344603 Loss T 0.065385 Method MME

S painting T real Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.254406 Loss T 0.074440 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [96, 34, 42, 43, 87, 46, 26, 83, 82, 23, 106, 90, 55, 110, 111, 54, 13, 113, 10, 72, 64, 60, 15, 79, 89, 71, 88, 73, 74, 84, 85, 75, 76, 77, 81, 80, 78, 86, 91, 0, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 112, 109, 92, 108, 105, 104, 103, 102, 101, 100, 99, 98, 97, 70, 95, 94, 107, 69, 62, 67, 29, 28, 27, 25, 24, 22, 21, 20, 19, 18, 17, 30, 16, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 31, 32, 33, 66, 65, 63, 124, 61, 59, 58, 57, 56, 53, 52, 51, 50, 49, 48, 47, 45, 44, 41, 40, 39, 38, 37, 36, 35, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.362378 Loss T 0.053757 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0433, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 2.0000, Accuracy: 44587/69952 F1 (63.7394%)


Val set: Average loss: 2.2104, Accuracy: 212/352 F1 (60.2273%)

best acc test 62.838804  acc val 60.227273 acc labeled target 98.941799
saving model...
S painting T real Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.186921 Loss T 0.056422 Method MME

S painting T real Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.281191 Loss T 0.076700 Method MME

S painting T real Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.318491 Loss T 0.077245 Method MME

S painting T real Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.395129 Loss T 0.062550 Method MME

S painting T real Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.206822 Loss T 0.064908 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0858, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 2.0280, Accuracy: 44375/69952 F1 (63.4364%)


Val set: Average loss: 2.3100, Accuracy: 199/352 F1 (56.5341%)

best acc test 62.838804  acc val 56.534091 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.396759 Loss T 0.072583 Method MME

S painting T real Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.284698 Loss T 0.048673 Method MME

S painting T real Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.337410 Loss T 0.066679 Method MME

S painting T real Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.068180 Loss T 0.069735 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.7777778 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [15, 77, 51, 104, 80, 107, 36, 109, 23, 56, 101, 96, 42, 118, 6, 61, 71, 88, 57, 85, 84, 87, 83, 89, 86, 0, 81, 79, 78, 76, 75, 74, 73, 72, 70, 69, 82, 90, 94, 92, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 108, 106, 105, 103, 102, 100, 99, 98, 97, 95, 68, 93, 91, 67, 62, 65, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 29, 30, 31, 32, 64, 63, 124, 60, 59, 58, 55, 54, 53, 52, 50, 49, 66, 48, 46, 45, 44, 43, 41, 40, 39, 38, 37, 35, 34, 33, 47, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.189915 Loss T 0.083207 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0683, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 2.0158, Accuracy: 44611/69952 F1 (63.7737%)


Val set: Average loss: 2.2217, Accuracy: 210/352 F1 (59.6591%)

best acc test 62.838804  acc val 59.659091 acc labeled target 98.500882
saving model...
S painting T real Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.082096 Loss T 0.072074 Method MME

S painting T real Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.535791 Loss T 0.070816 Method MME

S painting T real Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.252113 Loss T 0.046335 Method MME

S painting T real Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.247768 Loss T 0.069716 Method MME

S painting T real Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.103110 Loss T 0.063492 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0621, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 2.0337, Accuracy: 44796/69952 F1 (64.0382%)


Val set: Average loss: 2.2718, Accuracy: 208/352 F1 (59.0909%)

best acc test 62.838804  acc val 59.090909 acc labeled target 98.412698
saving model...
S painting T real Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.407264 Loss T 0.060517 Method MME

S painting T real Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.323543 Loss T 0.085951 Method MME

S painting T real Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.184266 Loss T 0.060162 Method MME

S painting T real Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.105378 Loss T 0.075626 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [13, 105, 101, 88, 94, 57, 58, 18, 31, 61, 69, 4, 34, 82, 21, 42, 16, 0, 87, 85, 90, 91, 86, 89, 81, 83, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 84, 92, 97, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 104, 103, 102, 100, 99, 98, 96, 93, 68, 62, 66, 30, 29, 28, 27, 26, 25, 24, 23, 22, 20, 19, 17, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 32, 67, 33, 36, 65, 64, 63, 124, 60, 59, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 35, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.298802 Loss T 0.073234 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.1124, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 2.0142, Accuracy: 44796/69952 F1 (64.0382%)


Val set: Average loss: 2.2171, Accuracy: 209/352 F1 (59.3750%)

best acc test 62.838804  acc val 59.375000 acc labeled target 97.266314
saving model...
S painting T real Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.145772 Loss T 0.064230 Method MME

S painting T real Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.316038 Loss T 0.057191 Method MME

S painting T real Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.373743 Loss T 0.069861 Method MME

S painting T real Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.137851 Loss T 0.060330 Method MME

S painting T real Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.208163 Loss T 0.077485 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0493, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 2.0365, Accuracy: 44960/69952 F1 (64.2726%)


Val set: Average loss: 2.2389, Accuracy: 210/352 F1 (59.6591%)

best acc test 62.838804  acc val 59.659091 acc labeled target 98.500882
saving model...
S painting T real Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.430943 Loss T 0.062807 Method MME

S painting T real Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.191419 Loss T 0.082688 Method MME

S painting T real Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.149853 Loss T 0.052789 Method MME

S painting T real Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.296300 Loss T 0.061899 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 96, 98, 86, 84, 43, 82, 46, 80, 18, 50, 15, 92, 54, 75, 118, 60, 77, 89, 88, 68, 87, 69, 70, 85, 83, 76, 72, 81, 73, 74, 90, 78, 71, 79, 0, 93, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 95, 67, 91, 94, 62, 64, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 29, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 65, 30, 32, 63, 124, 61, 59, 58, 57, 56, 55, 53, 52, 51, 49, 31, 48, 45, 44, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 47, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.115202 Loss T 0.060194 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0513, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 2.0596, Accuracy: 44897/69952 F1 (64.1826%)


Val set: Average loss: 2.1941, Accuracy: 216/352 F1 (61.3636%)

best acc test 62.838804  acc val 61.363636 acc labeled target 98.589065
saving model...
S painting T real Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.307356 Loss T 0.066466 Method MME

S painting T real Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.336163 Loss T 0.069455 Method MME

S painting T real Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.185435 Loss T 0.051787 Method MME

S painting T real Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.318202 Loss T 0.050368 Method MME

S painting T real Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.046024 Loss T 0.059647 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0952, Accuracy: 1104/1134 F1 (97.3545%)


Test set: Average loss: 2.0305, Accuracy: 45090/69952 F1 (64.4585%)


Val set: Average loss: 2.2526, Accuracy: 211/352 F1 (59.9432%)

best acc test 62.838804  acc val 59.943182 acc labeled target 97.354497
saving model...
S painting T real Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.232976 Loss T 0.073956 Method MME

S painting T real Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.100844 Loss T 0.065094 Method MME

S painting T real Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.322366 Loss T 0.091871 Method MME

S painting T real Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.142763 Loss T 0.045214 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.7777778
 1.        1.        0.7777778 0.8888889 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [118, 121, 42, 21, 54, 23, 105, 78, 107, 28, 81, 98, 96, 85, 88, 55, 18, 90, 6, 58, 123, 113, 75, 72, 2, 122, 71, 56, 87, 86, 84, 70, 77, 82, 80, 79, 73, 74, 76, 83, 0, 97, 91, 120, 119, 117, 116, 115, 114, 112, 111, 110, 109, 108, 106, 104, 103, 102, 101, 100, 99, 69, 95, 94, 93, 92, 89, 68, 62, 66, 31, 30, 29, 27, 26, 25, 24, 22, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 1, 32, 67, 33, 35, 65, 64, 63, 124, 61, 60, 59, 57, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.2297, 1.2056, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.7703, 0.7944, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.253031 Loss T 0.062931 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0741, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 2.0181, Accuracy: 45155/69952 F1 (64.5514%)


Val set: Average loss: 2.3142, Accuracy: 210/352 F1 (59.6591%)

best acc test 62.838804  acc val 59.659091 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.319806 Loss T 0.052550 Method MME

S painting T real Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.288108 Loss T 0.059032 Method MME

S painting T real Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.216630 Loss T 0.048040 Method MME

S painting T real Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.135633 Loss T 0.065651 Method MME

S painting T real Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.263606 Loss T 0.068987 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0745, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 2.0694, Accuracy: 45065/69952 F1 (64.4227%)


Val set: Average loss: 2.3488, Accuracy: 217/352 F1 (61.6477%)

best acc test 62.838804  acc val 61.647727 acc labeled target 97.619048
saving model...
S painting T real Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.234881 Loss T 0.054127 Method MME

S painting T real Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.266542 Loss T 0.062677 Method MME

S painting T real Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.105731 Loss T 0.056543 Method MME

S painting T real Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.107403 Loss T 0.057575 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        0.7777778 1.        0.8888889 0.8888889 0.8888889 1.
 1.        0.8888889 1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [65, 71, 80, 62, 89, 98, 88, 32, 28, 26, 22, 21, 108, 112, 78, 109, 123, 2, 75, 74, 73, 4, 5, 14, 77, 90, 69, 87, 86, 84, 70, 72, 83, 82, 81, 91, 76, 79, 85, 92, 100, 94, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 107, 106, 105, 104, 103, 102, 101, 99, 97, 96, 95, 93, 68, 0, 66, 34, 33, 31, 30, 29, 27, 25, 24, 23, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 8, 7, 6, 3, 1, 35, 36, 37, 38, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 67, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.214481 Loss T 0.060872 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0903, Accuracy: 1110/1134 F1 (97.8836%)


Test set: Average loss: 2.0605, Accuracy: 45073/69952 F1 (64.4342%)


Val set: Average loss: 2.3282, Accuracy: 210/352 F1 (59.6591%)

best acc test 62.838804  acc val 59.659091 acc labeled target 97.883598
saving model...
S painting T real Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.229918 Loss T 0.055249 Method MME

S painting T real Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.203375 Loss T 0.055990 Method MME

S painting T real Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.129837 Loss T 0.075265 Method MME

S painting T real Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.287084 Loss T 0.069446 Method MME

S painting T real Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.271776 Loss T 0.052480 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0998, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 2.0252, Accuracy: 45325/69952 F1 (64.7944%)


Val set: Average loss: 2.1848, Accuracy: 216/352 F1 (61.3636%)

best acc test 62.838804  acc val 61.363636 acc labeled target 97.619048
saving model...
S painting T real Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.043143 Loss T 0.066842 Method MME

S painting T real Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.222927 Loss T 0.057709 Method MME

S painting T real Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.160482 Loss T 0.049647 Method MME

S painting T real Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.074836 Loss T 0.047906 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 0.8888889 0.7777778 1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [78, 34, 28, 32, 68, 36, 38, 39, 51, 82, 80, 57, 77, 73, 65, 72, 104, 108, 69, 6, 2, 16, 118, 120, 13, 7, 88, 87, 86, 85, 84, 83, 119, 110, 89, 79, 121, 76, 75, 74, 122, 123, 71, 81, 90, 91, 92, 109, 112, 107, 106, 105, 103, 102, 113, 101, 100, 99, 114, 98, 97, 115, 96, 116, 117, 95, 94, 93, 111, 0, 62, 67, 30, 29, 27, 26, 25, 24, 23, 22, 21, 20, 19, 31, 18, 15, 14, 12, 11, 10, 9, 8, 5, 4, 3, 1, 17, 70, 33, 37, 66, 64, 63, 124, 61, 60, 59, 58, 56, 55, 54, 35, 53, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.200297 Loss T 0.067342 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0920, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 2.0031, Accuracy: 45541/69952 F1 (65.1032%)


Val set: Average loss: 2.2724, Accuracy: 205/352 F1 (58.2386%)

best acc test 62.838804  acc val 58.238636 acc labeled target 97.971781
saving model...
S painting T real Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.352378 Loss T 0.075806 Method MME

S painting T real Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.115356 Loss T 0.056312 Method MME

S painting T real Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.264253 Loss T 0.063975 Method MME

S painting T real Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.374281 Loss T 0.063127 Method MME

S painting T real Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.217571 Loss T 0.056561 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0641, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.9977, Accuracy: 45587/69952 F1 (65.1690%)


Val set: Average loss: 2.1027, Accuracy: 213/352 F1 (60.5114%)

best acc test 62.838804  acc val 60.511364 acc labeled target 98.059965
saving model...
S painting T real Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.079724 Loss T 0.074034 Method MME

S painting T real Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.140331 Loss T 0.056096 Method MME

S painting T real Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.069320 Loss T 0.062693 Method MME

S painting T real Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.189847 Loss T 0.078949 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        0.7777778 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [6, 9, 32, 70, 71, 75, 80, 45, 89, 36, 34, 97, 99, 102, 110, 66, 114, 119, 122, 13, 86, 85, 84, 83, 82, 81, 120, 79, 78, 111, 77, 76, 121, 74, 73, 72, 123, 69, 68, 87, 88, 90, 112, 113, 109, 108, 107, 106, 105, 104, 103, 101, 100, 98, 115, 96, 67, 95, 116, 94, 117, 93, 92, 91, 118, 0, 62, 64, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 30, 17, 15, 14, 12, 11, 10, 8, 7, 5, 4, 3, 2, 1, 16, 65, 31, 35, 63, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 33, 51, 49, 48, 47, 46, 44, 43, 42, 41, 40, 39, 38, 37, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.076657 Loss T 0.054450 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0792, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 2.0406, Accuracy: 45546/69952 F1 (65.1104%)


Val set: Average loss: 2.2821, Accuracy: 215/352 F1 (61.0795%)

best acc test 62.838804  acc val 61.079545 acc labeled target 98.324515
saving model...
S painting T real Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.192406 Loss T 0.044105 Method MME

S painting T real Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.101949 Loss T 0.057484 Method MME

S painting T real Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.150400 Loss T 0.058170 Method MME

S painting T real Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.241505 Loss T 0.052945 Method MME

S painting T real Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.115011 Loss T 0.046275 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0427, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 2.0507, Accuracy: 45618/69952 F1 (65.2133%)


Val set: Average loss: 2.3656, Accuracy: 212/352 F1 (60.2273%)

best acc test 62.838804  acc val 60.227273 acc labeled target 98.677249
saving model...
S painting T real Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.095079 Loss T 0.039787 Method MME

S painting T real Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.376689 Loss T 0.054637 Method MME

S painting T real Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.154463 Loss T 0.087294 Method MME

S painting T real Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.163225 Loss T 0.046444 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [32, 71, 73, 74, 75, 51, 80, 89, 93, 96, 105, 15, 65, 6, 10, 113, 87, 86, 85, 84, 83, 82, 81, 79, 78, 119, 77, 76, 120, 121, 122, 72, 123, 70, 69, 68, 67, 88, 118, 90, 91, 112, 115, 111, 110, 109, 108, 107, 106, 104, 103, 114, 102, 100, 99, 98, 97, 116, 66, 95, 94, 117, 92, 101, 0, 62, 63, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 30, 17, 14, 13, 12, 11, 9, 8, 7, 5, 4, 3, 2, 1, 16, 31, 33, 34, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S painting T real Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.163685 Loss T 0.050608 Method MME

32
32
32
32
32
32
32
32
32
32
32
32
tensor(1134.)

Labeled Target set: Average loss: 0.0667, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 2.0750, Accuracy: 45420/69952 F1 (64.9302%)


Val set: Average loss: 2.2950, Accuracy: 210/352 F1 (59.6591%)

