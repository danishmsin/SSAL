Dataset multi Source real Target sketch Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  70358
Unlabelled Target Dataset Size:  23826
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  23826 Source:  70358
Unlabeled Target Data Batches: 496
Per Class Accuracy Calculated According to the Labelled Target examples is:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
Top k classes which perform poorly are:  [0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 92, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 63, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 31, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839],
       dtype=torch.float64)
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161],
       dtype=torch.float64)
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 0 lr0.01 	 Loss Classification: 4.793185 Loss T 0.471225 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9878, Accuracy: 6/1134 F1 (0.5291%)


Test set: Average loss: 4.9881, Accuracy: 70/23808 F1 (0.2940%)


Val set: Average loss: 4.9885, Accuracy: 3/360 F1 (0.8333%)

best acc test 0.294019  acc val 0.833333 acc labeled target 0.529101
saving model...
S real T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.432875 Loss T 0.295796 Method MME

S real T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 0.964961 Loss T 0.242704 Method MME

S real T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 0.679238 Loss T 0.232527 Method MME

S real T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 0.597302 Loss T 0.185436 Method MME

S real T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.127262 Loss T 0.155656 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7446, Accuracy: 466/1134 F1 (41.0935%)


Test set: Average loss: 2.6093, Accuracy: 10873/23808 F1 (45.6695%)


Val set: Average loss: 2.2700, Accuracy: 174/360 F1 (48.3333%)

best acc test 45.669523  acc val 48.333333 acc labeled target 41.093474
saving model...
S real T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.635146 Loss T 0.170248 Method MME

S real T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.172971 Loss T 0.158431 Method MME

S real T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.863340 Loss T 0.149527 Method MME

S real T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.667262 Loss T 0.129775 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         0.6666667  0.22222222 0.5555556  0.22222222
 0.33333334 0.7777778  0.33333334 0.         0.5555556  0.8888889
 0.         0.         0.7777778  0.22222222 0.22222222 0.7777778
 0.33333334 0.33333334 0.6666667  0.33333334 0.44444445 0.11111111
 0.44444445 0.22222222 0.         0.6666667  0.5555556  0.11111111
 0.11111111 0.33333334 0.11111111 0.7777778  0.44444445 0.11111111
 0.33333334 0.         1.         0.8888889  0.33333334 0.6666667
 0.11111111 0.11111111 0.11111111 0.33333334 1.         0.6666667
 0.6666667  1.         0.22222222 0.33333334 0.6666667  0.5555556
 0.5555556  0.44444445 0.22222222 0.44444445 0.6666667  0.8888889
 0.7777778  0.22222222 0.5555556  0.22222222 0.11111111 0.33333334
 0.         0.6666667  0.11111111 0.5555556  0.11111111 0.
 0.33333334 0.33333334 0.6666667  0.11111111 0.5555556  0.33333334
 0.22222222 0.44444445 0.         0.         0.11111111 0.7777778
 0.22222222 0.11111111 0.6666667  0.6666667  0.         0.6666667
 0.44444445 0.8888889  0.6666667  0.44444445 1.         0.44444445
 0.44444445 0.33333334 0.         0.         0.6666667  0.33333334
 0.5555556  0.11111111 0.7777778  0.         0.22222222 0.33333334
 0.         0.33333334 0.33333334 0.44444445 0.6666667  0.7777778
 0.         1.         0.22222222 0.44444445 0.         0.33333334
 0.6666667  0.33333334 0.7777778  0.         0.         1.        ]
Top k classes which perform poorly are:  [99, 124, 88, 71, 98, 37, 105, 26, 80, 108, 13, 12, 81, 66, 118, 123, 114, 9, 64, 43, 44, 35, 32, 70, 30, 29, 82, 103, 75, 23, 85, 42, 68, 63, 56, 84, 50, 3, 116, 61, 78, 15, 5, 16, 106, 25, 109, 107, 18, 19, 21, 8, 77, 6, 31, 119, 51, 65, 73, 72, 97, 121, 45, 36, 101, 40, 110, 117, 55, 90, 93, 95, 96, 34, 24, 22, 111, 57, 79, 102, 62, 69, 4, 10, 28, 54, 76, 53, 74, 2, 112, 20, 27, 100, 41, 47, 58, 120, 52, 92, 67, 89, 87, 48, 86, 83, 113, 60, 7, 17, 14, 104, 33, 122, 59, 91, 11, 39, 0, 94, 49, 46, 38, 1, 115, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2567, 1.4004, 1.2869, 1.4004, 1.3583, 1.2297, 1.3583,
        1.5000, 1.2869, 1.2056, 1.5000, 1.5000, 1.2297, 1.4004, 1.4004, 1.2297,
        1.3583, 1.3583, 1.2567, 1.3583, 1.3206, 1.4474, 1.3206, 1.4004, 1.5000,
        1.2567, 1.2869, 1.4474, 1.4474, 1.3583, 1.4474, 1.2297, 1.3206, 1.4474,
        1.3583, 1.5000, 1.1839, 1.2056, 1.3583, 1.2567, 1.4474, 1.4474, 1.4474,
        1.3583, 1.1839, 1.2567, 1.2567, 1.1839, 1.4004, 1.3583, 1.2567, 1.2869,
        1.2869, 1.3206, 1.4004, 1.3206, 1.2567, 1.2056, 1.2297, 1.4004, 1.2869,
        1.4004, 1.4474, 1.3583, 1.5000, 1.2567, 1.4474, 1.2869, 1.4474, 1.5000,
        1.3583, 1.3583, 1.2567, 1.4474, 1.2869, 1.3583, 1.4004, 1.3206, 1.5000,
        1.5000, 1.4474, 1.2297, 1.4004, 1.4474, 1.2567, 1.2567, 1.5000, 1.2567,
        1.3206, 1.2056, 1.2567, 1.3206, 1.1839, 1.3206, 1.3206, 1.3583, 1.5000,
        1.5000, 1.2567, 1.3583, 1.2869, 1.4474, 1.2297, 1.5000, 1.4004, 1.3583,
        1.5000, 1.3583, 1.3583, 1.3206, 1.2567, 1.2297, 1.5000, 1.1839, 1.4004,
        1.3206, 1.5000, 1.3583, 1.2567, 1.3583, 1.2297, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7433, 0.5996, 0.7131, 0.5996, 0.6417, 0.7703, 0.6417,
        0.5000, 0.7131, 0.7944, 0.5000, 0.5000, 0.7703, 0.5996, 0.5996, 0.7703,
        0.6417, 0.6417, 0.7433, 0.6417, 0.6794, 0.5526, 0.6794, 0.5996, 0.5000,
        0.7433, 0.7131, 0.5526, 0.5526, 0.6417, 0.5526, 0.7703, 0.6794, 0.5526,
        0.6417, 0.5000, 0.8161, 0.7944, 0.6417, 0.7433, 0.5526, 0.5526, 0.5526,
        0.6417, 0.8161, 0.7433, 0.7433, 0.8161, 0.5996, 0.6417, 0.7433, 0.7131,
        0.7131, 0.6794, 0.5996, 0.6794, 0.7433, 0.7944, 0.7703, 0.5996, 0.7131,
        0.5996, 0.5526, 0.6417, 0.5000, 0.7433, 0.5526, 0.7131, 0.5526, 0.5000,
        0.6417, 0.6417, 0.7433, 0.5526, 0.7131, 0.6417, 0.5996, 0.6794, 0.5000,
        0.5000, 0.5526, 0.7703, 0.5996, 0.5526, 0.7433, 0.7433, 0.5000, 0.7433,
        0.6794, 0.7944, 0.7433, 0.6794, 0.8161, 0.6794, 0.6794, 0.6417, 0.5000,
        0.5000, 0.7433, 0.6417, 0.7131, 0.5526, 0.7703, 0.5000, 0.5996, 0.6417,
        0.5000, 0.6417, 0.6417, 0.6794, 0.7433, 0.7703, 0.5000, 0.8161, 0.5996,
        0.6794, 0.5000, 0.6417, 0.7433, 0.6417, 0.7703, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.832867 Loss T 0.147667 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.9032, Accuracy: 466/1134 F1 (41.0935%)


Test set: Average loss: 2.9247, Accuracy: 10152/23808 F1 (42.6411%)


Val set: Average loss: 2.8067, Accuracy: 152/360 F1 (42.2222%)

best acc test 45.669523  acc val 42.222222 acc labeled target 41.093474
saving model...
S real T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.405599 Loss T 0.131852 Method MME

S real T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.109400 Loss T 0.128808 Method MME

S real T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.661307 Loss T 0.144497 Method MME

S real T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.601714 Loss T 0.134162 Method MME

S real T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.110723 Loss T 0.148417 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3268, Accuracy: 571/1134 F1 (50.3527%)


Test set: Average loss: 2.2935, Accuracy: 12706/23808 F1 (53.3686%)


Val set: Average loss: 2.2420, Accuracy: 183/360 F1 (50.8333%)

best acc test 53.368616  acc val 50.833333 acc labeled target 50.352734
saving model...
S real T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.378399 Loss T 0.127499 Method MME

S real T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.005432 Loss T 0.110331 Method MME

S real T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.208104 Loss T 0.097322 Method MME

S real T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.786389 Loss T 0.110143 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.22222222 0.5555556  0.6666667  0.
 0.22222222 1.         0.33333334 0.         0.33333334 1.
 0.         0.22222222 0.22222222 0.6666667  1.         0.8888889
 0.44444445 0.         0.6666667  0.7777778  1.         0.22222222
 0.33333334 0.33333334 0.         1.         0.5555556  0.33333334
 0.33333334 0.33333334 0.11111111 0.6666667  1.         0.44444445
 0.22222222 0.         0.7777778  0.6666667  0.6666667  0.8888889
 0.5555556  0.         0.6666667  0.6666667  1.         0.8888889
 0.33333334 1.         0.33333334 0.33333334 0.8888889  0.33333334
 0.8888889  0.33333334 0.44444445 1.         0.6666667  0.33333334
 1.         0.22222222 0.7777778  0.33333334 0.8888889  0.6666667
 0.         0.44444445 0.44444445 0.8888889  0.33333334 0.
 0.8888889  0.5555556  1.         0.33333334 0.         0.6666667
 1.         0.5555556  0.         0.7777778  0.33333334 0.8888889
 0.5555556  0.11111111 0.7777778  0.6666667  0.11111111 0.22222222
 0.33333334 0.6666667  0.5555556  1.         1.         0.44444445
 0.33333334 0.8888889  0.33333334 0.         0.7777778  0.33333334
 0.6666667  0.33333334 0.6666667  0.         0.33333334 0.33333334
 0.         0.22222222 0.33333334 0.22222222 0.5555556  1.
 0.33333334 1.         0.22222222 0.6666667  0.         0.22222222
 0.33333334 0.7777778  0.7777778  0.         0.         1.        ]
Top k classes which perform poorly are:  [105, 108, 26, 37, 80, 43, 118, 71, 19, 66, 12, 99, 124, 123, 76, 9, 5, 88, 85, 32, 119, 109, 111, 6, 61, 23, 89, 14, 2, 116, 36, 13, 48, 110, 51, 107, 53, 106, 55, 59, 70, 63, 103, 50, 101, 98, 75, 90, 114, 31, 30, 29, 82, 25, 24, 8, 96, 10, 120, 68, 95, 56, 35, 18, 67, 84, 73, 79, 0, 112, 3, 28, 42, 92, 117, 104, 4, 87, 15, 20, 45, 58, 102, 65, 39, 40, 77, 91, 44, 33, 121, 122, 100, 62, 86, 81, 38, 21, 47, 83, 97, 41, 72, 69, 64, 54, 52, 17, 22, 11, 27, 7, 1, 16, 115, 94, 113, 46, 93, 49, 57, 60, 74, 78, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.4004, 1.2869, 1.2567, 1.5000, 1.4004, 1.1839, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.4004, 1.4004, 1.2567, 1.1839, 1.2056,
        1.3206, 1.5000, 1.2567, 1.2297, 1.1839, 1.4004, 1.3583, 1.3583, 1.5000,
        1.1839, 1.2869, 1.3583, 1.3583, 1.3583, 1.4474, 1.2567, 1.1839, 1.3206,
        1.4004, 1.5000, 1.2297, 1.2567, 1.2567, 1.2056, 1.2869, 1.5000, 1.2567,
        1.2567, 1.1839, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.2056, 1.3583,
        1.2056, 1.3583, 1.3206, 1.1839, 1.2567, 1.3583, 1.1839, 1.4004, 1.2297,
        1.3583, 1.2056, 1.2567, 1.5000, 1.3206, 1.3206, 1.2056, 1.3583, 1.5000,
        1.2056, 1.2869, 1.1839, 1.3583, 1.5000, 1.2567, 1.1839, 1.2869, 1.5000,
        1.2297, 1.3583, 1.2056, 1.2869, 1.4474, 1.2297, 1.2567, 1.4474, 1.4004,
        1.3583, 1.2567, 1.2869, 1.1839, 1.1839, 1.3206, 1.3583, 1.2056, 1.3583,
        1.5000, 1.2297, 1.3583, 1.2567, 1.3583, 1.2567, 1.5000, 1.3583, 1.3583,
        1.5000, 1.4004, 1.3583, 1.4004, 1.2869, 1.1839, 1.3583, 1.1839, 1.4004,
        1.2567, 1.5000, 1.4004, 1.3583, 1.2297, 1.2297, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.5996, 0.7131, 0.7433, 0.5000, 0.5996, 0.8161, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.5996, 0.5996, 0.7433, 0.8161, 0.7944,
        0.6794, 0.5000, 0.7433, 0.7703, 0.8161, 0.5996, 0.6417, 0.6417, 0.5000,
        0.8161, 0.7131, 0.6417, 0.6417, 0.6417, 0.5526, 0.7433, 0.8161, 0.6794,
        0.5996, 0.5000, 0.7703, 0.7433, 0.7433, 0.7944, 0.7131, 0.5000, 0.7433,
        0.7433, 0.8161, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.7944, 0.6417,
        0.7944, 0.6417, 0.6794, 0.8161, 0.7433, 0.6417, 0.8161, 0.5996, 0.7703,
        0.6417, 0.7944, 0.7433, 0.5000, 0.6794, 0.6794, 0.7944, 0.6417, 0.5000,
        0.7944, 0.7131, 0.8161, 0.6417, 0.5000, 0.7433, 0.8161, 0.7131, 0.5000,
        0.7703, 0.6417, 0.7944, 0.7131, 0.5526, 0.7703, 0.7433, 0.5526, 0.5996,
        0.6417, 0.7433, 0.7131, 0.8161, 0.8161, 0.6794, 0.6417, 0.7944, 0.6417,
        0.5000, 0.7703, 0.6417, 0.7433, 0.6417, 0.7433, 0.5000, 0.6417, 0.6417,
        0.5000, 0.5996, 0.6417, 0.5996, 0.7131, 0.8161, 0.6417, 0.8161, 0.5996,
        0.7433, 0.5000, 0.5996, 0.6417, 0.7703, 0.7703, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.352724 Loss T 0.120762 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5847, Accuracy: 554/1134 F1 (48.8536%)


Test set: Average loss: 2.4264, Accuracy: 12561/23808 F1 (52.7596%)


Val set: Average loss: 2.3520, Accuracy: 187/360 F1 (51.9444%)

best acc test 52.759577  acc val 51.944444 acc labeled target 48.853616
saving model...
S real T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.860908 Loss T 0.134591 Method MME

S real T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.630131 Loss T 0.109795 Method MME

S real T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 1.146634 Loss T 0.101526 Method MME

S real T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.428079 Loss T 0.127097 Method MME

S real T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.809915 Loss T 0.113238 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1687, Accuracy: 613/1134 F1 (54.0564%)


Test set: Average loss: 2.1612, Accuracy: 13603/23808 F1 (57.1363%)


Val set: Average loss: 1.9777, Accuracy: 213/360 F1 (59.1667%)

best acc test 57.136257  acc val 59.166667 acc labeled target 54.056437
saving model...
S real T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.579412 Loss T 0.114043 Method MME

S real T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.496160 Loss T 0.120700 Method MME

S real T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.597637 Loss T 0.097521 Method MME

S real T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.357018 Loss T 0.104496 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.5555556  0.6666667  0.8888889  0.33333334
 0.6666667  1.         0.33333334 0.         0.8888889  0.8888889
 0.         0.         0.5555556  0.11111111 1.         1.
 0.8888889  0.22222222 0.7777778  1.         0.22222222 0.33333334
 0.33333334 0.33333334 0.         0.7777778  0.6666667  0.44444445
 0.44444445 0.         0.22222222 0.8888889  0.5555556  0.5555556
 0.33333334 0.         0.7777778  0.7777778  0.44444445 0.44444445
 0.8888889  0.22222222 0.5555556  0.5555556  1.         0.44444445
 0.33333334 0.8888889  0.33333334 0.22222222 1.         0.22222222
 0.7777778  0.44444445 0.6666667  0.8888889  0.7777778  1.
 1.         0.11111111 1.         0.33333334 1.         0.6666667
 0.11111111 1.         0.22222222 0.7777778  0.22222222 0.22222222
 0.8888889  0.5555556  0.8888889  0.33333334 0.11111111 0.6666667
 0.7777778  0.33333334 0.         0.5555556  0.         0.6666667
 0.8888889  0.33333334 1.         0.6666667  0.22222222 0.5555556
 0.5555556  0.8888889  0.6666667  0.8888889  1.         0.5555556
 0.33333334 0.8888889  0.5555556  0.         1.         0.5555556
 0.6666667  0.33333334 0.6666667  0.         0.33333334 0.5555556
 0.         0.5555556  0.         0.5555556  0.6666667  1.
 0.22222222 1.         0.22222222 0.6666667  0.         0.33333334
 0.44444445 0.7777778  0.6666667  0.         0.         1.        ]
Top k classes which perform poorly are:  [13, 31, 110, 37, 99, 82, 12, 105, 118, 26, 124, 123, 108, 80, 9, 61, 66, 15, 76, 114, 53, 70, 68, 51, 32, 43, 88, 116, 71, 22, 19, 63, 75, 8, 25, 50, 85, 103, 96, 36, 5, 119, 23, 24, 79, 106, 48, 55, 41, 120, 40, 30, 29, 47, 73, 89, 81, 90, 109, 111, 2, 95, 45, 44, 107, 98, 35, 34, 101, 14, 3, 6, 77, 122, 102, 104, 87, 92, 28, 65, 117, 56, 112, 83, 54, 78, 69, 121, 58, 20, 27, 38, 39, 4, 10, 11, 18, 33, 97, 42, 49, 57, 93, 91, 72, 74, 84, 0, 115, 113, 62, 94, 86, 67, 64, 60, 59, 52, 46, 21, 17, 16, 7, 1, 100, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2869, 1.2567, 1.2056, 1.3583, 1.2567, 1.1839, 1.3583,
        1.5000, 1.2056, 1.2056, 1.5000, 1.5000, 1.2869, 1.4474, 1.1839, 1.1839,
        1.2056, 1.4004, 1.2297, 1.1839, 1.4004, 1.3583, 1.3583, 1.3583, 1.5000,
        1.2297, 1.2567, 1.3206, 1.3206, 1.5000, 1.4004, 1.2056, 1.2869, 1.2869,
        1.3583, 1.5000, 1.2297, 1.2297, 1.3206, 1.3206, 1.2056, 1.4004, 1.2869,
        1.2869, 1.1839, 1.3206, 1.3583, 1.2056, 1.3583, 1.4004, 1.1839, 1.4004,
        1.2297, 1.3206, 1.2567, 1.2056, 1.2297, 1.1839, 1.1839, 1.4474, 1.1839,
        1.3583, 1.1839, 1.2567, 1.4474, 1.1839, 1.4004, 1.2297, 1.4004, 1.4004,
        1.2056, 1.2869, 1.2056, 1.3583, 1.4474, 1.2567, 1.2297, 1.3583, 1.5000,
        1.2869, 1.5000, 1.2567, 1.2056, 1.3583, 1.1839, 1.2567, 1.4004, 1.2869,
        1.2869, 1.2056, 1.2567, 1.2056, 1.1839, 1.2869, 1.3583, 1.2056, 1.2869,
        1.5000, 1.1839, 1.2869, 1.2567, 1.3583, 1.2567, 1.5000, 1.3583, 1.2869,
        1.5000, 1.2869, 1.5000, 1.2869, 1.2567, 1.1839, 1.4004, 1.1839, 1.4004,
        1.2567, 1.5000, 1.3583, 1.3206, 1.2297, 1.2567, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7131, 0.7433, 0.7944, 0.6417, 0.7433, 0.8161, 0.6417,
        0.5000, 0.7944, 0.7944, 0.5000, 0.5000, 0.7131, 0.5526, 0.8161, 0.8161,
        0.7944, 0.5996, 0.7703, 0.8161, 0.5996, 0.6417, 0.6417, 0.6417, 0.5000,
        0.7703, 0.7433, 0.6794, 0.6794, 0.5000, 0.5996, 0.7944, 0.7131, 0.7131,
        0.6417, 0.5000, 0.7703, 0.7703, 0.6794, 0.6794, 0.7944, 0.5996, 0.7131,
        0.7131, 0.8161, 0.6794, 0.6417, 0.7944, 0.6417, 0.5996, 0.8161, 0.5996,
        0.7703, 0.6794, 0.7433, 0.7944, 0.7703, 0.8161, 0.8161, 0.5526, 0.8161,
        0.6417, 0.8161, 0.7433, 0.5526, 0.8161, 0.5996, 0.7703, 0.5996, 0.5996,
        0.7944, 0.7131, 0.7944, 0.6417, 0.5526, 0.7433, 0.7703, 0.6417, 0.5000,
        0.7131, 0.5000, 0.7433, 0.7944, 0.6417, 0.8161, 0.7433, 0.5996, 0.7131,
        0.7131, 0.7944, 0.7433, 0.7944, 0.8161, 0.7131, 0.6417, 0.7944, 0.7131,
        0.5000, 0.8161, 0.7131, 0.7433, 0.6417, 0.7433, 0.5000, 0.6417, 0.7131,
        0.5000, 0.7131, 0.5000, 0.7131, 0.7433, 0.8161, 0.5996, 0.8161, 0.5996,
        0.7433, 0.5000, 0.6417, 0.6794, 0.7703, 0.7433, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.499495 Loss T 0.111835 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4204, Accuracy: 590/1134 F1 (52.0282%)


Test set: Average loss: 2.3339, Accuracy: 13403/23808 F1 (56.2962%)


Val set: Average loss: 2.1366, Accuracy: 215/360 F1 (59.7222%)

best acc test 56.296203  acc val 59.722222 acc labeled target 52.028219
saving model...
S real T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.403588 Loss T 0.096377 Method MME

S real T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.286629 Loss T 0.067127 Method MME

S real T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.298461 Loss T 0.095372 Method MME

S real T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.866418 Loss T 0.098429 Method MME

S real T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.615105 Loss T 0.094848 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1806, Accuracy: 659/1134 F1 (58.1129%)


Test set: Average loss: 2.1413, Accuracy: 14202/23808 F1 (59.6522%)


Val set: Average loss: 1.9493, Accuracy: 214/360 F1 (59.4444%)

best acc test 56.296203  acc val 59.444444 acc labeled target 58.112875
saving model...
S real T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.958730 Loss T 0.127341 Method MME

S real T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.334896 Loss T 0.110382 Method MME

S real T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.975864 Loss T 0.073448 Method MME

S real T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.900903 Loss T 0.091752 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         0.5555556  0.44444445 0.7777778  0.33333334
 0.6666667  0.8888889  0.33333334 0.22222222 0.7777778  1.
 0.         0.         0.11111111 0.6666667  1.         1.
 0.8888889  0.33333334 0.6666667  1.         0.6666667  0.33333334
 0.33333334 0.33333334 0.         1.         0.6666667  0.22222222
 0.5555556  0.44444445 0.         0.5555556  0.8888889  0.33333334
 0.33333334 0.         0.8888889  1.         0.5555556  1.
 0.8888889  0.33333334 0.6666667  0.44444445 1.         0.8888889
 0.33333334 1.         0.33333334 0.11111111 1.         0.22222222
 1.         0.5555556  0.6666667  0.8888889  1.         0.6666667
 1.         0.         0.8888889  0.33333334 0.8888889  0.6666667
 0.         0.6666667  0.33333334 1.         0.33333334 0.22222222
 0.7777778  0.44444445 1.         0.33333334 0.22222222 1.
 0.6666667  0.7777778  0.         1.         0.33333334 0.
 0.5555556  0.7777778  1.         0.6666667  0.22222222 0.5555556
 0.44444445 1.         0.6666667  1.         1.         0.6666667
 0.6666667  0.6666667  0.33333334 0.         0.8888889  0.6666667
 0.6666667  0.6666667  0.6666667  0.         0.33333334 0.5555556
 0.         0.44444445 0.7777778  0.5555556  0.8888889  1.
 0.7777778  1.         0.33333334 0.6666667  0.         0.33333334
 0.8888889  0.7777778  0.44444445 0.         0.         1.        ]
Top k classes which perform poorly are:  [66, 123, 118, 26, 99, 124, 61, 37, 108, 105, 83, 80, 12, 13, 32, 51, 14, 88, 29, 71, 53, 9, 76, 43, 116, 82, 106, 63, 70, 36, 48, 35, 75, 50, 68, 119, 25, 8, 24, 23, 5, 19, 98, 31, 73, 122, 90, 3, 109, 45, 55, 111, 2, 30, 33, 107, 84, 40, 89, 96, 78, 103, 92, 97, 104, 87, 95, 102, 101, 65, 6, 59, 15, 56, 20, 22, 28, 117, 67, 44, 4, 10, 121, 85, 114, 110, 79, 72, 42, 64, 7, 57, 112, 18, 100, 34, 38, 47, 120, 62, 115, 113, 0, 93, 1, 11, 16, 17, 21, 27, 39, 41, 46, 94, 49, 54, 58, 60, 69, 74, 77, 81, 86, 91, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2869, 1.3206, 1.2297, 1.3583, 1.2567, 1.2056, 1.3583,
        1.4004, 1.2297, 1.1839, 1.5000, 1.5000, 1.4474, 1.2567, 1.1839, 1.1839,
        1.2056, 1.3583, 1.2567, 1.1839, 1.2567, 1.3583, 1.3583, 1.3583, 1.5000,
        1.1839, 1.2567, 1.4004, 1.2869, 1.3206, 1.5000, 1.2869, 1.2056, 1.3583,
        1.3583, 1.5000, 1.2056, 1.1839, 1.2869, 1.1839, 1.2056, 1.3583, 1.2567,
        1.3206, 1.1839, 1.2056, 1.3583, 1.1839, 1.3583, 1.4474, 1.1839, 1.4004,
        1.1839, 1.2869, 1.2567, 1.2056, 1.1839, 1.2567, 1.1839, 1.5000, 1.2056,
        1.3583, 1.2056, 1.2567, 1.5000, 1.2567, 1.3583, 1.1839, 1.3583, 1.4004,
        1.2297, 1.3206, 1.1839, 1.3583, 1.4004, 1.1839, 1.2567, 1.2297, 1.5000,
        1.1839, 1.3583, 1.5000, 1.2869, 1.2297, 1.1839, 1.2567, 1.4004, 1.2869,
        1.3206, 1.1839, 1.2567, 1.1839, 1.1839, 1.2567, 1.2567, 1.2567, 1.3583,
        1.5000, 1.2056, 1.2567, 1.2567, 1.2567, 1.2567, 1.5000, 1.3583, 1.2869,
        1.5000, 1.3206, 1.2297, 1.2869, 1.2056, 1.1839, 1.2297, 1.1839, 1.3583,
        1.2567, 1.5000, 1.3583, 1.2056, 1.2297, 1.3206, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7131, 0.6794, 0.7703, 0.6417, 0.7433, 0.7944, 0.6417,
        0.5996, 0.7703, 0.8161, 0.5000, 0.5000, 0.5526, 0.7433, 0.8161, 0.8161,
        0.7944, 0.6417, 0.7433, 0.8161, 0.7433, 0.6417, 0.6417, 0.6417, 0.5000,
        0.8161, 0.7433, 0.5996, 0.7131, 0.6794, 0.5000, 0.7131, 0.7944, 0.6417,
        0.6417, 0.5000, 0.7944, 0.8161, 0.7131, 0.8161, 0.7944, 0.6417, 0.7433,
        0.6794, 0.8161, 0.7944, 0.6417, 0.8161, 0.6417, 0.5526, 0.8161, 0.5996,
        0.8161, 0.7131, 0.7433, 0.7944, 0.8161, 0.7433, 0.8161, 0.5000, 0.7944,
        0.6417, 0.7944, 0.7433, 0.5000, 0.7433, 0.6417, 0.8161, 0.6417, 0.5996,
        0.7703, 0.6794, 0.8161, 0.6417, 0.5996, 0.8161, 0.7433, 0.7703, 0.5000,
        0.8161, 0.6417, 0.5000, 0.7131, 0.7703, 0.8161, 0.7433, 0.5996, 0.7131,
        0.6794, 0.8161, 0.7433, 0.8161, 0.8161, 0.7433, 0.7433, 0.7433, 0.6417,
        0.5000, 0.7944, 0.7433, 0.7433, 0.7433, 0.7433, 0.5000, 0.6417, 0.7131,
        0.5000, 0.6794, 0.7703, 0.7131, 0.7944, 0.8161, 0.7703, 0.8161, 0.6417,
        0.7433, 0.5000, 0.6417, 0.7944, 0.7703, 0.6794, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.925408 Loss T 0.090048 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5891, Accuracy: 593/1134 F1 (52.2928%)


Test set: Average loss: 2.4900, Accuracy: 13480/23808 F1 (56.6196%)


Val set: Average loss: 2.3458, Accuracy: 212/360 F1 (58.8889%)

best acc test 56.296203  acc val 58.888889 acc labeled target 52.292769
saving model...
S real T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.318507 Loss T 0.081748 Method MME

S real T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.681864 Loss T 0.088219 Method MME

S real T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.631155 Loss T 0.098602 Method MME

S real T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.583750 Loss T 0.064214 Method MME

S real T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.584741 Loss T 0.101836 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0534, Accuracy: 684/1134 F1 (60.3175%)


Test set: Average loss: 2.1532, Accuracy: 14533/23808 F1 (61.0425%)


Val set: Average loss: 1.9906, Accuracy: 215/360 F1 (59.7222%)

best acc test 61.042507  acc val 59.722222 acc labeled target 60.317460
saving model...
S real T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.513518 Loss T 0.081445 Method MME

S real T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.652021 Loss T 0.071813 Method MME

S real T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.760619 Loss T 0.106829 Method MME

S real T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.396312 Loss T 0.059865 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         1.         0.5555556  0.44444445 1.         0.33333334
 0.6666667  1.         0.6666667  0.11111111 0.8888889  1.
 0.         0.         0.7777778  0.         0.5555556  1.
 1.         0.5555556  0.7777778  0.8888889  1.         0.7777778
 0.44444445 0.33333334 0.         1.         0.6666667  0.44444445
 0.6666667  0.33333334 0.         0.5555556  0.7777778  0.33333334
 0.22222222 0.         0.8888889  0.8888889  0.5555556  1.
 1.         0.5555556  0.5555556  0.6666667  1.         0.6666667
 0.33333334 1.         0.33333334 0.33333334 1.         0.5555556
 0.7777778  0.5555556  1.         0.8888889  1.         1.
 1.         0.11111111 1.         0.33333334 1.         0.7777778
 0.6666667  0.6666667  0.11111111 0.7777778  0.44444445 0.33333334
 0.6666667  0.22222222 0.5555556  0.         0.         1.
 1.         0.7777778  0.         0.8888889  0.33333334 0.8888889
 0.44444445 0.33333334 1.         0.6666667  0.11111111 0.44444445
 0.44444445 1.         0.6666667  1.         1.         0.22222222
 0.6666667  1.         0.         0.         1.         0.5555556
 0.6666667  0.5555556  0.6666667  0.         0.33333334 0.33333334
 0.         0.6666667  0.6666667  0.5555556  0.7777778  1.
 0.6666667  1.         0.44444445 0.6666667  0.7777778  0.33333334
 1.         0.8888889  0.5555556  0.         0.         1.        ]
Top k classes which perform poorly are:  [98, 105, 124, 108, 80, 99, 75, 37, 32, 26, 15, 13, 76, 12, 123, 68, 61, 9, 88, 95, 73, 36, 31, 35, 107, 85, 82, 51, 48, 63, 5, 50, 119, 71, 25, 106, 29, 70, 90, 84, 89, 24, 116, 3, 55, 122, 53, 111, 2, 74, 101, 44, 103, 43, 40, 16, 19, 33, 92, 72, 102, 117, 28, 67, 66, 45, 47, 8, 87, 96, 6, 109, 110, 114, 104, 30, 79, 112, 65, 14, 118, 20, 69, 34, 23, 54, 39, 38, 83, 21, 81, 57, 10, 121, 113, 120, 100, 115, 0, 62, 94, 1, 4, 7, 11, 17, 18, 22, 27, 41, 42, 46, 49, 52, 56, 58, 59, 60, 64, 77, 78, 86, 91, 93, 97, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2869, 1.3206, 1.1839, 1.3583, 1.2567, 1.1839, 1.2567,
        1.4474, 1.2056, 1.1839, 1.5000, 1.5000, 1.2297, 1.5000, 1.2869, 1.1839,
        1.1839, 1.2869, 1.2297, 1.2056, 1.1839, 1.2297, 1.3206, 1.3583, 1.5000,
        1.1839, 1.2567, 1.3206, 1.2567, 1.3583, 1.5000, 1.2869, 1.2297, 1.3583,
        1.4004, 1.5000, 1.2056, 1.2056, 1.2869, 1.1839, 1.1839, 1.2869, 1.2869,
        1.2567, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.2869,
        1.2297, 1.2869, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.4474, 1.1839,
        1.3583, 1.1839, 1.2297, 1.2567, 1.2567, 1.4474, 1.2297, 1.3206, 1.3583,
        1.2567, 1.4004, 1.2869, 1.5000, 1.5000, 1.1839, 1.1839, 1.2297, 1.5000,
        1.2056, 1.3583, 1.2056, 1.3206, 1.3583, 1.1839, 1.2567, 1.4474, 1.3206,
        1.3206, 1.1839, 1.2567, 1.1839, 1.1839, 1.4004, 1.2567, 1.1839, 1.5000,
        1.5000, 1.1839, 1.2869, 1.2567, 1.2869, 1.2567, 1.5000, 1.3583, 1.3583,
        1.5000, 1.2567, 1.2567, 1.2869, 1.2297, 1.1839, 1.2567, 1.1839, 1.3206,
        1.2567, 1.2297, 1.3583, 1.1839, 1.2056, 1.2869, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7131, 0.6794, 0.8161, 0.6417, 0.7433, 0.8161, 0.7433,
        0.5526, 0.7944, 0.8161, 0.5000, 0.5000, 0.7703, 0.5000, 0.7131, 0.8161,
        0.8161, 0.7131, 0.7703, 0.7944, 0.8161, 0.7703, 0.6794, 0.6417, 0.5000,
        0.8161, 0.7433, 0.6794, 0.7433, 0.6417, 0.5000, 0.7131, 0.7703, 0.6417,
        0.5996, 0.5000, 0.7944, 0.7944, 0.7131, 0.8161, 0.8161, 0.7131, 0.7131,
        0.7433, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.7131,
        0.7703, 0.7131, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.5526, 0.8161,
        0.6417, 0.8161, 0.7703, 0.7433, 0.7433, 0.5526, 0.7703, 0.6794, 0.6417,
        0.7433, 0.5996, 0.7131, 0.5000, 0.5000, 0.8161, 0.8161, 0.7703, 0.5000,
        0.7944, 0.6417, 0.7944, 0.6794, 0.6417, 0.8161, 0.7433, 0.5526, 0.6794,
        0.6794, 0.8161, 0.7433, 0.8161, 0.8161, 0.5996, 0.7433, 0.8161, 0.5000,
        0.5000, 0.8161, 0.7131, 0.7433, 0.7131, 0.7433, 0.5000, 0.6417, 0.6417,
        0.5000, 0.7433, 0.7433, 0.7131, 0.7703, 0.8161, 0.7433, 0.8161, 0.6794,
        0.7433, 0.7703, 0.6417, 0.8161, 0.7944, 0.7131, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.753875 Loss T 0.092211 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4157, Accuracy: 619/1134 F1 (54.5855%)


Test set: Average loss: 2.3676, Accuracy: 13844/23808 F1 (58.1485%)


Val set: Average loss: 2.1680, Accuracy: 212/360 F1 (58.8889%)

best acc test 61.042507  acc val 58.888889 acc labeled target 54.585538
saving model...
S real T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.780783 Loss T 0.081451 Method MME

S real T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.359033 Loss T 0.070419 Method MME

S real T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.398419 Loss T 0.060765 Method MME

S real T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.609050 Loss T 0.066236 Method MME

S real T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.460413 Loss T 0.079872 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2486, Accuracy: 641/1134 F1 (56.5256%)


Test set: Average loss: 2.1396, Accuracy: 14631/23808 F1 (61.4541%)


Val set: Average loss: 2.0481, Accuracy: 210/360 F1 (58.3333%)

best acc test 61.042507  acc val 58.333333 acc labeled target 56.525573
saving model...
S real T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.440975 Loss T 0.084682 Method MME

S real T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.343315 Loss T 0.063223 Method MME

S real T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.789143 Loss T 0.071083 Method MME

S real T sketch Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.227774 Loss T 0.051762 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.44444445 0.6666667  0.7777778  0.33333334
 0.6666667  1.         0.8888889  0.11111111 0.6666667  1.
 0.         0.         0.33333334 0.11111111 0.6666667  1.
 0.8888889  0.44444445 0.7777778  1.         0.8888889  0.44444445
 0.33333334 0.33333334 0.         1.         0.6666667  0.33333334
 0.5555556  0.33333334 0.7777778  0.44444445 0.6666667  0.11111111
 0.33333334 0.         1.         0.8888889  0.5555556  0.8888889
 0.44444445 0.33333334 0.6666667  0.5555556  1.         0.5555556
 0.33333334 1.         0.33333334 0.11111111 1.         0.22222222
 0.8888889  0.5555556  0.8888889  0.8888889  1.         1.
 0.8888889  0.22222222 1.         0.33333334 1.         0.44444445
 0.44444445 0.6666667  0.         1.         0.22222222 0.33333334
 0.44444445 0.33333334 1.         0.11111111 0.33333334 1.
 0.8888889  0.22222222 0.         1.         0.22222222 0.11111111
 0.33333334 0.6666667  1.         0.6666667  0.         0.
 0.6666667  0.8888889  0.5555556  1.         1.         0.5555556
 0.5555556  0.7777778  0.         0.33333334 0.8888889  0.5555556
 0.6666667  0.6666667  0.6666667  0.         0.22222222 0.44444445
 0.         0.44444445 0.5555556  1.         1.         1.
 0.6666667  1.         0.22222222 0.6666667  0.11111111 0.33333334
 0.6666667  0.6666667  0.5555556  0.         0.         1.        ]
Top k classes which perform poorly are:  [68, 88, 13, 12, 26, 89, 37, 80, 108, 124, 123, 98, 105, 83, 35, 118, 75, 51, 15, 9, 82, 61, 53, 79, 116, 106, 70, 43, 99, 14, 50, 5, 48, 63, 119, 84, 71, 73, 24, 29, 31, 25, 36, 76, 107, 66, 42, 33, 19, 2, 72, 65, 109, 23, 101, 95, 47, 92, 40, 122, 96, 110, 30, 55, 45, 90, 104, 87, 85, 103, 102, 3, 28, 67, 6, 34, 117, 114, 10, 120, 121, 44, 16, 32, 97, 4, 20, 8, 100, 91, 0, 22, 39, 41, 78, 54, 56, 57, 60, 18, 115, 113, 112, 111, 62, 93, 1, 7, 11, 17, 21, 27, 38, 46, 94, 49, 58, 59, 64, 69, 74, 77, 81, 86, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.3206, 1.2567, 1.2297, 1.3583, 1.2567, 1.1839, 1.2056,
        1.4474, 1.2567, 1.1839, 1.5000, 1.5000, 1.3583, 1.4474, 1.2567, 1.1839,
        1.2056, 1.3206, 1.2297, 1.1839, 1.2056, 1.3206, 1.3583, 1.3583, 1.5000,
        1.1839, 1.2567, 1.3583, 1.2869, 1.3583, 1.2297, 1.3206, 1.2567, 1.4474,
        1.3583, 1.5000, 1.1839, 1.2056, 1.2869, 1.2056, 1.3206, 1.3583, 1.2567,
        1.2869, 1.1839, 1.2869, 1.3583, 1.1839, 1.3583, 1.4474, 1.1839, 1.4004,
        1.2056, 1.2869, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.4004, 1.1839,
        1.3583, 1.1839, 1.3206, 1.3206, 1.2567, 1.5000, 1.1839, 1.4004, 1.3583,
        1.3206, 1.3583, 1.1839, 1.4474, 1.3583, 1.1839, 1.2056, 1.4004, 1.5000,
        1.1839, 1.4004, 1.4474, 1.3583, 1.2567, 1.1839, 1.2567, 1.5000, 1.5000,
        1.2567, 1.2056, 1.2869, 1.1839, 1.1839, 1.2869, 1.2869, 1.2297, 1.5000,
        1.3583, 1.2056, 1.2869, 1.2567, 1.2567, 1.2567, 1.5000, 1.4004, 1.3206,
        1.5000, 1.3206, 1.2869, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.4004,
        1.2567, 1.4474, 1.3583, 1.2567, 1.2567, 1.2869, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.6794, 0.7433, 0.7703, 0.6417, 0.7433, 0.8161, 0.7944,
        0.5526, 0.7433, 0.8161, 0.5000, 0.5000, 0.6417, 0.5526, 0.7433, 0.8161,
        0.7944, 0.6794, 0.7703, 0.8161, 0.7944, 0.6794, 0.6417, 0.6417, 0.5000,
        0.8161, 0.7433, 0.6417, 0.7131, 0.6417, 0.7703, 0.6794, 0.7433, 0.5526,
        0.6417, 0.5000, 0.8161, 0.7944, 0.7131, 0.7944, 0.6794, 0.6417, 0.7433,
        0.7131, 0.8161, 0.7131, 0.6417, 0.8161, 0.6417, 0.5526, 0.8161, 0.5996,
        0.7944, 0.7131, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.5996, 0.8161,
        0.6417, 0.8161, 0.6794, 0.6794, 0.7433, 0.5000, 0.8161, 0.5996, 0.6417,
        0.6794, 0.6417, 0.8161, 0.5526, 0.6417, 0.8161, 0.7944, 0.5996, 0.5000,
        0.8161, 0.5996, 0.5526, 0.6417, 0.7433, 0.8161, 0.7433, 0.5000, 0.5000,
        0.7433, 0.7944, 0.7131, 0.8161, 0.8161, 0.7131, 0.7131, 0.7703, 0.5000,
        0.6417, 0.7944, 0.7131, 0.7433, 0.7433, 0.7433, 0.5000, 0.5996, 0.6794,
        0.5000, 0.6794, 0.7131, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.5996,
        0.7433, 0.5526, 0.6417, 0.7433, 0.7433, 0.7131, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.658951 Loss T 0.080625 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5539, Accuracy: 628/1134 F1 (55.3792%)


Test set: Average loss: 2.4847, Accuracy: 13819/23808 F1 (58.0435%)


Val set: Average loss: 2.3066, Accuracy: 206/360 F1 (57.2222%)

best acc test 61.042507  acc val 57.222222 acc labeled target 55.379189
saving model...
S real T sketch Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.196326 Loss T 0.053794 Method MME

S real T sketch Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.467237 Loss T 0.060771 Method MME

S real T sketch Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.882850 Loss T 0.051833 Method MME

S real T sketch Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.130301 Loss T 0.076007 Method MME

S real T sketch Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.710278 Loss T 0.055499 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3396, Accuracy: 644/1134 F1 (56.7901%)


Test set: Average loss: 2.1735, Accuracy: 14713/23808 F1 (61.7986%)


Val set: Average loss: 2.0727, Accuracy: 218/360 F1 (60.5556%)

best acc test 61.798555  acc val 60.555556 acc labeled target 56.790123
saving model...
S real T sketch Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.511488 Loss T 0.084932 Method MME

S real T sketch Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.281246 Loss T 0.111236 Method MME

S real T sketch Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.431832 Loss T 0.064219 Method MME

S real T sketch Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.515196 Loss T 0.058111 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  1.         0.33333334 0.44444445 1.         0.33333334
 0.6666667  0.8888889  0.7777778  0.         1.         1.
 0.         0.         0.33333334 0.22222222 1.         1.
 0.33333334 0.44444445 0.6666667  1.         0.44444445 1.
 0.5555556  0.22222222 0.         0.7777778  0.7777778  0.5555556
 0.5555556  0.11111111 0.33333334 0.33333334 0.         0.6666667
 0.11111111 0.         0.7777778  0.8888889  0.33333334 1.
 0.5555556  0.11111111 0.6666667  0.6666667  1.         0.44444445
 0.33333334 1.         0.33333334 0.33333334 1.         0.44444445
 1.         0.5555556  1.         0.8888889  1.         1.
 0.8888889  0.         1.         0.33333334 1.         0.5555556
 0.11111111 1.         0.22222222 1.         0.33333334 0.5555556
 0.33333334 0.33333334 1.         0.44444445 0.33333334 0.7777778
 0.7777778  0.5555556  0.         0.8888889  0.11111111 0.8888889
 0.5555556  0.11111111 1.         0.6666667  0.         0.22222222
 0.33333334 0.8888889  0.6666667  1.         0.8888889  0.6666667
 0.44444445 1.         0.22222222 0.33333334 0.8888889  0.6666667
 0.6666667  0.5555556  0.5555556  0.         0.22222222 0.6666667
 0.         0.44444445 0.6666667  0.7777778  0.8888889  1.
 0.5555556  1.         0.         0.6666667  0.         0.33333334
 0.6666667  1.         0.8888889  0.         0.         1.        ]
Top k classes which perform poorly are:  [61, 124, 108, 13, 12, 116, 118, 26, 9, 88, 80, 34, 123, 105, 37, 43, 85, 31, 82, 36, 66, 89, 106, 25, 68, 15, 98, 76, 90, 73, 63, 72, 48, 99, 51, 40, 70, 50, 33, 32, 2, 5, 14, 119, 18, 75, 3, 96, 19, 53, 22, 109, 47, 103, 30, 29, 104, 42, 71, 24, 114, 65, 79, 55, 84, 87, 117, 110, 92, 102, 20, 44, 95, 120, 35, 107, 45, 101, 6, 0, 77, 8, 27, 28, 78, 38, 111, 112, 39, 57, 91, 83, 60, 94, 81, 7, 122, 100, 113, 115, 121, 62, 93, 1, 4, 10, 11, 16, 17, 21, 23, 41, 46, 49, 52, 54, 56, 58, 59, 64, 67, 69, 74, 86, 97, 125]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.1839, 1.3583, 1.3206, 1.1839, 1.3583, 1.2567, 1.2056, 1.2297,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.4004, 1.1839, 1.1839,
        1.3583, 1.3206, 1.2567, 1.1839, 1.3206, 1.1839, 1.2869, 1.4004, 1.5000,
        1.2297, 1.2297, 1.2869, 1.2869, 1.4474, 1.3583, 1.3583, 1.5000, 1.2567,
        1.4474, 1.5000, 1.2297, 1.2056, 1.3583, 1.1839, 1.2869, 1.4474, 1.2567,
        1.2567, 1.1839, 1.3206, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.3206,
        1.1839, 1.2869, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.5000, 1.1839,
        1.3583, 1.1839, 1.2869, 1.4474, 1.1839, 1.4004, 1.1839, 1.3583, 1.2869,
        1.3583, 1.3583, 1.1839, 1.3206, 1.3583, 1.2297, 1.2297, 1.2869, 1.5000,
        1.2056, 1.4474, 1.2056, 1.2869, 1.4474, 1.1839, 1.2567, 1.5000, 1.4004,
        1.3583, 1.2056, 1.2567, 1.1839, 1.2056, 1.2567, 1.3206, 1.1839, 1.4004,
        1.3583, 1.2056, 1.2567, 1.2567, 1.2869, 1.2869, 1.5000, 1.4004, 1.2567,
        1.5000, 1.3206, 1.2567, 1.2297, 1.2056, 1.1839, 1.2869, 1.1839, 1.5000,
        1.2567, 1.5000, 1.3583, 1.2567, 1.1839, 1.2056, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.8161, 0.6417, 0.6794, 0.8161, 0.6417, 0.7433, 0.7944, 0.7703,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.5996, 0.8161, 0.8161,
        0.6417, 0.6794, 0.7433, 0.8161, 0.6794, 0.8161, 0.7131, 0.5996, 0.5000,
        0.7703, 0.7703, 0.7131, 0.7131, 0.5526, 0.6417, 0.6417, 0.5000, 0.7433,
        0.5526, 0.5000, 0.7703, 0.7944, 0.6417, 0.8161, 0.7131, 0.5526, 0.7433,
        0.7433, 0.8161, 0.6794, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.6794,
        0.8161, 0.7131, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.5000, 0.8161,
        0.6417, 0.8161, 0.7131, 0.5526, 0.8161, 0.5996, 0.8161, 0.6417, 0.7131,
        0.6417, 0.6417, 0.8161, 0.6794, 0.6417, 0.7703, 0.7703, 0.7131, 0.5000,
        0.7944, 0.5526, 0.7944, 0.7131, 0.5526, 0.8161, 0.7433, 0.5000, 0.5996,
        0.6417, 0.7944, 0.7433, 0.8161, 0.7944, 0.7433, 0.6794, 0.8161, 0.5996,
        0.6417, 0.7944, 0.7433, 0.7433, 0.7131, 0.7131, 0.5000, 0.5996, 0.7433,
        0.5000, 0.6794, 0.7433, 0.7703, 0.7944, 0.8161, 0.7131, 0.8161, 0.5000,
        0.7433, 0.5000, 0.6417, 0.7433, 0.8161, 0.7944, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.627627 Loss T 0.058953 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7019, Accuracy: 588/1134 F1 (51.8519%)


Test set: Average loss: 2.4683, Accuracy: 13986/23808 F1 (58.7450%)


Val set: Average loss: 2.4557, Accuracy: 199/360 F1 (55.2778%)

best acc test 61.798555  acc val 55.277778 acc labeled target 51.851852
saving model...
S real T sketch Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.450385 Loss T 0.056035 Method MME

S real T sketch Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.762111 Loss T 0.059771 Method MME

S real T sketch Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.886807 Loss T 0.080904 Method MME

S real T sketch Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.359811 Loss T 0.053246 Method MME

S real T sketch Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.612968 Loss T 0.065155 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3070, Accuracy: 646/1134 F1 (56.9665%)


Test set: Average loss: 2.2769, Accuracy: 14658/23808 F1 (61.5675%)


Val set: Average loss: 2.0347, Accuracy: 212/360 F1 (58.8889%)

best acc test 61.798555  acc val 58.888889 acc labeled target 56.966490
saving model...
S real T sketch Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.385621 Loss T 0.054753 Method MME

S real T sketch Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.539357 Loss T 0.084059 Method MME

S real T sketch Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.437076 Loss T 0.075422 Method MME

S real T sketch Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.743143 Loss T 0.064589 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.7777778  0.6666667  1.         0.33333334
 0.5555556  1.         0.6666667  0.11111111 0.6666667  1.
 0.         0.         0.         0.         1.         1.
 0.6666667  0.33333334 0.33333334 0.8888889  0.7777778  1.
 0.5555556  0.         0.         0.6666667  0.6666667  0.33333334
 0.44444445 0.33333334 0.         0.33333334 0.6666667  0.5555556
 0.33333334 0.         0.6666667  1.         0.33333334 0.8888889
 0.7777778  0.22222222 0.6666667  0.6666667  0.8888889  0.7777778
 0.33333334 1.         0.6666667  0.33333334 1.         0.
 0.44444445 0.5555556  0.8888889  0.6666667  1.         0.8888889
 1.         0.11111111 1.         0.33333334 0.8888889  0.8888889
 0.11111111 0.6666667  0.         0.8888889  0.33333334 0.33333334
 0.8888889  0.22222222 1.         0.22222222 0.44444445 1.
 1.         0.8888889  0.         1.         0.         0.44444445
 0.44444445 0.44444445 1.         0.6666667  0.         0.22222222
 0.5555556  0.7777778  0.5555556  1.         1.         0.6666667
 0.33333334 1.         0.22222222 0.5555556  0.8888889  0.5555556
 0.6666667  0.6666667  0.6666667  0.         0.33333334 0.33333334
 0.         0.33333334 0.6666667  0.8888889  0.6666667  1.
 1.         1.         0.6666667  0.6666667  0.44444445 0.44444445
 0.44444445 0.6666667  0.6666667  0.         0.         1.        ]
Top k classes which perform poorly are:  [32, 82, 108, 80, 105, 88, 124, 15, 14, 13, 26, 12, 53, 37, 68, 123, 25, 9, 66, 61, 73, 98, 43, 89, 75, 36, 51, 40, 109, 71, 70, 107, 48, 31, 63, 5, 29, 96, 33, 19, 106, 20, 54, 120, 76, 118, 119, 83, 84, 85, 30, 101, 99, 35, 6, 55, 24, 90, 92, 104, 95, 67, 110, 87, 0, 103, 28, 34, 38, 116, 44, 45, 27, 50, 102, 18, 8, 121, 122, 57, 3, 112, 10, 117, 47, 22, 42, 91, 2, 21, 100, 65, 46, 79, 111, 72, 56, 69, 59, 64, 41, 115, 114, 113, 62, 94, 1, 4, 7, 11, 16, 17, 23, 39, 97, 49, 58, 60, 74, 77, 78, 81, 86, 93, 52, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.2297, 1.2567, 1.1839, 1.3583, 1.2869, 1.1839, 1.2567,
        1.4474, 1.2567, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839,
        1.2567, 1.3583, 1.3583, 1.2056, 1.2297, 1.1839, 1.2869, 1.5000, 1.5000,
        1.2567, 1.2567, 1.3583, 1.3206, 1.3583, 1.5000, 1.3583, 1.2567, 1.2869,
        1.3583, 1.5000, 1.2567, 1.1839, 1.3583, 1.2056, 1.2297, 1.4004, 1.2567,
        1.2567, 1.2056, 1.2297, 1.3583, 1.1839, 1.2567, 1.3583, 1.1839, 1.5000,
        1.3206, 1.2869, 1.2056, 1.2567, 1.1839, 1.2056, 1.1839, 1.4474, 1.1839,
        1.3583, 1.2056, 1.2056, 1.4474, 1.2567, 1.5000, 1.2056, 1.3583, 1.3583,
        1.2056, 1.4004, 1.1839, 1.4004, 1.3206, 1.1839, 1.1839, 1.2056, 1.5000,
        1.1839, 1.5000, 1.3206, 1.3206, 1.3206, 1.1839, 1.2567, 1.5000, 1.4004,
        1.2869, 1.2297, 1.2869, 1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.4004,
        1.2869, 1.2056, 1.2869, 1.2567, 1.2567, 1.2567, 1.5000, 1.3583, 1.3583,
        1.5000, 1.3583, 1.2567, 1.2056, 1.2567, 1.1839, 1.1839, 1.1839, 1.2567,
        1.2567, 1.3206, 1.3206, 1.3206, 1.2567, 1.2567, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.7703, 0.7433, 0.8161, 0.6417, 0.7131, 0.8161, 0.7433,
        0.5526, 0.7433, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161,
        0.7433, 0.6417, 0.6417, 0.7944, 0.7703, 0.8161, 0.7131, 0.5000, 0.5000,
        0.7433, 0.7433, 0.6417, 0.6794, 0.6417, 0.5000, 0.6417, 0.7433, 0.7131,
        0.6417, 0.5000, 0.7433, 0.8161, 0.6417, 0.7944, 0.7703, 0.5996, 0.7433,
        0.7433, 0.7944, 0.7703, 0.6417, 0.8161, 0.7433, 0.6417, 0.8161, 0.5000,
        0.6794, 0.7131, 0.7944, 0.7433, 0.8161, 0.7944, 0.8161, 0.5526, 0.8161,
        0.6417, 0.7944, 0.7944, 0.5526, 0.7433, 0.5000, 0.7944, 0.6417, 0.6417,
        0.7944, 0.5996, 0.8161, 0.5996, 0.6794, 0.8161, 0.8161, 0.7944, 0.5000,
        0.8161, 0.5000, 0.6794, 0.6794, 0.6794, 0.8161, 0.7433, 0.5000, 0.5996,
        0.7131, 0.7703, 0.7131, 0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.5996,
        0.7131, 0.7944, 0.7131, 0.7433, 0.7433, 0.7433, 0.5000, 0.6417, 0.6417,
        0.5000, 0.6417, 0.7433, 0.7944, 0.7433, 0.8161, 0.8161, 0.8161, 0.7433,
        0.7433, 0.6794, 0.6794, 0.6794, 0.7433, 0.7433, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.260664 Loss T 0.088417 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6891, Accuracy: 612/1134 F1 (53.9683%)


Test set: Average loss: 2.4094, Accuracy: 14325/23808 F1 (60.1688%)


Val set: Average loss: 2.4512, Accuracy: 199/360 F1 (55.2778%)

best acc test 61.798555  acc val 55.277778 acc labeled target 53.968254
saving model...
S real T sketch Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.693681 Loss T 0.082024 Method MME

S real T sketch Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.511531 Loss T 0.085679 Method MME

S real T sketch Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.287655 Loss T 0.063311 Method MME

S real T sketch Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.710342 Loss T 0.062564 Method MME

S real T sketch Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.523603 Loss T 0.048052 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0360, Accuracy: 1127/1134 F1 (99.3827%)


Test set: Average loss: 1.8746, Accuracy: 16014/23808 F1 (67.2631%)


Val set: Average loss: 1.6075, Accuracy: 246/360 F1 (68.3333%)

best acc test 67.263105  acc val 68.333333 acc labeled target 99.382716
saving model...
S real T sketch Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.293995 Loss T 0.080553 Method MME

S real T sketch Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.519121 Loss T 0.083628 Method MME

S real T sketch Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.631687 Loss T 0.067481 Method MME

S real T sketch Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.309744 Loss T 0.062338 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [124, 99, 25, 84, 106, 70, 79, 71, 90, 89, 88, 65, 66, 87, 86, 85, 67, 83, 69, 82, 81, 80, 91, 78, 77, 76, 75, 74, 73, 72, 68, 92, 0, 64, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 98, 97, 96, 95, 93, 94, 62, 61, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.359831 Loss T 0.078405 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0715, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 2.1956, Accuracy: 15277/23808 F1 (64.1675%)


Val set: Average loss: 2.0064, Accuracy: 226/360 F1 (62.7778%)

best acc test 67.263105  acc val 62.777778 acc labeled target 98.236332
saving model...
S real T sketch Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.667217 Loss T 0.052685 Method MME

S real T sketch Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.623616 Loss T 0.067414 Method MME

S real T sketch Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.643655 Loss T 0.051904 Method MME

S real T sketch Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.661419 Loss T 0.051880 Method MME

S real T sketch Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.643580 Loss T 0.044574 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0578, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.9344, Accuracy: 16186/23808 F1 (67.9855%)


Val set: Average loss: 1.6901, Accuracy: 245/360 F1 (68.0556%)

best acc test 67.263105  acc val 68.055556 acc labeled target 98.941799
saving model...
S real T sketch Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.210587 Loss T 0.044667 Method MME

S real T sketch Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.641458 Loss T 0.046516 Method MME

S real T sketch Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.310731 Loss T 0.057963 Method MME

S real T sketch Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.738911 Loss T 0.054977 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [107, 94, 99, 26, 25, 102, 85, 36, 78, 34, 116, 69, 75, 67, 91, 90, 89, 88, 68, 70, 87, 86, 71, 72, 84, 83, 82, 73, 81, 80, 79, 77, 76, 74, 0, 95, 93, 123, 122, 121, 120, 119, 118, 117, 115, 114, 113, 112, 111, 110, 109, 108, 106, 105, 104, 103, 101, 100, 98, 97, 96, 66, 92, 65, 62, 63, 29, 28, 27, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.585648 Loss T 0.038540 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1524, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 2.2077, Accuracy: 15499/23808 F1 (65.1000%)


Val set: Average loss: 1.9837, Accuracy: 234/360 F1 (65.0000%)

best acc test 67.263105  acc val 65.000000 acc labeled target 97.442681
saving model...
S real T sketch Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.525673 Loss T 0.047105 Method MME

S real T sketch Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.050847 Loss T 0.060131 Method MME

S real T sketch Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.399078 Loss T 0.047747 Method MME

S real T sketch Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.443823 Loss T 0.061688 Method MME

S real T sketch Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.427073 Loss T 0.055059 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0410, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 2.0085, Accuracy: 16136/23808 F1 (67.7755%)


Val set: Average loss: 1.8257, Accuracy: 246/360 F1 (68.3333%)

best acc test 67.775538  acc val 68.333333 acc labeled target 98.941799
saving model...
S real T sketch Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.398304 Loss T 0.054342 Method MME

S real T sketch Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.321455 Loss T 0.063724 Method MME

S real T sketch Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.738194 Loss T 0.054218 Method MME

S real T sketch Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.374893 Loss T 0.036411 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [20, 9, 79, 111, 77, 101, 106, 98, 95, 33, 28, 88, 87, 89, 86, 90, 85, 84, 83, 0, 81, 91, 80, 78, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 82, 92, 96, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 93, 112, 109, 108, 107, 105, 104, 103, 102, 100, 99, 97, 66, 110, 65, 62, 63, 30, 29, 27, 26, 25, 24, 23, 22, 21, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 31, 64, 32, 35, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 34, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.390838 Loss T 0.049722 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0703, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 2.1796, Accuracy: 15548/23808 F1 (65.3058%)


Val set: Average loss: 1.9291, Accuracy: 233/360 F1 (64.7222%)

best acc test 67.775538  acc val 64.722222 acc labeled target 98.589065
saving model...
S real T sketch Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.145494 Loss T 0.070434 Method MME

S real T sketch Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.316425 Loss T 0.060324 Method MME

S real T sketch Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.434787 Loss T 0.040047 Method MME

S real T sketch Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.734874 Loss T 0.052741 Method MME

S real T sketch Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.374063 Loss T 0.047278 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0479, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.9849, Accuracy: 16214/23808 F1 (68.1032%)


Val set: Average loss: 1.5938, Accuracy: 253/360 F1 (70.2778%)

best acc test 68.103159  acc val 70.277778 acc labeled target 98.941799
saving model...
S real T sketch Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.267167 Loss T 0.047449 Method MME

S real T sketch Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.500884 Loss T 0.038007 Method MME

S real T sketch Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.442804 Loss T 0.034643 Method MME

S real T sketch Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.090121 Loss T 0.044306 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [82, 45, 20, 8, 40, 73, 9, 30, 124, 38, 72, 19, 91, 90, 89, 88, 87, 86, 85, 84, 0, 92, 81, 80, 79, 78, 77, 76, 75, 74, 71, 70, 69, 83, 93, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 68, 109, 67, 62, 65, 29, 28, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15, 14, 13, 12, 11, 10, 7, 6, 5, 4, 3, 2, 1, 31, 32, 33, 34, 64, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 66, 51, 49, 48, 47, 46, 44, 43, 42, 41, 39, 37, 36, 35, 50, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.404729 Loss T 0.046097 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0848, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 2.1603, Accuracy: 15812/23808 F1 (66.4146%)


Val set: Average loss: 1.8811, Accuracy: 232/360 F1 (64.4444%)

best acc test 68.103159  acc val 64.444444 acc labeled target 98.853616
saving model...
S real T sketch Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.486281 Loss T 0.051380 Method MME

S real T sketch Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.647375 Loss T 0.053738 Method MME

S real T sketch Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.040360 Loss T 0.029233 Method MME

S real T sketch Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 1.123114 Loss T 0.055923 Method MME

S real T sketch Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.404164 Loss T 0.044369 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0264, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 2.0387, Accuracy: 16348/23808 F1 (68.6660%)


Val set: Average loss: 1.6615, Accuracy: 245/360 F1 (68.0556%)

best acc test 68.103159  acc val 68.055556 acc labeled target 99.294533
saving model...
S real T sketch Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.226602 Loss T 0.026701 Method MME

S real T sketch Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.321302 Loss T 0.041745 Method MME

S real T sketch Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.313689 Loss T 0.045529 Method MME

S real T sketch Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.964044 Loss T 0.052579 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [99, 61, 90, 30, 118, 56, 14, 108, 81, 82, 83, 84, 0, 86, 87, 88, 89, 85, 80, 78, 91, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 92, 95, 94, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 93, 110, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 66, 109, 65, 62, 63, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 64, 31, 33, 124, 60, 59, 58, 57, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.055645 Loss T 0.039417 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0838, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 2.2743, Accuracy: 15661/23808 F1 (65.7804%)


Val set: Average loss: 2.0098, Accuracy: 236/360 F1 (65.5556%)

best acc test 68.103159  acc val 65.555556 acc labeled target 98.059965
saving model...
S real T sketch Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.251769 Loss T 0.049351 Method MME

S real T sketch Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.457628 Loss T 0.043826 Method MME

S real T sketch Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.542802 Loss T 0.050157 Method MME

S real T sketch Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.335658 Loss T 0.046481 Method MME

S real T sketch Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.104061 Loss T 0.022464 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0220, Accuracy: 1127/1134 F1 (99.3827%)


Test set: Average loss: 1.9904, Accuracy: 16531/23808 F1 (69.4346%)


Val set: Average loss: 1.5929, Accuracy: 255/360 F1 (70.8333%)

best acc test 69.434644  acc val 70.833333 acc labeled target 99.382716
saving model...
S real T sketch Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.141999 Loss T 0.057097 Method MME

S real T sketch Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.259064 Loss T 0.048443 Method MME

S real T sketch Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.414513 Loss T 0.044880 Method MME

S real T sketch Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.205765 Loss T 0.039355 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [50, 32, 14, 114, 115, 9, 96, 87, 86, 85, 81, 89, 90, 84, 83, 82, 91, 88, 80, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 113, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 66, 108, 65, 62, 63, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 34, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.223554 Loss T 0.047921 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1149, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 2.2066, Accuracy: 15982/23808 F1 (67.1287%)


Val set: Average loss: 1.8942, Accuracy: 236/360 F1 (65.5556%)

best acc test 69.434644  acc val 65.555556 acc labeled target 97.530864
saving model...
S real T sketch Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.217827 Loss T 0.033838 Method MME

S real T sketch Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.060063 Loss T 0.053926 Method MME

S real T sketch Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.521645 Loss T 0.042676 Method MME

S real T sketch Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.423892 Loss T 0.048326 Method MME

S real T sketch Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.184331 Loss T 0.040826 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0409, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 2.0153, Accuracy: 16553/23808 F1 (69.5270%)


Val set: Average loss: 1.6826, Accuracy: 251/360 F1 (69.7222%)

best acc test 69.434644  acc val 69.722222 acc labeled target 99.029982
saving model...
S real T sketch Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.144527 Loss T 0.039830 Method MME

S real T sketch Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.179243 Loss T 0.055020 Method MME

S real T sketch Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.423864 Loss T 0.039285 Method MME

S real T sketch Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.282152 Loss T 0.029282 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [57, 37, 34, 4, 60, 110, 118, 86, 9, 25, 26, 85, 0, 88, 84, 89, 90, 91, 92, 87, 83, 79, 81, 80, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 82, 93, 96, 95, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 94, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 68, 108, 67, 62, 65, 30, 29, 28, 27, 24, 23, 22, 21, 20, 19, 18, 17, 31, 16, 14, 13, 12, 11, 10, 8, 7, 6, 5, 3, 2, 1, 15, 66, 32, 35, 64, 63, 124, 61, 59, 58, 56, 55, 54, 53, 52, 51, 33, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 36, 49, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.106243 Loss T 0.050942 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1084, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 2.1451, Accuracy: 16029/23808 F1 (67.3261%)


Val set: Average loss: 1.8724, Accuracy: 238/360 F1 (66.1111%)

best acc test 69.434644  acc val 66.111111 acc labeled target 98.324515
saving model...
S real T sketch Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.065700 Loss T 0.049475 Method MME

S real T sketch Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.105307 Loss T 0.043486 Method MME

S real T sketch Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.310867 Loss T 0.025110 Method MME

S real T sketch Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.304372 Loss T 0.037733 Method MME

S real T sketch Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.116440 Loss T 0.019280 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0284, Accuracy: 1126/1134 F1 (99.2945%)


Test set: Average loss: 2.0717, Accuracy: 16558/23808 F1 (69.5480%)


Val set: Average loss: 1.7545, Accuracy: 250/360 F1 (69.4444%)

best acc test 69.434644  acc val 69.444444 acc labeled target 99.294533
saving model...
S real T sketch Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.302727 Loss T 0.035250 Method MME

S real T sketch Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.135173 Loss T 0.040192 Method MME

S real T sketch Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.279682 Loss T 0.034631 Method MME

S real T sketch Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.280879 Loss T 0.059756 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [33, 76, 52, 117, 91, 61, 3, 80, 90, 89, 88, 87, 81, 86, 85, 84, 83, 82, 0, 78, 92, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 77, 94, 66, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 108, 65, 62, 63, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 29, 64, 30, 32, 124, 60, 59, 58, 57, 56, 55, 54, 53, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.055034 Loss T 0.021288 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0719, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 2.2178, Accuracy: 16189/23808 F1 (67.9982%)


Val set: Average loss: 1.9800, Accuracy: 234/360 F1 (65.0000%)

best acc test 69.434644  acc val 65.000000 acc labeled target 98.148148
saving model...
S real T sketch Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.190531 Loss T 0.037699 Method MME

S real T sketch Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.262663 Loss T 0.027761 Method MME

S real T sketch Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.262312 Loss T 0.027007 Method MME

S real T sketch Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.444981 Loss T 0.025672 Method MME

S real T sketch Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.386828 Loss T 0.036025 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0278, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 2.1364, Accuracy: 16562/23808 F1 (69.5648%)


Val set: Average loss: 1.8507, Accuracy: 242/360 F1 (67.2222%)

best acc test 69.434644  acc val 67.222222 acc labeled target 99.559083
saving model...
S real T sketch Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.051376 Loss T 0.023636 Method MME

S real T sketch Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.474445 Loss T 0.018372 Method MME

S real T sketch Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.259398 Loss T 0.036383 Method MME

S real T sketch Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.476865 Loss T 0.037530 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [32, 91, 60, 44, 48, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 79, 93, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 66, 65, 62, 63, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 64, 29, 31, 124, 61, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 47, 46, 45, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 30, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.027774 Loss T 0.021964 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0596, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 2.2111, Accuracy: 16214/23808 F1 (68.1032%)


Val set: Average loss: 1.9009, Accuracy: 247/360 F1 (68.6111%)

best acc test 69.434644  acc val 68.611111 acc labeled target 98.853616
saving model...
S real T sketch Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.399724 Loss T 0.030882 Method MME

S real T sketch Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.163228 Loss T 0.033442 Method MME

S real T sketch Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.508165 Loss T 0.038215 Method MME

S real T sketch Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.111954 Loss T 0.048966 Method MME

S real T sketch Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.702099 Loss T 0.038609 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0152, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 2.1391, Accuracy: 16573/23808 F1 (69.6111%)


Val set: Average loss: 1.7700, Accuracy: 248/360 F1 (68.8889%)

best acc test 69.434644  acc val 68.888889 acc labeled target 99.559083
saving model...
S real T sketch Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.266115 Loss T 0.046873 Method MME

S real T sketch Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.236778 Loss T 0.054042 Method MME

S real T sketch Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.108553 Loss T 0.035822 Method MME

S real T sketch Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.406072 Loss T 0.027306 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [48, 68, 118, 117, 30, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 86, 80, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 67, 66, 79, 92, 94, 65, 123, 122, 121, 120, 119, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 93, 64, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 31, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.414760 Loss T 0.040236 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0611, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 2.1871, Accuracy: 16313/23808 F1 (68.5190%)


Val set: Average loss: 1.9223, Accuracy: 239/360 F1 (66.3889%)

best acc test 69.434644  acc val 66.388889 acc labeled target 98.500882
saving model...
S real T sketch Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.051733 Loss T 0.024057 Method MME

S real T sketch Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.453667 Loss T 0.026140 Method MME

S real T sketch Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.106877 Loss T 0.034826 Method MME

S real T sketch Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.211349 Loss T 0.039238 Method MME

S real T sketch Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.121940 Loss T 0.027524 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0182, Accuracy: 1130/1134 F1 (99.6473%)


Test set: Average loss: 2.1410, Accuracy: 16673/23808 F1 (70.0311%)


Val set: Average loss: 1.7954, Accuracy: 253/360 F1 (70.2778%)

best acc test 69.434644  acc val 70.277778 acc labeled target 99.647266
saving model...
S real T sketch Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.401835 Loss T 0.022254 Method MME

S real T sketch Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.045038 Loss T 0.043226 Method MME

S real T sketch Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.341174 Loss T 0.043990 Method MME

S real T sketch Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.307071 Loss T 0.033657 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [80, 76, 25, 95, 81, 82, 83, 84, 85, 0, 88, 89, 90, 91, 92, 87, 86, 79, 77, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 78, 93, 94, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 64, 63, 62, 61, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.416154 Loss T 0.023567 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0579, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 2.2098, Accuracy: 16314/23808 F1 (68.5232%)


Val set: Average loss: 1.9376, Accuracy: 248/360 F1 (68.8889%)

best acc test 69.434644  acc val 68.888889 acc labeled target 98.677249
saving model...
S real T sketch Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.308025 Loss T 0.014218 Method MME

S real T sketch Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.339618 Loss T 0.021308 Method MME

S real T sketch Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.458651 Loss T 0.039016 Method MME

S real T sketch Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.242526 Loss T 0.041345 Method MME

S real T sketch Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.371445 Loss T 0.017296 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0187, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 2.0995, Accuracy: 16777/23808 F1 (70.4679%)


Val set: Average loss: 1.6250, Accuracy: 257/360 F1 (71.3889%)

best acc test 70.467910  acc val 71.388889 acc labeled target 99.470899
saving model...
S real T sketch Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.193329 Loss T 0.024398 Method MME

S real T sketch Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.334282 Loss T 0.029507 Method MME

S real T sketch Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.025433 Loss T 0.049737 Method MME

S real T sketch Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.380754 Loss T 0.031153 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [124, 61, 3, 5, 53, 100, 0, 82, 83, 84, 85, 87, 81, 88, 89, 90, 86, 80, 77, 78, 91, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 79, 92, 94, 66, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 103, 102, 101, 99, 98, 97, 96, 95, 109, 65, 62, 63, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 4, 2, 1, 15, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.096384 Loss T 0.035834 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0433, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 2.2107, Accuracy: 16418/23808 F1 (68.9600%)


Val set: Average loss: 1.8859, Accuracy: 246/360 F1 (68.3333%)

best acc test 70.467910  acc val 68.333333 acc labeled target 99.206349
saving model...
S real T sketch Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.593796 Loss T 0.022261 Method MME

S real T sketch Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.236128 Loss T 0.039740 Method MME

S real T sketch Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.036121 Loss T 0.034133 Method MME

S real T sketch Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.118138 Loss T 0.035262 Method MME

S real T sketch Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.047071 Loss T 0.023932 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0322, Accuracy: 1127/1134 F1 (99.3827%)


Test set: Average loss: 2.1543, Accuracy: 16748/23808 F1 (70.3461%)


Val set: Average loss: 1.7308, Accuracy: 249/360 F1 (69.1667%)

best acc test 70.467910  acc val 69.166667 acc labeled target 99.382716
saving model...
S real T sketch Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.252518 Loss T 0.020894 Method MME

S real T sketch Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.043747 Loss T 0.017954 Method MME

S real T sketch Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.093608 Loss T 0.034929 Method MME

S real T sketch Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.141495 Loss T 0.024159 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [64, 21, 106, 117, 86, 58, 95, 88, 87, 90, 85, 84, 83, 82, 81, 89, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 91, 92, 0, 65, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 94, 62, 124, 28, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 61, 60, 59, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.149615 Loss T 0.029004 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0575, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 2.2632, Accuracy: 16384/23808 F1 (68.8172%)


Val set: Average loss: 1.9651, Accuracy: 247/360 F1 (68.6111%)

best acc test 70.467910  acc val 68.611111 acc labeled target 98.677249
saving model...
S real T sketch Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.265060 Loss T 0.023408 Method MME

S real T sketch Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.034516 Loss T 0.025335 Method MME

S real T sketch Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.193196 Loss T 0.024327 Method MME

S real T sketch Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.028489 Loss T 0.018565 Method MME

S real T sketch Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.192476 Loss T 0.025700 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0136, Accuracy: 1129/1134 F1 (99.5591%)


Test set: Average loss: 2.1119, Accuracy: 16828/23808 F1 (70.6821%)


Val set: Average loss: 1.6761, Accuracy: 254/360 F1 (70.5556%)

best acc test 70.467910  acc val 70.555556 acc labeled target 99.559083
saving model...
S real T sketch Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.183812 Loss T 0.035032 Method MME

S real T sketch Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.611979 Loss T 0.034301 Method MME

S real T sketch Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.407667 Loss T 0.026389 Method MME

S real T sketch Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.236105 Loss T 0.027941 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [65, 24, 21, 20, 105, 0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 66, 67, 68, 69, 70, 71, 92, 72, 74, 75, 76, 77, 78, 79, 73, 93, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 94, 111, 109, 108, 107, 106, 104, 103, 102, 101, 100, 99, 98, 97, 110, 64, 62, 124, 30, 29, 28, 27, 26, 25, 23, 22, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 63, 32, 34, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.284515 Loss T 0.015952 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0342, Accuracy: 1125/1134 F1 (99.2064%)


Test set: Average loss: 2.2855, Accuracy: 16481/23808 F1 (69.2246%)


Val set: Average loss: 1.8846, Accuracy: 243/360 F1 (67.5000%)

best acc test 70.467910  acc val 67.500000 acc labeled target 99.206349
saving model...
S real T sketch Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.262963 Loss T 0.027340 Method MME

S real T sketch Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.268385 Loss T 0.022237 Method MME

S real T sketch Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.736116 Loss T 0.052026 Method MME

S real T sketch Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.063099 Loss T 0.029003 Method MME

S real T sketch Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.346068 Loss T 0.035158 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0207, Accuracy: 1128/1134 F1 (99.4709%)


Test set: Average loss: 2.1848, Accuracy: 16843/23808 F1 (70.7451%)


Val set: Average loss: 1.8421, Accuracy: 254/360 F1 (70.5556%)

best acc test 70.467910  acc val 70.555556 acc labeled target 99.470899
saving model...
S real T sketch Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.135034 Loss T 0.034805 Method MME

S real T sketch Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.657118 Loss T 0.028074 Method MME

S real T sketch Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.236066 Loss T 0.014935 Method MME

S real T sketch Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.178871 Loss T 0.030970 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 36, 4, 89, 86, 21, 0, 90, 88, 87, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 92, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 30, 63, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.245053 Loss T 0.034605 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0689, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 2.2484, Accuracy: 16558/23808 F1 (69.5480%)


Val set: Average loss: 1.9109, Accuracy: 247/360 F1 (68.6111%)

best acc test 70.467910  acc val 68.611111 acc labeled target 99.029982
saving model...
S real T sketch Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.477941 Loss T 0.029915 Method MME

S real T sketch Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.158326 Loss T 0.024893 Method MME

S real T sketch Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.421601 Loss T 0.019523 Method MME

Terminated
