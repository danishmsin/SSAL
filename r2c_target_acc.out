Dataset multi Source real Target clipart Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  70358
Unlabelled Target Dataset Size:  18325
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  18325 Source:  70358
Unlabeled Target Data Batches: 381
S real T clipart Train Ep: 0 lr0.01 	 Loss Classification: 4.913864 Loss T 0.470833 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9638, Accuracy: 10/1134 F1 (0.8818%)


Test set: Average loss: 4.9661, Accuracy: 202/18312 F1 (1.1031%)


Val set: Average loss: 4.9799, Accuracy: 2/360 F1 (0.5556%)

best acc test 1.103102  acc val 0.555556 acc labeled target 0.881834
saving model...
S real T clipart Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.560890 Loss T 0.286010 Method MME

S real T clipart Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.155292 Loss T 0.229508 Method MME

S real T clipart Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 0.872413 Loss T 0.237713 Method MME

S real T clipart Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.547672 Loss T 0.199413 Method MME

S real T clipart Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.725123 Loss T 0.168536 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5468, Accuracy: 509/1134 F1 (44.8854%)


Test set: Average loss: 2.2427, Accuracy: 9074/18312 F1 (49.5522%)


Val set: Average loss: 2.3145, Accuracy: 166/360 F1 (46.1111%)

best acc test 49.552206  acc val 46.111111 acc labeled target 44.885362
saving model...
S real T clipart Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.768790 Loss T 0.183633 Method MME

S real T clipart Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.787926 Loss T 0.131653 Method MME

S real T clipart Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.810119 Loss T 0.160148 Method MME

S real T clipart Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.828253 Loss T 0.128074 Method MME

S real T clipart Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.395649 Loss T 0.132408 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2881, Accuracy: 565/1134 F1 (49.8236%)


Test set: Average loss: 2.0895, Accuracy: 9958/18312 F1 (54.3796%)


Val set: Average loss: 2.2507, Accuracy: 180/360 F1 (50.0000%)

best acc test 54.379642  acc val 50.000000 acc labeled target 49.823633
saving model...
S real T clipart Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.366965 Loss T 0.128446 Method MME

S real T clipart Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.948712 Loss T 0.157970 Method MME

S real T clipart Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.813315 Loss T 0.086565 Method MME

S real T clipart Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.413056 Loss T 0.129824 Method MME

S real T clipart Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.859446 Loss T 0.135345 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3050, Accuracy: 567/1134 F1 (50.0000%)


Test set: Average loss: 2.0958, Accuracy: 10217/18312 F1 (55.7940%)


Val set: Average loss: 2.1364, Accuracy: 202/360 F1 (56.1111%)

best acc test 55.794015  acc val 56.111111 acc labeled target 50.000000
saving model...
S real T clipart Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.808109 Loss T 0.143962 Method MME

S real T clipart Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.615201 Loss T 0.108845 Method MME

S real T clipart Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.414148 Loss T 0.120787 Method MME

S real T clipart Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.666777 Loss T 0.123771 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  0.5555556  0.6666667  0.33333334 0.         0.
 0.22222222 0.6666667  0.5555556  0.         0.11111111 0.7777778
 0.33333334 1.         0.8888889  0.11111111 0.7777778  1.
 0.7777778  0.6666667  0.         0.7777778  0.6666667  0.5555556
 0.33333334 0.5555556  0.33333334 1.         0.11111111 0.33333334
 0.33333334 0.11111111 0.6666667  0.8888889  0.5555556  0.6666667
 0.5555556  0.8888889  0.6666667  0.         0.5555556  0.44444445
 0.6666667  0.7777778  0.11111111 0.6666667  0.6666667  0.6666667
 0.33333334 0.6666667  0.6666667  0.11111111 1.         0.6666667
 0.6666667  0.8888889  1.         0.7777778  0.         0.5555556
 0.7777778  0.6666667  0.7777778  0.5555556  0.7777778  0.33333334
 0.22222222 0.7777778  0.44444445 0.         0.5555556  0.33333334
 0.6666667  0.33333334 0.         0.11111111 0.         0.33333334
 0.         0.6666667  0.11111111 0.8888889  0.         0.
 0.44444445 1.         0.5555556  0.6666667  0.         0.5555556
 0.33333334 0.6666667  0.11111111 0.6666667  0.33333334 0.6666667
 0.8888889  0.44444445 0.44444445 0.         0.7777778  0.22222222
 0.22222222 0.33333334 0.5555556  0.22222222 0.44444445 0.5555556
 0.         0.6666667  0.         1.         0.5555556  1.
 0.7777778  0.6666667  0.         1.         0.6666667  0.33333334
 1.         0.6666667  0.33333334 1.         0.         0.7777778 ]
Top k classes which perform poorly are:  [76, 82, 83, 116, 99, 74, 110, 20, 9, 69, 39, 108, 5, 4, 124, 58, 88, 78, 31, 28, 75, 44, 51, 10, 92, 15, 80, 105, 6, 102, 66, 101, 94, 103, 3, 65, 90, 77, 71, 73, 122, 12, 119, 30, 29, 26, 24, 48, 84, 106, 68, 97, 41, 98, 25, 112, 34, 70, 36, 86, 40, 23, 8, 107, 89, 59, 104, 1, 63, 7, 91, 87, 2, 121, 118, 93, 115, 95, 19, 32, 42, 53, 22, 50, 72, 35, 109, 38, 79, 45, 61, 46, 47, 49, 54, 114, 100, 0, 62, 125, 18, 21, 11, 57, 43, 64, 67, 60, 16, 55, 14, 37, 33, 96, 81, 123, 13, 120, 85, 17, 113, 111, 52, 56, 117, 27]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.2869, 1.2567, 1.3583, 1.5000, 1.5000, 1.4004, 1.2567, 1.2869,
        1.5000, 1.4474, 1.2297, 1.3583, 1.1839, 1.2056, 1.4474, 1.2297, 1.1839,
        1.2297, 1.2567, 1.5000, 1.2297, 1.2567, 1.2869, 1.3583, 1.2869, 1.3583,
        1.1839, 1.4474, 1.3583, 1.3583, 1.4474, 1.2567, 1.2056, 1.2869, 1.2567,
        1.2869, 1.2056, 1.2567, 1.5000, 1.2869, 1.3206, 1.2567, 1.2297, 1.4474,
        1.2567, 1.2567, 1.2567, 1.3583, 1.2567, 1.2567, 1.4474, 1.1839, 1.2567,
        1.2567, 1.2056, 1.1839, 1.2297, 1.5000, 1.2869, 1.2297, 1.2567, 1.2297,
        1.2869, 1.2297, 1.3583, 1.4004, 1.2297, 1.3206, 1.5000, 1.2869, 1.3583,
        1.2567, 1.3583, 1.5000, 1.4474, 1.5000, 1.3583, 1.5000, 1.2567, 1.4474,
        1.2056, 1.5000, 1.5000, 1.3206, 1.1839, 1.2869, 1.2567, 1.5000, 1.2869,
        1.3583, 1.2567, 1.4474, 1.2567, 1.3583, 1.2567, 1.2056, 1.3206, 1.3206,
        1.5000, 1.2297, 1.4004, 1.4004, 1.3583, 1.2869, 1.4004, 1.3206, 1.2869,
        1.5000, 1.2567, 1.5000, 1.1839, 1.2869, 1.1839, 1.2297, 1.2567, 1.5000,
        1.1839, 1.2567, 1.3583, 1.1839, 1.2567, 1.3583, 1.1839, 1.5000, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.7131, 0.7433, 0.6417, 0.5000, 0.5000, 0.5996, 0.7433, 0.7131,
        0.5000, 0.5526, 0.7703, 0.6417, 0.8161, 0.7944, 0.5526, 0.7703, 0.8161,
        0.7703, 0.7433, 0.5000, 0.7703, 0.7433, 0.7131, 0.6417, 0.7131, 0.6417,
        0.8161, 0.5526, 0.6417, 0.6417, 0.5526, 0.7433, 0.7944, 0.7131, 0.7433,
        0.7131, 0.7944, 0.7433, 0.5000, 0.7131, 0.6794, 0.7433, 0.7703, 0.5526,
        0.7433, 0.7433, 0.7433, 0.6417, 0.7433, 0.7433, 0.5526, 0.8161, 0.7433,
        0.7433, 0.7944, 0.8161, 0.7703, 0.5000, 0.7131, 0.7703, 0.7433, 0.7703,
        0.7131, 0.7703, 0.6417, 0.5996, 0.7703, 0.6794, 0.5000, 0.7131, 0.6417,
        0.7433, 0.6417, 0.5000, 0.5526, 0.5000, 0.6417, 0.5000, 0.7433, 0.5526,
        0.7944, 0.5000, 0.5000, 0.6794, 0.8161, 0.7131, 0.7433, 0.5000, 0.7131,
        0.6417, 0.7433, 0.5526, 0.7433, 0.6417, 0.7433, 0.7944, 0.6794, 0.6794,
        0.5000, 0.7703, 0.5996, 0.5996, 0.6417, 0.7131, 0.5996, 0.6794, 0.7131,
        0.5000, 0.7433, 0.5000, 0.8161, 0.7131, 0.8161, 0.7703, 0.7433, 0.5000,
        0.8161, 0.7433, 0.6417, 0.8161, 0.7433, 0.6417, 0.8161, 0.5000, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.011344 Loss T 0.111397 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4862, Accuracy: 566/1134 F1 (49.9118%)


Test set: Average loss: 2.3299, Accuracy: 9940/18312 F1 (54.2813%)


Val set: Average loss: 2.5379, Accuracy: 183/360 F1 (50.8333%)

best acc test 55.794015  acc val 50.833333 acc labeled target 49.911817
saving model...
S real T clipart Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.911458 Loss T 0.108919 Method MME

S real T clipart Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.422325 Loss T 0.101233 Method MME

S real T clipart Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.617521 Loss T 0.108670 Method MME

S real T clipart Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.643620 Loss T 0.108138 Method MME

S real T clipart Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.886732 Loss T 0.100881 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0700, Accuracy: 624/1134 F1 (55.0265%)


Test set: Average loss: 1.8716, Accuracy: 11063/18312 F1 (60.4139%)


Val set: Average loss: 1.9740, Accuracy: 214/360 F1 (59.4444%)

best acc test 60.413936  acc val 59.444444 acc labeled target 55.026455
saving model...
S real T clipart Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.971576 Loss T 0.103032 Method MME

S real T clipart Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.280002 Loss T 0.106017 Method MME

S real T clipart Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.420820 Loss T 0.103469 Method MME

S real T clipart Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.278867 Loss T 0.089273 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  0.8888889  0.6666667  0.33333334 0.33333334 0.22222222
 0.33333334 0.8888889  0.33333334 0.22222222 0.5555556  0.
 0.         0.22222222 1.         0.6666667  1.         0.6666667
 1.         0.6666667  0.         0.6666667  0.6666667  0.33333334
 0.5555556  0.33333334 0.5555556  1.         0.         0.33333334
 0.5555556  0.11111111 0.33333334 0.8888889  0.6666667  0.7777778
 0.6666667  0.6666667  0.22222222 0.6666667  1.         1.
 0.5555556  0.44444445 0.33333334 0.8888889  1.         0.6666667
 0.33333334 0.6666667  0.8888889  0.44444445 1.         0.7777778
 0.11111111 0.6666667  0.8888889  0.8888889  0.         0.8888889
 1.         0.11111111 0.8888889  0.6666667  1.         0.11111111
 0.         0.8888889  0.6666667  0.22222222 0.44444445 0.33333334
 0.6666667  0.         0.         0.22222222 0.44444445 1.
 0.         0.7777778  0.11111111 0.8888889  0.         0.
 1.         0.8888889  0.44444445 1.         0.         0.33333334
 0.11111111 0.6666667  0.         0.5555556  0.22222222 0.7777778
 0.6666667  0.44444445 1.         0.33333334 1.         0.7777778
 0.33333334 0.44444445 0.22222222 0.33333334 0.         0.7777778
 0.11111111 0.6666667  0.33333334 0.8888889  0.8888889  1.
 1.         0.6666667  0.33333334 1.         0.6666667  0.8888889
 0.8888889  0.6666667  0.5555556  1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [11, 82, 20, 83, 78, 28, 88, 74, 12, 73, 92, 106, 58, 124, 66, 90, 54, 31, 65, 108, 80, 61, 38, 69, 75, 94, 13, 9, 5, 104, 110, 44, 48, 105, 71, 32, 102, 99, 23, 6, 8, 4, 25, 116, 29, 3, 89, 43, 103, 97, 70, 76, 51, 86, 122, 93, 24, 26, 42, 30, 10, 68, 72, 91, 96, 0, 55, 2, 121, 15, 17, 118, 19, 21, 22, 115, 63, 34, 109, 36, 37, 39, 47, 49, 95, 107, 53, 101, 35, 79, 112, 111, 119, 120, 62, 85, 1, 7, 33, 50, 56, 57, 59, 45, 125, 67, 81, 123, 84, 14, 16, 18, 117, 27, 98, 64, 113, 40, 41, 87, 46, 77, 52, 100, 60, 114]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.2056, 1.2567, 1.3583, 1.3583, 1.4004, 1.3583, 1.2056, 1.3583,
        1.4004, 1.2869, 1.5000, 1.5000, 1.4004, 1.1839, 1.2567, 1.1839, 1.2567,
        1.1839, 1.2567, 1.5000, 1.2567, 1.2567, 1.3583, 1.2869, 1.3583, 1.2869,
        1.1839, 1.5000, 1.3583, 1.2869, 1.4474, 1.3583, 1.2056, 1.2567, 1.2297,
        1.2567, 1.2567, 1.4004, 1.2567, 1.1839, 1.1839, 1.2869, 1.3206, 1.3583,
        1.2056, 1.1839, 1.2567, 1.3583, 1.2567, 1.2056, 1.3206, 1.1839, 1.2297,
        1.4474, 1.2567, 1.2056, 1.2056, 1.5000, 1.2056, 1.1839, 1.4474, 1.2056,
        1.2567, 1.1839, 1.4474, 1.5000, 1.2056, 1.2567, 1.4004, 1.3206, 1.3583,
        1.2567, 1.5000, 1.5000, 1.4004, 1.3206, 1.1839, 1.5000, 1.2297, 1.4474,
        1.2056, 1.5000, 1.5000, 1.1839, 1.2056, 1.3206, 1.1839, 1.5000, 1.3583,
        1.4474, 1.2567, 1.5000, 1.2869, 1.4004, 1.2297, 1.2567, 1.3206, 1.1839,
        1.3583, 1.1839, 1.2297, 1.3583, 1.3206, 1.4004, 1.3583, 1.5000, 1.2297,
        1.4474, 1.2567, 1.3583, 1.2056, 1.2056, 1.1839, 1.1839, 1.2567, 1.3583,
        1.1839, 1.2567, 1.2056, 1.2056, 1.2567, 1.2869, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.7944, 0.7433, 0.6417, 0.6417, 0.5996, 0.6417, 0.7944, 0.6417,
        0.5996, 0.7131, 0.5000, 0.5000, 0.5996, 0.8161, 0.7433, 0.8161, 0.7433,
        0.8161, 0.7433, 0.5000, 0.7433, 0.7433, 0.6417, 0.7131, 0.6417, 0.7131,
        0.8161, 0.5000, 0.6417, 0.7131, 0.5526, 0.6417, 0.7944, 0.7433, 0.7703,
        0.7433, 0.7433, 0.5996, 0.7433, 0.8161, 0.8161, 0.7131, 0.6794, 0.6417,
        0.7944, 0.8161, 0.7433, 0.6417, 0.7433, 0.7944, 0.6794, 0.8161, 0.7703,
        0.5526, 0.7433, 0.7944, 0.7944, 0.5000, 0.7944, 0.8161, 0.5526, 0.7944,
        0.7433, 0.8161, 0.5526, 0.5000, 0.7944, 0.7433, 0.5996, 0.6794, 0.6417,
        0.7433, 0.5000, 0.5000, 0.5996, 0.6794, 0.8161, 0.5000, 0.7703, 0.5526,
        0.7944, 0.5000, 0.5000, 0.8161, 0.7944, 0.6794, 0.8161, 0.5000, 0.6417,
        0.5526, 0.7433, 0.5000, 0.7131, 0.5996, 0.7703, 0.7433, 0.6794, 0.8161,
        0.6417, 0.8161, 0.7703, 0.6417, 0.6794, 0.5996, 0.6417, 0.5000, 0.7703,
        0.5526, 0.7433, 0.6417, 0.7944, 0.7944, 0.8161, 0.8161, 0.7433, 0.6417,
        0.8161, 0.7433, 0.7944, 0.7944, 0.7433, 0.7131, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.504825 Loss T 0.071254 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2522, Accuracy: 614/1134 F1 (54.1446%)


Test set: Average loss: 2.0253, Accuracy: 10965/18312 F1 (59.8788%)


Val set: Average loss: 2.2400, Accuracy: 194/360 F1 (53.8889%)

best acc test 60.413936  acc val 53.888889 acc labeled target 54.144621
saving model...
S real T clipart Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.457634 Loss T 0.087440 Method MME

S real T clipart Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.547133 Loss T 0.070378 Method MME

S real T clipart Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.417887 Loss T 0.084682 Method MME

S real T clipart Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.222453 Loss T 0.090218 Method MME

S real T clipart Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.513662 Loss T 0.095186 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0186, Accuracy: 683/1134 F1 (60.2293%)


Test set: Average loss: 1.8117, Accuracy: 11844/18312 F1 (64.6789%)


Val set: Average loss: 1.9094, Accuracy: 226/360 F1 (62.7778%)

best acc test 64.678899  acc val 62.777778 acc labeled target 60.229277
saving model...
S real T clipart Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.543073 Loss T 0.098392 Method MME

S real T clipart Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.549776 Loss T 0.078900 Method MME

S real T clipart Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.798815 Loss T 0.089146 Method MME

S real T clipart Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.316881 Loss T 0.083540 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  0.6666667  0.6666667  0.44444445 0.44444445 0.44444445
 0.33333334 0.6666667  0.33333334 0.         0.5555556  0.6666667
 0.22222222 0.22222222 0.6666667  0.7777778  1.         0.8888889
 0.7777778  0.6666667  0.         1.         1.         0.6666667
 0.33333334 0.33333334 0.5555556  0.7777778  0.11111111 0.8888889
 0.5555556  0.         0.22222222 1.         0.5555556  1.
 0.6666667  0.7777778  0.5555556  0.44444445 1.         0.8888889
 0.6666667  0.5555556  0.         1.         1.         0.6666667
 0.33333334 0.6666667  1.         0.5555556  1.         1.
 0.7777778  1.         0.7777778  0.7777778  0.         0.6666667
 0.7777778  0.5555556  0.8888889  0.6666667  1.         1.
 0.33333334 0.8888889  0.44444445 0.33333334 0.5555556  0.44444445
 0.6666667  0.5555556  0.33333334 0.5555556  0.44444445 1.
 0.         0.6666667  0.         0.8888889  0.         0.33333334
 1.         1.         0.33333334 1.         0.         0.5555556
 0.44444445 0.6666667  0.5555556  0.7777778  0.22222222 0.7777778
 0.5555556  0.6666667  0.8888889  0.5555556  0.8888889  0.5555556
 0.44444445 0.44444445 0.33333334 0.33333334 0.44444445 0.8888889
 0.22222222 0.6666667  0.33333334 1.         0.6666667  1.
 1.         0.7777778  0.11111111 1.         0.         0.5555556
 1.         0.6666667  0.33333334 1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [31, 58, 44, 78, 124, 9, 80, 82, 118, 20, 88, 116, 28, 108, 32, 94, 13, 12, 122, 74, 48, 6, 8, 105, 110, 104, 24, 69, 83, 66, 25, 86, 103, 106, 71, 68, 3, 39, 90, 76, 5, 102, 4, 34, 61, 101, 96, 92, 119, 89, 70, 26, 10, 51, 99, 30, 73, 43, 75, 38, 72, 97, 91, 79, 47, 42, 121, 63, 112, 36, 109, 23, 19, 49, 11, 7, 2, 1, 59, 14, 95, 15, 18, 60, 115, 27, 37, 93, 54, 56, 57, 0, 107, 100, 98, 62, 125, 81, 67, 17, 29, 41, 123, 16, 120, 21, 22, 117, 33, 114, 113, 35, 85, 87, 45, 46, 50, 52, 53, 55, 64, 65, 77, 84, 111, 40]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.2567, 1.2567, 1.3206, 1.3206, 1.3206, 1.3583, 1.2567, 1.3583,
        1.5000, 1.2869, 1.2567, 1.4004, 1.4004, 1.2567, 1.2297, 1.1839, 1.2056,
        1.2297, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.3583, 1.3583, 1.2869,
        1.2297, 1.4474, 1.2056, 1.2869, 1.5000, 1.4004, 1.1839, 1.2869, 1.1839,
        1.2567, 1.2297, 1.2869, 1.3206, 1.1839, 1.2056, 1.2567, 1.2869, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.2567, 1.1839, 1.2869, 1.1839, 1.1839,
        1.2297, 1.1839, 1.2297, 1.2297, 1.5000, 1.2567, 1.2297, 1.2869, 1.2056,
        1.2567, 1.1839, 1.1839, 1.3583, 1.2056, 1.3206, 1.3583, 1.2869, 1.3206,
        1.2567, 1.2869, 1.3583, 1.2869, 1.3206, 1.1839, 1.5000, 1.2567, 1.5000,
        1.2056, 1.5000, 1.3583, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.2869,
        1.3206, 1.2567, 1.2869, 1.2297, 1.4004, 1.2297, 1.2869, 1.2567, 1.2056,
        1.2869, 1.2056, 1.2869, 1.3206, 1.3206, 1.3583, 1.3583, 1.3206, 1.2056,
        1.4004, 1.2567, 1.3583, 1.1839, 1.2567, 1.1839, 1.1839, 1.2297, 1.4474,
        1.1839, 1.5000, 1.2869, 1.1839, 1.2567, 1.3583, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.7433, 0.7433, 0.6794, 0.6794, 0.6794, 0.6417, 0.7433, 0.6417,
        0.5000, 0.7131, 0.7433, 0.5996, 0.5996, 0.7433, 0.7703, 0.8161, 0.7944,
        0.7703, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.6417, 0.6417, 0.7131,
        0.7703, 0.5526, 0.7944, 0.7131, 0.5000, 0.5996, 0.8161, 0.7131, 0.8161,
        0.7433, 0.7703, 0.7131, 0.6794, 0.8161, 0.7944, 0.7433, 0.7131, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.7433, 0.8161, 0.7131, 0.8161, 0.8161,
        0.7703, 0.8161, 0.7703, 0.7703, 0.5000, 0.7433, 0.7703, 0.7131, 0.7944,
        0.7433, 0.8161, 0.8161, 0.6417, 0.7944, 0.6794, 0.6417, 0.7131, 0.6794,
        0.7433, 0.7131, 0.6417, 0.7131, 0.6794, 0.8161, 0.5000, 0.7433, 0.5000,
        0.7944, 0.5000, 0.6417, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.7131,
        0.6794, 0.7433, 0.7131, 0.7703, 0.5996, 0.7703, 0.7131, 0.7433, 0.7944,
        0.7131, 0.7944, 0.7131, 0.6794, 0.6794, 0.6417, 0.6417, 0.6794, 0.7944,
        0.5996, 0.7433, 0.6417, 0.8161, 0.7433, 0.8161, 0.8161, 0.7703, 0.5526,
        0.8161, 0.5000, 0.7131, 0.8161, 0.7433, 0.6417, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.695499 Loss T 0.094338 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1884, Accuracy: 652/1134 F1 (57.4956%)


Test set: Average loss: 1.9229, Accuracy: 11572/18312 F1 (63.1935%)


Val set: Average loss: 2.0660, Accuracy: 212/360 F1 (58.8889%)

best acc test 64.678899  acc val 58.888889 acc labeled target 57.495591
saving model...
S real T clipart Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.483226 Loss T 0.064206 Method MME

S real T clipart Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.250206 Loss T 0.092984 Method MME

S real T clipart Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.288826 Loss T 0.067106 Method MME

S real T clipart Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.885136 Loss T 0.067091 Method MME

S real T clipart Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.524374 Loss T 0.053818 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0453, Accuracy: 664/1134 F1 (58.5538%)


Test set: Average loss: 1.7722, Accuracy: 12050/18312 F1 (65.8038%)


Val set: Average loss: 1.9013, Accuracy: 230/360 F1 (63.8889%)

best acc test 65.803844  acc val 63.888889 acc labeled target 58.553792
saving model...
S real T clipart Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.668855 Loss T 0.069590 Method MME

S real T clipart Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 1.155198 Loss T 0.070980 Method MME

S real T clipart Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.743066 Loss T 0.075956 Method MME

S real T clipart Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.718123 Loss T 0.054446 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.8888889  0.6666667  0.44444445 0.11111111 0.11111111
 0.22222222 0.6666667  0.5555556  0.         0.7777778  0.44444445
 0.33333334 0.44444445 1.         0.         1.         0.7777778
 1.         0.5555556  0.         0.8888889  0.7777778  0.6666667
 0.44444445 0.44444445 0.5555556  0.8888889  0.33333334 0.6666667
 0.5555556  0.         0.11111111 1.         0.7777778  1.
 0.6666667  0.6666667  0.5555556  0.11111111 0.8888889  0.33333334
 0.5555556  0.7777778  0.         0.8888889  0.6666667  0.6666667
 0.33333334 0.6666667  0.6666667  0.7777778  1.         1.
 0.22222222 1.         1.         0.7777778  0.22222222 0.6666667
 0.6666667  0.7777778  1.         0.5555556  1.         1.
 0.         1.         0.8888889  0.         0.5555556  0.44444445
 0.7777778  0.22222222 0.         0.6666667  0.         1.
 0.         0.7777778  0.         0.6666667  0.         0.
 1.         1.         0.33333334 0.8888889  0.         0.33333334
 0.22222222 0.6666667  0.11111111 0.7777778  0.33333334 0.8888889
 0.6666667  0.44444445 1.         0.22222222 1.         0.7777778
 0.22222222 0.44444445 0.6666667  0.33333334 0.44444445 0.8888889
 0.         0.7777778  0.5555556  1.         0.6666667  1.
 1.         0.6666667  0.5555556  1.         0.5555556  0.6666667
 1.         0.6666667  0.8888889  1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [31, 69, 20, 108, 74, 15, 76, 78, 66, 80, 124, 9, 83, 88, 44, 82, 32, 5, 4, 92, 39, 99, 90, 54, 58, 73, 102, 6, 105, 28, 48, 12, 86, 89, 41, 94, 71, 106, 97, 103, 24, 25, 3, 11, 13, 70, 19, 116, 26, 118, 63, 38, 8, 110, 30, 42, 75, 121, 7, 2, 112, 23, 104, 81, 37, 91, 50, 60, 36, 119, 59, 115, 46, 47, 96, 29, 49, 43, 34, 109, 10, 61, 93, 51, 17, 72, 57, 101, 22, 79, 107, 95, 125, 68, 45, 40, 27, 21, 122, 1, 87, 111, 113, 114, 120, 123, 117, 0, 98, 14, 16, 18, 33, 35, 52, 53, 55, 56, 64, 65, 67, 77, 84, 85, 100, 62]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.2056, 1.2567, 1.3206, 1.4474, 1.4474, 1.4004, 1.2567, 1.2869,
        1.5000, 1.2297, 1.3206, 1.3583, 1.3206, 1.1839, 1.5000, 1.1839, 1.2297,
        1.1839, 1.2869, 1.5000, 1.2056, 1.2297, 1.2567, 1.3206, 1.3206, 1.2869,
        1.2056, 1.3583, 1.2567, 1.2869, 1.5000, 1.4474, 1.1839, 1.2297, 1.1839,
        1.2567, 1.2567, 1.2869, 1.4474, 1.2056, 1.3583, 1.2869, 1.2297, 1.5000,
        1.2056, 1.2567, 1.2567, 1.3583, 1.2567, 1.2567, 1.2297, 1.1839, 1.1839,
        1.4004, 1.1839, 1.1839, 1.2297, 1.4004, 1.2567, 1.2567, 1.2297, 1.1839,
        1.2869, 1.1839, 1.1839, 1.5000, 1.1839, 1.2056, 1.5000, 1.2869, 1.3206,
        1.2297, 1.4004, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.2297, 1.5000,
        1.2567, 1.5000, 1.5000, 1.1839, 1.1839, 1.3583, 1.2056, 1.5000, 1.3583,
        1.4004, 1.2567, 1.4474, 1.2297, 1.3583, 1.2056, 1.2567, 1.3206, 1.1839,
        1.4004, 1.1839, 1.2297, 1.4004, 1.3206, 1.2567, 1.3583, 1.3206, 1.2056,
        1.5000, 1.2297, 1.2869, 1.1839, 1.2567, 1.1839, 1.1839, 1.2567, 1.2869,
        1.1839, 1.2869, 1.2567, 1.1839, 1.2567, 1.2056, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.7944, 0.7433, 0.6794, 0.5526, 0.5526, 0.5996, 0.7433, 0.7131,
        0.5000, 0.7703, 0.6794, 0.6417, 0.6794, 0.8161, 0.5000, 0.8161, 0.7703,
        0.8161, 0.7131, 0.5000, 0.7944, 0.7703, 0.7433, 0.6794, 0.6794, 0.7131,
        0.7944, 0.6417, 0.7433, 0.7131, 0.5000, 0.5526, 0.8161, 0.7703, 0.8161,
        0.7433, 0.7433, 0.7131, 0.5526, 0.7944, 0.6417, 0.7131, 0.7703, 0.5000,
        0.7944, 0.7433, 0.7433, 0.6417, 0.7433, 0.7433, 0.7703, 0.8161, 0.8161,
        0.5996, 0.8161, 0.8161, 0.7703, 0.5996, 0.7433, 0.7433, 0.7703, 0.8161,
        0.7131, 0.8161, 0.8161, 0.5000, 0.8161, 0.7944, 0.5000, 0.7131, 0.6794,
        0.7703, 0.5996, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.7703, 0.5000,
        0.7433, 0.5000, 0.5000, 0.8161, 0.8161, 0.6417, 0.7944, 0.5000, 0.6417,
        0.5996, 0.7433, 0.5526, 0.7703, 0.6417, 0.7944, 0.7433, 0.6794, 0.8161,
        0.5996, 0.8161, 0.7703, 0.5996, 0.6794, 0.7433, 0.6417, 0.6794, 0.7944,
        0.5000, 0.7703, 0.7131, 0.8161, 0.7433, 0.8161, 0.8161, 0.7433, 0.7131,
        0.8161, 0.7131, 0.7433, 0.8161, 0.7433, 0.7944, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.349029 Loss T 0.071125 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2323, Accuracy: 640/1134 F1 (56.4374%)


Test set: Average loss: 1.9211, Accuracy: 11708/18312 F1 (63.9362%)


Val set: Average loss: 2.1820, Accuracy: 217/360 F1 (60.2778%)

best acc test 65.803844  acc val 60.277778 acc labeled target 56.437390
saving model...
S real T clipart Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.355465 Loss T 0.051496 Method MME

S real T clipart Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 1.563504 Loss T 0.074626 Method MME

S real T clipart Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.145257 Loss T 0.073659 Method MME

S real T clipart Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.614188 Loss T 0.075264 Method MME

S real T clipart Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.752209 Loss T 0.054110 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8775, Accuracy: 693/1134 F1 (61.1111%)


Test set: Average loss: 1.7071, Accuracy: 12376/18312 F1 (67.5841%)


Val set: Average loss: 1.8613, Accuracy: 234/360 F1 (65.0000%)

best acc test 67.584098  acc val 65.000000 acc labeled target 61.111111
saving model...
S real T clipart Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.501078 Loss T 0.047753 Method MME

S real T clipart Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.627985 Loss T 0.070860 Method MME

S real T clipart Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.817386 Loss T 0.061997 Method MME

S real T clipart Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.702443 Loss T 0.047612 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  1.         0.6666667  0.5555556  0.         0.33333334
 0.33333334 1.         0.5555556  0.         0.6666667  0.33333334
 0.44444445 0.33333334 0.8888889  0.8888889  1.         0.7777778
 0.7777778  0.6666667  0.         0.5555556  1.         0.6666667
 0.33333334 0.44444445 0.5555556  0.7777778  0.5555556  0.8888889
 0.33333334 0.         0.5555556  1.         1.         1.
 0.6666667  0.5555556  0.44444445 0.11111111 0.8888889  0.8888889
 0.5555556  0.8888889  0.         0.6666667  1.         0.6666667
 0.33333334 0.6666667  0.6666667  1.         1.         1.
 1.         1.         1.         1.         0.33333334 0.6666667
 1.         0.44444445 0.8888889  0.5555556  1.         0.8888889
 0.22222222 0.         1.         0.44444445 0.5555556  0.6666667
 0.7777778  0.33333334 0.11111111 0.44444445 0.         1.
 0.         0.8888889  0.11111111 0.8888889  0.         0.
 0.8888889  1.         0.6666667  1.         0.         0.44444445
 0.22222222 0.5555556  0.         0.8888889  0.22222222 0.8888889
 0.8888889  0.44444445 1.         0.11111111 1.         1.
 0.22222222 0.44444445 0.44444445 0.33333334 0.5555556  0.8888889
 0.33333334 0.6666667  0.6666667  0.7777778  0.33333334 1.
 1.         0.8888889  0.5555556  1.         0.33333334 0.11111111
 1.         0.6666667  0.7777778  1.         0.         0.8888889 ]
Top k classes which perform poorly are:  [44, 83, 76, 20, 92, 9, 67, 78, 124, 31, 4, 88, 82, 39, 99, 119, 80, 74, 94, 66, 102, 90, 30, 108, 105, 48, 112, 58, 13, 24, 73, 118, 5, 6, 11, 104, 12, 75, 89, 103, 69, 97, 25, 61, 38, 63, 3, 28, 106, 116, 21, 37, 91, 70, 32, 26, 8, 42, 71, 86, 36, 23, 59, 10, 110, 109, 121, 19, 47, 2, 49, 50, 45, 18, 17, 122, 72, 0, 27, 111, 107, 93, 96, 115, 95, 62, 84, 14, 15, 29, 40, 41, 43, 125, 81, 65, 79, 60, 123, 1, 7, 120, 87, 117, 16, 22, 114, 113, 33, 34, 35, 77, 68, 85, 51, 52, 53, 101, 100, 54, 98, 55, 56, 57, 64, 46]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.1839, 1.2567, 1.2869, 1.5000, 1.3583, 1.3583, 1.1839, 1.2869,
        1.5000, 1.2567, 1.3583, 1.3206, 1.3583, 1.2056, 1.2056, 1.1839, 1.2297,
        1.2297, 1.2567, 1.5000, 1.2869, 1.1839, 1.2567, 1.3583, 1.3206, 1.2869,
        1.2297, 1.2869, 1.2056, 1.3583, 1.5000, 1.2869, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2869, 1.3206, 1.4474, 1.2056, 1.2056, 1.2869, 1.2056, 1.5000,
        1.2567, 1.1839, 1.2567, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567, 1.1839, 1.3206, 1.2056,
        1.2869, 1.1839, 1.2056, 1.4004, 1.5000, 1.1839, 1.3206, 1.2869, 1.2567,
        1.2297, 1.3583, 1.4474, 1.3206, 1.5000, 1.1839, 1.5000, 1.2056, 1.4474,
        1.2056, 1.5000, 1.5000, 1.2056, 1.1839, 1.2567, 1.1839, 1.5000, 1.3206,
        1.4004, 1.2869, 1.5000, 1.2056, 1.4004, 1.2056, 1.2056, 1.3206, 1.1839,
        1.4474, 1.1839, 1.1839, 1.4004, 1.3206, 1.3206, 1.3583, 1.2869, 1.2056,
        1.3583, 1.2567, 1.2567, 1.2297, 1.3583, 1.1839, 1.1839, 1.2056, 1.2869,
        1.1839, 1.3583, 1.4474, 1.1839, 1.2567, 1.2297, 1.1839, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.8161, 0.7433, 0.7131, 0.5000, 0.6417, 0.6417, 0.8161, 0.7131,
        0.5000, 0.7433, 0.6417, 0.6794, 0.6417, 0.7944, 0.7944, 0.8161, 0.7703,
        0.7703, 0.7433, 0.5000, 0.7131, 0.8161, 0.7433, 0.6417, 0.6794, 0.7131,
        0.7703, 0.7131, 0.7944, 0.6417, 0.5000, 0.7131, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7131, 0.6794, 0.5526, 0.7944, 0.7944, 0.7131, 0.7944, 0.5000,
        0.7433, 0.8161, 0.7433, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433, 0.8161, 0.6794, 0.7944,
        0.7131, 0.8161, 0.7944, 0.5996, 0.5000, 0.8161, 0.6794, 0.7131, 0.7433,
        0.7703, 0.6417, 0.5526, 0.6794, 0.5000, 0.8161, 0.5000, 0.7944, 0.5526,
        0.7944, 0.5000, 0.5000, 0.7944, 0.8161, 0.7433, 0.8161, 0.5000, 0.6794,
        0.5996, 0.7131, 0.5000, 0.7944, 0.5996, 0.7944, 0.7944, 0.6794, 0.8161,
        0.5526, 0.8161, 0.8161, 0.5996, 0.6794, 0.6794, 0.6417, 0.7131, 0.7944,
        0.6417, 0.7433, 0.7433, 0.7703, 0.6417, 0.8161, 0.8161, 0.7944, 0.7131,
        0.8161, 0.6417, 0.5526, 0.8161, 0.7433, 0.7703, 0.8161, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.794541 Loss T 0.073590 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0775, Accuracy: 670/1134 F1 (59.0829%)


Test set: Average loss: 1.8169, Accuracy: 12128/18312 F1 (66.2298%)


Val set: Average loss: 2.0920, Accuracy: 227/360 F1 (63.0556%)

best acc test 67.584098  acc val 63.055556 acc labeled target 59.082892
saving model...
S real T clipart Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.360971 Loss T 0.064445 Method MME

S real T clipart Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.569520 Loss T 0.057539 Method MME

S real T clipart Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.351678 Loss T 0.062634 Method MME

S real T clipart Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.212330 Loss T 0.074551 Method MME

S real T clipart Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.950714 Loss T 0.078954 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9074, Accuracy: 709/1134 F1 (62.5220%)


Test set: Average loss: 1.8378, Accuracy: 12344/18312 F1 (67.4093%)


Val set: Average loss: 2.0086, Accuracy: 234/360 F1 (65.0000%)

best acc test 67.409349  acc val 65.000000 acc labeled target 62.522046
saving model...
S real T clipart Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.444093 Loss T 0.061226 Method MME

S real T clipart Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.527346 Loss T 0.036050 Method MME

S real T clipart Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.713899 Loss T 0.069063 Method MME

S real T clipart Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.850224 Loss T 0.073494 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.33333334 1.         0.6666667  0.33333334 0.         0.33333334
 0.33333334 0.7777778  0.44444445 0.         0.6666667  0.6666667
 0.33333334 0.5555556  0.8888889  0.8888889  1.         0.6666667
 1.         0.6666667  0.         0.7777778  1.         0.6666667
 0.33333334 0.7777778  0.44444445 0.6666667  0.22222222 0.8888889
 0.6666667  0.         0.7777778  1.         1.         1.
 0.33333334 0.8888889  0.6666667  0.         1.         1.
 0.6666667  0.8888889  0.22222222 0.8888889  0.8888889  0.6666667
 0.33333334 0.6666667  0.7777778  0.6666667  1.         0.7777778
 0.8888889  1.         1.         0.7777778  0.33333334 0.6666667
 1.         0.7777778  1.         0.6666667  0.7777778  1.
 0.33333334 1.         0.8888889  0.         0.6666667  0.33333334
 0.6666667  0.6666667  0.         0.5555556  0.         1.
 0.         0.7777778  0.         0.7777778  0.         0.
 1.         1.         0.33333334 1.         0.         0.44444445
 0.         0.33333334 0.         0.6666667  0.44444445 0.8888889
 0.8888889  0.7777778  1.         0.6666667  0.8888889  1.
 0.33333334 0.44444445 0.5555556  0.33333334 0.5555556  1.
 0.11111111 0.6666667  0.5555556  1.         0.5555556  1.
 1.         0.7777778  0.44444445 0.8888889  0.44444445 0.7777778
 1.         0.6666667  0.6666667  1.         0.         1.        ]
Top k classes which perform poorly are:  [83, 74, 76, 31, 78, 80, 82, 9, 69, 20, 88, 4, 90, 39, 92, 124, 108, 44, 28, 71, 86, 58, 48, 105, 91, 36, 66, 0, 102, 12, 3, 24, 5, 6, 116, 26, 94, 118, 89, 103, 8, 75, 13, 112, 110, 104, 106, 109, 17, 121, 27, 70, 122, 10, 73, 11, 63, 2, 93, 99, 72, 19, 51, 38, 59, 42, 30, 47, 23, 49, 61, 81, 79, 119, 115, 50, 97, 53, 32, 57, 21, 64, 7, 25, 37, 45, 96, 100, 117, 95, 29, 46, 14, 15, 54, 68, 43, 107, 123, 120, 114, 113, 111, 62, 98, 1, 16, 18, 22, 33, 34, 35, 40, 41, 52, 55, 56, 60, 65, 67, 77, 84, 85, 87, 101, 125]
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.2567, 1.3583, 1.5000, 1.3583, 1.3583, 1.2297, 1.3206,
        1.5000, 1.2567, 1.2567, 1.3583, 1.2869, 1.2056, 1.2056, 1.1839, 1.2567,
        1.1839, 1.2567, 1.5000, 1.2297, 1.1839, 1.2567, 1.3583, 1.2297, 1.3206,
        1.2567, 1.4004, 1.2056, 1.2567, 1.5000, 1.2297, 1.1839, 1.1839, 1.1839,
        1.3583, 1.2056, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2056, 1.4004,
        1.2056, 1.2056, 1.2567, 1.3583, 1.2567, 1.2297, 1.2567, 1.1839, 1.2297,
        1.2056, 1.1839, 1.1839, 1.2297, 1.3583, 1.2567, 1.1839, 1.2297, 1.1839,
        1.2567, 1.2297, 1.1839, 1.3583, 1.1839, 1.2056, 1.5000, 1.2567, 1.3583,
        1.2567, 1.2567, 1.5000, 1.2869, 1.5000, 1.1839, 1.5000, 1.2297, 1.5000,
        1.2297, 1.5000, 1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3206,
        1.5000, 1.3583, 1.5000, 1.2567, 1.3206, 1.2056, 1.2056, 1.2297, 1.1839,
        1.2567, 1.2056, 1.1839, 1.3583, 1.3206, 1.2869, 1.3583, 1.2869, 1.1839,
        1.4474, 1.2567, 1.2869, 1.1839, 1.2869, 1.1839, 1.1839, 1.2297, 1.3206,
        1.2056, 1.3206, 1.2297, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.7433, 0.6417, 0.5000, 0.6417, 0.6417, 0.7703, 0.6794,
        0.5000, 0.7433, 0.7433, 0.6417, 0.7131, 0.7944, 0.7944, 0.8161, 0.7433,
        0.8161, 0.7433, 0.5000, 0.7703, 0.8161, 0.7433, 0.6417, 0.7703, 0.6794,
        0.7433, 0.5996, 0.7944, 0.7433, 0.5000, 0.7703, 0.8161, 0.8161, 0.8161,
        0.6417, 0.7944, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7944, 0.5996,
        0.7944, 0.7944, 0.7433, 0.6417, 0.7433, 0.7703, 0.7433, 0.8161, 0.7703,
        0.7944, 0.8161, 0.8161, 0.7703, 0.6417, 0.7433, 0.8161, 0.7703, 0.8161,
        0.7433, 0.7703, 0.8161, 0.6417, 0.8161, 0.7944, 0.5000, 0.7433, 0.6417,
        0.7433, 0.7433, 0.5000, 0.7131, 0.5000, 0.8161, 0.5000, 0.7703, 0.5000,
        0.7703, 0.5000, 0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6794,
        0.5000, 0.6417, 0.5000, 0.7433, 0.6794, 0.7944, 0.7944, 0.7703, 0.8161,
        0.7433, 0.7944, 0.8161, 0.6417, 0.6794, 0.7131, 0.6417, 0.7131, 0.8161,
        0.5526, 0.7433, 0.7131, 0.8161, 0.7131, 0.8161, 0.8161, 0.7703, 0.6794,
        0.7944, 0.6794, 0.7703, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.732215 Loss T 0.059830 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0573, Accuracy: 680/1134 F1 (59.9647%)


Test set: Average loss: 1.8537, Accuracy: 12182/18312 F1 (66.5247%)


Val set: Average loss: 2.1192, Accuracy: 225/360 F1 (62.5000%)

best acc test 67.409349  acc val 62.500000 acc labeled target 59.964727
saving model...
S real T clipart Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.563480 Loss T 0.058072 Method MME

S real T clipart Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.972409 Loss T 0.048475 Method MME

S real T clipart Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.648389 Loss T 0.061941 Method MME

S real T clipart Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.339167 Loss T 0.041793 Method MME

S real T clipart Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.365047 Loss T 0.073369 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.8346, Accuracy: 739/1134 F1 (65.1675%)


Test set: Average loss: 1.7784, Accuracy: 12587/18312 F1 (68.7364%)


Val set: Average loss: 2.0242, Accuracy: 232/360 F1 (64.4444%)

best acc test 67.409349  acc val 64.444444 acc labeled target 65.167549
saving model...
S real T clipart Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.353085 Loss T 0.042138 Method MME

S real T clipart Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.477504 Loss T 0.064279 Method MME

S real T clipart Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.266016 Loss T 0.046794 Method MME

S real T clipart Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.444033 Loss T 0.034393 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.5555556  0.6666667  0.         0.11111111
 0.33333334 0.7777778  0.6666667  0.         1.         0.8888889
 0.33333334 0.         0.8888889  0.8888889  0.8888889  1.
 1.         0.8888889  0.         0.7777778  1.         0.6666667
 0.44444445 0.5555556  0.5555556  0.6666667  0.44444445 0.8888889
 0.5555556  0.11111111 0.6666667  1.         1.         1.
 0.6666667  0.7777778  0.5555556  0.         1.         0.8888889
 0.6666667  0.8888889  0.44444445 0.7777778  0.7777778  0.6666667
 0.33333334 0.6666667  0.8888889  1.         1.         0.8888889
 0.8888889  1.         0.8888889  0.6666667  0.5555556  0.7777778
 1.         0.7777778  1.         0.6666667  1.         1.
 0.33333334 0.6666667  0.8888889  0.         0.6666667  0.6666667
 1.         0.44444445 0.         0.44444445 0.6666667  1.
 0.         0.8888889  0.         0.7777778  0.         0.11111111
 1.         1.         0.6666667  1.         0.         0.5555556
 0.22222222 0.6666667  0.         0.8888889  0.5555556  1.
 0.7777778  0.5555556  1.         0.6666667  1.         0.6666667
 0.33333334 0.33333334 0.33333334 0.22222222 0.8888889  0.7777778
 0.33333334 0.6666667  0.6666667  1.         0.5555556  1.
 0.8888889  0.8888889  0.6666667  1.         0.44444445 0.7777778
 0.7777778  0.6666667  0.44444445 1.         0.         0.7777778 ]
Top k classes which perform poorly are:  [13, 78, 20, 124, 82, 74, 9, 39, 80, 69, 92, 4, 88, 5, 83, 31, 90, 105, 104, 6, 103, 102, 12, 66, 108, 48, 44, 28, 24, 122, 73, 75, 118, 25, 89, 2, 94, 97, 38, 112, 58, 30, 26, 0, 67, 57, 86, 63, 76, 101, 47, 3, 121, 8, 116, 110, 109, 49, 27, 23, 70, 36, 99, 42, 91, 32, 71, 107, 81, 119, 120, 96, 125, 37, 21, 45, 59, 46, 61, 7, 15, 115, 114, 11, 19, 106, 29, 41, 43, 93, 14, 16, 68, 50, 53, 56, 79, 54, 111, 55, 113, 51, 77, 64, 10, 65, 1, 123, 117, 60, 18, 84, 85, 22, 33, 34, 35, 100, 72, 98, 40, 87, 95, 52, 17, 62]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.2869, 1.2567, 1.5000, 1.4474, 1.3583, 1.2297, 1.2567,
        1.5000, 1.1839, 1.2056, 1.3583, 1.5000, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.5000, 1.2297, 1.1839, 1.2567, 1.3206, 1.2869, 1.2869,
        1.2567, 1.3206, 1.2056, 1.2869, 1.4474, 1.2567, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2297, 1.2869, 1.5000, 1.1839, 1.2056, 1.2567, 1.2056, 1.3206,
        1.2297, 1.2297, 1.2567, 1.3583, 1.2567, 1.2056, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2056, 1.2567, 1.2869, 1.2297, 1.1839, 1.2297, 1.1839,
        1.2567, 1.1839, 1.1839, 1.3583, 1.2567, 1.2056, 1.5000, 1.2567, 1.2567,
        1.1839, 1.3206, 1.5000, 1.3206, 1.2567, 1.1839, 1.5000, 1.2056, 1.5000,
        1.2297, 1.5000, 1.4474, 1.1839, 1.1839, 1.2567, 1.1839, 1.5000, 1.2869,
        1.4004, 1.2567, 1.5000, 1.2056, 1.2869, 1.1839, 1.2297, 1.2869, 1.1839,
        1.2567, 1.1839, 1.2567, 1.3583, 1.3583, 1.3583, 1.4004, 1.2056, 1.2297,
        1.3583, 1.2567, 1.2567, 1.1839, 1.2869, 1.1839, 1.2056, 1.2056, 1.2567,
        1.1839, 1.3206, 1.2297, 1.2297, 1.2567, 1.3206, 1.1839, 1.5000, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.7131, 0.7433, 0.5000, 0.5526, 0.6417, 0.7703, 0.7433,
        0.5000, 0.8161, 0.7944, 0.6417, 0.5000, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.5000, 0.7703, 0.8161, 0.7433, 0.6794, 0.7131, 0.7131,
        0.7433, 0.6794, 0.7944, 0.7131, 0.5526, 0.7433, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7703, 0.7131, 0.5000, 0.8161, 0.7944, 0.7433, 0.7944, 0.6794,
        0.7703, 0.7703, 0.7433, 0.6417, 0.7433, 0.7944, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7944, 0.7433, 0.7131, 0.7703, 0.8161, 0.7703, 0.8161,
        0.7433, 0.8161, 0.8161, 0.6417, 0.7433, 0.7944, 0.5000, 0.7433, 0.7433,
        0.8161, 0.6794, 0.5000, 0.6794, 0.7433, 0.8161, 0.5000, 0.7944, 0.5000,
        0.7703, 0.5000, 0.5526, 0.8161, 0.8161, 0.7433, 0.8161, 0.5000, 0.7131,
        0.5996, 0.7433, 0.5000, 0.7944, 0.7131, 0.8161, 0.7703, 0.7131, 0.8161,
        0.7433, 0.8161, 0.7433, 0.6417, 0.6417, 0.6417, 0.5996, 0.7944, 0.7703,
        0.6417, 0.7433, 0.7433, 0.8161, 0.7131, 0.8161, 0.7944, 0.7944, 0.7433,
        0.8161, 0.6794, 0.7703, 0.7703, 0.7433, 0.6794, 0.8161, 0.5000, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.422741 Loss T 0.080838 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0567, Accuracy: 694/1134 F1 (61.1993%)


Test set: Average loss: 1.8615, Accuracy: 12359/18312 F1 (67.4913%)


Val set: Average loss: 2.0042, Accuracy: 234/360 F1 (65.0000%)

best acc test 67.491263  acc val 65.000000 acc labeled target 61.199295
saving model...
S real T clipart Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.848864 Loss T 0.055715 Method MME

S real T clipart Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.611928 Loss T 0.056004 Method MME

S real T clipart Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.646902 Loss T 0.058175 Method MME

S real T clipart Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.876365 Loss T 0.046955 Method MME

S real T clipart Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.548332 Loss T 0.043922 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0677, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.4545, Accuracy: 13397/18312 F1 (73.1597%)


Val set: Average loss: 1.6077, Accuracy: 247/360 F1 (68.6111%)

best acc test 73.159677  acc val 68.611111 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.220533 Loss T 0.044604 Method MME

S real T clipart Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.451149 Loss T 0.064497 Method MME

S real T clipart Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.067700 Loss T 0.039592 Method MME

S real T clipart Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.845648 Loss T 0.043953 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 63, 91, 66, 105, 42, 11, 34, 89, 90, 94, 122, 87, 85, 84, 83, 82, 88, 86, 0, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 81, 80, 93, 95, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 92, 110, 108, 107, 106, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 13, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 29, 30, 31, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 33, 32, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.321015 Loss T 0.032487 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0879, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.5771, Accuracy: 13148/18312 F1 (71.7999%)


Val set: Average loss: 1.6352, Accuracy: 253/360 F1 (70.2778%)

best acc test 71.799913  acc val 70.277778 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.822153 Loss T 0.054501 Method MME

S real T clipart Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.431271 Loss T 0.033624 Method MME

S real T clipart Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.724304 Loss T 0.035963 Method MME

S real T clipart Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.441053 Loss T 0.041202 Method MME

S real T clipart Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.593727 Loss T 0.050966 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0430, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 1.5696, Accuracy: 13368/18312 F1 (73.0013%)


Val set: Average loss: 1.6134, Accuracy: 251/360 F1 (69.7222%)

best acc test 71.799913  acc val 69.722222 acc labeled target 98.500882
saving model...
S real T clipart Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.339527 Loss T 0.049554 Method MME

S real T clipart Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.774834 Loss T 0.039109 Method MME

S real T clipart Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.220835 Loss T 0.041458 Method MME

S real T clipart Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.273311 Loss T 0.049509 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 103, 47, 25, 61, 39, 5, 78, 77, 23, 54, 84, 0, 86, 87, 88, 89, 90, 85, 83, 80, 81, 79, 76, 75, 74, 73, 72, 71, 70, 69, 68, 82, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 67, 109, 66, 62, 64, 29, 28, 27, 26, 24, 22, 21, 20, 19, 18, 17, 16, 30, 15, 13, 12, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 14, 65, 31, 33, 63, 124, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 32, 49, 46, 45, 44, 43, 42, 41, 40, 38, 37, 36, 35, 34, 48, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.215482 Loss T 0.047338 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0785, Accuracy: 1109/1134 F1 (97.7954%)


Test set: Average loss: 1.6145, Accuracy: 13271/18312 F1 (72.4716%)


Val set: Average loss: 1.6841, Accuracy: 252/360 F1 (70.0000%)

best acc test 71.799913  acc val 70.000000 acc labeled target 97.795414
saving model...
S real T clipart Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.412712 Loss T 0.041692 Method MME

S real T clipart Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.292664 Loss T 0.040065 Method MME

S real T clipart Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.790564 Loss T 0.033442 Method MME

S real T clipart Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.242626 Loss T 0.022641 Method MME

S real T clipart Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.836854 Loss T 0.045336 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0480, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.5496, Accuracy: 13585/18312 F1 (74.1863%)


Val set: Average loss: 1.4580, Accuracy: 264/360 F1 (73.3333%)

best acc test 74.186326  acc val 73.333333 acc labeled target 98.412698
saving model...
S real T clipart Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.212088 Loss T 0.031894 Method MME

S real T clipart Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.436997 Loss T 0.048744 Method MME

S real T clipart Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.150292 Loss T 0.043300 Method MME

S real T clipart Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.270742 Loss T 0.057706 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        0.5555556 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 91, 47, 99, 104, 13, 24, 54, 71, 56, 85, 84, 86, 83, 87, 88, 89, 82, 81, 0, 90, 78, 77, 76, 75, 74, 73, 72, 70, 69, 68, 67, 80, 79, 94, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 102, 101, 100, 98, 97, 96, 95, 66, 92, 65, 62, 63, 28, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 30, 31, 32, 124, 61, 60, 59, 58, 57, 55, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2869, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7131, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.477833 Loss T 0.028722 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0824, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.6893, Accuracy: 13250/18312 F1 (72.3569%)


Val set: Average loss: 1.7417, Accuracy: 250/360 F1 (69.4444%)

best acc test 74.186326  acc val 69.444444 acc labeled target 97.442681
saving model...
S real T clipart Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.856795 Loss T 0.043069 Method MME

S real T clipart Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.474275 Loss T 0.042301 Method MME

S real T clipart Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.363032 Loss T 0.041945 Method MME

S real T clipart Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.120976 Loss T 0.022445 Method MME

S real T clipart Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.856521 Loss T 0.030617 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0302, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.6130, Accuracy: 13575/18312 F1 (74.1317%)


Val set: Average loss: 1.6411, Accuracy: 259/360 F1 (71.9444%)

best acc test 74.186326  acc val 71.944444 acc labeled target 98.941799
saving model...
S real T clipart Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.269273 Loss T 0.034782 Method MME

S real T clipart Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.332249 Loss T 0.018583 Method MME

S real T clipart Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.667339 Loss T 0.024779 Method MME

S real T clipart Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.387667 Loss T 0.033979 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 29, 49, 122, 89, 88, 87, 86, 80, 84, 83, 90, 82, 81, 85, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 79, 92, 0, 64, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 93, 94, 62, 61, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.068708 Loss T 0.034271 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0547, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.5581, Accuracy: 13540/18312 F1 (73.9406%)


Val set: Average loss: 1.6835, Accuracy: 257/360 F1 (71.3889%)

best acc test 74.186326  acc val 71.388889 acc labeled target 98.148148
saving model...
S real T clipart Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.405407 Loss T 0.025893 Method MME

S real T clipart Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.087546 Loss T 0.030978 Method MME

S real T clipart Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.279136 Loss T 0.037900 Method MME

S real T clipart Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.253507 Loss T 0.028296 Method MME

S real T clipart Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.018641 Loss T 0.037906 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0352, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.6111, Accuracy: 13665/18312 F1 (74.6232%)


Val set: Average loss: 1.6574, Accuracy: 255/360 F1 (70.8333%)

best acc test 74.186326  acc val 70.833333 acc labeled target 98.853616
saving model...
S real T clipart Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.598504 Loss T 0.031451 Method MME

S real T clipart Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.146477 Loss T 0.030184 Method MME

S real T clipart Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.162984 Loss T 0.026128 Method MME

S real T clipart Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.195140 Loss T 0.041899 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 63, 103, 111, 29, 26, 11, 82, 83, 84, 0, 81, 87, 88, 89, 90, 85, 86, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 91, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 124, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 30, 15, 13, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.513223 Loss T 0.026984 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0622, Accuracy: 1111/1134 F1 (97.9718%)


Test set: Average loss: 1.5657, Accuracy: 13531/18312 F1 (73.8914%)


Val set: Average loss: 1.6219, Accuracy: 259/360 F1 (71.9444%)

best acc test 74.186326  acc val 71.944444 acc labeled target 97.971781
saving model...
S real T clipart Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.085670 Loss T 0.036660 Method MME

S real T clipart Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.418689 Loss T 0.030448 Method MME

S real T clipart Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.198085 Loss T 0.027848 Method MME

S real T clipart Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.428840 Loss T 0.026477 Method MME

S real T clipart Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.305063 Loss T 0.027096 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0445, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.5995, Accuracy: 13746/18312 F1 (75.0655%)


Val set: Average loss: 1.7255, Accuracy: 255/360 F1 (70.8333%)

best acc test 74.186326  acc val 70.833333 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.152226 Loss T 0.017289 Method MME

S real T clipart Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.162456 Loss T 0.033958 Method MME

S real T clipart Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.157445 Loss T 0.027172 Method MME

S real T clipart Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.472256 Loss T 0.032580 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [91, 103, 47, 29, 83, 100, 45, 80, 113, 64, 71, 124, 119, 73, 89, 88, 87, 86, 85, 84, 66, 67, 82, 81, 68, 69, 70, 90, 78, 77, 76, 75, 74, 72, 79, 0, 65, 123, 122, 121, 120, 118, 117, 116, 115, 114, 112, 111, 110, 92, 109, 107, 106, 105, 104, 102, 101, 99, 98, 97, 96, 95, 94, 108, 93, 62, 61, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 27, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 28, 30, 31, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 63, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.876298 Loss T 0.037052 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0767, Accuracy: 1113/1134 F1 (98.1481%)


Test set: Average loss: 1.6268, Accuracy: 13498/18312 F1 (73.7112%)


Val set: Average loss: 1.7865, Accuracy: 252/360 F1 (70.0000%)

best acc test 74.186326  acc val 70.000000 acc labeled target 98.148148
saving model...
S real T clipart Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.402075 Loss T 0.021694 Method MME

S real T clipart Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.335782 Loss T 0.043464 Method MME

S real T clipart Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.789665 Loss T 0.016527 Method MME

S real T clipart Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.343706 Loss T 0.037556 Method MME

S real T clipart Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.244402 Loss T 0.025101 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0431, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.6417, Accuracy: 13699/18312 F1 (74.8089%)


Val set: Average loss: 1.6540, Accuracy: 263/360 F1 (73.0556%)

best acc test 74.186326  acc val 73.055556 acc labeled target 98.589065
saving model...
S real T clipart Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.259047 Loss T 0.022746 Method MME

S real T clipart Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.062582 Loss T 0.020455 Method MME

S real T clipart Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.257747 Loss T 0.035573 Method MME

S real T clipart Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.290777 Loss T 0.039209 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 107, 42, 75, 81, 25, 57, 31, 106, 85, 87, 88, 84, 83, 89, 82, 86, 0, 80, 79, 78, 77, 76, 74, 73, 72, 71, 70, 69, 68, 67, 90, 91, 94, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 92, 111, 109, 108, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 110, 66, 62, 64, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 28, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 29, 30, 32, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 34, 33, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.131869 Loss T 0.043154 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0535, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.6737, Accuracy: 13459/18312 F1 (73.4983%)


Val set: Average loss: 1.6475, Accuracy: 258/360 F1 (71.6667%)

best acc test 74.186326  acc val 71.666667 acc labeled target 98.236332
saving model...
S real T clipart Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.146652 Loss T 0.025408 Method MME

S real T clipart Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.115033 Loss T 0.051372 Method MME

S real T clipart Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.233820 Loss T 0.023970 Method MME

S real T clipart Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.044692 Loss T 0.039309 Method MME

S real T clipart Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.453542 Loss T 0.027806 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0383, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.6369, Accuracy: 13851/18312 F1 (75.6389%)


Val set: Average loss: 1.6467, Accuracy: 264/360 F1 (73.3333%)

best acc test 75.638925  acc val 73.333333 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.020546 Loss T 0.019924 Method MME

S real T clipart Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.336882 Loss T 0.029618 Method MME

S real T clipart Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.325267 Loss T 0.030963 Method MME

S real T clipart Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.497045 Loss T 0.037599 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 91, 94, 72, 8, 110, 70, 4, 66, 90, 89, 88, 87, 86, 85, 84, 67, 83, 82, 81, 80, 68, 79, 78, 77, 76, 75, 74, 73, 69, 71, 92, 0, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 93, 111, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 109, 95, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 7, 6, 5, 3, 2, 1, 30, 64, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.403388 Loss T 0.032973 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0734, Accuracy: 1112/1134 F1 (98.0600%)


Test set: Average loss: 1.6292, Accuracy: 13623/18312 F1 (74.3938%)


Val set: Average loss: 1.8067, Accuracy: 252/360 F1 (70.0000%)

best acc test 75.638925  acc val 70.000000 acc labeled target 98.059965
saving model...
S real T clipart Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.186127 Loss T 0.023849 Method MME

S real T clipart Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.370583 Loss T 0.033498 Method MME

S real T clipart Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.296611 Loss T 0.031538 Method MME

S real T clipart Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.375708 Loss T 0.021816 Method MME

S real T clipart Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.345548 Loss T 0.037863 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0301, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.6573, Accuracy: 13873/18312 F1 (75.7591%)


Val set: Average loss: 1.7217, Accuracy: 258/360 F1 (71.6667%)

best acc test 75.638925  acc val 71.666667 acc labeled target 98.765432
saving model...
S real T clipart Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.532627 Loss T 0.036805 Method MME

S real T clipart Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.205764 Loss T 0.031073 Method MME

S real T clipart Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.149464 Loss T 0.030844 Method MME

S real T clipart Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.302009 Loss T 0.018366 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 103, 105, 34, 72, 79, 3, 70, 65, 90, 89, 88, 87, 86, 85, 84, 66, 83, 82, 81, 80, 67, 78, 77, 76, 75, 74, 73, 68, 71, 69, 92, 0, 64, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 104, 102, 101, 100, 99, 98, 97, 96, 95, 93, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 29, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.380485 Loss T 0.039429 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0619, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.6988, Accuracy: 13684/18312 F1 (74.7270%)


Val set: Average loss: 1.7702, Accuracy: 254/360 F1 (70.5556%)

best acc test 75.638925  acc val 70.555556 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.332057 Loss T 0.015379 Method MME

S real T clipart Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.008239 Loss T 0.023622 Method MME

S real T clipart Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.201566 Loss T 0.020747 Method MME

S real T clipart Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.384504 Loss T 0.040176 Method MME

S real T clipart Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.326497 Loss T 0.035955 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0295, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.6484, Accuracy: 13975/18312 F1 (76.3161%)


Val set: Average loss: 1.7394, Accuracy: 264/360 F1 (73.3333%)

best acc test 76.316077  acc val 73.333333 acc labeled target 98.589065
saving model...
S real T clipart Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.143165 Loss T 0.013689 Method MME

S real T clipart Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.109737 Loss T 0.017019 Method MME

S real T clipart Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.265622 Loss T 0.010718 Method MME

S real T clipart Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.113233 Loss T 0.021216 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.5555556 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 47, 63, 84, 14, 53, 56, 106, 69, 85, 80, 87, 83, 82, 88, 81, 89, 90, 86, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 68, 67, 66, 79, 91, 93, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 92, 65, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 29, 30, 31, 61, 60, 59, 58, 57, 55, 54, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2869, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7131, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.465398 Loss T 0.014755 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0535, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 1.6501, Accuracy: 13781/18312 F1 (75.2567%)


Val set: Average loss: 1.7212, Accuracy: 261/360 F1 (72.5000%)

best acc test 76.316077  acc val 72.500000 acc labeled target 98.500882
saving model...
S real T clipart Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.110499 Loss T 0.015499 Method MME

S real T clipart Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.103425 Loss T 0.018529 Method MME

S real T clipart Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.337025 Loss T 0.017503 Method MME

S real T clipart Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.320165 Loss T 0.020785 Method MME

S real T clipart Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.277884 Loss T 0.023946 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0294, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.7372, Accuracy: 13923/18312 F1 (76.0321%)


Val set: Average loss: 1.7682, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.032110  acc val 73.888889 acc labeled target 98.765432
saving model...
S real T clipart Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.678645 Loss T 0.019222 Method MME

S real T clipart Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.269963 Loss T 0.023424 Method MME

S real T clipart Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.210283 Loss T 0.035757 Method MME

S real T clipart Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.303039 Loss T 0.024904 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.6666667 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 58, 6, 64, 72, 112, 67, 65, 83, 84, 86, 82, 87, 88, 89, 90, 85, 81, 78, 79, 66, 76, 75, 74, 73, 71, 70, 69, 68, 80, 77, 0, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 92, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 29, 124, 30, 32, 60, 59, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.383283 Loss T 0.018826 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0458, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.6644, Accuracy: 13804/18312 F1 (75.3823%)


Val set: Average loss: 1.7879, Accuracy: 261/360 F1 (72.5000%)

best acc test 76.032110  acc val 72.500000 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.428329 Loss T 0.019724 Method MME

S real T clipart Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.079949 Loss T 0.026376 Method MME

S real T clipart Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.236701 Loss T 0.027814 Method MME

S real T clipart Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.132451 Loss T 0.022216 Method MME

S real T clipart Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.498811 Loss T 0.024137 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0331, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.6796, Accuracy: 13996/18312 F1 (76.4308%)


Val set: Average loss: 1.7014, Accuracy: 269/360 F1 (74.7222%)

best acc test 76.430756  acc val 74.722222 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.147055 Loss T 0.019745 Method MME

S real T clipart Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.196473 Loss T 0.031911 Method MME

S real T clipart Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.125866 Loss T 0.039358 Method MME

S real T clipart Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.374068 Loss T 0.020512 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [47, 63, 91, 57, 108, 33, 124, 9, 90, 88, 87, 92, 86, 85, 84, 83, 82, 81, 89, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 80, 79, 93, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 94, 66, 62, 64, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 13, 12, 11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 14, 29, 30, 31, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.169303 Loss T 0.024667 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0598, Accuracy: 1118/1134 F1 (98.5891%)


Test set: Average loss: 1.6888, Accuracy: 13859/18312 F1 (75.6826%)


Val set: Average loss: 1.8349, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.430756  acc val 73.888889 acc labeled target 98.589065
saving model...
S real T clipart Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.129816 Loss T 0.018272 Method MME

S real T clipart Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.276654 Loss T 0.028379 Method MME

S real T clipart Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.213665 Loss T 0.031140 Method MME

S real T clipart Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.267947 Loss T 0.023929 Method MME

S real T clipart Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.167298 Loss T 0.019807 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0342, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.6966, Accuracy: 14026/18312 F1 (76.5946%)


Val set: Average loss: 1.7647, Accuracy: 264/360 F1 (73.3333%)

best acc test 76.430756  acc val 73.333333 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.259050 Loss T 0.022245 Method MME

S real T clipart Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.252247 Loss T 0.021955 Method MME

S real T clipart Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.281010 Loss T 0.029841 Method MME

S real T clipart Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.377441 Loss T 0.010687 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.5555556 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 103, 56, 5, 47, 3, 89, 88, 87, 86, 80, 85, 84, 83, 82, 81, 90, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 92, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 93, 65, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 4, 2, 1, 15, 30, 31, 32, 61, 60, 59, 58, 57, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2869, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7131, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.043643 Loss T 0.012175 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0324, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.7135, Accuracy: 13913/18312 F1 (75.9775%)


Val set: Average loss: 1.7978, Accuracy: 269/360 F1 (74.7222%)

best acc test 75.977501  acc val 74.722222 acc labeled target 98.765432
saving model...
S real T clipart Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.126284 Loss T 0.021137 Method MME

S real T clipart Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.064667 Loss T 0.013588 Method MME

S real T clipart Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.167178 Loss T 0.028183 Method MME

S real T clipart Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.128728 Loss T 0.029641 Method MME

S real T clipart Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.209893 Loss T 0.015527 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0215, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.8080, Accuracy: 13944/18312 F1 (76.1468%)


Val set: Average loss: 1.9086, Accuracy: 265/360 F1 (73.6111%)

best acc test 75.977501  acc val 73.611111 acc labeled target 98.941799
saving model...
S real T clipart Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.316654 Loss T 0.008644 Method MME

S real T clipart Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.210892 Loss T 0.015522 Method MME

S real T clipart Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.104987 Loss T 0.019524 Method MME

S real T clipart Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.190795 Loss T 0.030397 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 103, 6, 93, 66, 69, 65, 90, 89, 88, 87, 86, 85, 84, 83, 82, 68, 81, 79, 92, 77, 76, 75, 74, 73, 72, 71, 70, 67, 80, 78, 0, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 64, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.138889 Loss T 0.016443 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0559, Accuracy: 1116/1134 F1 (98.4127%)


Test set: Average loss: 1.6870, Accuracy: 13935/18312 F1 (76.0976%)


Val set: Average loss: 1.7432, Accuracy: 264/360 F1 (73.3333%)

best acc test 75.977501  acc val 73.333333 acc labeled target 98.412698
saving model...
S real T clipart Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.223590 Loss T 0.019280 Method MME

S real T clipart Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.112193 Loss T 0.006265 Method MME

S real T clipart Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.142993 Loss T 0.018801 Method MME

S real T clipart Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.029680 Loss T 0.011469 Method MME

S real T clipart Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.240114 Loss T 0.014139 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0217, Accuracy: 1123/1134 F1 (99.0300%)


Test set: Average loss: 1.7991, Accuracy: 14034/18312 F1 (76.6383%)


Val set: Average loss: 2.0033, Accuracy: 267/360 F1 (74.1667%)

best acc test 75.977501  acc val 74.166667 acc labeled target 99.029982
saving model...
S real T clipart Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.205642 Loss T 0.025705 Method MME

S real T clipart Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.447523 Loss T 0.012170 Method MME

S real T clipart Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.391931 Loss T 0.026748 Method MME

S real T clipart Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.371007 Loss T 0.017833 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 6, 106, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 79, 92, 0, 64, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 93, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.227625 Loss T 0.013962 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0537, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 1.8056, Accuracy: 13856/18312 F1 (75.6662%)


Val set: Average loss: 1.9012, Accuracy: 265/360 F1 (73.6111%)

best acc test 75.977501  acc val 73.611111 acc labeled target 98.500882
saving model...
S real T clipart Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.146305 Loss T 0.025652 Method MME

S real T clipart Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.077113 Loss T 0.012187 Method MME

S real T clipart Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.112620 Loss T 0.011747 Method MME

S real T clipart Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.069641 Loss T 0.016141 Method MME

S real T clipart Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.242443 Loss T 0.010228 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0373, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.8304, Accuracy: 14050/18312 F1 (76.7256%)


Val set: Average loss: 1.8650, Accuracy: 268/360 F1 (74.4444%)

best acc test 75.977501  acc val 74.444444 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.151282 Loss T 0.016441 Method MME

S real T clipart Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.138657 Loss T 0.015769 Method MME

S real T clipart Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.070107 Loss T 0.021395 Method MME

S real T clipart Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.253196 Loss T 0.020201 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [47, 103, 63, 13, 55, 6, 34, 123, 70, 89, 88, 81, 90, 86, 85, 91, 84, 83, 82, 87, 0, 92, 78, 77, 76, 75, 74, 73, 72, 71, 69, 68, 67, 80, 79, 94, 95, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 109, 66, 62, 64, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 16, 14, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 15, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 65, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.173936 Loss T 0.011887 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0454, Accuracy: 1120/1134 F1 (98.7654%)


Test set: Average loss: 1.7570, Accuracy: 13907/18312 F1 (75.9447%)


Val set: Average loss: 1.8884, Accuracy: 264/360 F1 (73.3333%)

best acc test 75.977501  acc val 73.333333 acc labeled target 98.765432
saving model...
S real T clipart Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.057053 Loss T 0.012081 Method MME

S real T clipart Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.107705 Loss T 0.016516 Method MME

S real T clipart Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.137943 Loss T 0.021874 Method MME

S real T clipart Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.117159 Loss T 0.029767 Method MME

S real T clipart Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.015295 Loss T 0.016715 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0215, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 1.8081, Accuracy: 14079/18312 F1 (76.8840%)


Val set: Average loss: 1.8949, Accuracy: 271/360 F1 (75.2778%)

best acc test 76.884010  acc val 75.277778 acc labeled target 99.118166
saving model...
S real T clipart Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.109783 Loss T 0.017412 Method MME

S real T clipart Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.054159 Loss T 0.010558 Method MME

S real T clipart Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.308561 Loss T 0.018559 Method MME

S real T clipart Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.199688 Loss T 0.013939 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 91, 13, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 90, 78, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 77, 92, 0, 64, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.044498 Loss T 0.011747 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0434, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.7914, Accuracy: 13915/18312 F1 (75.9884%)


Val set: Average loss: 1.9021, Accuracy: 263/360 F1 (73.0556%)

best acc test 76.884010  acc val 73.055556 acc labeled target 98.853616
saving model...
S real T clipart Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.345779 Loss T 0.026897 Method MME

S real T clipart Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.197077 Loss T 0.014995 Method MME

S real T clipart Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.603256 Loss T 0.017766 Method MME

S real T clipart Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.183347 Loss T 0.009679 Method MME

S real T clipart Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.308495 Loss T 0.024094 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0185, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 1.8867, Accuracy: 14050/18312 F1 (76.7256%)


Val set: Average loss: 2.0237, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.884010  acc val 73.888889 acc labeled target 99.118166
saving model...
S real T clipart Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.201674 Loss T 0.019335 Method MME

S real T clipart Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.355317 Loss T 0.009953 Method MME

S real T clipart Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.113230 Loss T 0.012211 Method MME

S real T clipart Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.047488 Loss T 0.015684 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 103, 12, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 92, 93, 0, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 64, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.057473 Loss T 0.012957 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0544, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.7564, Accuracy: 13937/18312 F1 (76.1086%)


Val set: Average loss: 1.8027, Accuracy: 270/360 F1 (75.0000%)

best acc test 76.884010  acc val 75.000000 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.087200 Loss T 0.013176 Method MME

S real T clipart Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.205020 Loss T 0.010403 Method MME

S real T clipart Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.169995 Loss T 0.015973 Method MME

S real T clipart Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.217456 Loss T 0.017621 Method MME

S real T clipart Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.174060 Loss T 0.011752 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0314, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.8597, Accuracy: 14101/18312 F1 (77.0042%)


Val set: Average loss: 1.9774, Accuracy: 264/360 F1 (73.3333%)

best acc test 76.884010  acc val 73.333333 acc labeled target 98.853616
saving model...
S real T clipart Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.104155 Loss T 0.010601 Method MME

S real T clipart Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.566264 Loss T 0.008842 Method MME

S real T clipart Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.235245 Loss T 0.013612 Method MME

S real T clipart Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.120084 Loss T 0.021439 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 91, 63, 29, 4, 45, 99, 81, 82, 83, 84, 0, 86, 88, 89, 90, 85, 87, 80, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 92, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 93, 65, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 3, 2, 1, 14, 30, 31, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.030607 Loss T 0.006565 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0525, Accuracy: 1119/1134 F1 (98.6772%)


Test set: Average loss: 1.7758, Accuracy: 13989/18312 F1 (76.3925%)


Val set: Average loss: 1.8681, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.884010  acc val 73.888889 acc labeled target 98.677249
saving model...
S real T clipart Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.244247 Loss T 0.007672 Method MME

S real T clipart Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.364381 Loss T 0.020517 Method MME

S real T clipart Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.118144 Loss T 0.013771 Method MME

S real T clipart Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.097235 Loss T 0.026346 Method MME

S real T clipart Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.195174 Loss T 0.015158 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0240, Accuracy: 1122/1134 F1 (98.9418%)


Test set: Average loss: 1.9164, Accuracy: 14077/18312 F1 (76.8731%)


Val set: Average loss: 2.0961, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.884010  acc val 73.888889 acc labeled target 98.941799
saving model...
S real T clipart Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.127034 Loss T 0.012571 Method MME

S real T clipart Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.039862 Loss T 0.008118 Method MME

S real T clipart Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.055929 Loss T 0.009160 Method MME

S real T clipart Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.015508 Loss T 0.021129 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 91, 103, 29, 6, 9, 82, 83, 84, 85, 0, 87, 88, 89, 90, 81, 86, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 93, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 66, 94, 65, 62, 63, 30, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 8, 7, 5, 4, 3, 2, 1, 31, 64, 32, 34, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.362588 Loss T 0.003649 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0535, Accuracy: 1115/1134 F1 (98.3245%)


Test set: Average loss: 1.8227, Accuracy: 13992/18312 F1 (76.4089%)


Val set: Average loss: 1.9915, Accuracy: 269/360 F1 (74.7222%)

best acc test 76.884010  acc val 74.722222 acc labeled target 98.324515
saving model...
S real T clipart Train Ep: 28100 lr0.0036669608075000928 	 Loss Classification: 0.089914 Loss T 0.010136 Method MME

S real T clipart Train Ep: 28200 lr0.00365975891867815 	 Loss Classification: 0.360844 Loss T 0.015108 Method MME

S real T clipart Train Ep: 28300 lr0.003652589947415138 	 Loss Classification: 0.575325 Loss T 0.020570 Method MME

S real T clipart Train Ep: 28400 lr0.0036454536578964408 	 Loss Classification: 0.283232 Loss T 0.014097 Method MME

S real T clipart Train Ep: 28500 lr0.0036383498166050877 	 Loss Classification: 0.328929 Loss T 0.010177 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0295, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.8975, Accuracy: 14118/18312 F1 (77.0970%)


Val set: Average loss: 1.9635, Accuracy: 263/360 F1 (73.0556%)

best acc test 76.884010  acc val 73.055556 acc labeled target 98.853616
saving model...
S real T clipart Train Ep: 28600 lr0.0036312781922934662 	 Loss Classification: 0.129405 Loss T 0.009704 Method MME

S real T clipart Train Ep: 28700 lr0.003624238555955462 	 Loss Classification: 0.071763 Loss T 0.015286 Method MME

S real T clipart Train Ep: 28800 lr0.003617230680799007 	 Loss Classification: 0.219715 Loss T 0.008418 Method MME

S real T clipart Train Ep: 28900 lr0.0036102543422190363 	 Loss Classification: 0.039320 Loss T 0.011861 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 91, 63, 111, 11, 24, 30, 87, 86, 89, 85, 84, 90, 83, 82, 81, 88, 0, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 93, 65, 62, 124, 28, 27, 26, 25, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 64, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 29000 lr0.003603309317770844 	 Loss Classification: 0.210935 Loss T 0.017030 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0542, Accuracy: 1117/1134 F1 (98.5009%)


Test set: Average loss: 1.7792, Accuracy: 13937/18312 F1 (76.1086%)


Val set: Average loss: 1.8615, Accuracy: 262/360 F1 (72.7778%)

best acc test 76.884010  acc val 72.777778 acc labeled target 98.500882
saving model...
S real T clipart Train Ep: 29100 lr0.0035963953871438275 	 Loss Classification: 0.221128 Loss T 0.012850 Method MME

S real T clipart Train Ep: 29200 lr0.0035895123321356215 	 Loss Classification: 0.348374 Loss T 0.012757 Method MME

S real T clipart Train Ep: 29300 lr0.003582659936626608 	 Loss Classification: 0.382856 Loss T 0.012475 Method MME

S real T clipart Train Ep: 29400 lr0.0035758379865547998 	 Loss Classification: 0.058709 Loss T 0.005738 Method MME

S real T clipart Train Ep: 29500 lr0.0035690462698910875 	 Loss Classification: 0.203399 Loss T 0.002511 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0191, Accuracy: 1124/1134 F1 (99.1182%)


Test set: Average loss: 1.9354, Accuracy: 14109/18312 F1 (77.0478%)


Val set: Average loss: 2.0829, Accuracy: 268/360 F1 (74.4444%)

best acc test 76.884010  acc val 74.444444 acc labeled target 99.118166
saving model...
S real T clipart Train Ep: 29600 lr0.0035622845766148485 	 Loss Classification: 0.033870 Loss T 0.011362 Method MME

S real T clipart Train Ep: 29700 lr0.0035555526986899093 	 Loss Classification: 0.196724 Loss T 0.013769 Method MME

S real T clipart Train Ep: 29800 lr0.0035488504300408524 	 Loss Classification: 0.147076 Loss T 0.008342 Method MME

S real T clipart Train Ep: 29900 lr0.0035421775665296674 	 Loss Classification: 0.239297 Loss T 0.010315 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 48, 67, 90, 89, 88, 87, 86, 85, 84, 83, 65, 82, 81, 80, 79, 78, 91, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 66, 92, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 93, 62, 61, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 124, 29, 31, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 30, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 30000 lr0.003535533905932738 	 Loss Classification: 0.134732 Loss T 0.020914 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0482, Accuracy: 1114/1134 F1 (98.2363%)


Test set: Average loss: 1.7722, Accuracy: 13986/18312 F1 (76.3761%)


Val set: Average loss: 1.9223, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.884010  acc val 73.888889 acc labeled target 98.236332
saving model...
S real T clipart Train Ep: 30100 lr0.0035289192479181558 	 Loss Classification: 0.103742 Loss T 0.010316 Method MME

S real T clipart Train Ep: 30200 lr0.003522333394023364 	 Loss Classification: 0.365181 Loss T 0.006220 Method MME

S real T clipart Train Ep: 30300 lr0.0035157761476331158 	 Loss Classification: 0.073884 Loss T 0.014085 Method MME

S real T clipart Train Ep: 30400 lr0.003509247313957748 	 Loss Classification: 0.068541 Loss T 0.016921 Method MME

S real T clipart Train Ep: 30500 lr0.003502746700011762 	 Loss Classification: 0.302113 Loss T 0.013158 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0247, Accuracy: 1121/1134 F1 (98.8536%)


Test set: Average loss: 1.9390, Accuracy: 14102/18312 F1 (77.0096%)


Val set: Average loss: 2.1323, Accuracy: 270/360 F1 (75.0000%)

best acc test 76.884010  acc val 75.000000 acc labeled target 98.853616
saving model...
S real T clipart Train Ep: 30600 lr0.003496274114592713 	 Loss Classification: 0.197157 Loss T 0.011967 Method MME

S real T clipart Train Ep: 30700 lr0.0034898293682603908 	 Loss Classification: 0.108585 Loss T 0.008263 Method MME

S real T clipart Train Ep: 30800 lr0.0034834122733162975 	 Loss Classification: 0.159143 Loss T 0.013069 Method MME

S real T clipart Train Ep: 30900 lr0.0034770226437834152 	 Loss Classification: 0.102195 Loss T 0.013980 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.6666667 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 47, 91, 89, 12, 116, 92, 71, 90, 65, 88, 87, 86, 85, 84, 83, 82, 81, 70, 80, 66, 78, 67, 76, 75, 68, 74, 73, 72, 69, 79, 77, 0, 64, 123, 122, 121, 120, 119, 118, 117, 115, 114, 113, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 108, 94, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
