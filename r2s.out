Dataset multi Source real Target sketch Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  70358
Unlabelled Target Dataset Size:  23826
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  23826 Source:  70358
Unlabeled Target Data Batches: 496
S real T sketch Train Ep: 0 lr0.01 	 Loss Classification: 5.111156 Loss T 0.469564 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9926, Accuracy: 8/1134 F1 (0.7055%)


Test set: Average loss: 4.9677, Accuracy: 147/23808 F1 (0.6174%)


Val set: Average loss: 4.9973, Accuracy: 1/360 F1 (0.2778%)

Patience Reset, Counter is: 0
best acc test 0.617440  acc val 0.277778 acc labeled target 0.705467
saving model...
S real T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.355909 Loss T 0.305775 Method MME

S real T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 0.891443 Loss T 0.241527 Method MME

S real T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 0.998102 Loss T 0.216636 Method MME

S real T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.101033 Loss T 0.205290 Method MME

S real T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.386125 Loss T 0.175884 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7351, Accuracy: 460/1134 F1 (40.5644%)


Test set: Average loss: 2.5712, Accuracy: 10787/23808 F1 (45.3083%)


Val set: Average loss: 2.3924, Accuracy: 166/360 F1 (46.1111%)

Patience Reset, Counter is: 0
best acc test 45.308300  acc val 46.111111 acc labeled target 40.564374
saving model...
S real T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.175162 Loss T 0.159842 Method MME

S real T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.922777 Loss T 0.148832 Method MME

S real T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.797391 Loss T 0.169555 Method MME

S real T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.102173 Loss T 0.152756 Method MME

S real T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.643947 Loss T 0.132795 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5781, Accuracy: 521/1134 F1 (45.9436%)


Test set: Average loss: 2.3277, Accuracy: 12146/23808 F1 (51.0165%)


Val set: Average loss: 2.1951, Accuracy: 187/360 F1 (51.9444%)

Patience Reset, Counter is: 0
best acc test 51.016465  acc val 51.944444 acc labeled target 45.943563
saving model...
S real T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.047844 Loss T 0.124885 Method MME

S real T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.819786 Loss T 0.117941 Method MME

S real T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.248046 Loss T 0.129940 Method MME

S real T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.917481 Loss T 0.109444 Method MME

S real T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.190883 Loss T 0.118024 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3538, Accuracy: 588/1134 F1 (51.8519%)


Test set: Average loss: 2.2796, Accuracy: 12702/23808 F1 (53.3518%)


Val set: Average loss: 2.0311, Accuracy: 213/360 F1 (59.1667%)

Patience Reset, Counter is: 0
best acc test 53.351815  acc val 59.166667 acc labeled target 51.851852
saving model...
S real T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.642654 Loss T 0.122154 Method MME

S real T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.123913 Loss T 0.120565 Method MME

S real T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.537473 Loss T 0.104274 Method MME

S real T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.679217 Loss T 0.124701 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.6666667  0.5555556  0.         0.
 0.22222222 0.8888889  0.6666667  0.         0.8888889  1.
 0.22222222 0.         0.7777778  0.5555556  1.         1.
 0.5555556  0.11111111 0.5555556  0.8888889  0.5555556  0.8888889
 0.44444445 0.22222222 0.         0.7777778  0.44444445 0.5555556
 0.44444445 0.11111111 0.22222222 0.5555556  0.6666667  0.5555556
 0.6666667  0.         0.8888889  0.8888889  0.7777778  0.8888889
 0.6666667  0.22222222 0.6666667  0.5555556  0.8888889  0.7777778
 0.44444445 1.         0.33333334 0.22222222 0.6666667  0.44444445
 0.5555556  0.5555556  0.7777778  0.44444445 0.7777778  1.
 0.8888889  0.33333334 0.7777778  0.22222222 0.5555556  0.6666667
 0.11111111 0.         0.33333334 0.8888889  0.         0.33333334
 0.44444445 0.44444445 1.         0.22222222 0.22222222 0.6666667
 0.8888889  0.7777778  0.         0.33333334 0.33333334 0.6666667
 0.5555556  0.44444445 1.         0.6666667  0.         0.22222222
 0.         0.8888889  0.5555556  0.44444445 1.         0.6666667
 0.5555556  0.8888889  0.11111111 0.         0.44444445 0.44444445
 0.6666667  0.11111111 0.6666667  0.         0.33333334 0.5555556
 0.         0.22222222 0.33333334 0.8888889  0.22222222 0.8888889
 0.33333334 1.         0.5555556  0.6666667  0.5555556  0.33333334
 0.33333334 1.         0.7777778  0.         0.         0.8888889 ]
Top k classes which perform poorly are:  [99, 26, 37, 108, 124, 67, 13, 105, 9, 70, 123, 90, 88, 5, 80, 4, 19, 98, 31, 66, 103, 89, 51, 32, 43, 112, 75, 63, 76, 109, 6, 25, 12, 110, 81, 82, 114, 119, 50, 120, 71, 106, 68, 61, 53, 72, 57, 73, 30, 85, 24, 93, 101, 100, 28, 48, 84, 3, 92, 96, 15, 118, 29, 64, 18, 33, 35, 22, 116, 54, 55, 45, 20, 107, 117, 36, 87, 34, 42, 83, 44, 2, 8, 95, 104, 77, 65, 52, 102, 27, 56, 62, 40, 122, 14, 79, 47, 58, 113, 111, 0, 38, 7, 10, 21, 23, 97, 39, 41, 46, 125, 60, 69, 78, 91, 59, 74, 115, 17, 16, 11, 86, 121, 1, 49, 94]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2567, 1.2869, 1.5000, 1.5000, 1.4004, 1.2056, 1.2567,
        1.5000, 1.2056, 1.1839, 1.4004, 1.5000, 1.2297, 1.2869, 1.1839, 1.1839,
        1.2869, 1.4474, 1.2869, 1.2056, 1.2869, 1.2056, 1.3206, 1.4004, 1.5000,
        1.2297, 1.3206, 1.2869, 1.3206, 1.4474, 1.4004, 1.2869, 1.2567, 1.2869,
        1.2567, 1.5000, 1.2056, 1.2056, 1.2297, 1.2056, 1.2567, 1.4004, 1.2567,
        1.2869, 1.2056, 1.2297, 1.3206, 1.1839, 1.3583, 1.4004, 1.2567, 1.3206,
        1.2869, 1.2869, 1.2297, 1.3206, 1.2297, 1.1839, 1.2056, 1.3583, 1.2297,
        1.4004, 1.2869, 1.2567, 1.4474, 1.5000, 1.3583, 1.2056, 1.5000, 1.3583,
        1.3206, 1.3206, 1.1839, 1.4004, 1.4004, 1.2567, 1.2056, 1.2297, 1.5000,
        1.3583, 1.3583, 1.2567, 1.2869, 1.3206, 1.1839, 1.2567, 1.5000, 1.4004,
        1.5000, 1.2056, 1.2869, 1.3206, 1.1839, 1.2567, 1.2869, 1.2056, 1.4474,
        1.5000, 1.3206, 1.3206, 1.2567, 1.4474, 1.2567, 1.5000, 1.3583, 1.2869,
        1.5000, 1.4004, 1.3583, 1.2056, 1.4004, 1.2056, 1.3583, 1.1839, 1.2869,
        1.2567, 1.2869, 1.3583, 1.3583, 1.1839, 1.2297, 1.5000, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7433, 0.7131, 0.5000, 0.5000, 0.5996, 0.7944, 0.7433,
        0.5000, 0.7944, 0.8161, 0.5996, 0.5000, 0.7703, 0.7131, 0.8161, 0.8161,
        0.7131, 0.5526, 0.7131, 0.7944, 0.7131, 0.7944, 0.6794, 0.5996, 0.5000,
        0.7703, 0.6794, 0.7131, 0.6794, 0.5526, 0.5996, 0.7131, 0.7433, 0.7131,
        0.7433, 0.5000, 0.7944, 0.7944, 0.7703, 0.7944, 0.7433, 0.5996, 0.7433,
        0.7131, 0.7944, 0.7703, 0.6794, 0.8161, 0.6417, 0.5996, 0.7433, 0.6794,
        0.7131, 0.7131, 0.7703, 0.6794, 0.7703, 0.8161, 0.7944, 0.6417, 0.7703,
        0.5996, 0.7131, 0.7433, 0.5526, 0.5000, 0.6417, 0.7944, 0.5000, 0.6417,
        0.6794, 0.6794, 0.8161, 0.5996, 0.5996, 0.7433, 0.7944, 0.7703, 0.5000,
        0.6417, 0.6417, 0.7433, 0.7131, 0.6794, 0.8161, 0.7433, 0.5000, 0.5996,
        0.5000, 0.7944, 0.7131, 0.6794, 0.8161, 0.7433, 0.7131, 0.7944, 0.5526,
        0.5000, 0.6794, 0.6794, 0.7433, 0.5526, 0.7433, 0.5000, 0.6417, 0.7131,
        0.5000, 0.5996, 0.6417, 0.7944, 0.5996, 0.7944, 0.6417, 0.8161, 0.7131,
        0.7433, 0.7131, 0.6417, 0.6417, 0.8161, 0.7703, 0.5000, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.480774 Loss T 0.099388 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5702, Accuracy: 557/1134 F1 (49.1182%)


Test set: Average loss: 2.3587, Accuracy: 12718/23808 F1 (53.4190%)


Val set: Average loss: 2.3072, Accuracy: 194/360 F1 (53.8889%)

Patience getting saturated, current counter is:  0
best acc test 53.351815  acc val 53.888889 acc labeled target 49.118166
saving model...
S real T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.122402 Loss T 0.095850 Method MME

S real T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.698863 Loss T 0.120790 Method MME

S real T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.528314 Loss T 0.115536 Method MME

S real T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.120184 Loss T 0.093511 Method MME

S real T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 1.621423 Loss T 0.120690 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.2587, Accuracy: 600/1134 F1 (52.9101%)


Test set: Average loss: 2.0927, Accuracy: 13859/23808 F1 (58.2115%)


Val set: Average loss: 1.9919, Accuracy: 207/360 F1 (57.5000%)

Patience getting saturated, current counter is:  1
best acc test 53.351815  acc val 57.500000 acc labeled target 52.910053
saving model...
S real T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.683609 Loss T 0.115946 Method MME

S real T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.681375 Loss T 0.112203 Method MME

S real T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.705450 Loss T 0.103830 Method MME

S real T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.682356 Loss T 0.108035 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.5555556  0.33333334 0.8888889  0.
 0.44444445 0.7777778  0.44444445 0.         0.6666667  1.
 0.         0.11111111 0.7777778  0.6666667  0.33333334 0.8888889
 0.33333334 0.         0.8888889  0.8888889  0.5555556  0.6666667
 0.11111111 0.33333334 0.         0.8888889  0.6666667  0.
 0.33333334 0.11111111 0.         0.22222222 0.44444445 0.8888889
 0.33333334 0.         0.8888889  0.6666667  0.5555556  0.8888889
 0.22222222 0.5555556  0.6666667  0.5555556  1.         0.7777778
 0.33333334 1.         0.33333334 0.22222222 1.         0.11111111
 0.6666667  0.44444445 0.7777778  0.6666667  0.8888889  0.7777778
 0.8888889  0.33333334 0.7777778  0.33333334 0.5555556  0.6666667
 0.33333334 0.6666667  0.5555556  0.6666667  0.         0.22222222
 0.6666667  0.33333334 1.         0.33333334 0.         1.
 0.8888889  1.         0.         0.8888889  0.33333334 0.
 0.6666667  0.6666667  1.         0.6666667  0.         0.5555556
 0.22222222 1.         0.44444445 1.         1.         0.5555556
 0.33333334 1.         0.44444445 0.         0.6666667  0.6666667
 0.44444445 0.6666667  0.6666667  0.         0.33333334 0.44444445
 0.         0.33333334 0.5555556  1.         0.33333334 1.
 0.33333334 0.8888889  0.33333334 0.6666667  0.11111111 0.33333334
 0.8888889  0.8888889  0.6666667  0.         0.         1.        ]
Top k classes which perform poorly are:  [19, 108, 26, 124, 32, 70, 12, 76, 105, 29, 80, 37, 83, 123, 99, 5, 9, 88, 13, 53, 31, 24, 118, 42, 33, 71, 51, 90, 50, 112, 48, 61, 63, 66, 73, 106, 75, 82, 109, 114, 96, 3, 25, 18, 36, 119, 116, 16, 30, 102, 107, 8, 55, 6, 92, 98, 34, 110, 95, 89, 45, 2, 43, 22, 64, 40, 68, 103, 87, 85, 101, 104, 122, 100, 84, 10, 39, 15, 72, 44, 69, 67, 65, 23, 28, 117, 57, 54, 14, 47, 59, 7, 56, 62, 121, 120, 115, 0, 4, 81, 17, 78, 20, 21, 60, 58, 27, 35, 38, 41, 94, 1, 11, 111, 46, 97, 49, 52, 74, 77, 79, 86, 91, 93, 113, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2869, 1.3583, 1.2056, 1.5000, 1.3206, 1.2297, 1.3206,
        1.5000, 1.2567, 1.1839, 1.5000, 1.4474, 1.2297, 1.2567, 1.3583, 1.2056,
        1.3583, 1.5000, 1.2056, 1.2056, 1.2869, 1.2567, 1.4474, 1.3583, 1.5000,
        1.2056, 1.2567, 1.5000, 1.3583, 1.4474, 1.5000, 1.4004, 1.3206, 1.2056,
        1.3583, 1.5000, 1.2056, 1.2567, 1.2869, 1.2056, 1.4004, 1.2869, 1.2567,
        1.2869, 1.1839, 1.2297, 1.3583, 1.1839, 1.3583, 1.4004, 1.1839, 1.4474,
        1.2567, 1.3206, 1.2297, 1.2567, 1.2056, 1.2297, 1.2056, 1.3583, 1.2297,
        1.3583, 1.2869, 1.2567, 1.3583, 1.2567, 1.2869, 1.2567, 1.5000, 1.4004,
        1.2567, 1.3583, 1.1839, 1.3583, 1.5000, 1.1839, 1.2056, 1.1839, 1.5000,
        1.2056, 1.3583, 1.5000, 1.2567, 1.2567, 1.1839, 1.2567, 1.5000, 1.2869,
        1.4004, 1.1839, 1.3206, 1.1839, 1.1839, 1.2869, 1.3583, 1.1839, 1.3206,
        1.5000, 1.2567, 1.2567, 1.3206, 1.2567, 1.2567, 1.5000, 1.3583, 1.3206,
        1.5000, 1.3583, 1.2869, 1.1839, 1.3583, 1.1839, 1.3583, 1.2056, 1.3583,
        1.2567, 1.4474, 1.3583, 1.2056, 1.2056, 1.2567, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7131, 0.6417, 0.7944, 0.5000, 0.6794, 0.7703, 0.6794,
        0.5000, 0.7433, 0.8161, 0.5000, 0.5526, 0.7703, 0.7433, 0.6417, 0.7944,
        0.6417, 0.5000, 0.7944, 0.7944, 0.7131, 0.7433, 0.5526, 0.6417, 0.5000,
        0.7944, 0.7433, 0.5000, 0.6417, 0.5526, 0.5000, 0.5996, 0.6794, 0.7944,
        0.6417, 0.5000, 0.7944, 0.7433, 0.7131, 0.7944, 0.5996, 0.7131, 0.7433,
        0.7131, 0.8161, 0.7703, 0.6417, 0.8161, 0.6417, 0.5996, 0.8161, 0.5526,
        0.7433, 0.6794, 0.7703, 0.7433, 0.7944, 0.7703, 0.7944, 0.6417, 0.7703,
        0.6417, 0.7131, 0.7433, 0.6417, 0.7433, 0.7131, 0.7433, 0.5000, 0.5996,
        0.7433, 0.6417, 0.8161, 0.6417, 0.5000, 0.8161, 0.7944, 0.8161, 0.5000,
        0.7944, 0.6417, 0.5000, 0.7433, 0.7433, 0.8161, 0.7433, 0.5000, 0.7131,
        0.5996, 0.8161, 0.6794, 0.8161, 0.8161, 0.7131, 0.6417, 0.8161, 0.6794,
        0.5000, 0.7433, 0.7433, 0.6794, 0.7433, 0.7433, 0.5000, 0.6417, 0.6794,
        0.5000, 0.6417, 0.7131, 0.8161, 0.6417, 0.8161, 0.6417, 0.7944, 0.6417,
        0.7433, 0.5526, 0.6417, 0.7944, 0.7944, 0.7433, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.759911 Loss T 0.096380 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4714, Accuracy: 574/1134 F1 (50.6173%)


Test set: Average loss: 2.3154, Accuracy: 13373/23808 F1 (56.1702%)


Val set: Average loss: 2.1002, Accuracy: 204/360 F1 (56.6667%)

Patience getting saturated, current counter is:  2
best acc test 53.351815  acc val 56.666667 acc labeled target 50.617284
saving model...
S real T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.234823 Loss T 0.103552 Method MME

S real T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.651946 Loss T 0.079308 Method MME

S real T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.577284 Loss T 0.072375 Method MME

S real T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.368709 Loss T 0.093566 Method MME

S real T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.366767 Loss T 0.099622 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.1084, Accuracy: 650/1134 F1 (57.3192%)


Test set: Average loss: 1.9564, Accuracy: 14706/23808 F1 (61.7692%)


Val set: Average loss: 1.8348, Accuracy: 225/360 F1 (62.5000%)

Patience Reset, Counter is: 3
best acc test 61.769153  acc val 62.500000 acc labeled target 57.319224
saving model...
S real T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.630898 Loss T 0.097619 Method MME

S real T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.642542 Loss T 0.096120 Method MME

S real T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.785142 Loss T 0.076362 Method MME

S real T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.901998 Loss T 0.070442 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.6666667  0.5555556  0.7777778  0.22222222
 0.44444445 0.8888889  0.8888889  0.11111111 0.7777778  1.
 0.         0.11111111 0.22222222 0.5555556  1.         0.8888889
 0.6666667  0.44444445 0.7777778  0.8888889  0.8888889  0.44444445
 0.5555556  0.33333334 0.         0.44444445 0.6666667  0.11111111
 0.5555556  0.22222222 0.22222222 0.44444445 0.7777778  0.5555556
 0.22222222 0.         0.8888889  0.8888889  0.22222222 1.
 0.5555556  0.11111111 0.6666667  0.5555556  1.         0.5555556
 0.33333334 1.         0.33333334 0.33333334 0.8888889  0.33333334
 0.7777778  0.5555556  0.7777778  0.7777778  0.8888889  1.
 0.8888889  0.22222222 0.8888889  0.33333334 1.         0.7777778
 0.6666667  0.44444445 0.44444445 1.         0.         0.44444445
 0.44444445 0.7777778  0.8888889  0.33333334 0.11111111 1.
 0.8888889  0.6666667  0.         0.8888889  0.22222222 0.44444445
 0.5555556  0.33333334 0.8888889  0.6666667  0.         0.6666667
 0.22222222 1.         0.6666667  0.7777778  1.         0.6666667
 0.5555556  0.6666667  0.         0.22222222 0.8888889  0.44444445
 0.6666667  0.8888889  0.7777778  0.11111111 0.22222222 0.6666667
 0.6666667  0.33333334 0.6666667  0.8888889  0.44444445 1.
 0.5555556  0.8888889  0.33333334 0.6666667  0.         0.33333334
 0.6666667  0.8888889  0.8888889  0.11111111 0.11111111 1.        ]
Top k classes which perform poorly are:  [118, 98, 88, 70, 26, 37, 80, 12, 9, 124, 29, 76, 13, 43, 105, 123, 36, 32, 40, 82, 31, 14, 61, 106, 99, 5, 90, 53, 109, 63, 48, 25, 51, 85, 50, 75, 119, 116, 6, 83, 19, 101, 72, 23, 67, 68, 27, 33, 71, 112, 84, 55, 96, 42, 30, 47, 3, 35, 45, 24, 114, 15, 117, 102, 79, 18, 95, 87, 89, 2, 92, 97, 120, 110, 0, 28, 66, 44, 107, 108, 34, 104, 20, 54, 93, 65, 10, 73, 56, 57, 4, 121, 122, 100, 115, 111, 103, 62, 60, 22, 21, 17, 52, 58, 39, 38, 7, 74, 78, 81, 86, 8, 11, 1, 16, 91, 46, 41, 94, 49, 59, 64, 69, 77, 113, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.2567, 1.2869, 1.2297, 1.4004, 1.3206, 1.2056, 1.2056,
        1.4474, 1.2297, 1.1839, 1.5000, 1.4474, 1.4004, 1.2869, 1.1839, 1.2056,
        1.2567, 1.3206, 1.2297, 1.2056, 1.2056, 1.3206, 1.2869, 1.3583, 1.5000,
        1.3206, 1.2567, 1.4474, 1.2869, 1.4004, 1.4004, 1.3206, 1.2297, 1.2869,
        1.4004, 1.5000, 1.2056, 1.2056, 1.4004, 1.1839, 1.2869, 1.4474, 1.2567,
        1.2869, 1.1839, 1.2869, 1.3583, 1.1839, 1.3583, 1.3583, 1.2056, 1.3583,
        1.2297, 1.2869, 1.2297, 1.2297, 1.2056, 1.1839, 1.2056, 1.4004, 1.2056,
        1.3583, 1.1839, 1.2297, 1.2567, 1.3206, 1.3206, 1.1839, 1.5000, 1.3206,
        1.3206, 1.2297, 1.2056, 1.3583, 1.4474, 1.1839, 1.2056, 1.2567, 1.5000,
        1.2056, 1.4004, 1.3206, 1.2869, 1.3583, 1.2056, 1.2567, 1.5000, 1.2567,
        1.4004, 1.1839, 1.2567, 1.2297, 1.1839, 1.2567, 1.2869, 1.2567, 1.5000,
        1.4004, 1.2056, 1.3206, 1.2567, 1.2056, 1.2297, 1.4474, 1.4004, 1.2567,
        1.2567, 1.3583, 1.2567, 1.2056, 1.3206, 1.1839, 1.2869, 1.2056, 1.3583,
        1.2567, 1.5000, 1.3583, 1.2567, 1.2056, 1.2056, 1.4474, 1.4474, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.7433, 0.7131, 0.7703, 0.5996, 0.6794, 0.7944, 0.7944,
        0.5526, 0.7703, 0.8161, 0.5000, 0.5526, 0.5996, 0.7131, 0.8161, 0.7944,
        0.7433, 0.6794, 0.7703, 0.7944, 0.7944, 0.6794, 0.7131, 0.6417, 0.5000,
        0.6794, 0.7433, 0.5526, 0.7131, 0.5996, 0.5996, 0.6794, 0.7703, 0.7131,
        0.5996, 0.5000, 0.7944, 0.7944, 0.5996, 0.8161, 0.7131, 0.5526, 0.7433,
        0.7131, 0.8161, 0.7131, 0.6417, 0.8161, 0.6417, 0.6417, 0.7944, 0.6417,
        0.7703, 0.7131, 0.7703, 0.7703, 0.7944, 0.8161, 0.7944, 0.5996, 0.7944,
        0.6417, 0.8161, 0.7703, 0.7433, 0.6794, 0.6794, 0.8161, 0.5000, 0.6794,
        0.6794, 0.7703, 0.7944, 0.6417, 0.5526, 0.8161, 0.7944, 0.7433, 0.5000,
        0.7944, 0.5996, 0.6794, 0.7131, 0.6417, 0.7944, 0.7433, 0.5000, 0.7433,
        0.5996, 0.8161, 0.7433, 0.7703, 0.8161, 0.7433, 0.7131, 0.7433, 0.5000,
        0.5996, 0.7944, 0.6794, 0.7433, 0.7944, 0.7703, 0.5526, 0.5996, 0.7433,
        0.7433, 0.6417, 0.7433, 0.7944, 0.6794, 0.8161, 0.7131, 0.7944, 0.6417,
        0.7433, 0.5000, 0.6417, 0.7433, 0.7944, 0.7944, 0.5526, 0.5526, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.618923 Loss T 0.106680 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3700, Accuracy: 630/1134 F1 (55.5556%)


Test set: Average loss: 2.1760, Accuracy: 14217/23808 F1 (59.7152%)


Val set: Average loss: 2.1564, Accuracy: 197/360 F1 (54.7222%)

Patience getting saturated, current counter is:  0
best acc test 61.769153  acc val 54.722222 acc labeled target 55.555556
saving model...
S real T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.642440 Loss T 0.100660 Method MME

S real T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.708707 Loss T 0.078287 Method MME

S real T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.204017 Loss T 0.099515 Method MME

S real T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.393300 Loss T 0.070146 Method MME

S real T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.562801 Loss T 0.112010 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0524, Accuracy: 662/1134 F1 (58.3774%)


Test set: Average loss: 1.9995, Accuracy: 14756/23808 F1 (61.9792%)


Val set: Average loss: 1.8003, Accuracy: 215/360 F1 (59.7222%)

Patience getting saturated, current counter is:  1
best acc test 61.769153  acc val 59.722222 acc labeled target 58.377425
saving model...
S real T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.238979 Loss T 0.101874 Method MME

S real T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.243958 Loss T 0.081754 Method MME

S real T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.398724 Loss T 0.095705 Method MME

S real T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.174900 Loss T 0.077134 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.6666667  0.6666667  0.7777778  0.
 0.33333334 1.         0.7777778  0.         0.8888889  1.
 0.         0.11111111 0.5555556  0.33333334 0.8888889  0.8888889
 0.8888889  0.22222222 0.6666667  0.5555556  0.6666667  0.8888889
 0.11111111 0.22222222 0.         0.6666667  0.6666667  0.33333334
 0.5555556  0.44444445 0.6666667  0.22222222 1.         0.5555556
 0.11111111 0.         1.         0.44444445 0.22222222 1.
 1.         0.22222222 0.5555556  0.6666667  0.8888889  0.8888889
 0.33333334 1.         0.33333334 0.33333334 1.         0.22222222
 1.         0.44444445 0.8888889  0.7777778  1.         1.
 0.8888889  0.11111111 0.8888889  0.33333334 0.7777778  0.8888889
 0.22222222 0.6666667  0.44444445 0.6666667  0.         0.33333334
 0.5555556  0.44444445 0.8888889  0.33333334 0.22222222 1.
 0.8888889  0.6666667  0.         0.8888889  0.11111111 0.6666667
 0.6666667  0.5555556  0.8888889  0.6666667  0.22222222 0.6666667
 0.33333334 1.         0.6666667  1.         0.8888889  0.6666667
 0.33333334 0.8888889  0.5555556  0.6666667  1.         0.44444445
 0.5555556  0.6666667  0.6666667  0.         0.22222222 0.6666667
 0.33333334 0.33333334 0.5555556  1.         0.6666667  1.
 0.8888889  1.         0.44444445 0.6666667  0.         0.33333334
 0.6666667  0.7777778  0.6666667  0.         0.         1.        ]
Top k classes which perform poorly are:  [26, 123, 124, 70, 5, 80, 118, 105, 9, 37, 12, 24, 36, 13, 82, 61, 40, 106, 53, 66, 19, 76, 43, 88, 25, 33, 109, 90, 108, 50, 51, 71, 48, 75, 15, 6, 63, 29, 119, 96, 101, 68, 55, 73, 31, 39, 116, 44, 35, 102, 30, 72, 85, 98, 14, 110, 21, 83, 67, 79, 95, 92, 87, 84, 69, 45, 99, 2, 3, 122, 120, 117, 20, 27, 28, 22, 112, 89, 107, 104, 103, 32, 64, 121, 8, 4, 57, 97, 114, 94, 0, 62, 86, 10, 16, 17, 18, 23, 47, 56, 46, 60, 65, 81, 78, 74, 59, 1, 7, 93, 11, 77, 115, 34, 113, 38, 111, 41, 42, 91, 49, 52, 54, 58, 100, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2567, 1.2567, 1.2297, 1.5000, 1.3583, 1.1839, 1.2297,
        1.5000, 1.2056, 1.1839, 1.5000, 1.4474, 1.2869, 1.3583, 1.2056, 1.2056,
        1.2056, 1.4004, 1.2567, 1.2869, 1.2567, 1.2056, 1.4474, 1.4004, 1.5000,
        1.2567, 1.2567, 1.3583, 1.2869, 1.3206, 1.2567, 1.4004, 1.1839, 1.2869,
        1.4474, 1.5000, 1.1839, 1.3206, 1.4004, 1.1839, 1.1839, 1.4004, 1.2869,
        1.2567, 1.2056, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.4004,
        1.1839, 1.3206, 1.2056, 1.2297, 1.1839, 1.1839, 1.2056, 1.4474, 1.2056,
        1.3583, 1.2297, 1.2056, 1.4004, 1.2567, 1.3206, 1.2567, 1.5000, 1.3583,
        1.2869, 1.3206, 1.2056, 1.3583, 1.4004, 1.1839, 1.2056, 1.2567, 1.5000,
        1.2056, 1.4474, 1.2567, 1.2567, 1.2869, 1.2056, 1.2567, 1.4004, 1.2567,
        1.3583, 1.1839, 1.2567, 1.1839, 1.2056, 1.2567, 1.3583, 1.2056, 1.2869,
        1.2567, 1.1839, 1.3206, 1.2869, 1.2567, 1.2567, 1.5000, 1.4004, 1.2567,
        1.3583, 1.3583, 1.2869, 1.1839, 1.2567, 1.1839, 1.2056, 1.1839, 1.3206,
        1.2567, 1.5000, 1.3583, 1.2567, 1.2297, 1.2567, 1.5000, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7433, 0.7433, 0.7703, 0.5000, 0.6417, 0.8161, 0.7703,
        0.5000, 0.7944, 0.8161, 0.5000, 0.5526, 0.7131, 0.6417, 0.7944, 0.7944,
        0.7944, 0.5996, 0.7433, 0.7131, 0.7433, 0.7944, 0.5526, 0.5996, 0.5000,
        0.7433, 0.7433, 0.6417, 0.7131, 0.6794, 0.7433, 0.5996, 0.8161, 0.7131,
        0.5526, 0.5000, 0.8161, 0.6794, 0.5996, 0.8161, 0.8161, 0.5996, 0.7131,
        0.7433, 0.7944, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.5996,
        0.8161, 0.6794, 0.7944, 0.7703, 0.8161, 0.8161, 0.7944, 0.5526, 0.7944,
        0.6417, 0.7703, 0.7944, 0.5996, 0.7433, 0.6794, 0.7433, 0.5000, 0.6417,
        0.7131, 0.6794, 0.7944, 0.6417, 0.5996, 0.8161, 0.7944, 0.7433, 0.5000,
        0.7944, 0.5526, 0.7433, 0.7433, 0.7131, 0.7944, 0.7433, 0.5996, 0.7433,
        0.6417, 0.8161, 0.7433, 0.8161, 0.7944, 0.7433, 0.6417, 0.7944, 0.7131,
        0.7433, 0.8161, 0.6794, 0.7131, 0.7433, 0.7433, 0.5000, 0.5996, 0.7433,
        0.6417, 0.6417, 0.7131, 0.8161, 0.7433, 0.8161, 0.7944, 0.8161, 0.6794,
        0.7433, 0.5000, 0.6417, 0.7433, 0.7703, 0.7433, 0.5000, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.682915 Loss T 0.093700 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4064, Accuracy: 621/1134 F1 (54.7619%)


Test set: Average loss: 2.2321, Accuracy: 14270/23808 F1 (59.9378%)


Val set: Average loss: 2.2906, Accuracy: 193/360 F1 (53.6111%)

Patience getting saturated, current counter is:  2
best acc test 61.769153  acc val 53.611111 acc labeled target 54.761905
saving model...
S real T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 1.153463 Loss T 0.075844 Method MME

S real T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.549122 Loss T 0.082804 Method MME

S real T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.561095 Loss T 0.058710 Method MME

S real T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.914912 Loss T 0.074246 Method MME

S real T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.343249 Loss T 0.082027 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.0809, Accuracy: 667/1134 F1 (58.8183%)


Test set: Average loss: 1.9755, Accuracy: 15204/23808 F1 (63.8609%)


Val set: Average loss: 1.8794, Accuracy: 224/360 F1 (62.2222%)

Patience getting saturated, current counter is:  3
best acc test 61.769153  acc val 62.222222 acc labeled target 58.818342
saving model...
S real T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.507462 Loss T 0.078148 Method MME

S real T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 1.164357 Loss T 0.059645 Method MME

S real T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.264681 Loss T 0.058910 Method MME

S real T sketch Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.233107 Loss T 0.078831 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.6666667  0.6666667  1.         0.
 0.5555556  1.         0.8888889  0.         0.8888889  1.
 0.         0.         0.6666667  0.33333334 0.8888889  1.
 0.5555556  0.11111111 0.6666667  0.8888889  0.5555556  1.
 0.22222222 0.22222222 0.         0.8888889  0.6666667  0.22222222
 0.7777778  0.11111111 0.5555556  0.33333334 0.11111111 0.44444445
 0.22222222 0.         0.6666667  0.8888889  0.33333334 1.
 0.7777778  0.44444445 0.5555556  0.6666667  1.         0.8888889
 0.33333334 1.         0.33333334 0.33333334 1.         0.44444445
 0.8888889  0.5555556  0.7777778  0.8888889  1.         1.
 0.8888889  0.11111111 0.8888889  0.33333334 0.8888889  0.7777778
 0.11111111 0.8888889  0.33333334 1.         0.33333334 0.33333334
 0.7777778  0.44444445 1.         0.33333334 0.         1.
 0.8888889  0.5555556  0.         1.         0.22222222 0.44444445
 0.6666667  0.5555556  0.8888889  0.6666667  0.         0.33333334
 0.22222222 1.         0.6666667  0.8888889  0.7777778  0.5555556
 0.7777778  1.         0.22222222 0.33333334 1.         0.6666667
 0.6666667  0.6666667  0.6666667  0.         0.22222222 0.6666667
 0.11111111 0.5555556  0.6666667  0.6666667  0.7777778  1.
 1.         0.8888889  0.44444445 0.6666667  0.         0.5555556
 0.6666667  0.6666667  1.         0.33333334 0.         1.        ]
Top k classes which perform poorly are:  [105, 88, 124, 5, 37, 80, 9, 118, 26, 12, 13, 76, 66, 19, 31, 34, 108, 61, 36, 98, 29, 106, 25, 24, 82, 90, 48, 89, 51, 33, 99, 15, 75, 123, 63, 71, 70, 68, 50, 40, 53, 43, 35, 116, 73, 83, 55, 85, 95, 79, 0, 109, 18, 32, 119, 6, 22, 44, 3, 120, 107, 84, 117, 92, 14, 2, 20, 121, 45, 87, 110, 104, 103, 102, 28, 111, 38, 101, 112, 42, 56, 30, 65, 72, 96, 94, 115, 93, 62, 21, 78, 39, 86, 47, 67, 64, 8, 60, 10, 27, 16, 57, 54, 113, 114, 81, 7, 4, 122, 1, 17, 11, 46, 41, 49, 52, 58, 100, 59, 97, 69, 74, 77, 91, 23, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.2869, 1.1839, 1.2056,
        1.5000, 1.2056, 1.1839, 1.5000, 1.5000, 1.2567, 1.3583, 1.2056, 1.1839,
        1.2869, 1.4474, 1.2567, 1.2056, 1.2869, 1.1839, 1.4004, 1.4004, 1.5000,
        1.2056, 1.2567, 1.4004, 1.2297, 1.4474, 1.2869, 1.3583, 1.4474, 1.3206,
        1.4004, 1.5000, 1.2567, 1.2056, 1.3583, 1.1839, 1.2297, 1.3206, 1.2869,
        1.2567, 1.1839, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.3206,
        1.2056, 1.2869, 1.2297, 1.2056, 1.1839, 1.1839, 1.2056, 1.4474, 1.2056,
        1.3583, 1.2056, 1.2297, 1.4474, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583,
        1.2297, 1.3206, 1.1839, 1.3583, 1.5000, 1.1839, 1.2056, 1.2869, 1.5000,
        1.1839, 1.4004, 1.3206, 1.2567, 1.2869, 1.2056, 1.2567, 1.5000, 1.3583,
        1.4004, 1.1839, 1.2567, 1.2056, 1.2297, 1.2869, 1.2297, 1.1839, 1.4004,
        1.3583, 1.1839, 1.2567, 1.2567, 1.2567, 1.2567, 1.5000, 1.4004, 1.2567,
        1.4474, 1.2869, 1.2567, 1.2567, 1.2297, 1.1839, 1.1839, 1.2056, 1.3206,
        1.2567, 1.5000, 1.2869, 1.2567, 1.2567, 1.1839, 1.3583, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.7131, 0.8161, 0.7944,
        0.5000, 0.7944, 0.8161, 0.5000, 0.5000, 0.7433, 0.6417, 0.7944, 0.8161,
        0.7131, 0.5526, 0.7433, 0.7944, 0.7131, 0.8161, 0.5996, 0.5996, 0.5000,
        0.7944, 0.7433, 0.5996, 0.7703, 0.5526, 0.7131, 0.6417, 0.5526, 0.6794,
        0.5996, 0.5000, 0.7433, 0.7944, 0.6417, 0.8161, 0.7703, 0.6794, 0.7131,
        0.7433, 0.8161, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.6794,
        0.7944, 0.7131, 0.7703, 0.7944, 0.8161, 0.8161, 0.7944, 0.5526, 0.7944,
        0.6417, 0.7944, 0.7703, 0.5526, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417,
        0.7703, 0.6794, 0.8161, 0.6417, 0.5000, 0.8161, 0.7944, 0.7131, 0.5000,
        0.8161, 0.5996, 0.6794, 0.7433, 0.7131, 0.7944, 0.7433, 0.5000, 0.6417,
        0.5996, 0.8161, 0.7433, 0.7944, 0.7703, 0.7131, 0.7703, 0.8161, 0.5996,
        0.6417, 0.8161, 0.7433, 0.7433, 0.7433, 0.7433, 0.5000, 0.5996, 0.7433,
        0.5526, 0.7131, 0.7433, 0.7433, 0.7703, 0.8161, 0.8161, 0.7944, 0.6794,
        0.7433, 0.5000, 0.7131, 0.7433, 0.7433, 0.8161, 0.6417, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.346624 Loss T 0.075750 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4555, Accuracy: 632/1134 F1 (55.7319%)


Test set: Average loss: 2.1450, Accuracy: 14639/23808 F1 (61.4877%)


Val set: Average loss: 2.0590, Accuracy: 204/360 F1 (56.6667%)

Patience getting saturated, current counter is:  4
best acc test 61.769153  acc val 56.666667 acc labeled target 55.731922
saving model...
S real T sketch Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.205052 Loss T 0.065108 Method MME

S real T sketch Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.312205 Loss T 0.068494 Method MME

S real T sketch Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.179506 Loss T 0.090976 Method MME

S real T sketch Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.229548 Loss T 0.075058 Method MME

S real T sketch Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.824954 Loss T 0.067873 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9601, Accuracy: 677/1134 F1 (59.7002%)


Test set: Average loss: 1.9147, Accuracy: 15525/23808 F1 (65.2092%)


Val set: Average loss: 1.7887, Accuracy: 229/360 F1 (63.6111%)

Patience Reset, Counter is: 5
best acc test 65.209173  acc val 63.611111 acc labeled target 59.700176
saving model...
S real T sketch Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.050962 Loss T 0.069896 Method MME

S real T sketch Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.414100 Loss T 0.080377 Method MME

S real T sketch Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.335357 Loss T 0.057170 Method MME

S real T sketch Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.426600 Loss T 0.073275 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.6666667  0.6666667  0.7777778  0.
 0.6666667  0.8888889  0.5555556  0.         0.7777778  1.
 0.         0.         0.22222222 0.33333334 1.         1.
 0.8888889  0.33333334 0.6666667  0.8888889  0.44444445 0.6666667
 0.22222222 0.33333334 0.         0.8888889  0.6666667  0.44444445
 0.5555556  0.33333334 0.5555556  0.33333334 0.33333334 0.11111111
 0.33333334 0.11111111 0.8888889  0.7777778  0.44444445 0.8888889
 0.6666667  0.44444445 0.5555556  0.6666667  0.8888889  0.8888889
 0.33333334 1.         0.33333334 0.33333334 1.         0.8888889
 1.         0.6666667  0.7777778  0.5555556  1.         1.
 0.8888889  0.33333334 1.         0.33333334 0.8888889  1.
 0.33333334 0.6666667  0.6666667  0.8888889  0.22222222 0.5555556
 0.44444445 0.8888889  1.         0.33333334 0.22222222 0.7777778
 1.         0.7777778  0.         1.         0.33333334 0.22222222
 0.7777778  0.44444445 0.8888889  0.6666667  0.         0.11111111
 0.33333334 0.8888889  0.6666667  1.         1.         0.6666667
 0.33333334 0.8888889  0.         0.33333334 0.8888889  0.44444445
 0.7777778  1.         0.7777778  0.22222222 0.33333334 0.5555556
 0.         0.33333334 0.8888889  0.7777778  0.7777778  1.
 0.8888889  1.         0.44444445 0.6666667  0.33333334 0.5555556
 0.6666667  0.6666667  0.7777778  0.33333334 0.         1.        ]
Top k classes which perform poorly are:  [13, 124, 88, 108, 5, 98, 9, 80, 12, 26, 89, 35, 37, 14, 24, 105, 70, 76, 83, 82, 75, 36, 118, 34, 51, 33, 106, 31, 61, 50, 25, 48, 66, 123, 19, 90, 109, 15, 99, 96, 63, 101, 72, 29, 40, 85, 22, 43, 116, 57, 107, 71, 44, 32, 8, 119, 30, 68, 67, 87, 92, 95, 0, 120, 2, 20, 121, 55, 117, 3, 23, 28, 45, 6, 42, 84, 122, 111, 10, 39, 77, 112, 4, 102, 56, 104, 79, 97, 110, 7, 100, 27, 53, 18, 21, 86, 60, 38, 41, 73, 46, 47, 69, 114, 64, 91, 113, 115, 62, 94, 1, 11, 16, 17, 49, 52, 103, 54, 59, 65, 74, 78, 81, 93, 58, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.2567, 1.2567, 1.2297, 1.5000, 1.2567, 1.2056, 1.2869,
        1.5000, 1.2297, 1.1839, 1.5000, 1.5000, 1.4004, 1.3583, 1.1839, 1.1839,
        1.2056, 1.3583, 1.2567, 1.2056, 1.3206, 1.2567, 1.4004, 1.3583, 1.5000,
        1.2056, 1.2567, 1.3206, 1.2869, 1.3583, 1.2869, 1.3583, 1.3583, 1.4474,
        1.3583, 1.4474, 1.2056, 1.2297, 1.3206, 1.2056, 1.2567, 1.3206, 1.2869,
        1.2567, 1.2056, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.2056,
        1.1839, 1.2567, 1.2297, 1.2869, 1.1839, 1.1839, 1.2056, 1.3583, 1.1839,
        1.3583, 1.2056, 1.1839, 1.3583, 1.2567, 1.2567, 1.2056, 1.4004, 1.2869,
        1.3206, 1.2056, 1.1839, 1.3583, 1.4004, 1.2297, 1.1839, 1.2297, 1.5000,
        1.1839, 1.3583, 1.4004, 1.2297, 1.3206, 1.2056, 1.2567, 1.5000, 1.4474,
        1.3583, 1.2056, 1.2567, 1.1839, 1.1839, 1.2567, 1.3583, 1.2056, 1.5000,
        1.3583, 1.2056, 1.3206, 1.2297, 1.1839, 1.2297, 1.4004, 1.3583, 1.2869,
        1.5000, 1.3583, 1.2056, 1.2297, 1.2297, 1.1839, 1.2056, 1.1839, 1.3206,
        1.2567, 1.3583, 1.2869, 1.2567, 1.2567, 1.2297, 1.3583, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.7433, 0.7433, 0.7703, 0.5000, 0.7433, 0.7944, 0.7131,
        0.5000, 0.7703, 0.8161, 0.5000, 0.5000, 0.5996, 0.6417, 0.8161, 0.8161,
        0.7944, 0.6417, 0.7433, 0.7944, 0.6794, 0.7433, 0.5996, 0.6417, 0.5000,
        0.7944, 0.7433, 0.6794, 0.7131, 0.6417, 0.7131, 0.6417, 0.6417, 0.5526,
        0.6417, 0.5526, 0.7944, 0.7703, 0.6794, 0.7944, 0.7433, 0.6794, 0.7131,
        0.7433, 0.7944, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.7944,
        0.8161, 0.7433, 0.7703, 0.7131, 0.8161, 0.8161, 0.7944, 0.6417, 0.8161,
        0.6417, 0.7944, 0.8161, 0.6417, 0.7433, 0.7433, 0.7944, 0.5996, 0.7131,
        0.6794, 0.7944, 0.8161, 0.6417, 0.5996, 0.7703, 0.8161, 0.7703, 0.5000,
        0.8161, 0.6417, 0.5996, 0.7703, 0.6794, 0.7944, 0.7433, 0.5000, 0.5526,
        0.6417, 0.7944, 0.7433, 0.8161, 0.8161, 0.7433, 0.6417, 0.7944, 0.5000,
        0.6417, 0.7944, 0.6794, 0.7703, 0.8161, 0.7703, 0.5996, 0.6417, 0.7131,
        0.5000, 0.6417, 0.7944, 0.7703, 0.7703, 0.8161, 0.7944, 0.8161, 0.6794,
        0.7433, 0.6417, 0.7131, 0.7433, 0.7433, 0.7703, 0.6417, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.613421 Loss T 0.064321 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4734, Accuracy: 645/1134 F1 (56.8783%)


Test set: Average loss: 2.2326, Accuracy: 14788/23808 F1 (62.1136%)


Val set: Average loss: 2.1349, Accuracy: 218/360 F1 (60.5556%)

Patience getting saturated, current counter is:  0
best acc test 65.209173  acc val 60.555556 acc labeled target 56.878307
saving model...
S real T sketch Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.381418 Loss T 0.094398 Method MME

S real T sketch Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.649314 Loss T 0.066707 Method MME

S real T sketch Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.158909 Loss T 0.062525 Method MME

S real T sketch Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.380965 Loss T 0.069427 Method MME

S real T sketch Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.291885 Loss T 0.060930 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 1.9778, Accuracy: 699/1134 F1 (61.6402%)


Test set: Average loss: 1.9380, Accuracy: 15602/23808 F1 (65.5326%)


Val set: Average loss: 1.8231, Accuracy: 228/360 F1 (63.3333%)

Patience getting saturated, current counter is:  1
best acc test 65.209173  acc val 63.333333 acc labeled target 61.640212
saving model...
S real T sketch Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.368877 Loss T 0.060717 Method MME

S real T sketch Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.140470 Loss T 0.087488 Method MME

S real T sketch Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.846799 Loss T 0.059046 Method MME

S real T sketch Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.083771 Loss T 0.072716 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.6666667  0.5555556  0.8888889  0.
 0.6666667  1.         0.6666667  0.22222222 0.7777778  1.
 0.         0.11111111 0.33333334 0.6666667  0.8888889  0.8888889
 0.8888889  0.5555556  0.6666667  1.         0.5555556  1.
 0.22222222 0.33333334 0.11111111 0.8888889  0.6666667  0.44444445
 0.33333334 0.22222222 0.22222222 0.33333334 0.7777778  0.5555556
 0.11111111 0.         0.7777778  1.         0.         0.7777778
 0.44444445 0.44444445 0.5555556  0.33333334 1.         0.7777778
 0.33333334 1.         0.33333334 0.33333334 1.         0.44444445
 0.8888889  0.6666667  0.8888889  0.6666667  1.         1.
 0.8888889  0.22222222 0.8888889  0.33333334 0.8888889  0.6666667
 0.7777778  0.7777778  0.6666667  1.         0.22222222 0.7777778
 1.         0.8888889  1.         0.22222222 0.         0.7777778
 1.         0.5555556  0.         0.8888889  0.22222222 0.7777778
 0.7777778  0.5555556  0.8888889  0.6666667  0.         0.33333334
 0.44444445 0.7777778  0.6666667  1.         1.         0.6666667
 0.5555556  1.         0.33333334 0.44444445 1.         0.6666667
 0.7777778  0.6666667  0.6666667  0.         0.33333334 0.6666667
 0.         0.6666667  1.         0.7777778  0.8888889  1.
 0.7777778  0.8888889  0.44444445 0.6666667  0.11111111 0.7777778
 0.6666667  0.8888889  1.         0.33333334 0.         1.        ]
Top k classes which perform poorly are:  [88, 105, 12, 124, 80, 76, 37, 108, 40, 5, 36, 26, 13, 118, 32, 31, 24, 61, 9, 82, 75, 70, 45, 123, 48, 50, 51, 33, 30, 89, 106, 25, 14, 98, 63, 53, 43, 90, 99, 42, 29, 116, 79, 96, 85, 0, 44, 3, 35, 19, 22, 65, 68, 117, 15, 8, 92, 120, 6, 2, 87, 95, 101, 109, 103, 104, 57, 107, 55, 28, 20, 67, 84, 83, 47, 91, 34, 10, 38, 119, 114, 71, 41, 66, 102, 77, 111, 115, 121, 112, 62, 81, 86, 54, 56, 60, 64, 27, 17, 18, 73, 4, 16, 11, 7, 21, 23, 122, 113, 1, 39, 49, 46, 52, 58, 59, 100, 69, 72, 97, 74, 94, 93, 78, 110, 125]
Per cls weights according to the accuracy are:  tensor([1.2869, 1.1839, 1.2567, 1.2869, 1.2056, 1.5000, 1.2567, 1.1839, 1.2567,
        1.4004, 1.2297, 1.1839, 1.5000, 1.4474, 1.3583, 1.2567, 1.2056, 1.2056,
        1.2056, 1.2869, 1.2567, 1.1839, 1.2869, 1.1839, 1.4004, 1.3583, 1.4474,
        1.2056, 1.2567, 1.3206, 1.3583, 1.4004, 1.4004, 1.3583, 1.2297, 1.2869,
        1.4474, 1.5000, 1.2297, 1.1839, 1.5000, 1.2297, 1.3206, 1.3206, 1.2869,
        1.3583, 1.1839, 1.2297, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.3206,
        1.2056, 1.2567, 1.2056, 1.2567, 1.1839, 1.1839, 1.2056, 1.4004, 1.2056,
        1.3583, 1.2056, 1.2567, 1.2297, 1.2297, 1.2567, 1.1839, 1.4004, 1.2297,
        1.1839, 1.2056, 1.1839, 1.4004, 1.5000, 1.2297, 1.1839, 1.2869, 1.5000,
        1.2056, 1.4004, 1.2297, 1.2297, 1.2869, 1.2056, 1.2567, 1.5000, 1.3583,
        1.3206, 1.2297, 1.2567, 1.1839, 1.1839, 1.2567, 1.2869, 1.1839, 1.3583,
        1.3206, 1.1839, 1.2567, 1.2297, 1.2567, 1.2567, 1.5000, 1.3583, 1.2567,
        1.5000, 1.2567, 1.1839, 1.2297, 1.2056, 1.1839, 1.2297, 1.2056, 1.3206,
        1.2567, 1.4474, 1.2297, 1.2567, 1.2056, 1.1839, 1.3583, 1.5000, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7131, 0.8161, 0.7433, 0.7131, 0.7944, 0.5000, 0.7433, 0.8161, 0.7433,
        0.5996, 0.7703, 0.8161, 0.5000, 0.5526, 0.6417, 0.7433, 0.7944, 0.7944,
        0.7944, 0.7131, 0.7433, 0.8161, 0.7131, 0.8161, 0.5996, 0.6417, 0.5526,
        0.7944, 0.7433, 0.6794, 0.6417, 0.5996, 0.5996, 0.6417, 0.7703, 0.7131,
        0.5526, 0.5000, 0.7703, 0.8161, 0.5000, 0.7703, 0.6794, 0.6794, 0.7131,
        0.6417, 0.8161, 0.7703, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.6794,
        0.7944, 0.7433, 0.7944, 0.7433, 0.8161, 0.8161, 0.7944, 0.5996, 0.7944,
        0.6417, 0.7944, 0.7433, 0.7703, 0.7703, 0.7433, 0.8161, 0.5996, 0.7703,
        0.8161, 0.7944, 0.8161, 0.5996, 0.5000, 0.7703, 0.8161, 0.7131, 0.5000,
        0.7944, 0.5996, 0.7703, 0.7703, 0.7131, 0.7944, 0.7433, 0.5000, 0.6417,
        0.6794, 0.7703, 0.7433, 0.8161, 0.8161, 0.7433, 0.7131, 0.8161, 0.6417,
        0.6794, 0.8161, 0.7433, 0.7703, 0.7433, 0.7433, 0.5000, 0.6417, 0.7433,
        0.5000, 0.7433, 0.8161, 0.7703, 0.7944, 0.8161, 0.7703, 0.7944, 0.6794,
        0.7433, 0.5526, 0.7703, 0.7433, 0.7944, 0.8161, 0.6417, 0.5000, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.157658 Loss T 0.081559 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3531, Accuracy: 631/1134 F1 (55.6437%)


Test set: Average loss: 2.2000, Accuracy: 14924/23808 F1 (62.6848%)


Val set: Average loss: 2.2086, Accuracy: 207/360 F1 (57.5000%)

Patience getting saturated, current counter is:  2
best acc test 65.209173  acc val 57.500000 acc labeled target 55.643739
saving model...
S real T sketch Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.382879 Loss T 0.068700 Method MME

S real T sketch Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.116631 Loss T 0.067206 Method MME

S real T sketch Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.415086 Loss T 0.064331 Method MME

S real T sketch Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.520044 Loss T 0.048341 Method MME

S real T sketch Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.564279 Loss T 0.048146 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1586, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 1.7501, Accuracy: 16220/23808 F1 (68.1284%)


Val set: Average loss: 1.5348, Accuracy: 242/360 F1 (67.2222%)

Patience Reset, Counter is: 3
best acc test 68.128360  acc val 67.222222 acc labeled target 97.001764
saving model...
S real T sketch Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.523401 Loss T 0.053104 Method MME

S real T sketch Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.309175 Loss T 0.054818 Method MME

S real T sketch Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.266748 Loss T 0.070201 Method MME

S real T sketch Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.310562 Loss T 0.043170 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.6666667 1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.7777778 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [80, 99, 0, 26, 28, 103, 36, 37, 38, 96, 95, 45, 47, 88, 87, 85, 84, 59, 61, 63, 25, 106, 35, 108, 7, 10, 111, 112, 16, 8, 14, 86, 118, 119, 83, 82, 81, 120, 79, 122, 78, 123, 77, 76, 75, 74, 73, 121, 89, 91, 117, 105, 109, 110, 104, 102, 101, 100, 98, 90, 72, 114, 97, 115, 116, 94, 93, 92, 107, 113, 71, 62, 69, 31, 30, 29, 27, 24, 23, 22, 21, 20, 19, 18, 17, 15, 13, 12, 11, 9, 6, 5, 4, 3, 2, 1, 32, 33, 34, 39, 68, 67, 66, 65, 64, 124, 60, 58, 57, 56, 55, 70, 54, 52, 51, 50, 49, 48, 46, 44, 43, 42, 41, 40, 53, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2567,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7433,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.494782 Loss T 0.059671 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2952, Accuracy: 1067/1134 F1 (94.0917%)


Test set: Average loss: 2.0523, Accuracy: 15677/23808 F1 (65.8476%)


Val set: Average loss: 1.9526, Accuracy: 229/360 F1 (63.6111%)

Patience getting saturated, current counter is:  0
best acc test 68.128360  acc val 63.611111 acc labeled target 94.091711
saving model...
S real T sketch Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.462164 Loss T 0.056390 Method MME

S real T sketch Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.199602 Loss T 0.044641 Method MME

S real T sketch Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.327793 Loss T 0.063113 Method MME

S real T sketch Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.122766 Loss T 0.055194 Method MME

S real T sketch Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.627861 Loss T 0.059740 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1335, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 1.8519, Accuracy: 16266/23808 F1 (68.3216%)


Val set: Average loss: 1.6286, Accuracy: 238/360 F1 (66.1111%)

Patience getting saturated, current counter is:  1
best acc test 68.128360  acc val 66.111111 acc labeled target 97.266314
saving model...
S real T sketch Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.231896 Loss T 0.048641 Method MME

S real T sketch Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.484304 Loss T 0.068247 Method MME

S real T sketch Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.246545 Loss T 0.052467 Method MME

S real T sketch Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.370113 Loss T 0.055209 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 0.8888889 0.8888889 0.8888889
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        0.7777778 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [44, 67, 24, 25, 26, 27, 53, 52, 31, 32, 34, 88, 36, 99, 98, 96, 105, 92, 54, 59, 15, 13, 61, 114, 75, 18, 78, 5, 118, 83, 91, 90, 74, 89, 76, 79, 87, 86, 80, 81, 82, 85, 84, 77, 0, 100, 94, 123, 122, 121, 120, 119, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 104, 103, 102, 101, 73, 97, 95, 93, 72, 62, 70, 33, 30, 29, 28, 23, 22, 21, 20, 19, 17, 16, 14, 12, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 35, 71, 37, 39, 69, 68, 66, 65, 64, 63, 124, 60, 58, 57, 56, 55, 51, 50, 49, 48, 47, 46, 45, 43, 42, 41, 40, 38, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.229512 Loss T 0.072766 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2485, Accuracy: 1074/1134 F1 (94.7090%)


Test set: Average loss: 2.0504, Accuracy: 15753/23808 F1 (66.1668%)


Val set: Average loss: 1.8287, Accuracy: 232/360 F1 (64.4444%)

Patience getting saturated, current counter is:  2
best acc test 68.128360  acc val 64.444444 acc labeled target 94.708995
saving model...
S real T sketch Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.280657 Loss T 0.040439 Method MME

S real T sketch Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.160360 Loss T 0.057292 Method MME

S real T sketch Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.158387 Loss T 0.056583 Method MME

S real T sketch Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.179009 Loss T 0.075646 Method MME

S real T sketch Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.650527 Loss T 0.053865 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1212, Accuracy: 1107/1134 F1 (97.6190%)


Test set: Average loss: 1.8561, Accuracy: 16470/23808 F1 (69.1784%)


Val set: Average loss: 1.6342, Accuracy: 243/360 F1 (67.5000%)

Patience Reset, Counter is: 3
best acc test 69.178427  acc val 67.500000 acc labeled target 97.619048
saving model...
S real T sketch Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.056488 Loss T 0.030840 Method MME

S real T sketch Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.450176 Loss T 0.038566 Method MME

S real T sketch Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.179233 Loss T 0.049095 Method MME

S real T sketch Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.442646 Loss T 0.048936 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.7777778 1.        1.
 0.7777778 0.8888889 0.8888889 0.8888889 0.8888889 0.8888889 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [25, 28, 99, 103, 88, 48, 29, 30, 31, 32, 33, 72, 90, 36, 45, 38, 95, 19, 106, 65, 13, 57, 63, 80, 114, 84, 91, 73, 74, 75, 76, 77, 79, 85, 89, 81, 82, 87, 86, 83, 78, 92, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 93, 111, 109, 108, 107, 105, 104, 102, 101, 100, 98, 97, 96, 110, 71, 62, 69, 27, 26, 24, 23, 22, 21, 20, 18, 17, 16, 15, 34, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 12, 70, 35, 39, 68, 67, 66, 64, 124, 61, 60, 59, 58, 56, 55, 37, 54, 52, 51, 50, 49, 47, 46, 44, 43, 42, 41, 40, 53, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.2297, 1.2056, 1.2056, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.7703, 0.7944, 0.7944, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.106392 Loss T 0.036848 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2395, Accuracy: 1078/1134 F1 (95.0617%)


Test set: Average loss: 1.9963, Accuracy: 16007/23808 F1 (67.2337%)


Val set: Average loss: 1.9337, Accuracy: 223/360 F1 (61.9444%)

Patience getting saturated, current counter is:  0
best acc test 69.178427  acc val 61.944444 acc labeled target 95.061728
saving model...
S real T sketch Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.296915 Loss T 0.039039 Method MME

S real T sketch Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.377087 Loss T 0.034241 Method MME

S real T sketch Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.161352 Loss T 0.050253 Method MME

S real T sketch Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.217622 Loss T 0.042297 Method MME

S real T sketch Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.130802 Loss T 0.069731 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1528, Accuracy: 1091/1134 F1 (96.2081%)


Test set: Average loss: 1.8015, Accuracy: 16643/23808 F1 (69.9051%)


Val set: Average loss: 1.6725, Accuracy: 250/360 F1 (69.4444%)

Patience Reset, Counter is: 1
best acc test 69.905074  acc val 69.444444 acc labeled target 96.208113
saving model...
S real T sketch Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.869377 Loss T 0.036431 Method MME

S real T sketch Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.190558 Loss T 0.040633 Method MME

S real T sketch Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.379599 Loss T 0.058634 Method MME

S real T sketch Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.439238 Loss T 0.037277 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        0.8888889
 1.        0.8888889 0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        0.7777778
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        0.8888889 1.        0.7777778 1.        1.        1.
 0.7777778 1.        0.8888889 0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.7777778
 1.        0.7777778 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [77, 34, 73, 99, 97, 0, 32, 35, 100, 39, 47, 92, 50, 55, 57, 85, 84, 60, 61, 65, 66, 80, 79, 71, 27, 107, 37, 13, 116, 2, 15, 11, 5, 6, 9, 16, 119, 17, 117, 86, 118, 120, 83, 82, 81, 121, 122, 78, 123, 76, 87, 88, 109, 90, 106, 105, 104, 103, 110, 102, 111, 112, 101, 113, 114, 115, 98, 96, 95, 94, 93, 91, 108, 89, 75, 62, 72, 31, 30, 29, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 14, 12, 10, 8, 7, 4, 3, 1, 33, 36, 38, 40, 70, 69, 68, 67, 64, 63, 124, 59, 58, 56, 74, 54, 52, 51, 49, 48, 46, 45, 44, 43, 42, 41, 53, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.546423 Loss T 0.054007 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2276, Accuracy: 1079/1134 F1 (95.1499%)


Test set: Average loss: 1.9759, Accuracy: 16226/23808 F1 (68.1536%)


Val set: Average loss: 1.6606, Accuracy: 248/360 F1 (68.8889%)

Patience getting saturated, current counter is:  0
best acc test 69.905074  acc val 68.888889 acc labeled target 95.149912
saving model...
S real T sketch Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.132953 Loss T 0.038716 Method MME

S real T sketch Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.337342 Loss T 0.050509 Method MME

S real T sketch Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.121750 Loss T 0.044632 Method MME

S real T sketch Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.446073 Loss T 0.038059 Method MME

S real T sketch Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.387853 Loss T 0.032535 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1398, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 1.8392, Accuracy: 16763/23808 F1 (70.4091%)


Val set: Average loss: 1.5268, Accuracy: 256/360 F1 (71.1111%)

Patience Reset, Counter is: 1
best acc test 70.409106  acc val 71.111111 acc labeled target 96.737213
saving model...
S real T sketch Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.233983 Loss T 0.032697 Method MME

S real T sketch Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.119811 Loss T 0.056647 Method MME

S real T sketch Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.301146 Loss T 0.049422 Method MME

S real T sketch Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.191524 Loss T 0.036676 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 0.8888889 0.7777778 0.8888889 0.8888889 1.        0.8888889
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 0.8888889 0.8888889 1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        0.7777778 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        0.7777778 1.       ]
Top k classes which perform poorly are:  [107, 124, 30, 85, 25, 86, 28, 29, 31, 32, 102, 34, 36, 37, 51, 99, 98, 90, 84, 92, 45, 118, 19, 17, 75, 2, 78, 64, 10, 65, 109, 67, 5, 120, 91, 89, 76, 83, 77, 79, 87, 80, 81, 82, 88, 0, 101, 94, 123, 122, 121, 119, 117, 116, 115, 114, 113, 112, 93, 111, 108, 106, 105, 104, 103, 74, 100, 97, 96, 95, 110, 73, 62, 71, 35, 33, 27, 26, 24, 23, 22, 21, 20, 18, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 4, 3, 1, 38, 72, 39, 41, 70, 69, 68, 66, 63, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 44, 43, 42, 40, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.2056, 1.2297, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.7944, 0.7703, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.035469 Loss T 0.045372 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2186, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 2.0228, Accuracy: 16173/23808 F1 (67.9309%)


Val set: Average loss: 1.7912, Accuracy: 235/360 F1 (65.2778%)

Patience getting saturated, current counter is:  0
best acc test 70.409106  acc val 65.277778 acc labeled target 95.943563
saving model...
S real T sketch Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.142605 Loss T 0.048308 Method MME

S real T sketch Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.237434 Loss T 0.035609 Method MME

S real T sketch Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.277619 Loss T 0.051097 Method MME

S real T sketch Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.464699 Loss T 0.039146 Method MME

S real T sketch Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.396767 Loss T 0.043503 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1344, Accuracy: 1101/1134 F1 (97.0900%)


Test set: Average loss: 1.8835, Accuracy: 16744/23808 F1 (70.3293%)


Val set: Average loss: 1.6482, Accuracy: 248/360 F1 (68.8889%)

Patience getting saturated, current counter is:  1
best acc test 70.409106  acc val 68.888889 acc labeled target 97.089947
saving model...
S real T sketch Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.338544 Loss T 0.055535 Method MME

S real T sketch Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.232816 Loss T 0.054564 Method MME

S real T sketch Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.379734 Loss T 0.045796 Method MME

S real T sketch Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.198860 Loss T 0.040182 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 0.8888889 0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        0.7777778
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 0.7777778 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [83, 75, 106, 23, 24, 25, 105, 84, 85, 29, 62, 72, 36, 37, 89, 40, 41, 48, 31, 32, 22, 18, 65, 14, 13, 119, 118, 124, 107, 116, 73, 74, 90, 76, 77, 87, 86, 78, 79, 80, 81, 82, 91, 88, 92, 99, 94, 123, 122, 121, 120, 117, 115, 114, 113, 112, 111, 93, 110, 108, 104, 103, 102, 101, 100, 98, 97, 96, 95, 109, 71, 0, 69, 33, 30, 28, 27, 26, 21, 20, 19, 17, 16, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 34, 35, 38, 39, 68, 67, 66, 64, 63, 61, 60, 59, 58, 57, 56, 70, 55, 53, 52, 51, 50, 49, 47, 46, 45, 44, 43, 42, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.582175 Loss T 0.038756 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1681, Accuracy: 1091/1134 F1 (96.2081%)


Test set: Average loss: 2.0511, Accuracy: 16250/23808 F1 (68.2544%)


Val set: Average loss: 2.0174, Accuracy: 229/360 F1 (63.6111%)

Patience getting saturated, current counter is:  2
best acc test 70.409106  acc val 63.611111 acc labeled target 96.208113
saving model...
S real T sketch Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.181136 Loss T 0.029772 Method MME

S real T sketch Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.296399 Loss T 0.045960 Method MME

S real T sketch Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.058912 Loss T 0.039000 Method MME

S real T sketch Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.602394 Loss T 0.051309 Method MME

S real T sketch Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.525401 Loss T 0.038206 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1322, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 1.8725, Accuracy: 16789/23808 F1 (70.5183%)


Val set: Average loss: 1.6264, Accuracy: 244/360 F1 (67.7778%)

Patience getting saturated, current counter is:  3
best acc test 70.409106  acc val 67.777778 acc labeled target 96.825397
saving model...
S real T sketch Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.361645 Loss T 0.031477 Method MME

S real T sketch Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.150711 Loss T 0.037027 Method MME

S real T sketch Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.196249 Loss T 0.018868 Method MME

S real T sketch Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.339585 Loss T 0.043311 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        0.7777778 0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 0.7777778 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        0.8888889 1.        0.7777778 1.        1.       ]
Top k classes which perform poorly are:  [123, 39, 118, 79, 36, 57, 104, 26, 27, 56, 84, 99, 23, 51, 71, 40, 90, 42, 43, 32, 47, 106, 19, 109, 60, 16, 70, 121, 13, 5, 78, 68, 82, 74, 89, 88, 77, 76, 87, 83, 86, 85, 80, 81, 75, 91, 0, 93, 122, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 108, 107, 105, 103, 102, 101, 100, 98, 97, 96, 95, 94, 92, 73, 62, 69, 29, 28, 25, 24, 22, 21, 20, 18, 17, 15, 30, 14, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 12, 31, 33, 34, 67, 66, 65, 64, 63, 124, 61, 59, 58, 55, 54, 53, 52, 50, 49, 48, 46, 45, 44, 41, 38, 37, 35, 72, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T sketch Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.217048 Loss T 0.039445 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2040, Accuracy: 1091/1134 F1 (96.2081%)


Test set: Average loss: 1.9894, Accuracy: 16484/23808 F1 (69.2372%)


Val set: Average loss: 1.9106, Accuracy: 233/360 F1 (64.7222%)

Patience getting saturated, current counter is:  4
best acc test 70.409106  acc val 64.722222 acc labeled target 96.208113
saving model...
S real T sketch Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.342885 Loss T 0.042741 Method MME

S real T sketch Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.593131 Loss T 0.046038 Method MME

S real T sketch Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.179133 Loss T 0.043041 Method MME

S real T sketch Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.447052 Loss T 0.038453 Method MME

S real T sketch Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.074860 Loss T 0.037379 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1636, Accuracy: 1096/1134 F1 (96.6490%)


Test set: Average loss: 1.9051, Accuracy: 16940/23808 F1 (71.1526%)


Val set: Average loss: 1.5052, Accuracy: 253/360 F1 (70.2778%)

Patience getting saturated, current counter is:  5
