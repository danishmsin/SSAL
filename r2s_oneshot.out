Dataset multi Source real Target sketch Labeled num perclass 1 Network resnet34
126 classes in this dataset
Unlabelled Target Dataset Size:  24330
Labelled Target Dataset Size:  126
Misc. Labelled Target Dataset Size:  126
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  24330 Source:  70358
Unlabeled Target Data Size: 506
S real T sketch Train Ep: 0 lr0.01 	 Loss Classification: 4.785237 Loss T 0.470609 Method MME

S real T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 0.921809 Loss T 0.305084 Method MME

S real T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.293983 Loss T 0.236497 Method MME

S real T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.059211 Loss T 0.205296 Method MME

S real T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.081909 Loss T 0.184708 Method MME

S real T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.778796 Loss T 0.196483 Method MME


Labeled Target set: Average loss: 2.7964, Accuracy: 145/360 F1 (40.2778%)


Test set: Average loss: 2.6105, Accuracy: 10937/24312 F1 (44.9860%)


Val set: Average loss: 2.5526, Accuracy: 160/360 F1 (44.4444%)

best acc test 44.986015  acc val 44.444444 acc labeled target 40.277778
saving model...
S real T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.623135 Loss T 0.169448 Method MME

S real T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.651097 Loss T 0.164778 Method MME

S real T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 0.822247 Loss T 0.143066 Method MME

S real T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.958164 Loss T 0.147309 Method MME

S real T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.158076 Loss T 0.156044 Method MME


Labeled Target set: Average loss: 2.5119, Accuracy: 168/360 F1 (46.6667%)


Test set: Average loss: 2.4829, Accuracy: 12252/24312 F1 (50.3949%)


Val set: Average loss: 2.3054, Accuracy: 196/360 F1 (54.4444%)

best acc test 50.394867  acc val 54.444444 acc labeled target 46.666667
saving model...
S real T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.892957 Loss T 0.150686 Method MME

S real T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 1.028547 Loss T 0.112213 Method MME

S real T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.652166 Loss T 0.108621 Method MME

S real T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 1.148749 Loss T 0.139576 Method MME

S real T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.571699 Loss T 0.111125 Method MME


Labeled Target set: Average loss: 2.3613, Accuracy: 172/360 F1 (47.7778%)


Test set: Average loss: 2.3988, Accuracy: 12847/24312 F1 (52.8422%)


Val set: Average loss: 2.2092, Accuracy: 200/360 F1 (55.5556%)

best acc test 52.842218  acc val 55.555556 acc labeled target 47.777778
saving model...
S real T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.978014 Loss T 0.153349 Method MME

S real T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.647855 Loss T 0.123829 Method MME

S real T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.793571 Loss T 0.127488 Method MME

S real T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.629677 Loss T 0.102258 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.         1.         1.         1.         1.         0.
 0.         0.6666667  1.         0.33333334 1.         1.
 0.         1.         1.         1.         0.33333334 0.6666667
 0.6666667  0.         1.         1.         1.         0.
 0.6666667  0.6666667         nan 0.         1.                nan
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.33333334 0.         0.
 0.         0.         1.         0.         1.         1.
 0.         1.         0.33333334 0.         0.6666667  0.33333334
 1.         1.         0.6666667  0.6666667  1.         0.6666667
        nan 0.         1.         0.         1.                nan
 0.         0.         0.         0.6666667  0.6666667  0.
        nan 1.         0.6666667  0.         0.         0.
 1.         0.         0.         0.         0.         0.33333334
        nan 1.         1.         1.         0.         0.
 0.         1.         1.         1.         1.         0.
 0.         0.         0.         1.         0.         0.
 0.         1.         0.         0.6666667  1.         1.
 0.         0.         0.6666667  0.         1.         1.
 1.         1.         1.         1.         0.         0.
 0.         1.         0.         0.         1.         1.        ]
Top k classes which perform poorly are:  [0, 37, 40, 41, 42, 43, 89, 45, 104, 48, 51, 102, 101, 100, 61, 98, 63, 97, 90, 82, 81, 80, 79, 77, 36, 76, 95, 71, 68, 67, 66, 96, 75, 35, 88, 33, 34, 19, 118, 119, 111, 12, 23, 5, 120, 6, 27, 109, 108, 32, 30, 31, 123, 122, 83, 9, 39, 53, 50, 16, 7, 70, 69, 74, 18, 52, 17, 59, 57, 56, 110, 25, 105, 24, 107, 91, 92, 121, 115, 103, 114, 112, 113, 94, 99, 117, 116, 93, 106, 62, 86, 1, 2, 3, 4, 8, 10, 11, 13, 14, 15, 20, 21, 22, 28, 87, 38, 46, 85, 78, 73, 64, 44, 58, 124, 54, 49, 47, 55, 125, 60, 65, 72, 26, 84, 29]
0
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
1
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
2
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
3
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
4
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
5
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
6
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
7
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
8
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
9
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
10
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
11
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
12
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
13
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
14
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
15
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
16
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
17
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
18
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
19
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
20
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
21
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
22
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
23
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
24
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
25
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
26
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
27
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
28
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
29
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
30
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
31
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
32
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
33
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
34
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
35
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
36
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
37
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
38
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
39
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
40
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
41
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
42
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
43
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
44
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
45
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
46
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
47
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
48
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
49
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
50
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
51
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
52
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
53
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
54
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
55
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
56
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
57
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
58
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
59
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
60
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
61
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
62
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
63
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
64
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
65
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
66
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
67
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
68
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
69
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
70
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
71
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
72
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
73
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
74
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
75
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
76
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
77
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
78
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
79
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
80
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
81
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
82
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
83
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
84
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
85
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
86
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
87
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
88
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
89
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
90
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
91
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
92
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
93
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
94
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
95
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
96
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
97
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
98
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
99
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
100
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
101
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
102
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
103
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
104
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
105
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
106
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
107
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
108
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
109
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
110
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
111
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
112
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
113
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
114
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
115
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
116
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
117
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
118
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
119
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
120
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
121
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
122
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
123
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
124
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
125
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.2567, 1.1839,
        1.3583, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839, 1.3583, 1.2567,
        1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567,    nan,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,
        1.5000, 1.5000, 1.1839, 1.3583, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.3583, 1.5000, 1.2567, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.2567,    nan, 1.5000, 1.1839,
        1.5000, 1.1839,    nan, 1.5000, 1.5000, 1.5000, 1.2567, 1.2567, 1.5000,
           nan, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583,    nan, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.1839, 1.1839,
        1.5000, 1.5000, 1.2567, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
0
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
1
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
2
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
3
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
4
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
5
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
6
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
7
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
8
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
9
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
10
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
11
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
12
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
13
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
14
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
15
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
16
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
17
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
18
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
19
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
20
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
21
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
22
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
23
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
24
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
25
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
26
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
27
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
28
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
29
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
30
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
31
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
32
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
33
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
34
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
35
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
36
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
37
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
38
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
39
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
40
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
41
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
42
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
43
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
44
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
45
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
46
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
47
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
48
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
49
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
50
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
51
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
52
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
53
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
54
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
55
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
56
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
57
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
58
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
59
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
60
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
61
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
62
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
63
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
64
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
65
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
66
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
67
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
68
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
69
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
70
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
71
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
72
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
73
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
74
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
75
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
76
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
77
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
78
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
79
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
80
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
81
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
82
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
83
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
84
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
85
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
86
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
87
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
88
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
89
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
90
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
91
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
92
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
93
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
94
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
95
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
96
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
97
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
98
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
99
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
100
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
101
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
102
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
103
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
104
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
105
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
106
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
107
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
108
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
109
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
110
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
111
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
112
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
113
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
114
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
115
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
116
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
117
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
118
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
119
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
120
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
121
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
122
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
123
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
124
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
125
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.7433, 0.8161,
        0.6417, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161, 0.6417, 0.7433,
        0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433,    nan,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.8161, 0.6417, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.6417, 0.5000, 0.7433, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.7433,    nan, 0.5000, 0.8161,
        0.5000, 0.8161,    nan, 0.5000, 0.5000, 0.5000, 0.7433, 0.7433, 0.5000,
           nan, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417,    nan, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.8161, 0.8161,
        0.5000, 0.5000, 0.7433, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
Assigned Classwise weights to source
Pred num ex per class (pseudo labels + labelled target examples):  [ 24 190  38  32  52  64  46  99 128  48  62 197   8  19  75  44 202 247
  33  17  64  91  75  27  42  48  19  44  66   6  21   7  19  11  22   4
   8   8 126 102 112 117  27  50 108  79 114 276 159 259  44 112 121  33
  54 102 114 118 160 213 175  19 137 108  65  52  51 148  26 113  14  54
  87  70  53   1  15  95  82  80   4  32   7  17 159 100  89 140   1  36
 117 117 108 141 127 178  84 151  17 189 379  67 217 215 177  62  53  30
   2  47  53 122 257 206  70 251  25 304   3 108 216 261 100   8  15 216]
CBFL per class weights: tensor([1.0070, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0403, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9916, 1.0036, 0.9941, 0.9951, 0.9928, 1.0243, 0.9919, 0.9941,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0253, 1.0087, 0.9926, 1.0573,
        1.0160, 0.9953, 0.9915, 0.9916, 0.9919, 0.9915, 0.9935, 0.9959, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0108,
        0.9935, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9959, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9974, 0.9984,
        0.9984, 0.9927, 1.0138, 0.9924, 0.9915, 0.9920, 1.0002, 0.9916, 0.9951,
        0.9914, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9923, 0.9915],
       device='cuda:0')
S real T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 1.040006 Loss T 0.104177 Method MME


Labeled Target set: Average loss: 2.7577, Accuracy: 168/360 F1 (46.6667%)


Test set: Average loss: 2.5370, Accuracy: 12665/24312 F1 (52.0936%)


Val set: Average loss: 2.4689, Accuracy: 191/360 F1 (53.0556%)

best acc test 52.842218  acc val 53.055556 acc labeled target 46.666667
saving model...
Pred num ex per class (pseudo labels + labelled target examples):  [ 24 190  38  32  52  64  46 100 128  48  62 197   8  19  75  44 202 247
  33  17  64  91  75  27  42  48  19  44  66   6  21   7  19  11  22   4
   8   8 126 102 112 117  27  50 108  79 114 276 160 259  44 112 121  34
  54 102 114 118 160 214 175  19 137 108  65  52  51 148  26 113  14  54
  87  70  53   1  15  95  82  80   4  32   7  17 159 100  89 140   1  36
 117 118 108 141 127 178  84 151  17 190 379  67 217 216 177  62  53  30
   2  47  54 122 257 206  70 251  25 304   3 108 216 261 100   8  15 216]
CBFL per class weights: tensor([1.0070, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0253, 1.0087, 0.9926, 1.0573,
        1.0160, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9935, 0.9959, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9935, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9959, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9914, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9923, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 24 190  38  32  52  64  46 100 128  48  62 197   8  19  75  44 202 247
  33  17  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   8   8 127 102 112 117  27  50 108  79 114 276 160 260  44 112 121  34
  54 102 114 118 160 214 175  19 137 108  65  52  51 148  26 113  14  55
  88  70  53   1  15  95  82  80   4  32   7  17 159 100  89 140   1  36
 117 118 108 141 127 178  84 151  17 190 379  67 217 216 177  62  53  30
   2  47  54 122 257 206  70 251  25 304   3 108 216 261 100   8  15 216]
CBFL per class weights: tensor([1.0071, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0160, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9959, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9935, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9959, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9927, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 24 190  38  32  52  64  46 100 128  48  62 197   8  19  75  44 202 247
  33  17  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   8   8 127 102 112 117  27  50 108  79 115 276 160 260  44 112 121  34
  54 102 114 118 160 215 175  19 137 108  65  52  51 148  26 113  14  55
  88  70  53   1  15  95  82  80   4  32   7  17 159 100  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 379  67 217 216 177  62  53  30
   2  47  54 122 257 206  70 251  25 304   3 108 217 262 100   8  15 216]
CBFL per class weights: tensor([1.0071, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0160, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9959, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9935, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9959, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 24 190  38  32  52  64  46 100 128  48  62 197   8  20  75  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 112 117  27  50 108  79 115 276 160 260  44 112 121  34
  54 102 114 118 160 215 175  19 137 108  65  52  51 148  26 113  14  55
  88  70  53   1  15  95  83  80   4  32   7  17 160 100  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 379  67 218 216 177  62  53  30
   2  47  54 122 257 206  69 251  25 304   3 108 218 262 100   8  15 216]
CBFL per class weights: tensor([1.0071, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9935, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 197   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 112 117  27  50 108  79 115 276 160 260  44 112 121  34
  55 102 114 118 160 215 175  19 137 108  65  52  51 148  26 113  14  55
  88  70  53   1  15  95  83  81   4  32   7  17 160 100  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 216 177  62  53  30
   2  47  54 122 257 206  69 251  25 304   3 108 219 262 100   8  15 216]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9920, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9925, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 197   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 112 117  27  50 108  79 115 276 160 260  44 112 121  34
  56 102 114 118 160 215 175  19 137 108  65  52  51 148  26 113  14  55
  88  70  53   1  15  95  83  81   4  32   7  17 160 100  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 305   3 108 220 262 100   8  15 216]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0034, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9925, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 197   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  50 108  79 115 277 160 260  44 112 121  34
  56 102 114 118 160 215 175  19 137 109  65  52  51 148  27 113  14  55
  88  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 305   3 108 220 262 101   8  15 216]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 197   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  50 108  79 115 277 160 260  44 112 121  34
  57 102 115 118 160 215 175  19 137 109  65  52  51 148  27 113  14  55
  88  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 306   3 108 220 263 101   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 198   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  79 115 277 160 260  44 112 121  34
  57 102 115 118 160 218 175  19 137 109  65  52  51 148  27 113  14  55
  88  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 306   3 108 220 264 101   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 199   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  79 115 277 160 260  44 111 121  34
  57 102 115 118 160 218 176  19 137 110  65  52  51 148  27 113  14  55
  88  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 380  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 306   3 108 220 265 101   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  32  52  64  46 100 128  48  62 199   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  79 115 277 161 260  44 111 121  34
  57 102 115 118 160 218 176  19 137 111  65  52  51 148  27 113  14  55
  88  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 141 127 179  84 152  17 190 381  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 307   3 108 220 265 101   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0176, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0036, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0573,
        1.0158, 0.9953, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9934, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9918, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  33  52  64  46 100 128  48  62 199   8  20  76  44 202 247
  33  18  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  79 115 277 161 260  44 111 121  34
  58 102 115 118 160 218 176  19 137 111  65  52  51 148  27 114  14  55
  89  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 142 127 179  84 152  17 190 381  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 307   3 108 220 265 101   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0173, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9923, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  33  52  64  46 100 128  48  62 199   8  20  76  44 202 247
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 161 261  44 111 121  34
  58 102 115 118 160 218 176  19 137 111  65  52  51 148  27 114  14  55
  89  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 142 127 179  84 152  17 190 381  67 219 218 177  63  53  30
   2  47  54 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0173, 0.9921, 1.0027, 1.0404, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9920, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0001, 0.9963, 1.0250, 1.0087, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9916, 1.0170, 0.9914,
        0.9920, 0.9921, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9925, 1.0051,
        1.0002, 0.9924, 0.9995, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9928, 0.9926, 0.9978, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  34  52  64  47 100 128  48  62 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 161 261  44 111 121  34
  59 102 115 118 160 218 176  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 142 127 179  84 152  17 190 381  67 219 219 177  63  53  30
   2  47  54 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0171, 0.9921, 1.0027, 1.0399, 0.9956, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9927, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  34  52  64  47 100 128  48  62 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 161 261  44 111 122  34
  59 102 115 119 160 218 178  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 161 101  89 140   1  36
 117 118 108 142 127 179  84 152  17 190 381  67 219 221 177  63  53  30
   2  47  54 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0171, 0.9921, 1.0027, 1.0399, 0.9956, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9927, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9927, 1.0136, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  34  52  64  47 100 128  48  62 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 161 261  44 111 122  34
  59 102 115 119 160 218 178  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 161 102  89 140   1  36
 117 118 108 143 127 179  84 152  17 190 381  67 219 221 177  63  53  30
   2  47  55 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0171, 0.9921, 1.0027, 1.0399, 0.9956, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0002, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9927, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 100 128  48  63 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 161 261  44 111 122  34
  60 102 116 119 160 218 179  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 161 102  89 140   1  36
 117 118 108 143 127 179  84 152  17 190 381  67 219 221 177  63  53  30
   2  47  55 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9921, 1.0027, 1.0399, 0.9956, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9934, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9927, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 162 261  44 111 122  34
  61 102 116 119 160 219 179  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 162 102  89 139   1  36
 118 118 108 143 127 179  84 152  17 190 381  67 220 222 177  63  53  30
   2  47  55 122 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9921, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2807, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9916, 0.9935, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 162 261  44 111 122  34
  62 102 116 119 160 220 179  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 162 102  89 139   1  36
 118 118 108 143 127 179  84 152  17 190 381  68 220 223 177  63  53  30
   2  47  55 123 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9921, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  76  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 277 162 261  44 111 122  34
  62 102 117 119 160 220 179  19 137 111  65  52  51 148  27 114  14  56
  89  70  53   1  15  95  83  82   4  32   7  17 162 102  89 139   1  36
 118 118 108 143 127 179  84 152  17 190 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  69 251  25 307   3 108 220 265 102   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9921, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  77  44 202 248
  33  19  64  91  75  27  42  48  19  44  66   6  21   7  20  11  22   4
   9   8 127 102 113 117  27  49 108  80 115 278 162 261  45 111 122  34
  64 102 117 119 160 220 179  19 137 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  95  83  82   4  32   7  17 162 102  89 139   1  36
 118 118 108 143 127 179  84 152  17 190 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  69 251  25 307   3 108 220 265 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9921, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0243, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0088, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0019, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9914,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9924, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9916, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9924, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  77  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 113 117  27  49 108  80 115 278 162 261  45 111 122  34
  65 103 117 119 160 220 179  19 137 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  95  83  82   4  32   7  17 163 102  89 139   1  36
 118 118 108 143 127 179  84 152  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  69 251  25 307   3 108 220 266 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9927, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  78  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 114 117  27  49 108  80 115 278 162 261  45 111 122  34
  65 103 117 119 160 220 179  19 137 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  95  83  82   4  32   7  17 163 102  89 139   1  36
 118 118 108 143 127 179  84 153  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  70 251  25 307   3 108 220 266 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9927, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 199   8  20  78  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 114 117  27  49 108  80 115 278 162 261  45 111 122  34
  65 103 117 119 160 220 180  19 136 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  95  83  82   4  32   7  17 163 102  89 139   1  36
 118 119 108 143 127 179  84 153  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  70 251  25 307   3 108 220 266 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9927, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 200   8  20  78  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 114 117  27  49 108  80 116 278 162 261  45 111 122  34
  65 103 117 119 160 220 180  19 136 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  96  83  82   4  32   7  17 163 102  89 139   1  36
 118 119 108 143 127 179  84 153  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  70 251  25 307   3 108 220 266 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9927, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 200   8  20  79  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 114 117  27  49 108  80 116 278 162 261  45 111 122  34
  65 103 117 119 160 220 180  19 136 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  96  83  82   4  32   7  17 163 102  89 139   1  36
 118 119 108 143 127 179  84 153  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 266 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9927, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 200   8  20  79  44 202 248
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  12  22   4
   9   8 127 102 114 117  27  49 109  80 116 278 162 261  45 111 122  34
  65 103 117 119 160 220 180  19 136 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  96  83  82   4  32   7  17 163 102  89 139   1  36
 119 119 108 143 127 179  84 153  17 191 382  68 220 223 177  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9921, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9928, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0086, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9916, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9916, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9917, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 191  38  35  52  64  47 101 128  48  63 200   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 102 114 117  27  49 109  80 116 278 162 261  45 111 122  34
  65 103 117 119 160 221 180  19 136 111  65  52  51 148  27 114  14  56
  90  70  53   1  15  96  83  83   4  32   7  17 163 102  89 139   1  36
 119 119 108 143 127 179  84 153  17 191 382  68 220 223 178  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  47 101 129  48  63 200   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 102 114 118  27  49 109  80 116 278 162 261  45 111 122  34
  65 103 117 119 160 221 180  19 136 111  65  52  51 149  27 114  14  56
  91  70  53   1  15  96  83  83   4  32   7  17 163 102  89 139   1  36
 119 120 108 143 127 179  84 153  17 191 382  68 220 223 178  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  47 101 129  48  63 200   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 102 114 118  27  49 109  80 117 278 162 261  45 111 122  34
  65 103 117 119 161 222 180  19 136 111  65  52  51 149  27 114  14  56
  91  70  53   1  15  97  83  83   4  32   7  17 163 102  89 139   1  36
 119 120 108 143 127 179  84 153  17 191 382  68 220 223 178  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0399, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9914, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9920, 0.9915, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0106,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9915, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  48 101 129  48  63 200   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 109  80 117 278 162 261  45 111 122  34
  65 103 117 119 162 222 180  19 136 111  65  52  52 149  27 114  14  56
  91  70  53   1  15  97  83  83   4  32   7  17 163 102  89 139   1  36
 119 120 108 143 127 179  84 153  17 192 382  68 220 223 178  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0394, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  48 101 129  48  63 201   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 109  80 117 278 162 262  45 111 122  34
  65 103 117 119 162 222 180  19 136 111  65  52  52 149  27 114  14  56
  91  70  53   1  15  97  83  83   4  32   7  17 163 102  89 139   1  36
 119 120 108 143 127 179  84 153  17 192 382  68 220 223 178  63  53  30
   2  47  55 123 257 206  70 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0394, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0003, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  48 102 129  48  63 201   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  66   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 109  80 117 278 162 262  45 111 122  34
  65 103 117 119 162 222 180  19 136 111  65  52  52 149  27 114  14  56
  91  70  53   1  15  97  83  83   4  32   7  17 163 102  89 139   1  36
 120 120 108 143 127 179  84 153  17 192 382  68 220 223 178  63  54  30
   2  47  55 123 257 206  71 251  26 307   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0394, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  48 102 129  48  63 201   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 109  80 117 278 162 262  45 112 122  34
  65 103 117 119 162 222 180  19 136 111  65  52  52 149  27 114  14  56
  91  70  53   1  15  97  83  83   4  32   7  17 163 102  89 139   1  36
 120 120 108 143 127 179  84 152  17 192 382  68 220 223 178  63  54  30
   2  47  55 123 257 206  71 251  26 308   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0394, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  48 102 129  48  63 201   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 109  80 117 278 162 262  45 112 122  34
  65 103 117 119 162 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 163 102  89 139   1  36
 120 120 108 145 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 257 206  71 251  26 308   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0394, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9921, 0.9921, 0.9914, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  49 102 129  48  63 201   8  20  79  44 202 247
  33  19  64  91  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 110  80 117 279 162 262  45 112 122  34
  65 103 117 119 162 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 146 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 206  71 251  26 308   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0389, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9991, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0018, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  49 102 129  48  63 202   8  20  79  44 202 247
  33  19  64  92  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 110  79 117 279 162 262  45 112 122  34
  66 104 117 119 162 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 146 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 206  71 251  26 308   3 108 220 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0389, 0.9955, 0.9929,
        0.9931, 0.9970, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  49 102 129  48  62 202   8  20  79  44 201 248
  33  19  64  92  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 110  79 117 279 162 262  45 113 122  34
  66 104 117 119 162 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 146 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 206  71 251  26 308   3 108 221 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0389, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  49 102 129  48  62 202   8  20  79  44 201 248
  33  19  64  92  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 118  27  49 110  79 117 280 162 262  45 113 122  34
  66 104 117 119 162 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 146 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 206  71 251  26 308   3 108 221 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0389, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  49 102 129  48  62 202   8  20  79  44 201 248
  33  19  64  92  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 119  27  49 110  79 117 280 162 262  45 113 122  34
  66 104 117 119 163 222 180  19 136 111  65  53  52 149  27 114  14  56
  91  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0389, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9951, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9927,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 25 190  38  35  52  64  50 102 129  48  62 202   8  20  79  44 201 248
  33  20  64  92  75  27  43  48  19  44  67   6  21   7  20  13  22   4
   9   8 127 101 114 119  27  49 110  79 117 280 162 262  45 114 122  34
  66 104 117 119 163 222 180  19 136 111  65  53  52 149  27 114  14  56
  92  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   8  15 215]
CBFL per class weights: tensor([1.0069, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0384, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9923, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0084, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9919, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9914, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9917, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 26 190  38  35  52  64  50 102 129  48  62 202   8  20  79  44 201 249
  33  21  64  92  75  27  43  48  19  44  67   6  21   7  20  14  22   4
   9   8 127 101 114 119  27  49 110  79 117 281 162 262  45 114 122  34
  66 104 117 119 163 222 180  19 136 111  65  53  52 149  27 115  14  56
  92  70  53   1  15  97  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 383  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   8  15 215]
CBFL per class weights: tensor([1.0068, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0384, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1093, 1.0002, 0.9964, 1.0250, 1.0083, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9919, 0.9915, 0.9936, 0.9960, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9915, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0051,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9914, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9974, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 26 190  38  35  52  64  52 102 129  48  62 202   8  20  79  44 201 249
  33  21  64  92  75  27  43  48  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 117 281 162 262  45 114 122  34
  66 105 116 119 163 222 180  19 136 112  65  53  52 149  27 115  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 164 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0068, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0374, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 26 190  38  35  52  64  52 102 129  48  62 202   8  20  79  44 201 249
  33  21  64  93  75  27  43  48  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 117 281 162 262  45 114 122  34
  66 105 116 119 163 222 180  19 136 112  65  53  52 149  27 115  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0068, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0374, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 26 190  38  35  52  64  52 102 130  48  62 203   8  20  79  44 201 249
  33  21  64  93  75  27  43  47  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 117 281 162 262  45 114 122  34
  66 105 116 119 163 222 180  19 136 112  65  53  52 149  27 115  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 251  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0068, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0374, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9944, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9926, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9915,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0482,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  48  62 203   8  20  79  44 201 249
  33  21  64  93  75  27  43  47  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 117 281 162 262  45 114 122  34
  66 105 116 119 163 222 180  19 136 112  65  53  52 149  27 115  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9932, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 203   8  20  79  44 201 249
  33  21  64  93  75  27  43  47  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 117 281 162 262  45 114 123  34
  66 105 116 119 164 222 180  19 136 112  65  53  52 149  27 116  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9942, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 249
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 118 280 162 262  45 114 123  34
  66 105 116 119 164 222 180  19 136 112  66  53  52 149  27 116  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9927, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 249
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   4
   9   8 127 102 114 119  27  49 110  79 118 280 162 262  45 114 124  34
  66 105 116 119 164 222 180  19 136 112  66  53  52 149  27 116  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9914, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0574,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9984, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 249
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 262  45 114 124  34
  66 105 116 119 164 222 180  19 136 112  66  53  52 149  27 116  14  56
  92  70  53   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  68 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9919, 0.9935, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 263  45 114 124  34
  66 105 116 119 164 222 180  19 136 112  66  53  52 149  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  69 220 223 178  63  54  30
   2  47  55 123 258 205  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 263  45 114 124  34
  66 105 116 119 164 223 180  19 136 112  66  53  52 149  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  69 220 223 178  63  54  30
   2  47  55 123 258 206  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 263  45 114 124  34
  66 105 116 119 164 223 180  19 136 112  66  53  52 149  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 102  89 140   1  36
 120 120 108 147 127 179  84 152  17 192 384  69 220 223 178  63  54  30
   2  47  55 123 258 206  71 252  26 308   3 108 221 267 103   7  15 215]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 263  45 115 124  34
  66 105 116 119 164 224 180  19 136 112  66  53  52 149  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 384  69 220 223 178  63  54  30
   2  47  55 123 258 206  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9960, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 27 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 280 162 263  45 115 124  34
  66 105 116 119 164 225 180  19 136 112  66  53  52 150  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 102  89 139   1  36
 120 120 108 147 127 179  84 152  17 192 384  69 220 223 178  63  54  30
   2  47  55 123 258 206  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0066, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0483,
        0.9915, 0.9915, 0.9933, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  22  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 281 162 263  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  52 150  27 116  14  56
  92  71  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  36
 120 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  30
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 281 162 263  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  52 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  36
 120 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  30
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 281 162 263  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  52 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  30
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0027, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9985,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 119  27  49 110  79 118 281 162 263  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  64  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 120  27  49 110  79 118 281 162 263  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0037, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  65  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 120  27  49 110  79 118 281 162 264  45 115 124  34
  67 105 116 119 164 225 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 139   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 308   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  65  94  75  27  43  47  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 110  79 118 281 162 264  45 115 124  34
  67 105 116 119 164 226 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 140   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 309   3 108 221 267 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9919, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  52  64  53 102 130  49  62 204   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 110  79 118 281 162 265  45 115 124  34
  67 105 116 119 165 228 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 140   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 309   3 108 221 268 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 205   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 281 162 266  45 115 124  34
  67 105 116 119 165 228 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 141   1  35
 121 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  31
   2  47  55 123 258 207  71 252  26 309   3 108 221 268 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0012, 0.9922,
        0.9928, 0.9918, 0.9934, 1.2808, 0.9935, 0.9915, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9984,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 205   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 281 162 266  45 115 124  34
  67 105 116 119 165 228 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 141   1  35
 122 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  32
   2  47  55 123 258 208  71 252  26 309   3 108 221 268 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0017, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9916, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 205   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 281 162 266  45 115 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 141   1  35
 122 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  32
   2  47  55 123 258 208  71 252  26 310   3 108 221 268 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 206   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 281 162 266  45 115 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 165 101  89 141   1  35
 122 120 108 147 127 179  84 152  16 192 385  70 220 223 178  63  54  32
   2  47  55 123 258 208  71 252  26 310   3 108 221 268 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9940, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 206   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 281 162 266  45 116 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 150  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 166 101  89 142   1  36
 122 120 108 147 127 179  84 152  16 193 385  70 220 223 178  63  54  32
   2  47  55 123 258 208  71 252  26 310   3 108 221 269 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9939, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9959, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 206   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 282 162 266  45 116 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 152  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 166 101  89 142   1  36
 121 120 108 147 127 179  84 152  16 193 385  70 220 223 178  63  54  32
   2  47  55 123 258 209  71 252  26 310   3 108 221 269 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9939, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9958, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
[W python_anomaly_mode.cpp:104] Warning: Error detected in MulBackward0. Traceback of forward call that caused the error:
  File "main_classwise.py", line 425, in <module>
    train()
  File "main_classwise.py", line 282, in train
    loss = torch.mean(weights_source * criterion(out1, target))
 (function _print_stack)
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 206   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 282 162 268  45 116 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 152  27 116  14  57
  92  72  54   1  15  98  84  83   4  32   7  17 166 101  89 142   1  36
 121 120 108 147 127 179  84 152  16 193 385  70 220 223 179  63  54  32
   2  47  55 123 258 209  71 252  26 310   3 108 221 269 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9939, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9958, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9925, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9927, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 28 190  38  35  53  64  53 102 130  49  62 206   8  20  79  44 201 250
  33  23  65  94  75  27  43  48  19  44  67   6  21   7  20  14  22   5
   9   9 127 102 114 121  27  49 111  79 118 283 162 268  45 116 124  34
  67 106 116 119 165 229 180  19 136 112  66  53  53 152  27 116  14  57
  92  72  54   1  15  98  86  83   4  32   7  17 166 101  89 142   1  36
 122 120 108 147 127 179  84 152  16 194 385  70 220 223 179  63  54  32
   2  47  55 123 258 209  71 252  26 310   3 108 221 269 103   7  15 216]
CBFL per class weights: tensor([1.0065, 0.9922, 1.0063, 1.0168, 0.9922, 1.0028, 1.0369, 0.9955, 0.9929,
        0.9931, 0.9971, 0.9915, 0.9945, 0.9919, 0.9924, 0.9921, 0.9915, 0.9915,
        0.9924, 0.9917, 1.0036, 0.9941, 0.9952, 0.9929, 1.0240, 0.9919, 0.9942,
        0.9921, 0.9916, 1.1094, 1.0002, 0.9964, 1.0250, 1.0083, 0.9927, 1.0567,
        1.0158, 0.9954, 0.9916, 0.9917, 0.9920, 0.9915, 0.9936, 0.9961, 0.9916,
        0.9992, 0.9923, 0.9914, 0.9916, 0.9918, 0.9917, 0.9939, 0.9926, 1.0107,
        0.9933, 1.0016, 0.9916, 0.9922, 0.9921, 0.9915, 0.9917, 1.0171, 0.9915,
        0.9920, 0.9922, 0.9926, 0.9944, 0.9958, 1.0033, 0.9931, 1.0013, 0.9922,
        0.9928, 0.9918, 0.9935, 1.2808, 0.9935, 0.9916, 0.9924, 0.9926, 1.0052,
        1.0003, 0.9924, 0.9996, 0.9916, 0.9925, 0.9920, 0.9917, 0.9936, 0.9928,
        0.9926, 0.9917, 0.9918, 0.9917, 0.9929, 0.9927, 0.9979, 0.9918, 1.0489,
        0.9915, 0.9915, 0.9932, 0.9921, 0.9916, 0.9918, 0.9919, 0.9975, 0.9983,
        0.9985, 0.9928, 1.0134, 0.9924, 0.9915, 0.9920, 1.0002, 0.9917, 0.9951,
        0.9915, 1.0190, 0.9918, 0.9915, 0.9932, 0.9920, 0.9925, 0.9924, 0.9915],
       device='cuda:0')
Traceback (most recent call last):
  File "main_classwise.py", line 425, in <module>
    train()
  File "main_classwise.py", line 291, in train
    loss.backward(retain_graph=True)
  File "/home/megh/anaconda3/envs/ssal/lib/python3.7/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/megh/anaconda3/envs/ssal/lib/python3.7/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'MulBackward0' returned nan values in its 1th output.
