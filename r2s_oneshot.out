Dataset multi Source real Target sketch Labeled num perclass 1 Network resnet34
126 classes in this dataset
Unlabelled Target Dataset Size:  24330
Labelled Target Dataset Size:  126
Misc. Labelled Target Dataset Size:  126
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  24330 Source:  70358
Unlabeled Target Data Size: 506
S real T sketch Train Ep: 0 lr0.01 	 Loss Classification: 4.960710 Loss T 0.471541 Method MME


Labeled Target set: Average loss: 4.9221, Accuracy: 4/378 F1 (1.0582%)


Test set: Average loss: 4.8976, Accuracy: 189/24312 F1 (0.7774%)


Val set: Average loss: 4.9671, Accuracy: 2/360 F1 (0.5556%)

best acc test 0.777394  acc val 0.555556 acc labeled target 1.058201
saving model...
S real T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 0.963053 Loss T 0.303494 Method MME

S real T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 0.789695 Loss T 0.228863 Method MME

S real T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 1.462324 Loss T 0.211926 Method MME

S real T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 0.984987 Loss T 0.190317 Method MME

S real T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.877412 Loss T 0.179826 Method MME


Labeled Target set: Average loss: 2.6180, Accuracy: 169/378 F1 (44.7090%)


Test set: Average loss: 2.5166, Accuracy: 11257/24312 F1 (46.3022%)


Val set: Average loss: 2.4157, Accuracy: 175/360 F1 (48.6111%)

best acc test 46.302238  acc val 48.611111 acc labeled target 44.708995
saving model...
S real T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.830583 Loss T 0.190256 Method MME

S real T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.368540 Loss T 0.158058 Method MME

S real T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.362388 Loss T 0.160717 Method MME

S real T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.765595 Loss T 0.135373 Method MME

S real T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.577783 Loss T 0.131100 Method MME


Labeled Target set: Average loss: 2.5134, Accuracy: 179/378 F1 (47.3545%)


Test set: Average loss: 2.3160, Accuracy: 12643/24312 F1 (52.0031%)


Val set: Average loss: 2.1657, Accuracy: 188/360 F1 (52.2222%)

best acc test 52.003126  acc val 52.222222 acc labeled target 47.354497
saving model...
S real T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.071855 Loss T 0.124785 Method MME

S real T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.279081 Loss T 0.142187 Method MME

S real T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.667595 Loss T 0.126255 Method MME

S real T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.252535 Loss T 0.092172 Method MME

S real T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.004012 Loss T 0.112415 Method MME


Labeled Target set: Average loss: 2.1672, Accuracy: 189/378 F1 (50.0000%)


Test set: Average loss: 2.2342, Accuracy: 13371/24312 F1 (54.9975%)


Val set: Average loss: 2.1780, Accuracy: 191/360 F1 (53.0556%)

best acc test 54.997532  acc val 53.055556 acc labeled target 50.000000
saving model...
S real T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.955579 Loss T 0.131947 Method MME

S real T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.853754 Loss T 0.093575 Method MME

S real T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.638802 Loss T 0.114876 Method MME

S real T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.596252 Loss T 0.123174 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.33333334 1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         0.         1.
 0.33333334 0.6666667  1.         1.         0.33333334 0.
 1.         0.         0.         0.         0.6666667  0.
 0.         0.         0.         0.         0.         0.33333334
 0.         0.33333334 1.         0.         0.6666667  0.
 0.         0.         1.         0.         0.33333334 1.
 0.         1.         0.6666667  0.         0.6666667  0.
 1.         1.         0.6666667  0.         1.         1.
 0.6666667  0.6666667  1.         0.         1.         1.
 0.6666667  0.         0.         0.33333334 0.         0.
 1.         0.33333334 0.33333334 0.         0.         0.33333334
 1.         0.         0.         0.33333334 0.         0.
 1.         0.33333334 1.         1.         0.         0.
 0.33333334 1.         1.         1.         1.         0.
 0.33333334 0.         0.         1.         0.6666667  1.
 0.         1.         0.         1.         0.6666667  1.
 0.         0.33333334 1.         0.33333334 1.         0.33333334
 1.         1.         1.         1.         0.         0.
 0.         1.         0.         0.         1.         1.        ]
Top k classes which perform poorly are:  [45, 29, 30, 31, 32, 33, 34, 71, 36, 70, 39, 68, 41, 42, 43, 67, 89, 97, 98, 48, 104, 63, 51, 57, 53, 26, 27, 108, 123, 122, 88, 120, 5, 119, 118, 83, 82, 12, 25, 80, 15, 16, 95, 76, 75, 23, 79, 102, 69, 81, 85, 77, 74, 73, 96, 0, 22, 113, 111, 18, 109, 35, 37, 46, 90, 50, 52, 19, 60, 28, 61, 100, 56, 40, 106, 66, 121, 92, 93, 117, 94, 116, 107, 99, 112, 101, 105, 110, 103, 115, 114, 62, 87, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 17, 20, 21, 24, 38, 86, 84, 78, 72, 65, 64, 91, 124, 58, 55, 54, 49, 47, 44, 59, 125]
0
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
1
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
2
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
3
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
4
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
5
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
6
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
7
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
8
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
9
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
10
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
11
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
12
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
13
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
14
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
15
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
16
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
17
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
18
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
19
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
20
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
21
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
22
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
23
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
24
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
25
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
26
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
27
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
28
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
29
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
30
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
31
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
32
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
33
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
34
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
35
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
36
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
37
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
38
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
39
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
40
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
41
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
42
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
43
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
44
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
45
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
46
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
47
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
48
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
49
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
50
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
51
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
52
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
53
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
54
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
55
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
56
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
57
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
58
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
59
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
60
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
61
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
62
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
63
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
64
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
65
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
66
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
67
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
68
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
69
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
70
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
71
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
72
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
73
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
74
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
75
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
76
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
77
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
78
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
79
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
80
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
81
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
82
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
83
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
84
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
85
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
86
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
87
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
88
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
89
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
90
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
91
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
92
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
93
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
94
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
95
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
96
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
97
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
98
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
99
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
100
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
101
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
102
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
103
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
104
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
105
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
106
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
107
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
108
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
109
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
110
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
111
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
112
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
113
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
114
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
115
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
116
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
117
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
118
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
119
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
120
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
121
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
122
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
123
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
124
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
125
Per cls weights according to the accuracy are:  tensor([1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.5000, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.1839, 1.2567, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.5000,
        1.3583, 1.5000, 1.5000, 1.1839, 1.3583, 1.1839, 1.1839, 1.5000, 1.5000,
        1.3583, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.3583, 1.5000, 1.5000,
        1.1839, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.5000, 1.3583, 1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
0
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
1
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
2
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
3
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
4
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
5
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
6
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
7
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
8
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
9
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
10
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
11
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
12
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
13
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
14
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
15
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
16
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
17
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
18
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
19
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
20
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
21
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
22
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
23
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
24
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
25
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
26
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
27
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
28
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
29
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
30
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
31
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
32
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
33
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
34
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
35
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
36
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
37
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
38
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
39
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
40
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
41
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
42
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
43
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
44
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
45
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
46
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
47
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
48
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
49
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
50
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
51
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
52
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
53
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
54
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
55
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
56
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
57
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
58
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
59
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
60
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
61
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
62
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
63
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
64
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
65
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
66
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
67
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
68
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
69
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
70
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
71
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
72
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
73
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
74
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
75
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
76
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
77
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
78
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
79
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
80
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
81
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
82
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
83
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
84
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
85
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
86
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
87
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
88
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
89
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
90
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
91
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
92
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
93
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
94
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
95
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
96
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
97
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
98
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
99
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
100
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
101
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
102
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
103
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
104
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
105
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
106
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
107
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
108
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
109
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
110
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
111
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
112
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
113
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
114
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
115
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
116
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
117
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
118
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
119
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
120
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
121
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
122
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
123
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
124
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
125
Per cls weights according to the accuracy are:  tensor([0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.5000, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.8161, 0.7433, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.5000,
        0.6417, 0.5000, 0.5000, 0.8161, 0.6417, 0.8161, 0.8161, 0.5000, 0.5000,
        0.6417, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.6417, 0.5000, 0.5000,
        0.8161, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.5000, 0.6417, 0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
Assigned Classwise weights to source
S real T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.539338 Loss T 0.102497 Method MME


Labeled Target set: Average loss: 2.4172, Accuracy: 195/378 F1 (51.5873%)


Test set: Average loss: 2.3500, Accuracy: 13015/24312 F1 (53.5332%)


Val set: Average loss: 2.2965, Accuracy: 185/360 F1 (51.3889%)

best acc test 54.997532  acc val 51.388889 acc labeled target 51.587302
saving model...
S real T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.868760 Loss T 0.111234 Method MME

S real T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.730785 Loss T 0.094258 Method MME

S real T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.199351 Loss T 0.088419 Method MME

S real T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.101571 Loss T 0.101819 Method MME

S real T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.595660 Loss T 0.112646 Method MME


Labeled Target set: Average loss: 2.0823, Accuracy: 215/378 F1 (56.8783%)


Test set: Average loss: 2.1054, Accuracy: 14320/24312 F1 (58.9010%)


Val set: Average loss: 1.9107, Accuracy: 217/360 F1 (60.2778%)

best acc test 58.900954  acc val 60.277778 acc labeled target 56.878307
saving model...
S real T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.884199 Loss T 0.111076 Method MME

S real T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.457686 Loss T 0.084425 Method MME

S real T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.358669 Loss T 0.127670 Method MME

S real T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.495554 Loss T 0.103072 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.         1.         1.         1.         1.         0.33333334
 0.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         0.         1.
 1.         0.         1.         1.         0.6666667  0.
 0.6666667  0.         0.         0.33333334 0.6666667  0.
 0.         0.33333334 0.         0.33333334 0.         0.
 0.         1.         1.         0.         1.         0.
 0.         0.         1.         0.33333334 0.         1.
 0.         1.         1.         0.         1.         0.
 1.         1.         0.6666667  0.33333334 1.         0.33333334
 1.         0.6666667  1.         0.         1.         1.
 0.         0.         0.33333334 1.         0.         1.
 1.         0.33333334 1.         0.         0.6666667  0.
 1.         0.         1.         1.         0.         0.6666667
 1.         0.6666667  1.         1.         0.         0.33333334
 1.         1.         0.6666667  0.6666667  1.         0.
 1.         0.         0.         1.         1.         0.6666667
 0.         1.         0.         1.         0.6666667  1.
 0.33333334 0.33333334 0.6666667  0.6666667  1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         0.         0.         0.33333334 1.        ]
Top k classes which perform poorly are:  [0, 32, 34, 35, 36, 39, 41, 43, 46, 104, 48, 102, 51, 53, 98, 97, 63, 95, 66, 67, 70, 75, 77, 79, 88, 82, 30, 29, 42, 6, 12, 19, 118, 119, 15, 16, 122, 25, 123, 26, 23, 5, 73, 89, 68, 124, 59, 27, 57, 31, 33, 108, 45, 109, 106, 83, 24, 76, 22, 92, 93, 110, 85, 111, 61, 101, 28, 56, 116, 113, 114, 121, 90, 120, 100, 91, 87, 105, 107, 94, 115, 112, 117, 96, 99, 103, 62, 84, 37, 21, 20, 18, 17, 14, 13, 38, 11, 9, 8, 7, 4, 3, 2, 1, 10, 86, 40, 47, 81, 80, 78, 74, 72, 71, 69, 44, 65, 60, 58, 55, 54, 52, 50, 49, 64, 125]
0
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
1
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
2
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
3
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
4
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
5
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
6
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
7
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
8
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
9
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
10
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
11
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
12
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
13
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
14
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
15
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
16
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
17
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
18
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
19
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
20
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
21
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
22
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
23
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
24
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
25
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
26
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
27
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
28
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
29
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
30
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
31
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
32
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
33
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
34
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
35
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
36
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
37
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
38
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
39
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
40
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
41
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
42
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
43
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
44
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
45
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
46
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
47
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
48
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
49
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
50
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
51
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
52
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
53
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
54
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
55
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
56
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
57
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
58
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
59
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
60
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
61
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
62
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
63
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
64
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
65
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
66
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
67
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
68
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
69
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
70
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
71
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
72
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
73
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
74
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
75
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
76
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
77
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
78
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
79
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
80
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
81
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
82
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
83
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
84
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
85
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
86
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
87
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
88
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
89
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
90
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
91
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
92
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
93
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
94
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
95
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
96
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
97
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
98
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
99
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
100
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
101
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
102
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
103
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
104
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
105
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
106
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
107
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
108
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
109
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
110
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
111
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
112
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
113
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
114
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
115
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
116
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
117
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
118
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
119
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
120
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
121
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
122
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
123
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
124
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
125
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.5000, 1.1839, 1.1839, 1.2567, 1.5000, 1.2567, 1.5000, 1.5000,
        1.3583, 1.2567, 1.5000, 1.5000, 1.3583, 1.5000, 1.3583, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000,
        1.1839, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839, 1.5000, 1.1839,
        1.1839, 1.3583, 1.1839, 1.5000, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.5000, 1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.5000, 1.3583,
        1.1839, 1.1839, 1.2567, 1.2567, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000,
        1.1839, 1.1839, 1.2567, 1.5000, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.3583, 1.2567, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.3583, 1.1839])
0
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
1
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
2
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
3
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
4
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
5
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
6
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
7
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
8
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
9
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
10
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
11
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
12
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
13
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
14
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
15
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
16
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
17
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
18
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
19
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
20
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
21
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
22
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
23
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
24
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
25
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
26
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
27
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
28
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
29
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
30
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
31
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
32
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
33
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
34
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
35
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
36
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
37
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
38
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
39
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
40
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
41
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
42
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
43
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
44
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
45
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
46
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
47
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
48
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
49
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
50
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
51
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
52
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
53
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
54
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
55
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
56
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
57
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
58
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
59
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
60
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
61
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
62
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
63
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
64
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
65
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
66
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
67
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
68
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
69
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
70
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
71
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
72
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
73
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
74
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
75
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
76
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
77
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
78
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
79
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
80
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
81
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
82
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
83
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
84
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
85
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
86
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
87
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
88
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
89
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
90
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
91
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
92
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
93
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
94
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
95
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
96
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
97
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
98
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
99
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
100
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
101
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
102
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
103
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
104
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
105
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
106
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
107
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
108
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
109
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
110
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
111
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
112
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
113
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
114
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
115
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
116
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
117
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
118
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
119
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
120
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
121
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
122
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
123
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
124
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
125
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.5000, 0.8161, 0.8161, 0.7433, 0.5000, 0.7433, 0.5000, 0.5000,
        0.6417, 0.7433, 0.5000, 0.5000, 0.6417, 0.5000, 0.6417, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000,
        0.8161, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161, 0.5000, 0.8161,
        0.8161, 0.6417, 0.8161, 0.5000, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.5000, 0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.5000, 0.6417,
        0.8161, 0.8161, 0.7433, 0.7433, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000,
        0.8161, 0.8161, 0.7433, 0.5000, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.6417, 0.7433, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.6417, 0.8161])
Assigned Classwise weights to source
S real T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.398160 Loss T 0.066293 Method MME


Labeled Target set: Average loss: 2.1266, Accuracy: 198/378 F1 (52.3810%)


Test set: Average loss: 2.2938, Accuracy: 13994/24312 F1 (57.5601%)


Val set: Average loss: 2.2779, Accuracy: 198/360 F1 (55.0000%)

best acc test 58.900954  acc val 55.000000 acc labeled target 52.380952
saving model...
S real T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.830081 Loss T 0.129754 Method MME

S real T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.557443 Loss T 0.103496 Method MME

S real T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.193653 Loss T 0.120083 Method MME

S real T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.260246 Loss T 0.094042 Method MME

S real T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.688359 Loss T 0.118752 Method MME


Labeled Target set: Average loss: 2.0511, Accuracy: 212/378 F1 (56.0847%)


Test set: Average loss: 2.0309, Accuracy: 14794/24312 F1 (60.8506%)


Val set: Average loss: 1.8444, Accuracy: 217/360 F1 (60.2778%)

best acc test 60.850609  acc val 60.277778 acc labeled target 56.084656
saving model...
S real T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.428515 Loss T 0.078854 Method MME

S real T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.582711 Loss T 0.083378 Method MME

S real T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 1.015661 Loss T 0.088305 Method MME

S real T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.509130 Loss T 0.058085 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         0.         0.         1.
 1.         1.         1.         1.         1.         0.
 0.6666667  0.6666667  0.         0.         0.6666667  0.
 0.         0.         0.         0.         0.         0.33333334
 0.         0.         1.         0.         0.6666667  0.
 0.         0.         1.         0.         0.33333334 1.
 0.         1.         0.         0.         1.         0.33333334
 1.         0.6666667  1.         0.33333334 1.         1.
 1.         0.6666667  1.         0.         1.         1.
 0.33333334 0.         0.         0.6666667  0.         0.6666667
 1.         0.33333334 0.         0.         0.33333334 0.
 1.         1.         1.         1.         0.         0.
 1.         1.         1.         1.         0.         0.
 0.         1.         1.         1.         1.         0.
 0.         0.         0.         1.         1.         1.
 0.         1.         0.         1.         1.         1.
 0.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         0.         0.         1.         1.        ]
Top k classes which perform poorly are:  [0, 34, 36, 37, 39, 41, 43, 104, 45, 48, 102, 50, 51, 98, 33, 97, 95, 63, 67, 68, 70, 74, 75, 77, 90, 89, 88, 82, 83, 96, 32, 42, 30, 123, 122, 5, 119, 118, 12, 15, 31, 109, 108, 16, 29, 23, 27, 26, 76, 46, 66, 73, 35, 53, 57, 71, 61, 25, 69, 55, 24, 28, 40, 116, 91, 117, 120, 92, 121, 106, 94, 114, 93, 105, 113, 112, 99, 100, 101, 111, 110, 87, 103, 107, 115, 86, 62, 84, 20, 19, 18, 17, 14, 13, 11, 21, 10, 8, 7, 6, 4, 3, 2, 1, 9, 85, 22, 44, 81, 80, 79, 78, 72, 65, 64, 38, 124, 59, 58, 56, 54, 52, 49, 47, 60, 125]
0
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
1
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
2
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
3
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
4
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
5
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
6
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
7
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
8
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
9
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
10
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
11
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
12
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
13
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
14
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
15
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
16
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
17
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
18
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
19
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
20
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
21
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
22
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
23
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
24
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
25
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
26
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
27
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
28
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
29
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
30
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
31
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
32
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
33
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
34
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
35
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
36
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
37
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
38
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
39
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
40
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
41
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
42
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
43
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
44
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
45
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
46
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
47
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
48
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
49
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
50
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
51
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
52
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
53
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
54
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
55
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
56
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
57
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
58
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
59
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
60
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
61
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
62
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
63
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
64
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
65
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
66
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
67
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
68
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
69
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
70
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
71
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
72
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
73
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
74
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
75
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
76
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
77
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
78
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
79
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
80
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
81
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
82
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
83
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
84
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
85
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
86
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
87
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
88
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
89
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
90
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
91
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
92
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
93
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
94
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
95
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
96
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
97
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
98
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
99
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
100
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
101
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
102
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
103
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
104
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
105
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
106
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
107
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
108
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
109
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
110
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
111
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
112
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
113
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
114
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
115
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
116
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
117
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
118
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
119
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
120
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
121
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
122
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
123
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
124
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
125
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.2567, 1.2567, 1.5000,
        1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.3583,
        1.5000, 1.5000, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.3583, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.1839, 1.3583,
        1.1839, 1.2567, 1.1839, 1.3583, 1.1839, 1.1839, 1.1839, 1.2567, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.2567, 1.5000, 1.2567,
        1.1839, 1.3583, 1.5000, 1.5000, 1.3583, 1.5000, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000, 1.5000, 1.5000,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.5000, 1.1839, 1.1839, 1.1839,
        1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839, 1.1839])
0
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
1
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
2
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
3
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
4
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
5
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
6
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
7
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
8
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
9
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
10
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
11
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
12
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
13
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
14
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
15
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
16
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
17
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
18
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
19
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
20
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
21
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
22
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
23
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
24
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
25
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
26
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
27
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
28
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
29
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
30
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
31
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
32
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
33
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
34
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
35
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
36
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
37
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
38
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
39
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
40
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
41
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
42
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
43
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
44
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
45
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
46
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
47
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
48
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
49
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
50
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
51
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
52
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
53
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
54
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
55
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
56
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
57
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
58
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
59
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
60
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
61
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
62
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
63
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
64
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
65
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
66
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
67
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
68
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
69
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
70
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
71
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
72
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
73
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
74
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
75
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
76
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
77
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
78
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
79
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
80
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
81
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
82
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
83
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
84
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
85
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
86
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
87
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
88
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
89
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
90
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
91
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
92
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
93
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
94
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
95
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
96
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
97
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
98
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
99
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
100
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
101
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
102
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
103
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
104
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
105
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
106
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
107
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
108
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
109
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
110
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
111
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
112
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
113
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
114
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
115
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
116
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
117
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
118
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
119
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
120
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
121
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
122
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
123
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
124
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
125
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.7433, 0.7433, 0.5000,
        0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.6417,
        0.5000, 0.5000, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.6417, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.8161, 0.6417,
        0.8161, 0.7433, 0.8161, 0.6417, 0.8161, 0.8161, 0.8161, 0.7433, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.7433, 0.5000, 0.7433,
        0.8161, 0.6417, 0.5000, 0.5000, 0.6417, 0.5000, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000, 0.5000, 0.5000,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.5000, 0.8161, 0.8161, 0.8161,
        0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161, 0.8161])
Assigned Classwise weights to source
S real T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.556635 Loss T 0.123644 Method MME


Labeled Target set: Average loss: 2.2943, Accuracy: 202/378 F1 (53.4392%)


Test set: Average loss: 2.2982, Accuracy: 14359/24312 F1 (59.0614%)


Val set: Average loss: 2.1723, Accuracy: 218/360 F1 (60.5556%)

best acc test 59.061369  acc val 60.555556 acc labeled target 53.439153
saving model...
S real T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.378601 Loss T 0.082505 Method MME

S real T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.261677 Loss T 0.078805 Method MME

S real T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.680195 Loss T 0.074424 Method MME

S real T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.407753 Loss T 0.090340 Method MME

S real T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.385516 Loss T 0.068053 Method MME


Labeled Target set: Average loss: 1.7682, Accuracy: 218/378 F1 (57.6720%)


Test set: Average loss: 2.0609, Accuracy: 15020/24312 F1 (61.7802%)


Val set: Average loss: 1.8991, Accuracy: 221/360 F1 (61.3889%)

best acc test 61.780191  acc val 61.388889 acc labeled target 57.671958
saving model...
S real T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.215163 Loss T 0.095904 Method MME

S real T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.254209 Loss T 0.056579 Method MME

S real T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.667495 Loss T 0.066883 Method MME

S real T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.516875 Loss T 0.070820 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.         1.         1.         0.33333334 1.         0.
 0.33333334 1.         1.         1.         1.         1.
 0.         1.         1.         0.         0.         1.
 1.         1.         1.         1.         0.6666667  0.
 0.         0.         0.         0.33333334 0.33333334 0.
 0.6666667  0.         0.         0.         0.         1.
 0.         0.         1.         0.6666667  0.33333334 0.
 0.6666667  0.         1.         0.33333334 0.         1.
 0.         1.         0.         0.         0.6666667  0.
 1.         1.         0.6666667  1.         1.         1.
 1.         0.         1.         0.         1.         1.
 0.33333334 0.         0.         1.         0.         1.
 1.         0.6666667  0.33333334 0.         0.         0.
 1.         1.         0.         1.         0.         0.
 1.         1.         1.         1.         0.         0.
 0.6666667  1.         0.6666667  1.         1.         1.
 1.         0.33333334 0.         1.         0.33333334 1.
 0.33333334 1.         0.         1.         0.6666667  1.
 0.33333334 0.6666667  1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.
 1.         1.         0.         0.33333334 1.         1.        ]
Top k classes which perform poorly are:  [0, 70, 23, 24, 25, 26, 46, 29, 68, 31, 32, 33, 34, 36, 37, 67, 63, 43, 41, 104, 48, 75, 98, 122, 53, 83, 5, 61, 82, 119, 50, 118, 80, 12, 51, 77, 15, 16, 76, 89, 88, 97, 45, 28, 66, 108, 102, 27, 74, 6, 3, 123, 40, 100, 92, 73, 90, 42, 56, 52, 106, 39, 30, 22, 109, 121, 120, 117, 116, 115, 91, 114, 113, 112, 93, 110, 101, 94, 107, 95, 96, 105, 103, 99, 111, 87, 62, 85, 35, 21, 20, 19, 18, 17, 14, 38, 13, 10, 9, 8, 7, 4, 2, 1, 11, 86, 44, 49, 84, 81, 79, 78, 72, 71, 69, 47, 65, 124, 60, 59, 58, 57, 55, 54, 64, 125]
0
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
1
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
2
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
3
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
4
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
5
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
6
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
7
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
8
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
9
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
10
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
11
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
12
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
13
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
14
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
15
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
16
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
17
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
18
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
19
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
20
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
21
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
22
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
23
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
24
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
25
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
26
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
27
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
28
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
29
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
30
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
31
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
32
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
33
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
34
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
35
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
36
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
37
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
38
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
39
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
40
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
41
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
42
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
43
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
44
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
45
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
46
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
47
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
48
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
49
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
50
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
51
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
52
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
53
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
54
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
55
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
56
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
57
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
58
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
59
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
60
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
61
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
62
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
63
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
64
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
65
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
66
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
67
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
68
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
69
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
70
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
71
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
72
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
73
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
74
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
75
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
76
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
77
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
78
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
79
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
80
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
81
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
82
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
83
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
84
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
85
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
86
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
87
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
88
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
89
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
90
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
91
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
92
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
93
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
94
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
95
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
96
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
97
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
98
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
99
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
100
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
101
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
102
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
103
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
104
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
105
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
106
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
107
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
108
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
109
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
110
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
111
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
112
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
113
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
114
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
115
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
116
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
117
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
118
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
119
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
120
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
121
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
122
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
123
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
124
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
125
Per cls weights according to the accuracy are:  tensor([1.5000, 1.1839, 1.1839, 1.3583, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.5000, 1.1839, 1.1839, 1.5000, 1.5000, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000,
        1.3583, 1.3583, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839,
        1.5000, 1.5000, 1.1839, 1.2567, 1.3583, 1.5000, 1.2567, 1.5000, 1.1839,
        1.3583, 1.5000, 1.1839, 1.5000, 1.1839, 1.5000, 1.5000, 1.2567, 1.5000,
        1.1839, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.1839,
        1.5000, 1.1839, 1.1839, 1.3583, 1.5000, 1.5000, 1.1839, 1.5000, 1.1839,
        1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.1839, 1.1839, 1.5000, 1.5000,
        1.2567, 1.1839, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.3583, 1.5000,
        1.1839, 1.3583, 1.1839, 1.3583, 1.1839, 1.5000, 1.1839, 1.2567, 1.1839,
        1.3583, 1.2567, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.5000, 1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.1839, 1.1839])
0
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
1
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
2
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
3
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
4
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
5
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
6
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
7
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
8
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
9
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
10
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
11
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
12
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
13
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
14
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
15
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
16
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
17
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
18
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
19
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
20
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
21
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
22
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
23
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
24
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
25
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
26
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
27
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
28
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
29
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
30
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
31
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
32
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
33
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
34
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
35
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
36
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
37
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
38
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
39
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
40
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
41
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
42
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
43
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
44
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
45
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
46
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
47
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
48
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
49
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
50
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
51
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
52
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
53
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
54
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
55
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
56
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
57
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
58
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
59
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
60
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
61
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
62
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
63
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
64
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
65
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
66
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
67
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
68
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
69
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
70
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
71
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
72
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
73
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
74
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
75
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
76
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
77
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
78
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
79
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
80
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
81
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
82
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
83
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
84
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
85
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
86
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
87
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
88
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
89
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
90
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
91
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
92
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
93
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
94
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
95
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
96
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
97
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
98
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
99
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
100
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
101
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
102
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
103
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
104
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
105
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
106
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
107
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
108
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
109
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
110
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
111
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
112
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
113
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
114
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
115
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
116
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
117
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
118
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
119
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
120
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
121
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
122
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
123
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
124
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
125
Per cls weights according to the accuracy are:  tensor([0.5000, 0.8161, 0.8161, 0.6417, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.5000, 0.8161, 0.8161, 0.5000, 0.5000, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000,
        0.6417, 0.6417, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161,
        0.5000, 0.5000, 0.8161, 0.7433, 0.6417, 0.5000, 0.7433, 0.5000, 0.8161,
        0.6417, 0.5000, 0.8161, 0.5000, 0.8161, 0.5000, 0.5000, 0.7433, 0.5000,
        0.8161, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.8161,
        0.5000, 0.8161, 0.8161, 0.6417, 0.5000, 0.5000, 0.8161, 0.5000, 0.8161,
        0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.8161, 0.8161, 0.5000, 0.5000,
        0.7433, 0.8161, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.6417, 0.5000,
        0.8161, 0.6417, 0.8161, 0.6417, 0.8161, 0.5000, 0.8161, 0.7433, 0.8161,
        0.6417, 0.7433, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.5000, 0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.8161, 0.8161])
Assigned Classwise weights to source
S real T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.477404 Loss T 0.078478 Method MME


Labeled Target set: Average loss: 2.4385, Accuracy: 201/378 F1 (53.1746%)


Test set: Average loss: 2.3096, Accuracy: 14503/24312 F1 (59.6537%)


Val set: Average loss: 2.2713, Accuracy: 205/360 F1 (56.9444%)

best acc test 61.780191  acc val 56.944444 acc labeled target 53.174603
saving model...
S real T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.437020 Loss T 0.085227 Method MME

S real T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.470157 Loss T 0.064480 Method MME

S real T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.352834 Loss T 0.068442 Method MME

S real T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.576002 Loss T 0.067943 Method MME

Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 250  67 114 329  80  52 133  22 178 551
  53  30  65 135 101  72  58  82  42  86 139  20  49  16  67  20  60  11
  15  10 201 143 160 192 114  82 122 184 144 434 170 426 146 202 141  55
 179 171 203 151 356 499 192  56 213 204 129 106  99 179  47 269  63 140
 151 117 104  14  38 439 314 125   2 141   7  16 308 146 129 135   3  72
 210 153 167 243 139 222 138 226  64 320 552 208 372 431 217 165  99 139
   3  82 161 227 343 390 155 292  76 387  17 125 377 353 156  17  39 222]
CBFL per class weights: tensor([ 0.7532,  0.3673,  0.6605,  0.6736,  0.4729,  0.4917,  0.3694,  0.4029,
         0.3666,  0.6876,  0.4940,  0.3497,  0.6099,  0.8278,  0.4570,  1.6985,
         0.4045,  0.3383,  0.8159,  1.2944,  0.7024,  0.4538,  0.5284,  0.6542,
         0.7627,  0.6002,  0.9785,  0.5823,  0.4477,  1.8503,  0.8664,  2.2682,
         0.6876,  1.8503,  0.7440,  3.2192,  2.4076,  3.5237,  0.3885,  0.4419,
         0.4213,  0.3942,  0.4940,  0.6002,  0.4768,  0.3998,  0.4406,  0.3413,
         0.4115,  0.3417,  0.4379,  0.3879,  0.4447,  0.7934,  0.4037,  0.4105,
         0.3873,  0.4315,  0.3466,  0.3392,  0.3942,  0.7828,  0.3818,  0.3867,
         0.4638,  0.5141,  0.5346,  0.4037,  0.8950,  0.3611,  0.7183,  0.4462,
         0.4315,  0.4873,  0.5196,  2.5670,  1.0614,  0.3411,  0.3519,  0.4710,
        16.9311,  0.4447,  4.9596,  2.2682,  0.3529,  0.4379,  0.4638,  0.4538,
        11.3440,  0.6542,  0.3834,  0.4291,  0.4143,  0.3690,  0.4477,  0.3775,
         0.4491,  0.3757,  0.7102,  0.3510,  0.3382,  0.3845,  0.3451,  0.3414,
         0.3798,  0.4162,  0.5346,  0.4477, 11.3440,  0.6002,  0.4203,  0.3753,
         0.3480,  0.3438,  0.4268,  0.3558,  0.6308,  0.3440,  2.1453,  0.4710,
         0.3447,  0.3469,  0.4257,  2.1453,  1.0390,  0.3775], device='cuda:0')
S real T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 3.980363 Loss T 0.097926 Method MME


Labeled Target set: Average loss: 2.2100, Accuracy: 218/378 F1 (57.6720%)


Test set: Average loss: 2.1363, Accuracy: 14937/24312 F1 (61.4388%)


Val set: Average loss: 1.9063, Accuracy: 222/360 F1 (61.6667%)

best acc test 61.438796  acc val 61.666667 acc labeled target 57.671958
saving model...
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 250  67 114 329  80  52 133  22 178 551
  53  30  65 135 101  73  58  82  42  86 139  20  49  16  67  20  60  11
  15  10 201 143 160 192 114  82 122 184 144 434 170 426 146 203 141  55
 179 171 203 151 356 499 192  56 213 204 129 106  99 179  47 269  63 140
 151 117 104  14  38 439 315 125   2 141   7  16 308 146 129 135   3  72
 210 153 167 243 139 223 138 226  64 320 552 208 371 431 217 165  99 139
   3  82 161 227 343 390 155 292  76 387  17 125 377 353 156  17  39 222]
CBFL per class weights: tensor([ 0.7533,  0.3673,  0.6605,  0.6737,  0.4730,  0.4918,  0.3694,  0.4030,
         0.3667,  0.6876,  0.4941,  0.3498,  0.6099,  0.8278,  0.4570,  1.6986,
         0.4046,  0.3383,  0.8159,  1.2945,  0.7025,  0.4538,  0.5284,  0.6482,
         0.7628,  0.6002,  0.9785,  0.5823,  0.4477,  1.8504,  0.8665,  2.2684,
         0.6876,  1.8504,  0.7441,  3.2194,  2.4078,  3.5239,  0.3885,  0.4420,
         0.4213,  0.3942,  0.4941,  0.6002,  0.4769,  0.3999,  0.4406,  0.3413,
         0.4115,  0.3417,  0.4379,  0.3873,  0.4448,  0.7935,  0.4038,  0.4106,
         0.3873,  0.4316,  0.3466,  0.3392,  0.3942,  0.7829,  0.3818,  0.3867,
         0.4638,  0.5141,  0.5346,  0.4038,  0.8950,  0.3611,  0.7183,  0.4462,
         0.4316,  0.4873,  0.5197,  2.5671,  1.0614,  0.3411,  0.3518,  0.4711,
        16.9321,  0.4448,  4.9599,  2.2684,  0.3529,  0.4379,  0.4638,  0.4538,
        11.3447,  0.6543,  0.3834,  0.4292,  0.4143,  0.3690,  0.4477,  0.3770,
         0.4492,  0.3757,  0.7103,  0.3510,  0.3383,  0.3845,  0.3452,  0.3414,
         0.3798,  0.4162,  0.5346,  0.4477, 11.3447,  0.6002,  0.4203,  0.3753,
         0.3480,  0.3438,  0.4268,  0.3559,  0.6308,  0.3440,  2.1454,  0.4711,
         0.3447,  0.3469,  0.4257,  2.1454,  1.0391,  0.3775], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 250  67 114 329  80  52 133  22 178 551
  53  30  65 135 101  73  58  82  42  86 139  20  49  16  67  20  60  11
  15  10 201 143 160 192 114  82 122 184 144 434 170 426 146 203 141  55
 179 171 203 151 356 499 192  56 213 204 129 106  99 179  47 269  63 141
 151 117 104  14  38 439 315 125   2 141   7  16 308 146 129 135   3  72
 210 153 167 243 139 223 138 226  64 320 552 208 371 431 217 165  99 139
   3  82 161 227 343 390 155 292  76 387  17 125 377 353 156  17  39 222]
CBFL per class weights: tensor([ 0.7533,  0.3673,  0.6605,  0.6737,  0.4730,  0.4918,  0.3694,  0.4030,
         0.3667,  0.6876,  0.4941,  0.3498,  0.6099,  0.8278,  0.4570,  1.6986,
         0.4046,  0.3383,  0.8159,  1.2945,  0.7025,  0.4538,  0.5284,  0.6482,
         0.7628,  0.6002,  0.9785,  0.5823,  0.4477,  1.8504,  0.8665,  2.2684,
         0.6876,  1.8504,  0.7441,  3.2194,  2.4078,  3.5239,  0.3885,  0.4420,
         0.4213,  0.3942,  0.4941,  0.6002,  0.4769,  0.3999,  0.4406,  0.3413,
         0.4115,  0.3417,  0.4379,  0.3873,  0.4448,  0.7935,  0.4038,  0.4106,
         0.3873,  0.4316,  0.3466,  0.3392,  0.3942,  0.7829,  0.3818,  0.3867,
         0.4638,  0.5141,  0.5346,  0.4038,  0.8950,  0.3611,  0.7183,  0.4448,
         0.4316,  0.4873,  0.5197,  2.5672,  1.0614,  0.3411,  0.3518,  0.4711,
        16.9323,  0.4448,  4.9599,  2.2684,  0.3529,  0.4379,  0.4638,  0.4538,
        11.3448,  0.6543,  0.3834,  0.4292,  0.4143,  0.3690,  0.4477,  0.3770,
         0.4492,  0.3757,  0.7103,  0.3510,  0.3383,  0.3845,  0.3452,  0.3414,
         0.3799,  0.4162,  0.5346,  0.4477, 11.3448,  0.6002,  0.4203,  0.3753,
         0.3480,  0.3438,  0.4268,  0.3559,  0.6309,  0.3440,  2.1454,  0.4711,
         0.3448,  0.3469,  0.4257,  2.1454,  1.0391,  0.3775], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 250  67 114 329  80  52 133  22 178 550
  53  30  65 136 101  73  58  82  42  86 139  20  49  16  67  20  60  11
  15  10 201 143 160 192 114  82 122 184 144 434 170 426 146 203 141  55
 179 171 203 151 356 499 192  56 213 204 129 106  99 179  47 269  63 141
 151 117 104  14  38 439 315 125   3 141   7  16 308 146 129 135   3  72
 210 153 167 243 139 223 138 226  64 319 552 208 371 431 217 165  99 139
   3  82 161 227 343 390 155 292  76 387  17 125 377 353 156  17  39 222]
CBFL per class weights: tensor([ 0.7882,  0.3844,  0.6912,  0.7050,  0.4949,  0.5146,  0.3865,  0.4217,
         0.3837,  0.7196,  0.5170,  0.3660,  0.6382,  0.8662,  0.4782,  1.7775,
         0.4233,  0.3540,  0.8538,  1.3546,  0.7351,  0.4732,  0.5530,  0.6782,
         0.7982,  0.6281,  1.0240,  0.6093,  0.4685,  1.9363,  0.9067,  2.3737,
         0.7196,  1.9363,  0.7786,  3.3689,  2.5196,  3.6875,  0.4065,  0.4625,
         0.4409,  0.4125,  0.5170,  0.6281,  0.4990,  0.4184,  0.4610,  0.3571,
         0.4306,  0.3575,  0.4582,  0.4053,  0.4654,  0.8303,  0.4225,  0.4296,
         0.4053,  0.4516,  0.3627,  0.3549,  0.4125,  0.8192,  0.3996,  0.4047,
         0.4853,  0.5380,  0.5594,  0.4225,  0.9366,  0.3779,  0.7516,  0.4654,
         0.4516,  0.5099,  0.5438,  2.6863,  1.1107,  0.3569,  0.3681,  0.4929,
        11.8714,  0.4654,  5.1902,  2.3737,  0.3693,  0.4582,  0.4853,  0.4749,
        11.8714,  0.6846,  0.4012,  0.4491,  0.4335,  0.3862,  0.4685,  0.3945,
         0.4700,  0.3932,  0.7432,  0.3675,  0.3540,  0.4023,  0.3613,  0.3573,
         0.3975,  0.4355,  0.5594,  0.4685, 11.8714,  0.6281,  0.4398,  0.3927,
         0.3642,  0.3597,  0.4467,  0.3724,  0.6601,  0.3600,  2.2450,  0.4929,
         0.3608,  0.3630,  0.4455,  2.2450,  1.0873,  0.3950], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 250  67 114 329  80  52 133  22 178 549
  53  30  65 136 101  73  58  82  42  86 139  20  49  16  67  19  60  11
  15  10 201 143 160 192 114  82 122 184 144 434 170 426 144 203 141  55
 179 171 203 151 356 498 192  56 213 204 129 106  99 179  47 269  63 141
 151 117 104  14  38 439 315 125  15 140   7  16 308 146 129 135   3  72
 210 153 167 243 139 223 138 226  64 319 551 208 370 432 217 165  99 139
   3  82 161 227 343 389 155 292  76 387  17 125 377 353 155  17  39 222]
CBFL per class weights: tensor([ 0.8507,  0.4149,  0.7460,  0.7608,  0.5342,  0.5554,  0.4172,  0.4551,
         0.4141,  0.7766,  0.5580,  0.3950,  0.6888,  0.9349,  0.5161,  1.9183,
         0.4569,  0.3821,  0.9215,  1.4619,  0.7934,  0.5107,  0.5968,  0.7320,
         0.8615,  0.6779,  1.1051,  0.6576,  0.5056,  2.0898,  0.9785,  2.5618,
         0.7766,  2.1891,  0.8403,  3.6359,  2.7193,  3.9798,  0.4387,  0.4991,
         0.4758,  0.4452,  0.5580,  0.6779,  0.5386,  0.4516,  0.4976,  0.3855,
         0.4647,  0.3859,  0.4976,  0.4374,  0.5023,  0.8961,  0.4560,  0.4637,
         0.4374,  0.4874,  0.3915,  0.3831,  0.4452,  0.8842,  0.4312,  0.4368,
         0.5238,  0.5806,  0.6038,  0.4560,  1.0108,  0.4079,  0.8112,  0.5023,
         0.4874,  0.5503,  0.5869,  2.8993,  1.1988,  0.3852,  0.3973,  0.5320,
         2.7193,  0.5039,  5.6016,  2.5618,  0.3986,  0.4946,  0.5238,  0.5125,
        12.8124,  0.7389,  0.4330,  0.4847,  0.4679,  0.4168,  0.5056,  0.4258,
         0.5073,  0.4243,  0.8021,  0.3966,  0.3820,  0.4342,  0.3900,  0.3856,
         0.4290,  0.4701,  0.6038,  0.5056, 12.8124,  0.6779,  0.4747,  0.4238,
         0.3931,  0.3883,  0.4821,  0.4019,  0.7125,  0.3885,  2.4230,  0.5320,
         0.3893,  0.3918,  0.4821,  2.4230,  1.1735,  0.4263], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 248  67 114 329  80  52 133  22 178 548
  53  30  65 136 101  73  58  82  42  86 139  20  49  16  67  19  60  11
  15  10 201 143 159 191 113  82 122 184 144 434 171 426 144 203 141  55
 178 171 203 151 355 496 192  56 213 204 129 106  98 179  47 269  63 141
 151 117 104  14  38 438 315 124  38 140   7  16 308 146 128 135   3  72
 210 152 167 243 139 223 138 226  64 319 551 208 370 432 217 165  99 139
   3  81 161 226 343 388 155 292  76 387  17 125 377 353 155  17  39 222]
CBFL per class weights: tensor([ 0.8610,  0.4198,  0.7550,  0.7700,  0.5406,  0.5621,  0.4222,  0.4606,
         0.4198,  0.7859,  0.5647,  0.3998,  0.6971,  0.9462,  0.5224,  1.9415,
         0.4624,  0.3867,  0.9326,  1.4795,  0.8029,  0.5169,  0.6040,  0.7408,
         0.8719,  0.6860,  1.1184,  0.6655,  0.5117,  2.1150,  0.9903,  2.5927,
         0.7859,  2.2155,  0.8505,  3.6797,  2.7520,  4.0278,  0.4440,  0.5051,
         0.4828,  0.4513,  0.5674,  0.6860,  0.5451,  0.4570,  0.5036,  0.3901,
         0.4693,  0.3905,  0.5036,  0.4427,  0.5084,  0.9069,  0.4624,  0.4693,
         0.4427,  0.4933,  0.3963,  0.3878,  0.4505,  0.8948,  0.4364,  0.4420,
         0.5301,  0.5876,  0.6147,  0.4615,  1.0230,  0.4128,  0.8210,  0.5084,
         0.4933,  0.5570,  0.5940,  2.9342,  1.2132,  0.3899,  0.4021,  0.5406,
         1.2132,  0.5100,  5.6691,  2.5927,  0.4034,  0.5005,  0.5321,  0.5187,
        12.9668,  0.7478,  0.4382,  0.4919,  0.4735,  0.4218,  0.5117,  0.4309,
         0.5134,  0.4294,  0.8118,  0.4014,  0.3866,  0.4395,  0.3947,  0.3902,
         0.4342,  0.4757,  0.6110,  0.5117, 12.9668,  0.6915,  0.4804,  0.4294,
         0.3978,  0.3931,  0.4879,  0.4067,  0.7210,  0.3932,  2.4521,  0.5384,
         0.3940,  0.3965,  0.4879,  2.4521,  1.1877,  0.4315], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 246  67 114 329  79  52 133  22 177 547
  53  30  65 136 101  73  58  82  42  86 139  20  48  16  67  19  60  11
  15  10 201 143 159 191 113  82 122 184 143 433 171 426 144 203 141  55
 178 170 202 151 355 494 192  56 213 204 129 106  98 179  47 269  63 141
 151 116 104  14  38 434 315 124  69 140   7  16 308 146 128 135   3  72
 210 152 167 243 139 223 138 226  64 319 551 207 368 432 217 165  99 139
   3  80 161 225 343 388 155 292  76 387  17 124 376 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8637,  0.4212,  0.7574,  0.7725,  0.5423,  0.5639,  0.4236,  0.4620,
         0.4220,  0.7885,  0.5665,  0.4011,  0.7051,  0.9492,  0.5240,  1.9477,
         0.4648,  0.3880,  0.9356,  1.4843,  0.8055,  0.5185,  0.6059,  0.7432,
         0.8746,  0.6882,  1.1220,  0.6677,  0.5133,  2.1218,  1.0095,  2.6010,
         0.7885,  2.2226,  0.8532,  3.6915,  2.7609,  4.0407,  0.4454,  0.5068,
         0.4843,  0.4528,  0.5692,  0.6882,  0.5468,  0.4585,  0.5068,  0.3914,
         0.4708,  0.3918,  0.5052,  0.4441,  0.5100,  0.9098,  0.4639,  0.4718,
         0.4448,  0.4949,  0.3976,  0.3891,  0.4520,  0.8977,  0.4378,  0.4434,
         0.5318,  0.5895,  0.6167,  0.4630,  1.0263,  0.4141,  0.8236,  0.5100,
         0.4949,  0.5613,  0.5959,  2.9436,  1.2171,  0.3914,  0.4034,  0.5423,
         0.7725,  0.5116,  5.6873,  2.6010,  0.4047,  0.5021,  0.5338,  0.5203,
        13.0084,  0.7502,  0.4396,  0.4935,  0.4750,  0.4232,  0.5133,  0.4323,
         0.5150,  0.4308,  0.8144,  0.4027,  0.3879,  0.4415,  0.3962,  0.3915,
         0.4356,  0.4773,  0.6130,  0.5133, 13.0084,  0.6993,  0.4819,  0.4313,
         0.3991,  0.3943,  0.4894,  0.4080,  0.7234,  0.3944,  2.4600,  0.5423,
         0.3954,  0.3978,  0.4908,  2.4600,  1.1915,  0.4329], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 177 547
  53  30  65 136 101  73  57  82  42  86 139  20  48  16  67  19  59  11
  15  10 201 143 159 191 113  82 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 494 192  56 213 204 129 106  98 179  47 269  63 141
 151 116 104  14  38 433 314 124  83 140   7  16 307 146 128 135   3  72
 210 151 167 243 139 223 138 224  64 319 551 207 367 432 217 165  99 139
   3  80 161 224 343 388 155 292  76 387  17 124 376 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8642,  0.4214,  0.7578,  0.7729,  0.5426,  0.5642,  0.4238,  0.4623,
         0.4218,  0.7808,  0.5668,  0.4013,  0.7055,  0.9498,  0.5243,  1.9488,
         0.4651,  0.3882,  0.9361,  1.4852,  0.8060,  0.5188,  0.6063,  0.7436,
         0.8865,  0.6886,  1.1227,  0.6681,  0.5136,  2.1230,  1.0101,  2.6025,
         0.7889,  2.2239,  0.8642,  3.6937,  2.7625,  4.0430,  0.4457,  0.5071,
         0.4846,  0.4530,  0.5695,  0.6886,  0.5471,  0.4588,  0.5071,  0.3917,
         0.4711,  0.3920,  0.5055,  0.4444,  0.5103,  0.9104,  0.4642,  0.4721,
         0.4450,  0.4951,  0.3978,  0.3893,  0.4523,  0.8982,  0.4381,  0.4437,
         0.5321,  0.5899,  0.6170,  0.4632,  1.0269,  0.4143,  0.8241,  0.5103,
         0.4951,  0.5616,  0.5962,  2.9453,  1.2178,  0.3916,  0.4038,  0.5426,
         0.6833,  0.5119,  5.6905,  2.6025,  0.4051,  0.5024,  0.5341,  0.5206,
        13.0159,  0.7506,  0.4399,  0.4951,  0.4753,  0.4234,  0.5136,  0.4326,
         0.5153,  0.4321,  0.8149,  0.4029,  0.3881,  0.4417,  0.3965,  0.3917,
         0.4358,  0.4775,  0.6134,  0.5136, 13.0159,  0.6997,  0.4822,  0.4321,
         0.3993,  0.3946,  0.4897,  0.4083,  0.7238,  0.3947,  2.4614,  0.5426,
         0.3956,  0.3980,  0.4910,  2.4614,  1.1922,  0.4331], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 176 547
  53  30  65 136 101  73  57  82  42  86 139  20  48  16  67  19  59  11
  15  10 201 143 159 191 113  82 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 493 192  56 213 204 129 106  98 179  47 269  63 141
 151 116 104  14  38 431 314 124  90 140   7  16 307 146 128 135   3  72
 210 151 167 243 139 223 138 224  64 319 551 207 366 432 217 165  99 139
   3  80 161 224 343 388 155 292  76 387  17 124 377 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8645,  0.4215,  0.7580,  0.7731,  0.5428,  0.5643,  0.4239,  0.4624,
         0.4219,  0.7810,  0.5670,  0.4014,  0.7057,  0.9500,  0.5245,  1.9493,
         0.4662,  0.3883,  0.9364,  1.4855,  0.8062,  0.5190,  0.6064,  0.7438,
         0.8867,  0.6888,  1.1230,  0.6682,  0.5138,  2.1236,  1.0104,  2.6032,
         0.7891,  2.2245,  0.8645,  3.6946,  2.7632,  4.0441,  0.4458,  0.5072,
         0.4848,  0.4531,  0.5697,  0.6888,  0.5473,  0.4589,  0.5072,  0.3918,
         0.4712,  0.3921,  0.5056,  0.4445,  0.5104,  0.9106,  0.4643,  0.4722,
         0.4451,  0.4953,  0.3979,  0.3894,  0.4524,  0.8984,  0.4382,  0.4438,
         0.5323,  0.5900,  0.6172,  0.4634,  1.0271,  0.4144,  0.8243,  0.5104,
         0.4953,  0.5618,  0.5964,  2.9461,  1.2181,  0.3918,  0.4039,  0.5428,
         0.6496,  0.5121,  5.6920,  2.6032,  0.4052,  0.5025,  0.5343,  0.5208,
        13.0193,  0.7508,  0.4400,  0.4953,  0.4754,  0.4235,  0.5138,  0.4327,
         0.5155,  0.4322,  0.8151,  0.4030,  0.3882,  0.4419,  0.3967,  0.3918,
         0.4359,  0.4777,  0.6135,  0.5138, 13.0193,  0.6999,  0.4823,  0.4322,
         0.3994,  0.3947,  0.4898,  0.4084,  0.7240,  0.3948,  2.4621,  0.5428,
         0.3956,  0.3981,  0.4912,  2.4621,  1.1925,  0.4332], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 176 546
  53  30  65 136 101  73  57  82  41  86 139  20  48  16  67  19  59  11
  15  11 201 143 159 191 113  82 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 493 192  56 213 204 129 106  98 179  47 269  63 141
 152 116 104  14  38 431 313 124  94 140   7  16 307 146 128 135   3  72
 211 151 167 243 139 223 138 224  64 319 551 207 366 432 217 165  99 139
   3  80 161 224 343 388 155 292  76 387  17 124 377 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8668,  0.4227,  0.7601,  0.7752,  0.5443,  0.5659,  0.4251,  0.4637,
         0.4231,  0.7832,  0.5685,  0.4025,  0.7076,  0.9526,  0.5259,  1.9547,
         0.4675,  0.3894,  0.9389,  1.4896,  0.8084,  0.5204,  0.6081,  0.7459,
         0.8891,  0.6907,  1.1481,  0.6701,  0.5152,  2.1294,  1.0132,  2.6104,
         0.7913,  2.2306,  0.8668,  3.7048,  2.7708,  3.7048,  0.4470,  0.5086,
         0.4861,  0.4544,  0.5712,  0.6907,  0.5488,  0.4602,  0.5086,  0.3929,
         0.4725,  0.3932,  0.5070,  0.4457,  0.5118,  0.9131,  0.4656,  0.4735,
         0.4464,  0.4966,  0.3990,  0.3905,  0.4536,  0.9009,  0.4394,  0.4450,
         0.5337,  0.5916,  0.6189,  0.4646,  1.0300,  0.4156,  0.8266,  0.5118,
         0.4952,  0.5633,  0.5980,  2.9542,  1.2215,  0.3929,  0.4052,  0.5443,
         0.6344,  0.5135,  5.7077,  2.6104,  0.4063,  0.5039,  0.5358,  0.5222,
        13.0551,  0.7529,  0.4406,  0.4966,  0.4767,  0.4247,  0.5152,  0.4339,
         0.5169,  0.4334,  0.8173,  0.4041,  0.3893,  0.4431,  0.3978,  0.3929,
         0.4371,  0.4790,  0.6152,  0.5152, 13.0551,  0.7018,  0.4836,  0.4334,
         0.4005,  0.3958,  0.4912,  0.4095,  0.7260,  0.3958,  2.4689,  0.5443,
         0.3967,  0.3992,  0.4925,  2.4689,  1.1958,  0.4344], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 176 546
  53  30  65 136 101  73  57  82  41  86 139  20  48  16  67  19  59  11
  15  11 201 143 159 191 113  83 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 492 192  56 213 204 129 106  98 179  47 269  63 141
 152 116 104  14  38 431 313 124  95 140   7  16 307 146 128 135   3  72
 211 151 167 243 139 223 138 224  64 319 551 207 366 432 217 165  99 139
   3  80 161 224 343 388 155 292  76 387  17 123 378 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8669,  0.4227,  0.7602,  0.7753,  0.5443,  0.5659,  0.4251,  0.4637,
         0.4231,  0.7832,  0.5686,  0.4025,  0.7077,  0.9527,  0.5259,  1.9548,
         0.4675,  0.3894,  0.9390,  1.4897,  0.8084,  0.5204,  0.6081,  0.7459,
         0.8892,  0.6907,  1.1482,  0.6701,  0.5152,  2.1295,  1.0132,  2.6105,
         0.7914,  2.2307,  0.8669,  3.7050,  2.7710,  3.7050,  0.4471,  0.5086,
         0.4861,  0.4544,  0.5713,  0.6854,  0.5488,  0.4602,  0.5086,  0.3929,
         0.4725,  0.3932,  0.5070,  0.4457,  0.5119,  0.9132,  0.4656,  0.4735,
         0.4464,  0.4967,  0.3990,  0.3906,  0.4536,  0.9010,  0.4394,  0.4451,
         0.5337,  0.5917,  0.6189,  0.4647,  1.0300,  0.4156,  0.8266,  0.5119,
         0.4953,  0.5633,  0.5981,  2.9544,  1.2215,  0.3929,  0.4052,  0.5443,
         0.6304,  0.5135,  5.7080,  2.6105,  0.4063,  0.5040,  0.5358,  0.5222,
        13.0559,  0.7529,  0.4406,  0.4967,  0.4768,  0.4247,  0.5152,  0.4339,
         0.5169,  0.4334,  0.8174,  0.4041,  0.3893,  0.4431,  0.3978,  0.3929,
         0.4371,  0.4790,  0.6152,  0.5152, 13.0559,  0.7019,  0.4837,  0.4334,
         0.4005,  0.3958,  0.4912,  0.4095,  0.7260,  0.3959,  2.4690,  0.5465,
         0.3967,  0.3993,  0.4926,  2.4690,  1.1958,  0.4344], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  41  86 139  20  48  16  67  19  59  11
  15  12 201 143 159 191 113  83 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 491 193  56 213 204 129 106  98 179  47 269  63 141
 152 116 104  14  38 431 313 124  96 140   7  16 307 146 128 135   3  72
 211 151 167 242 139 223 138 224  64 319 551 207 366 432 217 165  99 139
   3  80 161 224 343 388 156 292  76 387  17 123 378 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8689,  0.4237,  0.7620,  0.7771,  0.5456,  0.5673,  0.4261,  0.4648,
         0.4241,  0.7850,  0.5699,  0.4035,  0.7093,  0.9549,  0.5272,  1.9594,
         0.4696,  0.3903,  0.9412,  1.4932,  0.8103,  0.5217,  0.6096,  0.7477,
         0.8913,  0.6924,  1.1509,  0.6717,  0.5164,  2.1346,  1.0156,  2.6167,
         0.7932,  2.2360,  0.8689,  3.7138,  2.7775,  3.4211,  0.4481,  0.5098,
         0.4873,  0.4555,  0.5726,  0.6870,  0.5501,  0.4613,  0.5098,  0.3939,
         0.4736,  0.3941,  0.5082,  0.4468,  0.5131,  0.9153,  0.4667,  0.4747,
         0.4474,  0.4978,  0.4000,  0.3915,  0.4539,  0.9031,  0.4405,  0.4461,
         0.5350,  0.5931,  0.6204,  0.4658,  1.0324,  0.4166,  0.8286,  0.5131,
         0.4964,  0.5647,  0.5995,  2.9613,  1.2244,  0.3939,  0.4062,  0.5456,
         0.6280,  0.5147,  5.7215,  2.6167,  0.4073,  0.5051,  0.5370,  0.5235,
        13.0867,  0.7547,  0.4417,  0.4978,  0.4779,  0.4261,  0.5164,  0.4349,
         0.5181,  0.4344,  0.8193,  0.4051,  0.3902,  0.4442,  0.3988,  0.3938,
         0.4382,  0.4801,  0.6167,  0.5164, 13.0867,  0.7035,  0.4848,  0.4344,
         0.4015,  0.3967,  0.4911,  0.4105,  0.7277,  0.3968,  2.4748,  0.5478,
         0.3976,  0.4002,  0.4937,  2.4748,  1.1987,  0.4355], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  41  86 139  20  48  16  67  19  59  11
  15  14 201 143 159 191 113  83 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 490 193  56 213 204 129 106  98 179  47 269  63 141
 152 116 104  14  38 431 313 124  96 140   7  16 307 146 128 136   3  72
 211 151 167 242 139 223 138 224  64 318 551 207 366 432 217 165  99 139
   3  80 161 224 343 388 156 292  76 387  17 123 378 353 154  17  39 222]
CBFL per class weights: tensor([ 0.8721,  0.4253,  0.7648,  0.7800,  0.5476,  0.5694,  0.4277,  0.4665,
         0.4257,  0.7879,  0.5720,  0.4050,  0.7119,  0.9584,  0.5291,  1.9666,
         0.4713,  0.3917,  0.9447,  1.4987,  0.8133,  0.5236,  0.6118,  0.7504,
         0.8946,  0.6949,  1.1552,  0.6742,  0.5183,  2.1424,  1.0194,  2.6263,
         0.7961,  2.2442,  0.8721,  3.7274,  2.7877,  2.9722,  0.4498,  0.5117,
         0.4891,  0.4572,  0.5747,  0.6895,  0.5521,  0.4630,  0.5117,  0.3953,
         0.4754,  0.3956,  0.5101,  0.4484,  0.5149,  0.9187,  0.4684,  0.4764,
         0.4491,  0.4997,  0.4014,  0.3930,  0.4556,  0.9064,  0.4421,  0.4477,
         0.5370,  0.5952,  0.6227,  0.4675,  1.0362,  0.4181,  0.8316,  0.5149,
         0.4983,  0.5668,  0.6017,  2.9722,  1.2289,  0.3953,  0.4077,  0.5476,
         0.6303,  0.5166,  5.7425,  2.6263,  0.4088,  0.5070,  0.5390,  0.5236,
        13.1348,  0.7575,  0.4433,  0.4997,  0.4797,  0.4277,  0.5183,  0.4365,
         0.5200,  0.4360,  0.8223,  0.4068,  0.3917,  0.4458,  0.4002,  0.3953,
         0.4398,  0.4819,  0.6190,  0.5183, 13.1348,  0.7061,  0.4866,  0.4360,
         0.4029,  0.3982,  0.4929,  0.4120,  0.7304,  0.3983,  2.4839,  0.5498,
         0.3991,  0.4017,  0.4955,  2.4839,  1.2031,  0.4371], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  40  86 139  20  48  16  67  19  59  11
  15  18 201 143 159 191 113  83 122 184 143 431 171 426 144 203 141  55
 178 170 202 151 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140   7  16 307 146 128 136   3  72
 211 151 167 241 139 223 138 224  64 317 551 207 366 432 217 165  99 139
   5  80 161 224 343 388 156 292  76 387  17 123 378 353 154  17  39 222]
CBFL per class weights: tensor([ 0.9139,  0.4457,  0.8014,  0.8174,  0.5739,  0.5967,  0.4482,  0.4889,
         0.4461,  0.8257,  0.5994,  0.4244,  0.7461,  1.0044,  0.5545,  2.0609,
         0.4939,  0.4105,  0.9900,  1.5706,  0.8523,  0.5487,  0.6412,  0.7864,
         0.9375,  0.7282,  1.2350,  0.7065,  0.5432,  2.2451,  1.0682,  2.7522,
         0.8343,  2.3518,  0.9139,  3.9061,  2.9214,  2.4704,  0.4713,  0.5362,
         0.5125,  0.4791,  0.6023,  0.7226,  0.5786,  0.4852,  0.5362,  0.4143,
         0.4981,  0.4146,  0.5346,  0.4699,  0.5396,  0.9627,  0.4909,  0.4993,
         0.4706,  0.5236,  0.4207,  0.4118,  0.4775,  0.9499,  0.4633,  0.4692,
         0.5627,  0.6238,  0.6525,  0.4899,  1.0859,  0.4385,  0.8715,  0.5396,
         0.5222,  0.5939,  0.6305,  3.1147,  1.2879,  0.4143,  0.4272,  0.5739,
         0.6605,  0.5414,  6.0179,  2.7522,  0.4284,  0.5313,  0.5649,  0.5487,
        13.7646,  0.7938,  0.4645,  0.5236,  0.5027,  0.4486,  0.5432,  0.4575,
         0.5450,  0.4569,  0.8618,  0.4265,  0.4104,  0.4672,  0.4194,  0.4142,
         0.4609,  0.5050,  0.6486,  0.5432,  8.3416,  0.7400,  0.5099,  0.4569,
         0.4223,  0.4173,  0.5165,  0.4318,  0.7654,  0.4174,  2.6030,  0.5762,
         0.4182,  0.4209,  0.5193,  2.6030,  1.2607,  0.4580], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  40  86 139  20  48  16  67  19  59  11
  15  21 201 143 159 191 113  83 122 184 143 430 171 426 144 203 141  55
 178 170 202 151 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140   7  16 307 146 128 136   3  72
 211 151 167 241 139 223 138 224  64 317 551 207 366 431 217 165  99 139
   7  80 161 224 343 388 156 292  76 387  17 123 378 353 154  17  39 222]
CBFL per class weights: tensor([ 0.9453,  0.4552,  0.8186,  0.8348,  0.5861,  0.6094,  0.4578,  0.4993,
         0.4556,  0.8433,  0.6122,  0.4334,  0.7620,  1.0258,  0.5663,  2.1049,
         0.5044,  0.4193,  1.0111,  1.6041,  0.8705,  0.5604,  0.6549,  0.8032,
         0.9575,  0.7438,  1.2614,  0.7216,  0.5548,  2.2931,  1.0910,  2.8110,
         0.8521,  2.4020,  0.9335,  3.9895,  2.9838,  2.1945,  0.4814,  0.5477,
         0.5234,  0.4893,  0.6151,  0.7380,  0.5909,  0.4955,  0.5477,  0.4232,
         0.5088,  0.4234,  0.5460,  0.4799,  0.5512,  0.9833,  0.5013,  0.5099,
         0.4807,  0.5348,  0.4297,  0.4206,  0.4876,  0.9701,  0.4732,  0.4792,
         0.5747,  0.6371,  0.6664,  0.5003,  1.1091,  0.4478,  0.8901,  0.5512,
         0.5333,  0.6066,  0.6440,  3.1812,  1.3153,  0.4231,  0.4363,  0.5861,
         0.6746,  0.5529,  6.1464,  2.8110,  0.4376,  0.5427,  0.5769,  0.5604,
        14.0585,  0.8108,  0.4745,  0.5348,  0.5134,  0.4582,  0.5548,  0.4672,
         0.5566,  0.4667,  0.8802,  0.4356,  0.4192,  0.4771,  0.4284,  0.4231,
         0.4707,  0.5158,  0.6625,  0.5548,  6.1464,  0.7558,  0.5208,  0.4667,
         0.4313,  0.4262,  0.5275,  0.4410,  0.7818,  0.4263,  2.6586,  0.5885,
         0.4271,  0.4299,  0.5304,  2.6586,  1.2877,  0.4678], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 124 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  40  86 139  20  48  16  67  19  59  11
  15  25 201 143 158 191 113  83 122 184 143 430 171 425 144 203 141  55
 178 170 202 151 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140   7  16 307 146 128 136   3  72
 211 151 167 240 139 223 138 224  64 317 551 207 366 430 217 165  99 139
  12  80 161 224 343 388 156 292  76 387  17 123 378 352 154  17  39 222]
CBFL per class weights: tensor([ 0.9666,  0.4655,  0.8370,  0.8537,  0.5994,  0.6232,  0.4681,  0.5106,
         0.4659,  0.8624,  0.6261,  0.4432,  0.7792,  1.0490,  0.5791,  2.1525,
         0.5158,  0.4288,  1.0340,  1.6404,  0.8902,  0.5731,  0.6696,  0.8214,
         0.9791,  0.7606,  1.2899,  0.7379,  0.5673,  2.3449,  1.1157,  2.8745,
         0.8714,  2.4563,  0.9546,  4.0797,  3.0512,  1.9218,  0.4923,  0.5601,
         0.5366,  0.5004,  0.6290,  0.7547,  0.6043,  0.5067,  0.5601,  0.4327,
         0.5203,  0.4330,  0.5583,  0.4908,  0.5636,  1.0055,  0.5127,  0.5214,
         0.4915,  0.5469,  0.4394,  0.4301,  0.4987,  0.9921,  0.4839,  0.4901,
         0.5877,  0.6515,  0.6815,  0.5116,  1.1342,  0.4580,  0.9102,  0.5636,
         0.5454,  0.6203,  0.6585,  3.2531,  1.3451,  0.4327,  0.4462,  0.5994,
         0.6899,  0.5654,  6.2853,  2.8745,  0.4474,  0.5549,  0.5900,  0.5731,
        14.3762,  0.8291,  0.4852,  0.5469,  0.5250,  0.4690,  0.5673,  0.4778,
         0.5692,  0.4772,  0.9000,  0.4454,  0.4287,  0.4879,  0.4381,  0.4327,
         0.4813,  0.5274,  0.6775,  0.5673,  3.7582,  0.7729,  0.5326,  0.4772,
         0.4410,  0.4358,  0.5395,  0.4510,  0.7994,  0.4359,  2.7187,  0.6018,
         0.4368,  0.4398,  0.5424,  2.7187,  1.3168,  0.4784], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 123 115 242 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  40  86 139  20  48  16  67  19  59  11
  15  27 201 143 158 191 112  83 122 184 143 430 171 425 144 203 141  55
 178 170 202 150 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140   9  16 307 146 128 136   3  72
 211 151 167 240 139 223 138 224  64 316 551 207 366 429 217 165  99 139
  17  79 161 224 343 388 156 292  76 387  17 123 378 352 154  17  39 222]
CBFL per class weights: tensor([ 0.9862,  0.4749,  0.8540,  0.8710,  0.6140,  0.6358,  0.4776,  0.5210,
         0.4753,  0.8799,  0.6387,  0.4522,  0.7950,  1.0702,  0.5909,  2.1960,
         0.5263,  0.4374,  1.0549,  1.6736,  0.9082,  0.5847,  0.6832,  0.8380,
         0.9989,  0.7760,  1.3160,  0.7528,  0.5788,  2.3923,  1.1383,  2.9327,
         0.8890,  2.5060,  0.9739,  4.1622,  3.1129,  1.8330,  0.5022,  0.5714,
         0.5475,  0.5105,  0.6448,  0.7700,  0.6165,  0.5170,  0.5714,  0.4415,
         0.5308,  0.4418,  0.5696,  0.5007,  0.5750,  1.0259,  0.5230,  0.5320,
         0.5015,  0.5595,  0.4483,  0.4388,  0.5088,  1.0121,  0.4937,  0.5000,
         0.5996,  0.6647,  0.6953,  0.5220,  1.1571,  0.4672,  0.9287,  0.5750,
         0.5564,  0.6329,  0.6719,  3.3190,  1.3723,  0.4414,  0.4552,  0.6115,
         0.7038,  0.5769,  5.0372,  2.9327,  0.4565,  0.5661,  0.6019,  0.5847,
        14.6671,  0.8459,  0.4950,  0.5580,  0.5356,  0.4785,  0.5788,  0.4875,
         0.5807,  0.4869,  0.9183,  0.4546,  0.4373,  0.4978,  0.4469,  0.4415,
         0.4911,  0.5381,  0.6912,  0.5788,  2.7737,  0.7950,  0.5434,  0.4869,
         0.4499,  0.4446,  0.5504,  0.4601,  0.8156,  0.4447,  2.7737,  0.6140,
         0.4456,  0.4487,  0.5533,  2.7737,  1.3434,  0.4880], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 123 115 241 180 247  68 114 329  79  52 133  22 175 546
  53  30  65 136 101  73  57  82  40  86 139  20  48  16  67  19  59  11
  15  28 201 142 157 191 112  83 122 184 143 430 171 425 144 203 141  55
 178 170 202 150 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140  12  16 307 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 551 207 366 428 217 165  99 139
  19  79 161 224 343 388 156 292  76 387  17 123 378 352 154  17  39 222]
CBFL per class weights: tensor([ 0.9982,  0.4807,  0.8644,  0.8816,  0.6215,  0.6436,  0.4839,  0.5273,
         0.4812,  0.8906,  0.6466,  0.4577,  0.8047,  1.0833,  0.5981,  2.2229,
         0.5327,  0.4428,  1.0678,  1.6940,  0.9193,  0.5918,  0.6916,  0.8482,
         1.0112,  0.7855,  1.3321,  0.7620,  0.5859,  2.4216,  1.1522,  2.9686,
         0.8999,  2.5367,  0.9858,  4.2132,  3.1510,  1.7978,  0.5084,  0.5802,
         0.5556,  0.5167,  0.6527,  0.7794,  0.6241,  0.5233,  0.5784,  0.4469,
         0.5373,  0.4472,  0.5766,  0.5068,  0.5821,  1.0384,  0.5294,  0.5385,
         0.5076,  0.5664,  0.4538,  0.4442,  0.5150,  1.0245,  0.4997,  0.5061,
         0.6070,  0.6728,  0.7038,  0.5284,  1.1713,  0.4730,  0.9400,  0.5821,
         0.5632,  0.6406,  0.6801,  3.3596,  1.3891,  0.4468,  0.4608,  0.6190,
         0.7124,  0.5839,  3.8812,  2.9686,  0.4621,  0.5731,  0.6093,  0.5918,
        14.8466,  0.8562,  0.5011,  0.5648,  0.5422,  0.4849,  0.5859,  0.4934,
         0.5878,  0.4928,  0.9295,  0.4602,  0.4427,  0.5039,  0.4524,  0.4470,
         0.4971,  0.5447,  0.6996,  0.5859,  2.5367,  0.8047,  0.5500,  0.4928,
         0.4555,  0.4501,  0.5571,  0.4657,  0.8256,  0.4502,  2.8076,  0.6215,
         0.4511,  0.4542,  0.5601,  2.8076,  1.3598,  0.4940], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 123 115 241 180 246  68 114 329  79  52 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  59  11
  15  28 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 170 202 150 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140  22  16 306 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 551 207 365 428 217 165  99 139
  21  79 161 224 343 388 156 292  76 387  17 123 377 352 154  17  39 222]
CBFL per class weights: tensor([ 1.0132,  0.4879,  0.8774,  0.8948,  0.6308,  0.6532,  0.4911,  0.5352,
         0.4888,  0.9039,  0.6562,  0.4646,  0.8168,  1.0995,  0.6070,  2.2561,
         0.5407,  0.4494,  1.0838,  1.7194,  0.9331,  0.6007,  0.7019,  0.8609,
         1.0263,  0.7972,  1.3520,  0.7734,  0.5946,  2.4578,  1.1888,  3.0129,
         0.9133,  2.5746,  1.0005,  4.2762,  3.1981,  1.8246,  0.5168,  0.5889,
         0.5640,  0.5245,  0.6625,  0.7910,  0.6334,  0.5311,  0.5870,  0.4536,
         0.5453,  0.4539,  0.5852,  0.5152,  0.5908,  1.0539,  0.5374,  0.5465,
         0.5152,  0.5749,  0.4605,  0.4508,  0.5227,  1.0398,  0.5072,  0.5137,
         0.6160,  0.6829,  0.7143,  0.5363,  1.1888,  0.4800,  0.9541,  0.5908,
         0.5716,  0.6502,  0.6902,  3.4098,  1.4098,  0.4535,  0.4677,  0.6282,
         0.7231,  0.5927,  2.2561,  3.0129,  0.4692,  0.5816,  0.6184,  0.6007,
        15.0685,  0.8690,  0.5086,  0.5732,  0.5503,  0.4921,  0.5946,  0.5008,
         0.5966,  0.5002,  0.9434,  0.4671,  0.4493,  0.5114,  0.4593,  0.4537,
         0.5045,  0.5528,  0.7101,  0.5946,  2.3522,  0.8168,  0.5582,  0.5002,
         0.4623,  0.4568,  0.5654,  0.4727,  0.8379,  0.4569,  2.8496,  0.6308,
         0.4579,  0.4610,  0.5685,  2.8496,  1.3802,  0.5014], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 123 115 241 180 246  68 114 329  79  52 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  59  11
  15  28 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 170 202 150 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  38 431 313 124  96 140  26  16 306 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 551 207 365 428 217 165  99 139
  21  79 161 224 343 388 156 292  76 387  17 123 377 352 154  17  39 222]
CBFL per class weights: tensor([ 1.0157,  0.4891,  0.8795,  0.8970,  0.6323,  0.6548,  0.4923,  0.5365,
         0.4900,  0.9062,  0.6578,  0.4657,  0.8188,  1.1023,  0.6085,  2.2617,
         0.5420,  0.4505,  1.0864,  1.7236,  0.9354,  0.6021,  0.7036,  0.8630,
         1.0288,  0.7992,  1.3553,  0.7753,  0.5961,  2.4639,  1.1917,  3.0204,
         0.9156,  2.5810,  1.0030,  4.2867,  3.2060,  1.8291,  0.5181,  0.5903,
         0.5653,  0.5258,  0.6641,  0.7930,  0.6350,  0.5324,  0.5885,  0.4547,
         0.5467,  0.4550,  0.5866,  0.5165,  0.5922,  1.0565,  0.5387,  0.5479,
         0.5165,  0.5763,  0.4617,  0.4519,  0.5240,  1.0424,  0.5084,  0.5149,
         0.6175,  0.6846,  0.7161,  0.5376,  1.1917,  0.4812,  0.9564,  0.5922,
         0.5730,  0.6518,  0.6919,  3.4182,  1.4133,  0.4546,  0.4688,  0.6298,
         0.7249,  0.5941,  1.9510,  3.0204,  0.4704,  0.5831,  0.6199,  0.6021,
        15.1057,  0.8712,  0.5098,  0.5746,  0.5516,  0.4933,  0.5961,  0.5020,
         0.5981,  0.5014,  0.9457,  0.4682,  0.4504,  0.5127,  0.4604,  0.4548,
         0.5058,  0.5542,  0.7118,  0.5961,  2.3580,  0.8188,  0.5596,  0.5014,
         0.4634,  0.4579,  0.5668,  0.4738,  0.8400,  0.4580,  2.8566,  0.6323,
         0.4590,  0.4621,  0.5699,  2.8566,  1.3836,  0.5026], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  52 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 170 202 149 355 490 193  56 213 204 129 106  98 179  47 268  63 141
 152 116 104  14  39 431 313 124  96 140  30  16 306 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 550 207 365 428 217 165  99 139
  21  79 161 224 343 388 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([ 1.0180,  0.4903,  0.8816,  0.8991,  0.6365,  0.6563,  0.4935,  0.5378,
         0.4912,  0.9083,  0.6594,  0.4668,  0.8207,  1.1048,  0.6099,  2.2670,
         0.5433,  0.4516,  1.0890,  1.7276,  0.9376,  0.6036,  0.7053,  0.8651,
         1.0312,  0.8011,  1.3585,  0.7771,  0.5975,  2.4696,  1.1945,  3.0275,
         0.9177,  2.5870,  1.0180,  4.2968,  3.2135,  1.7787,  0.5193,  0.5917,
         0.5667,  0.5270,  0.6657,  0.7949,  0.6365,  0.5337,  0.5898,  0.4558,
         0.5480,  0.4561,  0.5880,  0.5177,  0.5936,  1.0590,  0.5399,  0.5492,
         0.5177,  0.5793,  0.4628,  0.4530,  0.5252,  1.0449,  0.5096,  0.5161,
         0.6190,  0.6862,  0.7178,  0.5389,  1.1945,  0.4823,  0.9587,  0.5936,
         0.5744,  0.6533,  0.6936,  3.4262,  1.3868,  0.4557,  0.4699,  0.6312,
         0.7266,  0.5955,  1.7276,  3.0275,  0.4715,  0.5844,  0.6214,  0.6036,
        15.1411,  0.8732,  0.5110,  0.5760,  0.5529,  0.4945,  0.5975,  0.5032,
         0.5995,  0.5026,  0.9479,  0.4693,  0.4515,  0.5139,  0.4615,  0.4559,
         0.5070,  0.5555,  0.7135,  0.5975,  2.3635,  0.8207,  0.5609,  0.5026,
         0.4645,  0.4590,  0.5682,  0.4749,  0.8420,  0.4591,  2.8633,  0.6338,
         0.4602,  0.4632,  0.5712,  2.8633,  1.3868,  0.5038], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  52 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 170 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  14  39 431 313 124  96 140  30  16 306 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 550 207 365 428 217 165  99 139
  22  79 161 224 343 388 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([ 1.0187,  0.4906,  0.8822,  0.8997,  0.6369,  0.6568,  0.4938,  0.5382,
         0.4915,  0.9089,  0.6598,  0.4671,  0.8213,  1.1056,  0.6104,  2.2685,
         0.5437,  0.4519,  1.0897,  1.7288,  0.9382,  0.6040,  0.7058,  0.8656,
         1.0319,  0.8016,  1.3594,  0.7777,  0.5979,  2.4713,  1.1953,  3.0295,
         0.9184,  2.5888,  1.0187,  4.2997,  3.2157,  1.7799,  0.5196,  0.5921,
         0.5671,  0.5274,  0.6661,  0.7954,  0.6369,  0.5340,  0.5902,  0.4561,
         0.5483,  0.4564,  0.5884,  0.5180,  0.5940,  1.0597,  0.5403,  0.5495,
         0.5180,  0.5797,  0.4631,  0.4533,  0.5256,  1.0456,  0.5100,  0.5165,
         0.6194,  0.6866,  0.7183,  0.5392,  1.1953,  0.4827,  0.9704,  0.5940,
         0.5748,  0.6538,  0.6940,  3.4285,  1.3878,  0.4560,  0.4702,  0.6317,
         0.7271,  0.5959,  1.7288,  3.0295,  0.4718,  0.5848,  0.6218,  0.6040,
        15.1514,  0.8738,  0.5114,  0.5764,  0.5533,  0.4948,  0.5979,  0.5036,
         0.5999,  0.5030,  0.9486,  0.4696,  0.4518,  0.5142,  0.4618,  0.4562,
         0.5073,  0.5559,  0.7140,  0.5979,  2.2685,  0.8213,  0.5613,  0.5030,
         0.4648,  0.4593,  0.5685,  0.4753,  0.8425,  0.4594,  2.8653,  0.6343,
         0.4605,  0.4635,  0.5716,  2.8653,  1.3878,  0.5042], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  52 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  14  39 431 313 124  96 140  33  16 306 146 128 136   3  72
 211 151 167 239 139 223 138 224  64 316 550 207 365 427 217 165  99 139
  23  79 161 224 343 388 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([ 1.0205,  0.4914,  0.8837,  0.9013,  0.6380,  0.6579,  0.4947,  0.5391,
         0.4923,  0.9105,  0.6610,  0.4679,  0.8227,  1.1075,  0.6114,  2.2725,
         0.5446,  0.4527,  1.0916,  1.7319,  0.9398,  0.6050,  0.7070,  0.8672,
         1.0337,  0.8030,  1.3618,  0.7790,  0.5989,  2.4757,  1.1974,  3.0348,
         0.9200,  2.5933,  1.0205,  4.3072,  3.2214,  1.7830,  0.5205,  0.5932,
         0.5681,  0.5283,  0.6673,  0.7968,  0.6380,  0.5350,  0.5913,  0.4569,
         0.5493,  0.4572,  0.5895,  0.5189,  0.5951,  1.0616,  0.5413,  0.5517,
         0.5189,  0.5807,  0.4639,  0.4541,  0.5265,  1.0474,  0.5109,  0.5174,
         0.6205,  0.6878,  0.7195,  0.5402,  1.1974,  0.4835,  0.9721,  0.5951,
         0.5758,  0.6549,  0.6953,  3.4346,  1.3902,  0.4568,  0.4711,  0.6328,
         0.7283,  0.5970,  1.5971,  3.0348,  0.4726,  0.5859,  0.6229,  0.6050,
        15.1780,  0.8753,  0.5123,  0.5774,  0.5543,  0.4957,  0.5989,  0.5044,
         0.6009,  0.5038,  0.9503,  0.4704,  0.4526,  0.5151,  0.4626,  0.4571,
         0.5082,  0.5569,  0.7153,  0.5989,  2.1843,  0.8227,  0.5623,  0.5038,
         0.4656,  0.4601,  0.5695,  0.4761,  0.8440,  0.4602,  2.8703,  0.6354,
         0.4613,  0.4643,  0.5726,  2.8703,  1.3902,  0.5050], device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  51 133  22 175 545
  53  30  65 136 101  73  57  82  40  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  14  39 431 313 124  96 140  33  16 306 146 128 136   5  72
 211 151 167 239 139 223 138 224  64 316 550 207 365 427 217 165  99 139
  23  79 161 224 343 387 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([1.0712, 0.5159, 0.9276, 0.9461, 0.6697, 0.6906, 0.5193, 0.5659, 0.5168,
        0.9557, 0.6938, 0.4912, 0.8636, 1.1799, 0.6418, 2.3854, 0.5717, 0.4752,
        1.1459, 1.8179, 0.9865, 0.6351, 0.7421, 0.9102, 1.0851, 0.8429, 1.4295,
        0.8177, 0.6287, 2.5987, 1.2569, 3.1856, 0.9657, 2.7222, 1.0712, 4.5212,
        3.3814, 1.8716, 0.5464, 0.6226, 0.5963, 0.5545, 0.7005, 0.8364, 0.6697,
        0.5616, 0.6207, 0.4796, 0.5766, 0.4799, 0.6187, 0.5447, 0.6246, 1.1143,
        0.5682, 0.5792, 0.5447, 0.6095, 0.4869, 0.4767, 0.5526, 1.0994, 0.5362,
        0.5431, 0.6513, 0.7220, 0.7553, 0.5670, 1.2569, 0.5075, 1.0204, 0.6246,
        0.6044, 0.6874, 0.7298, 3.6052, 1.4593, 0.4795, 0.4945, 0.6642, 0.7645,
        0.6266, 1.6764, 3.1856, 0.4961, 0.6150, 0.6538, 0.6351, 9.6551, 0.9188,
        0.5377, 0.6061, 0.5818, 0.5203, 0.6287, 0.5295, 0.6308, 0.5289, 0.9975,
        0.4938, 0.4751, 0.5407, 0.4856, 0.4798, 0.5334, 0.5845, 0.7508, 0.6287,
        2.2928, 0.8636, 0.5902, 0.5289, 0.4888, 0.4831, 0.5978, 0.4998, 0.8859,
        0.4831, 3.0129, 0.6669, 0.4843, 0.4874, 0.6011, 3.0129, 1.4593, 0.5301],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  51 133  22 175 545
  53  30  65 136 101  73  57  82  39  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  14  39 431 313 124  96 140  33  16 306 146 128 136   7  72
 211 151 167 239 139 223 138 224  64 316 550 207 365 427 217 165  99 139
  24  79 161 224 343 387 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([1.0951, 0.5273, 0.9483, 0.9672, 0.6846, 0.7060, 0.5308, 0.5785, 0.5283,
        0.9770, 0.7093, 0.5021, 0.8828, 1.2062, 0.6561, 2.4386, 0.5844, 0.4858,
        1.1714, 1.8584, 1.0085, 0.6492, 0.7586, 0.9305, 1.1092, 0.8617, 1.4918,
        0.8359, 0.6427, 2.6565, 1.2849, 3.2565, 0.9872, 2.7828, 1.0951, 4.6219,
        3.4567, 1.9133, 0.5586, 0.6365, 0.6096, 0.5669, 0.7161, 0.8550, 0.6846,
        0.5741, 0.6345, 0.4902, 0.5894, 0.4906, 0.6325, 0.5569, 0.6385, 1.1392,
        0.5808, 0.5921, 0.5569, 0.6231, 0.4978, 0.4873, 0.5649, 1.1239, 0.5482,
        0.5552, 0.6658, 0.7381, 0.7721, 0.5796, 1.2849, 0.5188, 1.0431, 0.6385,
        0.6178, 0.7028, 0.7461, 3.6855, 1.4918, 0.4902, 0.5055, 0.6790, 0.7815,
        0.6406, 1.7137, 3.2565, 0.5072, 0.6287, 0.6684, 0.6492, 7.1206, 0.9393,
        0.5497, 0.6196, 0.5948, 0.5319, 0.6427, 0.5413, 0.6448, 0.5406, 1.0197,
        0.5048, 0.4857, 0.5528, 0.4964, 0.4904, 0.5453, 0.5975, 0.7675, 0.6427,
        2.2570, 0.8828, 0.6034, 0.5406, 0.4996, 0.4938, 0.6112, 0.5109, 0.9057,
        0.4938, 3.0800, 0.6818, 0.4950, 0.4982, 0.6144, 3.0800, 1.4918, 0.5419],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  51 133  22 175 545
  53  30  65 136 101  73  57  82  39  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 430 313 124  96 140  33  16 306 146 128 136  10  72
 211 150 167 239 139 223 138 224  64 316 550 207 365 426 217 165  99 139
  25  79 161 224 343 385 156 292  76 387  17 123 376 352 154  17  39 222]
CBFL per class weights: tensor([1.1161, 0.5374, 0.9665, 0.9857, 0.6977, 0.7195, 0.5410, 0.5896, 0.5384,
        0.9957, 0.7229, 0.5118, 0.8997, 1.2293, 0.6687, 2.4853, 0.5956, 0.4951,
        1.1938, 1.8940, 1.0278, 0.6617, 0.7732, 0.9483, 1.1305, 0.8782, 1.5203,
        0.8520, 0.6550, 2.7074, 1.3095, 3.3189, 1.0061, 2.8361, 1.1161, 4.7104,
        3.5229, 1.9499, 0.5693, 0.6487, 0.6212, 0.5777, 0.7298, 0.8714, 0.6977,
        0.5851, 0.6466, 0.4996, 0.6007, 0.5000, 0.6446, 0.5675, 0.6508, 1.1610,
        0.5919, 0.6034, 0.5675, 0.6351, 0.5073, 0.4966, 0.5758, 1.1455, 0.5587,
        0.5658, 0.6786, 0.7522, 0.7869, 0.5907, 1.3095, 0.5288, 1.0631, 0.6508,
        0.6297, 0.7162, 0.7603, 3.5229, 1.5203, 0.4996, 0.5152, 0.6920, 0.7965,
        0.6529, 1.7466, 3.3189, 0.5169, 0.6407, 0.6812, 0.6617, 5.1559, 0.9573,
        0.5602, 0.6332, 0.6062, 0.5421, 0.6550, 0.5517, 0.6572, 0.5510, 1.0392,
        0.5145, 0.4950, 0.5634, 0.5059, 0.4999, 0.5558, 0.6090, 0.7822, 0.6550,
        2.2189, 0.8997, 0.6149, 0.5510, 0.5092, 0.5035, 0.6229, 0.5207, 0.9230,
        0.5033, 3.1390, 0.6948, 0.5045, 0.5078, 0.6262, 3.1390, 1.5203, 0.5523],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  51 131  22 175 545
  53  30  65 136 101  73  57  82  39  86 139  20  47  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 193  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 429 313 124  96 140  33  16 306 146 128 136  17  72
 211 150 167 239 139 223 138 224  64 316 550 207 365 426 217 165  99 139
  25  79 161 224 343 383 156 292  76 387  17 123 376 352 153  17  39 222]
CBFL per class weights: tensor([1.1342, 0.5462, 0.9821, 1.0017, 0.7090, 0.7312, 0.5498, 0.5991, 0.5472,
        1.0119, 0.7346, 0.5200, 0.9143, 1.2492, 0.6845, 2.5256, 0.6052, 0.5031,
        1.2132, 1.9247, 1.0445, 0.6724, 0.7857, 0.9637, 1.1488, 0.8924, 1.5450,
        0.8658, 0.6656, 2.7513, 1.3307, 3.3727, 1.0224, 2.8821, 1.1342, 4.7868,
        3.5800, 1.9816, 0.5785, 0.6592, 0.6313, 0.5871, 0.7416, 0.8855, 0.7090,
        0.5945, 0.6571, 0.5077, 0.6105, 0.5081, 0.6551, 0.5767, 0.6613, 1.1798,
        0.6015, 0.6132, 0.5767, 0.6454, 0.5155, 0.5047, 0.5851, 1.1640, 0.5677,
        0.5750, 0.6896, 0.7644, 0.7996, 0.6003, 1.3307, 0.5373, 1.0804, 0.6613,
        0.6399, 0.7278, 0.7727, 3.5800, 1.5450, 0.5078, 0.5235, 0.7032, 0.8094,
        0.6634, 1.7749, 3.3727, 0.5252, 0.6511, 0.6922, 0.6724, 3.1899, 0.9728,
        0.5693, 0.6435, 0.6160, 0.5509, 0.6656, 0.5606, 0.6678, 0.5599, 1.0560,
        0.5228, 0.5030, 0.5725, 0.5141, 0.5080, 0.5648, 0.6189, 0.7949, 0.6656,
        2.2549, 0.9143, 0.6249, 0.5599, 0.5175, 0.5119, 0.6330, 0.5291, 0.9380,
        0.5115, 3.1899, 0.7061, 0.5127, 0.5160, 0.6381, 3.1899, 1.5450, 0.5613],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  51 131  22 175 545
  53  30  65 136 101  73  57  82  39  86 139  20  46  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 169 202 149 355 490 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 428 312 124  96 140  33  16 306 145 128 136  27  72
 211 150 167 239 139 223 138 224  64 316 550 207 364 426 217 165  99 139
  25  79 161 224 343 382 156 292  76 387  17 123 376 352 153  17  39 222]
CBFL per class weights: tensor([1.1437, 0.5508, 0.9904, 1.0101, 0.7150, 0.7374, 0.5544, 0.6042, 0.5518,
        1.0204, 0.7408, 0.5244, 0.9220, 1.2598, 0.6902, 2.5469, 0.6104, 0.5073,
        1.2234, 1.9409, 1.0533, 0.6781, 0.7924, 0.9719, 1.1585, 0.9000, 1.5580,
        0.8731, 0.6713, 2.7745, 1.3648, 3.4012, 1.0310, 2.9064, 1.1437, 4.8272,
        3.6103, 1.9983, 0.5834, 0.6648, 0.6366, 0.5921, 0.7479, 0.8930, 0.7150,
        0.5996, 0.6627, 0.5120, 0.6156, 0.5124, 0.6606, 0.5816, 0.6669, 1.1898,
        0.6066, 0.6184, 0.5816, 0.6508, 0.5199, 0.5089, 0.5910, 1.1739, 0.5725,
        0.5799, 0.6954, 0.7709, 0.8064, 0.6054, 1.3420, 0.5419, 1.0895, 0.6669,
        0.6453, 0.7340, 0.7792, 3.6103, 1.5580, 0.5122, 0.5282, 0.7092, 0.8163,
        0.6691, 1.7899, 3.4012, 0.5297, 0.6586, 0.6981, 0.6781, 2.1259, 0.9810,
        0.5741, 0.6489, 0.6212, 0.5555, 0.6713, 0.5653, 0.6735, 0.5647, 1.0650,
        0.5272, 0.5072, 0.5773, 0.5186, 0.5123, 0.5695, 0.6241, 0.8016, 0.6713,
        2.2740, 0.9220, 0.6302, 0.5647, 0.5218, 0.5163, 0.6383, 0.5336, 0.9459,
        0.5158, 3.2168, 0.7121, 0.5170, 0.5204, 0.6435, 3.2168, 1.5580, 0.5660],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  50 130  22 175 544
  53  30  65 136 101  73  57  82  39  86 139  20  46  16  67  18  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 490 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 425 312 123  96 140  33  16 306 145 128 136  39  72
 211 150 167 239 139 223 138 224  64 316 550 207 364 426 217 165  99 139
  25  79 161 224 343 382 156 292  76 387  17 123 376 352 153  17  39 222]
CBFL per class weights: tensor([1.1473, 0.5525, 0.9935, 1.0133, 0.7173, 0.7397, 0.5562, 0.6061, 0.5535,
        1.0236, 0.7431, 0.5261, 0.9249, 1.2831, 0.6950, 2.5549, 0.6123, 0.5090,
        1.2273, 1.9470, 1.0566, 0.6802, 0.7948, 0.9749, 1.1622, 0.9028, 1.5629,
        0.8758, 0.6734, 2.7833, 1.3691, 3.4119, 1.0343, 3.0626, 1.1473, 4.8424,
        3.6216, 2.0046, 0.5852, 0.6669, 0.6386, 0.5939, 0.7502, 0.8958, 0.7173,
        0.6015, 0.6648, 0.5136, 0.6176, 0.5140, 0.6627, 0.5834, 0.6690, 1.1935,
        0.6085, 0.6217, 0.5834, 0.6528, 0.5215, 0.5105, 0.5929, 1.1775, 0.5743,
        0.5817, 0.6976, 0.7733, 0.8089, 0.6073, 1.3462, 0.5436, 1.0929, 0.6690,
        0.6473, 0.7363, 0.7816, 3.6216, 1.5629, 0.5140, 0.5298, 0.7143, 0.8188,
        0.6712, 1.7955, 3.4119, 0.5313, 0.6607, 0.7003, 0.6802, 1.5629, 0.9841,
        0.5759, 0.6510, 0.6231, 0.5573, 0.6734, 0.5671, 0.6756, 0.5664, 1.0683,
        0.5289, 0.5088, 0.5791, 0.5202, 0.5139, 0.5713, 0.6261, 0.8041, 0.6734,
        2.2811, 0.9249, 0.6322, 0.5664, 0.5235, 0.5180, 0.6403, 0.5353, 0.9489,
        0.5174, 3.2269, 0.7143, 0.5187, 0.5220, 0.6455, 3.2269, 1.5629, 0.5678],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  50 130  22 175 544
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 489 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 425 311 123  96 140  33  16 306 145 128 136  45  72
 211 150 167 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 381 156 292  76 387  17 123 376 351 153  17  39 222]
CBFL per class weights: tensor([1.1513, 0.5544, 0.9970, 1.0168, 0.7198, 0.7422, 0.5581, 0.6082, 0.5554,
        1.0272, 0.7457, 0.5279, 0.9281, 1.2875, 0.6974, 2.5638, 0.6144, 0.5107,
        1.2315, 1.9538, 1.0603, 0.6826, 0.7976, 0.9783, 1.1662, 0.9059, 1.5684,
        0.8789, 0.6757, 2.6729, 1.3739, 3.4238, 1.0379, 2.9257, 1.1513, 4.8592,
        3.6342, 2.0115, 0.5873, 0.6692, 0.6408, 0.5960, 0.7528, 0.8989, 0.7198,
        0.6035, 0.6671, 0.5154, 0.6197, 0.5158, 0.6650, 0.5855, 0.6713, 1.1976,
        0.6106, 0.6239, 0.5855, 0.6551, 0.5233, 0.5123, 0.5950, 1.1816, 0.5763,
        0.5837, 0.7000, 0.7760, 0.8117, 0.6094, 1.3509, 0.5455, 1.0967, 0.6713,
        0.6496, 0.7388, 0.7844, 3.6342, 1.5684, 0.5158, 0.5319, 0.7168, 0.8217,
        0.6735, 1.8017, 3.4238, 0.5332, 0.6630, 0.7027, 0.6826, 1.3979, 0.9875,
        0.5779, 0.6532, 0.6253, 0.5592, 0.6757, 0.5691, 0.6780, 0.5684, 1.0720,
        0.5307, 0.5106, 0.5811, 0.5222, 0.5157, 0.5733, 0.6282, 0.8069, 0.6757,
        2.2890, 0.9281, 0.6343, 0.5684, 0.5253, 0.5199, 0.6425, 0.5371, 0.9522,
        0.5192, 3.2381, 0.7168, 0.5205, 0.5240, 0.6478, 3.2381, 1.5684, 0.5698],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 58 248  71  69 122 115 241 180 246  68 114 329  79  50 130  22 175 544
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 489 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  15  39 425 311 123  96 140  33  16 306 145 128 136  47  72
 211 150 167 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 381 156 292  76 387  17 123 376 351 153  17  39 222]
CBFL per class weights: tensor([1.1517, 0.5546, 0.9974, 1.0172, 0.7200, 0.7425, 0.5583, 0.6084, 0.5557,
        1.0276, 0.7460, 0.5281, 0.9285, 1.2880, 0.6977, 2.5647, 0.6146, 0.5109,
        1.2320, 1.9545, 1.0607, 0.6828, 0.7979, 0.9787, 1.1666, 0.9063, 1.5689,
        0.8792, 0.6760, 2.6739, 1.3744, 3.4250, 1.0383, 2.9268, 1.1517, 4.8610,
        3.6355, 2.0123, 0.5875, 0.6694, 0.6411, 0.5962, 0.7531, 0.8992, 0.7200,
        0.6038, 0.6673, 0.5156, 0.6199, 0.5160, 0.6652, 0.5857, 0.6716, 1.1981,
        0.6109, 0.6241, 0.5857, 0.6554, 0.5235, 0.5125, 0.5952, 1.1821, 0.5765,
        0.5839, 0.7003, 0.7763, 0.8120, 0.6096, 1.3514, 0.5457, 1.0971, 0.6716,
        0.6498, 0.7391, 0.7847, 3.6355, 1.5689, 0.5160, 0.5321, 0.7171, 0.8220,
        0.6737, 1.8024, 3.4250, 0.5334, 0.6632, 0.7030, 0.6828, 1.3514, 0.9879,
        0.5781, 0.6535, 0.6255, 0.5594, 0.6760, 0.5693, 0.6782, 0.5686, 1.0724,
        0.5309, 0.5108, 0.5814, 0.5224, 0.5159, 0.5735, 0.6285, 0.8072, 0.6760,
        2.2899, 0.9285, 0.6346, 0.5686, 0.5255, 0.5201, 0.6428, 0.5373, 0.9525,
        0.5194, 3.2394, 0.7171, 0.5207, 0.5242, 0.6480, 3.2394, 1.5689, 0.5700],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 130  22 175 544
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  19  58  11
  15  29 200 142 157 191 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 487 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  16  39 424 311 123  96 140  33  16 306 145 128 136  53  72
 211 150 167 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 153  17  39 222]
CBFL per class weights: tensor([1.1405, 0.5562, 1.0001, 1.0200, 0.7220, 0.7445, 0.5598, 0.6101, 0.5572,
        1.0304, 0.7480, 0.5296, 0.9310, 1.2916, 0.6996, 2.5717, 0.6163, 0.5123,
        1.2354, 1.9599, 1.0636, 0.6847, 0.8001, 0.9813, 1.1698, 0.9087, 1.5732,
        0.8816, 0.6778, 2.6812, 1.3781, 3.4344, 1.0411, 2.9348, 1.1549, 4.8743,
        3.6455, 2.0178, 0.5891, 0.6713, 0.6428, 0.5978, 0.7552, 0.9017, 0.7220,
        0.6054, 0.6691, 0.5170, 0.6216, 0.5174, 0.6671, 0.5873, 0.6734, 1.2014,
        0.6125, 0.6258, 0.5873, 0.6572, 0.5250, 0.5140, 0.5968, 1.1853, 0.5781,
        0.5855, 0.7022, 0.7784, 0.8142, 0.6113, 1.3551, 0.5472, 1.1001, 0.6734,
        0.6516, 0.7411, 0.7868, 3.4344, 1.5732, 0.5175, 0.5336, 0.7190, 0.8242,
        0.6756, 1.8073, 3.4344, 0.5348, 0.6650, 0.7049, 0.6847, 1.2354, 0.9906,
        0.5797, 0.6553, 0.6272, 0.5609, 0.6778, 0.5709, 0.6801, 0.5702, 1.0754,
        0.5324, 0.5122, 0.5830, 0.5238, 0.5173, 0.5751, 0.6302, 0.8094, 0.6778,
        2.2961, 0.9310, 0.6363, 0.5702, 0.5269, 0.5217, 0.6445, 0.5388, 0.9551,
        0.5208, 3.2482, 0.7190, 0.5221, 0.5256, 0.6498, 3.2482, 1.5732, 0.5715],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  19  58  11
  15  29 200 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 487 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  16  39 424 311 123  96 140  33  16 306 145 128 136  54  72
 211 150 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1406, 0.5562, 1.0002, 1.0201, 0.7221, 0.7446, 0.5599, 0.6102, 0.5572,
        1.0305, 0.7481, 0.5296, 0.9311, 1.2917, 0.7023, 2.5721, 0.6164, 0.5124,
        1.2355, 1.9601, 1.0637, 0.6848, 0.8002, 0.9815, 1.1700, 0.9089, 1.5734,
        0.8817, 0.6779, 2.6815, 1.3783, 3.4349, 1.0412, 2.9352, 1.1550, 4.8750,
        3.6460, 2.0181, 0.5892, 0.6713, 0.6429, 0.5990, 0.7553, 0.9018, 0.7221,
        0.6055, 0.6692, 0.5171, 0.6217, 0.5174, 0.6671, 0.5874, 0.6735, 1.2015,
        0.6126, 0.6259, 0.5874, 0.6572, 0.5250, 0.5141, 0.5969, 1.1855, 0.5782,
        0.5856, 0.7023, 0.7785, 0.8144, 0.6114, 1.3553, 0.5472, 1.1003, 0.6735,
        0.6517, 0.7412, 0.7869, 3.4349, 1.5734, 0.5175, 0.5337, 0.7191, 0.8243,
        0.6757, 1.8076, 3.4349, 0.5349, 0.6651, 0.7050, 0.6848, 1.2182, 0.9907,
        0.5798, 0.6554, 0.6259, 0.5610, 0.6779, 0.5709, 0.6802, 0.5703, 1.0755,
        0.5325, 0.5123, 0.5830, 0.5239, 0.5174, 0.5752, 0.6303, 0.8095, 0.6779,
        2.2965, 0.9311, 0.6364, 0.5703, 0.5270, 0.5218, 0.6446, 0.5389, 0.9553,
        0.5209, 3.2487, 0.7191, 0.5222, 0.5257, 0.6481, 3.2487, 1.5734, 0.5716],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  19  58  11
  15  29 200 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 487 192  56 213 204 129 106  98 179  47 268  62 141
 152 116 104  17  39 424 311 123  96 140  33  16 306 145 128 136  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1423, 0.5570, 1.0017, 1.0216, 0.7232, 0.7457, 0.5607, 0.6111, 0.5581,
        1.0320, 0.7492, 0.5304, 0.9325, 1.2936, 0.7033, 2.5759, 0.6173, 0.5132,
        1.2373, 1.9630, 1.0653, 0.6858, 0.8014, 0.9829, 1.1717, 0.9102, 1.5758,
        0.8830, 0.6789, 2.6855, 1.3803, 3.4399, 1.0428, 2.9395, 1.1567, 4.8821,
        3.6513, 2.0210, 0.5900, 0.6723, 0.6439, 0.5998, 0.7564, 0.9031, 0.7232,
        0.6064, 0.6702, 0.5178, 0.6226, 0.5182, 0.6681, 0.5882, 0.6745, 1.2033,
        0.6135, 0.6268, 0.5882, 0.6582, 0.5258, 0.5148, 0.5978, 1.1872, 0.5790,
        0.5864, 0.7033, 0.7796, 0.8155, 0.6123, 1.3573, 0.5480, 1.1019, 0.6745,
        0.6526, 0.7423, 0.7881, 3.2534, 1.5758, 0.5183, 0.5344, 0.7202, 0.8255,
        0.6767, 1.8102, 3.4399, 0.5357, 0.6661, 0.7060, 0.6858, 1.2200, 0.9922,
        0.5806, 0.6582, 0.6268, 0.5618, 0.6789, 0.5718, 0.6811, 0.5711, 1.0771,
        0.5332, 0.5130, 0.5839, 0.5246, 0.5181, 0.5760, 0.6312, 0.8107, 0.6789,
        2.2998, 0.9325, 0.6373, 0.5711, 0.5278, 0.5226, 0.6456, 0.5397, 0.9567,
        0.5216, 3.2534, 0.7202, 0.5229, 0.5264, 0.6490, 3.2534, 1.5758, 0.5725],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  16  67  20  58  11
  15  29 199 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 487 192  56 213 204 129 106  97 179  47 268  62 141
 152 116 104  18  39 424 311 123  96 140  33  16 306 145 128 136  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1450, 0.5583, 1.0040, 1.0240, 0.7249, 0.7475, 0.5620, 0.6125, 0.5594,
        1.0344, 0.7510, 0.5316, 0.9347, 1.2966, 0.7050, 2.5819, 0.6187, 0.5144,
        1.2402, 1.9676, 1.0678, 0.6874, 0.8032, 0.9852, 1.1744, 0.9123, 1.5794,
        0.8851, 0.6805, 2.6917, 1.3836, 3.4479, 1.0452, 2.8126, 1.1594, 4.8935,
        3.6598, 2.0257, 0.5923, 0.6739, 0.6454, 0.6012, 0.7581, 0.9053, 0.7249,
        0.6078, 0.6718, 0.5191, 0.6241, 0.5194, 0.6697, 0.5896, 0.6760, 1.2061,
        0.6149, 0.6283, 0.5896, 0.6597, 0.5270, 0.5160, 0.5992, 1.1900, 0.5804,
        0.5878, 0.7050, 0.7815, 0.8224, 0.6137, 1.3604, 0.5493, 1.1044, 0.6760,
        0.6541, 0.7441, 0.7899, 3.0949, 1.5794, 0.5195, 0.5357, 0.7219, 0.8275,
        0.6782, 1.8144, 3.4479, 0.5370, 0.6676, 0.7077, 0.6874, 1.2228, 0.9945,
        0.5820, 0.6597, 0.6283, 0.5631, 0.6805, 0.5731, 0.6827, 0.5724, 1.0796,
        0.5345, 0.5142, 0.5852, 0.5259, 0.5193, 0.5774, 0.6327, 0.8126, 0.6805,
        2.3052, 0.9347, 0.6388, 0.5724, 0.5290, 0.5238, 0.6471, 0.5409, 0.9589,
        0.5229, 3.2610, 0.7219, 0.5241, 0.5277, 0.6506, 3.2610, 1.5794, 0.5738],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  17  67  21  58  11
  15  29 199 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 487 192  56 213 204 129 106  97 179  47 268  62 141
 152 116 104  19  39 424 311 123  96 140  33  17 306 145 128 136  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1508, 0.5612, 1.0092, 1.0292, 0.7286, 0.7513, 0.5649, 0.6156, 0.5622,
        1.0397, 0.7548, 0.5344, 0.9395, 1.3033, 0.7086, 2.5951, 0.6219, 0.5170,
        1.2466, 1.9777, 1.0732, 0.6909, 0.8074, 0.9903, 1.1805, 0.9170, 1.5875,
        0.8896, 0.6840, 2.7056, 1.3907, 3.2777, 1.0506, 2.7056, 1.1654, 4.9186,
        3.6786, 2.0361, 0.5954, 0.6774, 0.6487, 0.6043, 0.7620, 0.9099, 0.7286,
        0.6109, 0.6752, 0.5217, 0.6273, 0.5221, 0.6731, 0.5926, 0.6795, 1.2123,
        0.6181, 0.6315, 0.5926, 0.6631, 0.5297, 0.5187, 0.6022, 1.1961, 0.5834,
        0.5908, 0.7086, 0.7855, 0.8266, 0.6169, 1.3674, 0.5521, 1.1101, 0.6795,
        0.6575, 0.7479, 0.7940, 2.9614, 1.5875, 0.5222, 0.5384, 0.7256, 0.8317,
        0.6817, 1.8238, 3.2777, 0.5397, 0.6711, 0.7113, 0.6909, 1.2291, 0.9996,
        0.5850, 0.6631, 0.6315, 0.5660, 0.6840, 0.5760, 0.6862, 0.5754, 1.0851,
        0.5372, 0.5168, 0.5883, 0.5286, 0.5220, 0.5803, 0.6359, 0.8168, 0.6840,
        2.3170, 0.9395, 0.6421, 0.5754, 0.5317, 0.5265, 0.6504, 0.5437, 0.9638,
        0.5255, 3.2777, 0.7256, 0.5268, 0.5304, 0.6539, 3.2777, 1.5875, 0.5767],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  17  67  22  58  11
  15  29 199 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  20  39 424 311 123  96 140  33  17 306 145 128 137  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1531, 0.5623, 1.0111, 1.0312, 0.7300, 0.7528, 0.5660, 0.6168, 0.5633,
        1.0417, 0.7563, 0.5354, 0.9413, 1.3058, 0.7099, 2.6001, 0.6231, 0.5180,
        1.2490, 1.9815, 1.0753, 0.6922, 0.8089, 0.9922, 1.1827, 0.9188, 1.5906,
        0.8913, 0.6853, 2.7108, 1.3933, 3.2840, 1.0526, 2.6001, 1.1676, 4.9281,
        3.6857, 2.0401, 0.5965, 0.6787, 0.6499, 0.6055, 0.7635, 0.9116, 0.7300,
        0.6121, 0.6765, 0.5227, 0.6285, 0.5231, 0.6744, 0.5937, 0.6808, 1.2146,
        0.6193, 0.6327, 0.5937, 0.6644, 0.5308, 0.5197, 0.6034, 1.1984, 0.5845,
        0.5920, 0.7099, 0.7870, 0.8333, 0.6180, 1.3700, 0.5532, 1.1122, 0.6808,
        0.6588, 0.7493, 0.7955, 2.8325, 1.5906, 0.5232, 0.5395, 0.7270, 0.8333,
        0.6830, 1.8273, 3.2840, 0.5407, 0.6723, 0.7127, 0.6899, 1.2315, 1.0015,
        0.5861, 0.6644, 0.6327, 0.5671, 0.6853, 0.5771, 0.6876, 0.5765, 1.0872,
        0.5383, 0.5178, 0.5894, 0.5296, 0.5230, 0.5814, 0.6371, 0.8184, 0.6853,
        2.3215, 0.9413, 0.6433, 0.5765, 0.5327, 0.5275, 0.6516, 0.5447, 0.9657,
        0.5266, 3.2840, 0.7270, 0.5278, 0.5314, 0.6551, 3.2840, 1.5906, 0.5778],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 122 115 241 180 246  68 114 329  79  50 129  22 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  17  67  22  58  11
  15  29 199 142 157 190 112  83 122 184 143 430 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  22  39 424 311 123  96 140  33  17 306 145 128 137  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  25  79 161 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1552, 0.5633, 1.0130, 1.0331, 0.7313, 0.7541, 0.5671, 0.6180, 0.5644,
        1.0437, 0.7577, 0.5364, 0.9430, 1.3082, 0.7113, 2.6049, 0.6243, 0.5189,
        1.2513, 1.9852, 1.0773, 0.6935, 0.8104, 0.9940, 1.1849, 0.9205, 1.5935,
        0.8930, 0.6865, 2.7158, 1.3959, 3.2901, 1.0545, 2.6049, 1.1698, 4.9372,
        3.6925, 2.0438, 0.5976, 0.6799, 0.6511, 0.6066, 0.7649, 0.9133, 0.7313,
        0.6132, 0.6778, 0.5237, 0.6296, 0.5241, 0.6757, 0.5948, 0.6821, 1.2169,
        0.6204, 0.6339, 0.5948, 0.6656, 0.5317, 0.5207, 0.6045, 1.2006, 0.5856,
        0.5931, 0.7113, 0.7884, 0.8349, 0.6192, 1.3726, 0.5542, 1.1143, 0.6821,
        0.6600, 0.7507, 0.7970, 2.6049, 1.5935, 0.5241, 0.5405, 0.7283, 0.8349,
        0.6843, 1.8306, 3.2901, 0.5417, 0.6736, 0.7140, 0.6912, 1.2337, 1.0034,
        0.5872, 0.6656, 0.6339, 0.5682, 0.6865, 0.5782, 0.6888, 0.5775, 1.0892,
        0.5393, 0.5188, 0.5905, 0.5305, 0.5240, 0.5825, 0.6383, 0.8199, 0.6865,
        2.3258, 0.9430, 0.6445, 0.5775, 0.5337, 0.5285, 0.6528, 0.5457, 0.9675,
        0.5275, 3.2901, 0.7283, 0.5288, 0.5324, 0.6564, 3.2901, 1.5935, 0.5789],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 120 115 241 180 246  68 114 329  79  50 129  23 175 543
  53  30  65 136 101  73  57  82  39  86 139  21  46  17  67  23  58  11
  15  29 199 142 157 190 112  83 122 183 143 430 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  22  39 424 311 123  96 140  33  18 306 145 128 137  54  72
 211 149 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  26  79 162 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1593, 0.5653, 1.0166, 1.0368, 0.7401, 0.7568, 0.5691, 0.6201, 0.5663,
        1.0473, 0.7603, 0.5383, 0.9463, 1.3128, 0.7138, 2.5126, 0.6265, 0.5208,
        1.2557, 1.9922, 1.0811, 0.6960, 0.8133, 0.9975, 1.1891, 0.9237, 1.5991,
        0.8961, 0.6890, 2.7253, 1.4008, 3.3017, 1.0583, 2.5126, 1.1739, 4.9546,
        3.7055, 2.0510, 0.5997, 0.6823, 0.6534, 0.6087, 0.7676, 0.9166, 0.7339,
        0.6166, 0.6802, 0.5255, 0.6319, 0.5259, 0.6780, 0.5969, 0.6845, 1.2212,
        0.6226, 0.6361, 0.5969, 0.6680, 0.5336, 0.5225, 0.6066, 1.2048, 0.5876,
        0.5952, 0.7138, 0.7912, 0.8378, 0.6214, 1.3774, 0.5562, 1.1182, 0.6845,
        0.6623, 0.7533, 0.7998, 2.6141, 1.5991, 0.5260, 0.5424, 0.7309, 0.8378,
        0.6867, 1.8371, 3.1335, 0.5437, 0.6760, 0.7165, 0.6936, 1.2381, 1.0069,
        0.5892, 0.6680, 0.6361, 0.5702, 0.6890, 0.5803, 0.6913, 0.5796, 1.0931,
        0.5412, 0.5206, 0.5926, 0.5324, 0.5258, 0.5846, 0.6406, 0.8228, 0.6890,
        2.2550, 0.9463, 0.6452, 0.5796, 0.5356, 0.5303, 0.6552, 0.5477, 0.9709,
        0.5294, 3.3017, 0.7309, 0.5307, 0.5343, 0.6587, 3.3017, 1.5991, 0.5810],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  31  65 136 101  73  57  82  39  86 139  21  46  17  67  23  58  11
  15  29 199 142 157 190 112  83 122 183 143 430 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  24  39 424 311 123  96 140  33  18 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  27  79 162 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1622, 0.5667, 1.0191, 1.0394, 0.7452, 0.7587, 0.5705, 0.6217, 0.5673,
        1.0500, 0.7623, 0.5396, 0.9487, 1.3161, 0.7156, 2.5189, 0.6281, 0.5221,
        1.2589, 1.9420, 1.0838, 0.6977, 0.8153, 1.0000, 1.1921, 0.9261, 1.6032,
        0.8984, 0.6907, 2.7322, 1.4044, 3.3101, 1.0609, 2.5189, 1.1769, 4.9671,
        3.7149, 2.0562, 0.6012, 0.6840, 0.6551, 0.6103, 0.7695, 0.9189, 0.7358,
        0.6181, 0.6819, 0.5269, 0.6335, 0.5272, 0.6798, 0.5985, 0.6862, 1.2242,
        0.6242, 0.6377, 0.5985, 0.6697, 0.5350, 0.5238, 0.6082, 1.2079, 0.5891,
        0.5967, 0.7156, 0.7932, 0.8399, 0.6229, 1.3809, 0.5576, 1.1211, 0.6862,
        0.6640, 0.7553, 0.8018, 2.4257, 1.6032, 0.5273, 0.5437, 0.7327, 0.8399,
        0.6884, 1.8418, 3.1415, 0.5450, 0.6777, 0.7183, 0.6953, 1.2412, 1.0094,
        0.5907, 0.6716, 0.6377, 0.5716, 0.6907, 0.5817, 0.6930, 0.5810, 1.0958,
        0.5425, 0.5219, 0.5941, 0.5338, 0.5272, 0.5861, 0.6422, 0.8248, 0.6907,
        2.1875, 0.9487, 0.6468, 0.5810, 0.5370, 0.5317, 0.6568, 0.5491, 0.9733,
        0.5307, 3.3101, 0.7327, 0.5320, 0.5356, 0.6603, 3.3101, 1.6032, 0.5824],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  31  65 136 101  73  57  82  39  86 139  21  46  17  67  23  58  11
  15  29 199 142 157 190 112  83 122 183 143 430 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  24  39 424 311 123  96 140  33  18 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  27  79 162 224 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1622, 0.5667, 1.0191, 1.0394, 0.7452, 0.7587, 0.5705, 0.6217, 0.5673,
        1.0500, 0.7623, 0.5396, 0.9487, 1.3161, 0.7156, 2.5189, 0.6281, 0.5221,
        1.2589, 1.9420, 1.0838, 0.6977, 0.8153, 1.0000, 1.1921, 0.9261, 1.6032,
        0.8984, 0.6907, 2.7322, 1.4044, 3.3101, 1.0609, 2.5189, 1.1769, 4.9671,
        3.7149, 2.0562, 0.6012, 0.6840, 0.6551, 0.6103, 0.7695, 0.9189, 0.7358,
        0.6181, 0.6819, 0.5269, 0.6335, 0.5272, 0.6798, 0.5985, 0.6862, 1.2242,
        0.6242, 0.6377, 0.5985, 0.6697, 0.5350, 0.5238, 0.6082, 1.2079, 0.5891,
        0.5967, 0.7156, 0.7932, 0.8399, 0.6229, 1.3809, 0.5576, 1.1211, 0.6862,
        0.6640, 0.7553, 0.8018, 2.4257, 1.6032, 0.5273, 0.5437, 0.7327, 0.8399,
        0.6884, 1.8418, 3.1415, 0.5450, 0.6777, 0.7183, 0.6953, 1.2412, 1.0094,
        0.5907, 0.6716, 0.6377, 0.5716, 0.6907, 0.5817, 0.6930, 0.5810, 1.0958,
        0.5425, 0.5219, 0.5941, 0.5338, 0.5272, 0.5861, 0.6422, 0.8248, 0.6907,
        2.1875, 0.9487, 0.6468, 0.5810, 0.5370, 0.5317, 0.6568, 0.5491, 0.9733,
        0.5307, 3.3101, 0.7327, 0.5320, 0.5356, 0.6603, 3.3101, 1.6032, 0.5824],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  31  65 136 101  73  57  82  39  86 139  21  46  16  68  23  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  26  39 424 311 123  96 140  33  19 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  27  79 162 223 343 379 156 292  76 387  17 123 376 351 154  17  39 222]
CBFL per class weights: tensor([1.1635, 0.5674, 1.0202, 1.0405, 0.7460, 0.7595, 0.5711, 0.6224, 0.5679,
        1.0511, 0.7631, 0.5402, 0.9498, 1.3176, 0.7163, 2.5216, 0.6287, 0.5227,
        1.2602, 1.9441, 1.0850, 0.6985, 0.8162, 1.0011, 1.1934, 0.9271, 1.6049,
        0.8994, 0.6915, 2.7352, 1.4059, 3.5036, 1.0511, 2.5216, 1.1782, 4.9725,
        3.7189, 2.0584, 0.6019, 0.6848, 0.6558, 0.6109, 0.7704, 0.9199, 0.7366,
        0.6188, 0.6826, 0.5275, 0.6341, 0.5278, 0.6805, 0.5991, 0.6870, 1.2256,
        0.6249, 0.6384, 0.5991, 0.6704, 0.5355, 0.5244, 0.6088, 1.2092, 0.5898,
        0.5973, 0.7163, 0.7941, 0.8408, 0.6236, 1.3824, 0.5582, 1.1223, 0.6870,
        0.6647, 0.7561, 0.8027, 2.2632, 1.6049, 0.5279, 0.5443, 0.7335, 0.8408,
        0.6892, 1.8437, 2.9939, 0.5456, 0.6784, 0.7191, 0.6961, 1.2426, 1.0105,
        0.5914, 0.6723, 0.6384, 0.5722, 0.6915, 0.5824, 0.6938, 0.5817, 1.0970,
        0.5431, 0.5225, 0.5947, 0.5343, 0.5277, 0.5867, 0.6429, 0.8257, 0.6915,
        2.1898, 0.9498, 0.6475, 0.5824, 0.5375, 0.5322, 0.6575, 0.5496, 0.9744,
        0.5313, 3.3137, 0.7335, 0.5326, 0.5362, 0.6611, 3.3137, 1.6049, 0.5831],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  68  23  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  26  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  27  79 162 223 343 379 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1652, 0.5682, 1.0218, 1.0421, 0.7471, 0.7607, 0.5720, 0.6233, 0.5687,
        1.0527, 0.7642, 0.5410, 0.9512, 1.3195, 0.7174, 2.5254, 0.6297, 0.5234,
        1.2621, 1.8952, 1.0866, 0.6995, 0.8174, 1.0026, 1.1952, 0.9284, 1.6073,
        0.9007, 0.6925, 2.7393, 1.4080, 3.5088, 1.0527, 2.5254, 1.1799, 4.9799,
        3.7245, 2.0615, 0.6028, 0.6858, 0.6568, 0.6119, 0.7715, 0.9212, 0.7377,
        0.6197, 0.6836, 0.5283, 0.6351, 0.5286, 0.6815, 0.6000, 0.6880, 1.2274,
        0.6258, 0.6394, 0.6000, 0.6714, 0.5363, 0.5252, 0.6097, 1.2110, 0.5907,
        0.5982, 0.7174, 0.7953, 0.8421, 0.6245, 1.3844, 0.5590, 1.1239, 0.6880,
        0.6657, 0.7572, 0.8038, 2.2665, 1.6073, 0.5287, 0.5451, 0.7346, 0.8421,
        0.6902, 1.8465, 2.8623, 0.5464, 0.6794, 0.7202, 0.6971, 1.2444, 1.0120,
        0.5923, 0.6733, 0.6394, 0.5731, 0.6925, 0.5832, 0.6948, 0.5825, 1.0987,
        0.5439, 0.5233, 0.5956, 0.5351, 0.5285, 0.5876, 0.6438, 0.8270, 0.6925,
        2.1931, 0.9512, 0.6485, 0.5832, 0.5383, 0.5330, 0.6585, 0.5505, 0.9758,
        0.5321, 3.3186, 0.7346, 0.5334, 0.5371, 0.6620, 3.3186, 1.6073, 0.5839],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  68  24  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  27  79 162 223 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1667, 0.5690, 1.0231, 1.0435, 0.7481, 0.7617, 0.5727, 0.6241, 0.5695,
        1.0541, 0.7652, 0.5417, 0.9524, 1.3213, 0.7184, 2.5288, 0.6305, 0.5241,
        1.2638, 1.8977, 1.0881, 0.7005, 0.8185, 1.0039, 1.1968, 0.9297, 1.6095,
        0.9019, 0.6934, 2.7429, 1.4099, 3.5135, 1.0541, 2.4351, 1.1815, 4.9865,
        3.7294, 2.0642, 0.6036, 0.6867, 0.6576, 0.6127, 0.7725, 0.9225, 0.7386,
        0.6205, 0.6845, 0.5290, 0.6359, 0.5293, 0.6824, 0.6008, 0.6889, 1.2290,
        0.6266, 0.6402, 0.6008, 0.6723, 0.5371, 0.5259, 0.6105, 1.2126, 0.5914,
        0.5990, 0.7184, 0.7963, 0.8432, 0.6254, 1.3863, 0.5598, 1.1254, 0.6889,
        0.6666, 0.7582, 0.8049, 2.1960, 1.6095, 0.5294, 0.5459, 0.7356, 0.8432,
        0.6911, 1.8489, 2.8661, 0.5472, 0.6803, 0.7211, 0.6981, 1.2461, 1.0134,
        0.5930, 0.6742, 0.6402, 0.5739, 0.6934, 0.5840, 0.6957, 0.5833, 1.1001,
        0.5446, 0.5240, 0.5964, 0.5359, 0.5292, 0.5883, 0.6447, 0.8281, 0.6934,
        2.1960, 0.9524, 0.6494, 0.5840, 0.5391, 0.5339, 0.6594, 0.5512, 0.9771,
        0.5328, 3.3230, 0.7356, 0.5341, 0.5379, 0.6629, 3.3230, 1.6095, 0.5847],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  68  24  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  28  79 162 223 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1674, 0.5693, 1.0237, 1.0440, 0.7485, 0.7621, 0.5730, 0.6245, 0.5698,
        1.0547, 0.7656, 0.5420, 0.9530, 1.3220, 0.7188, 2.5301, 0.6308, 0.5244,
        1.2645, 1.8987, 1.0887, 0.7008, 0.8189, 1.0045, 1.1974, 0.9302, 1.6103,
        0.9024, 0.6938, 2.7444, 1.4106, 3.5154, 1.0547, 2.4364, 1.1821, 4.9892,
        3.7314, 2.0654, 0.6039, 0.6871, 0.6580, 0.6130, 0.7730, 0.9230, 0.7390,
        0.6209, 0.6849, 0.5293, 0.6363, 0.5296, 0.6828, 0.6011, 0.6893, 1.2297,
        0.6270, 0.6406, 0.6011, 0.6726, 0.5373, 0.5262, 0.6109, 1.2133, 0.5918,
        0.5993, 0.7188, 0.7968, 0.8437, 0.6257, 1.3870, 0.5601, 1.1260, 0.6893,
        0.6669, 0.7586, 0.8054, 2.1972, 1.6103, 0.5297, 0.5462, 0.7360, 0.8437,
        0.6915, 1.8499, 2.8677, 0.5475, 0.6807, 0.7215, 0.6984, 1.2468, 1.0139,
        0.5934, 0.6746, 0.6406, 0.5742, 0.6938, 0.5843, 0.6961, 0.5836, 1.1007,
        0.5449, 0.5243, 0.5967, 0.5361, 0.5295, 0.5887, 0.6450, 0.8285, 0.6938,
        2.1289, 0.9530, 0.6497, 0.5843, 0.5394, 0.5341, 0.6597, 0.5515, 0.9776,
        0.5331, 3.3248, 0.7360, 0.5344, 0.5381, 0.6633, 3.3248, 1.6103, 0.5850],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  69  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 224  64 316 550 207 363 426 217 165  99 139
  28  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1683, 0.5697, 1.0244, 1.0448, 0.7491, 0.7627, 0.5735, 0.6250, 0.5702,
        1.0555, 0.7662, 0.5425, 0.9537, 1.3230, 0.7193, 2.5321, 0.6313, 0.5248,
        1.2654, 1.9002, 1.0895, 0.7014, 0.8196, 1.0052, 1.1983, 0.9309, 1.6116,
        0.9031, 0.6943, 2.7465, 1.4117, 3.5181, 1.0448, 2.3521, 1.1830, 4.9930,
        3.7343, 2.0669, 0.6044, 0.6876, 0.6585, 0.6135, 0.7736, 0.9237, 0.7396,
        0.6213, 0.6854, 0.5297, 0.6368, 0.5300, 0.6833, 0.6016, 0.6898, 1.2306,
        0.6274, 0.6410, 0.6016, 0.6732, 0.5378, 0.5266, 0.6113, 1.2142, 0.5922,
        0.5998, 0.7193, 0.7974, 0.8443, 0.6262, 1.3881, 0.5605, 1.1269, 0.6898,
        0.6674, 0.7592, 0.8060, 2.1989, 1.6116, 0.5301, 0.5466, 0.7365, 0.8443,
        0.6920, 1.8514, 2.8699, 0.5479, 0.6812, 0.7220, 0.6990, 1.2477, 1.0147,
        0.5938, 0.6751, 0.6410, 0.5746, 0.6943, 0.5848, 0.6966, 0.5841, 1.1016,
        0.5454, 0.5247, 0.5972, 0.5365, 0.5299, 0.5891, 0.6455, 0.8291, 0.6943,
        2.1305, 0.9537, 0.6502, 0.5855, 0.5398, 0.5346, 0.6602, 0.5519, 0.9784,
        0.5335, 3.3273, 0.7365, 0.5348, 0.5386, 0.6638, 3.3273, 1.6116, 0.5855],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  69  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 225  64 316 550 207 363 426 217 165  99 139
  28  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1683, 0.5697, 1.0245, 1.0448, 0.7491, 0.7627, 0.5735, 0.6250, 0.5702,
        1.0555, 0.7662, 0.5425, 0.9537, 1.3230, 0.7193, 2.5321, 0.6313, 0.5248,
        1.2654, 1.9002, 1.0895, 0.7014, 0.8196, 1.0052, 1.1983, 0.9309, 1.6116,
        0.9031, 0.6943, 2.7465, 1.4117, 3.5181, 1.0448, 2.3521, 1.1830, 4.9931,
        3.7343, 2.0670, 0.6044, 0.6876, 0.6585, 0.6135, 0.7736, 0.9237, 0.7396,
        0.6213, 0.6854, 0.5297, 0.6368, 0.5300, 0.6833, 0.6016, 0.6898, 1.2306,
        0.6275, 0.6411, 0.6016, 0.6732, 0.5378, 0.5266, 0.6113, 1.2142, 0.5922,
        0.5998, 0.7193, 0.7974, 0.8443, 0.6262, 1.3881, 0.5605, 1.1269, 0.6898,
        0.6674, 0.7592, 0.8060, 2.1989, 1.6116, 0.5301, 0.5466, 0.7365, 0.8443,
        0.6920, 1.8514, 2.8699, 0.5479, 0.6812, 0.7221, 0.6990, 1.2477, 1.0147,
        0.5938, 0.6751, 0.6411, 0.5746, 0.6943, 0.5848, 0.6966, 0.5834, 1.1016,
        0.5454, 0.5247, 0.5972, 0.5366, 0.5299, 0.5891, 0.6455, 0.8291, 0.6943,
        2.1306, 0.9537, 0.6502, 0.5855, 0.5398, 0.5346, 0.6602, 0.5519, 0.9784,
        0.5335, 3.3274, 0.7365, 0.5348, 0.5386, 0.6638, 3.3274, 1.6116, 0.5855],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  69  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 225  64 316 550 207 363 426 217 165  99 139
  28  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1683, 0.5697, 1.0245, 1.0448, 0.7491, 0.7627, 0.5735, 0.6250, 0.5702,
        1.0555, 0.7662, 0.5425, 0.9537, 1.3230, 0.7193, 2.5321, 0.6313, 0.5248,
        1.2654, 1.9002, 1.0895, 0.7014, 0.8196, 1.0052, 1.1983, 0.9309, 1.6116,
        0.9031, 0.6943, 2.7465, 1.4117, 3.5181, 1.0448, 2.3521, 1.1830, 4.9931,
        3.7343, 2.0670, 0.6044, 0.6876, 0.6585, 0.6135, 0.7736, 0.9237, 0.7396,
        0.6213, 0.6854, 0.5297, 0.6368, 0.5300, 0.6833, 0.6016, 0.6898, 1.2306,
        0.6275, 0.6411, 0.6016, 0.6732, 0.5378, 0.5266, 0.6113, 1.2142, 0.5922,
        0.5998, 0.7193, 0.7974, 0.8443, 0.6262, 1.3881, 0.5605, 1.1269, 0.6898,
        0.6674, 0.7592, 0.8060, 2.1989, 1.6116, 0.5301, 0.5466, 0.7365, 0.8443,
        0.6920, 1.8514, 2.8699, 0.5479, 0.6812, 0.7221, 0.6990, 1.2477, 1.0147,
        0.5938, 0.6751, 0.6411, 0.5746, 0.6943, 0.5848, 0.6966, 0.5834, 1.1016,
        0.5454, 0.5247, 0.5972, 0.5366, 0.5299, 0.5891, 0.6455, 0.8291, 0.6943,
        2.1306, 0.9537, 0.6502, 0.5855, 0.5398, 0.5346, 0.6602, 0.5519, 0.9784,
        0.5335, 3.3274, 0.7365, 0.5348, 0.5386, 0.6638, 3.3274, 1.6116, 0.5855],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  53  32  65 136 101  73  57  82  39  86 139  21  46  16  69  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 225  64 316 550 207 363 426 217 165  99 139
  28  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1683, 0.5697, 1.0245, 1.0448, 0.7491, 0.7627, 0.5735, 0.6250, 0.5702,
        1.0555, 0.7662, 0.5425, 0.9537, 1.3230, 0.7193, 2.5321, 0.6313, 0.5248,
        1.2654, 1.9002, 1.0895, 0.7014, 0.8196, 1.0052, 1.1983, 0.9309, 1.6116,
        0.9031, 0.6943, 2.7465, 1.4117, 3.5181, 1.0448, 2.3521, 1.1830, 4.9931,
        3.7343, 2.0670, 0.6044, 0.6876, 0.6585, 0.6135, 0.7736, 0.9237, 0.7396,
        0.6213, 0.6854, 0.5297, 0.6368, 0.5300, 0.6833, 0.6016, 0.6898, 1.2306,
        0.6275, 0.6411, 0.6016, 0.6732, 0.5378, 0.5266, 0.6113, 1.2142, 0.5922,
        0.5998, 0.7193, 0.7974, 0.8443, 0.6262, 1.3881, 0.5605, 1.1269, 0.6898,
        0.6674, 0.7592, 0.8060, 2.1989, 1.6116, 0.5301, 0.5466, 0.7365, 0.8443,
        0.6920, 1.8514, 2.8699, 0.5479, 0.6812, 0.7221, 0.6990, 1.2477, 1.0147,
        0.5938, 0.6751, 0.6411, 0.5746, 0.6943, 0.5848, 0.6966, 0.5834, 1.1016,
        0.5454, 0.5247, 0.5972, 0.5366, 0.5299, 0.5891, 0.6455, 0.8291, 0.6943,
        2.1306, 0.9537, 0.6502, 0.5855, 0.5398, 0.5346, 0.6602, 0.5519, 0.9784,
        0.5335, 3.3274, 0.7365, 0.5348, 0.5386, 0.6638, 3.3274, 1.6116, 0.5855],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  52  32  65 136 101  73  57  82  39  86 139  21  46  16  70  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 211 148 168 239 139 223 138 225  64 316 550 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1688, 0.5700, 1.0249, 1.0453, 0.7495, 0.7630, 0.5737, 0.6252, 0.5705,
        1.0559, 0.7666, 0.5427, 0.9541, 1.3236, 0.7196, 2.5332, 0.6316, 0.5251,
        1.2844, 1.9010, 1.0900, 0.7017, 0.8199, 1.0057, 1.1989, 0.9313, 1.6123,
        0.9035, 0.6946, 2.7477, 1.4123, 3.5196, 1.0349, 2.3531, 1.1835, 4.9953,
        3.7359, 2.0679, 0.6046, 0.6879, 0.6588, 0.6137, 0.7739, 0.9241, 0.7399,
        0.6216, 0.6857, 0.5299, 0.6370, 0.5302, 0.6836, 0.6018, 0.6901, 1.2312,
        0.6277, 0.6413, 0.6018, 0.6735, 0.5380, 0.5268, 0.6116, 1.2147, 0.5925,
        0.6000, 0.7196, 0.7977, 0.8447, 0.6265, 1.3887, 0.5607, 1.1274, 0.6901,
        0.6677, 0.7595, 0.8063, 2.1999, 1.6123, 0.5303, 0.5468, 0.7369, 0.8447,
        0.6923, 1.8522, 2.8711, 0.5481, 0.6815, 0.7224, 0.6993, 1.2483, 1.0152,
        0.5941, 0.6754, 0.6413, 0.5749, 0.6946, 0.5850, 0.6969, 0.5836, 1.1020,
        0.5456, 0.5249, 0.5974, 0.5368, 0.5301, 0.5894, 0.6458, 0.8295, 0.6946,
        2.0679, 0.9541, 0.6505, 0.5857, 0.5400, 0.5348, 0.6605, 0.5522, 0.9788,
        0.5337, 3.3288, 0.7369, 0.5350, 0.5388, 0.6641, 3.3288, 1.6123, 0.5857],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  86 139  21  46  16  70  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  20 306 145 128 137  54  72
 212 148 168 239 138 223 139 225  64 316 550 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1687, 0.5699, 1.0249, 1.0453, 0.7494, 0.7630, 0.5737, 0.6252, 0.5705,
        1.0559, 0.7666, 0.5427, 0.9541, 1.3236, 0.7196, 2.5331, 0.6316, 0.5250,
        1.2844, 1.9009, 1.0899, 0.7017, 0.8246, 1.0057, 1.1988, 0.9313, 1.6122,
        0.9035, 0.6946, 2.7476, 1.4123, 3.5195, 1.0349, 2.3530, 1.1835, 4.9951,
        3.7358, 2.0678, 0.6046, 0.6879, 0.6588, 0.6137, 0.7739, 0.9240, 0.7399,
        0.6216, 0.6857, 0.5299, 0.6370, 0.5302, 0.6836, 0.6018, 0.6901, 1.2311,
        0.6277, 0.6413, 0.6018, 0.6734, 0.5380, 0.5268, 0.6116, 1.2147, 0.5925,
        0.6000, 0.7196, 0.7977, 0.8446, 0.6265, 1.3887, 0.5607, 1.1274, 0.6901,
        0.6677, 0.7595, 0.8063, 2.1998, 1.6122, 0.5303, 0.5468, 0.7368, 0.8446,
        0.6923, 1.8521, 2.8710, 0.5481, 0.6815, 0.7223, 0.6993, 1.2482, 1.0151,
        0.5932, 0.6754, 0.6413, 0.5748, 0.6969, 0.5850, 0.6946, 0.5836, 1.1020,
        0.5456, 0.5249, 0.5974, 0.5368, 0.5301, 0.5894, 0.6458, 0.8295, 0.6946,
        2.0678, 0.9541, 0.6505, 0.5857, 0.5400, 0.5348, 0.6605, 0.5521, 0.9788,
        0.5337, 3.3287, 0.7368, 0.5350, 0.5388, 0.6641, 3.3287, 1.6122, 0.5857],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 180 247  68 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  86 139  21  46  16  70  25  58  11
  15  29 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  21 306 145 128 137  54  72
 212 148 168 239 138 223 139 225  64 316 550 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1699, 0.5705, 1.0259, 1.0463, 0.7502, 0.7637, 0.5743, 0.6258, 0.5710,
        1.0569, 0.7673, 0.5432, 0.9550, 1.3249, 0.7203, 2.5356, 0.6322, 0.5256,
        1.2857, 1.9028, 1.0910, 0.7023, 0.8255, 1.0066, 1.2000, 0.9322, 1.6138,
        0.9043, 0.6953, 2.7503, 1.4137, 3.5230, 1.0359, 2.3554, 1.1847, 5.0000,
        3.7395, 2.0698, 0.6052, 0.6886, 0.6594, 0.6143, 0.7746, 0.9250, 0.7406,
        0.6222, 0.6864, 0.5304, 0.6377, 0.5307, 0.6843, 0.6024, 0.6908, 1.2323,
        0.6283, 0.6419, 0.6024, 0.6741, 0.5385, 0.5273, 0.6122, 1.2159, 0.5930,
        0.6006, 0.7203, 0.7985, 0.8455, 0.6271, 1.3900, 0.5613, 1.1285, 0.6908,
        0.6684, 0.7602, 0.8071, 2.2020, 1.6138, 0.5308, 0.5473, 0.7376, 0.8455,
        0.6930, 1.8539, 2.7503, 0.5486, 0.6822, 0.7231, 0.6999, 1.2494, 1.0161,
        0.5938, 0.6761, 0.6419, 0.5754, 0.6976, 0.5856, 0.6953, 0.5842, 1.1031,
        0.5461, 0.5254, 0.5980, 0.5373, 0.5306, 0.5899, 0.6464, 0.8303, 0.6953,
        2.0698, 0.9550, 0.6511, 0.5863, 0.5405, 0.5353, 0.6612, 0.5527, 0.9798,
        0.5342, 3.3320, 0.7376, 0.5355, 0.5393, 0.6647, 3.3320, 1.6138, 0.5863],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  31 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  21 306 145 128 137  54  72
 212 148 168 239 138 223 139 225  64 316 550 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1752, 0.5731, 1.0305, 1.0510, 0.7536, 0.7672, 0.5769, 0.6299, 0.5736,
        1.0728, 0.7708, 0.5457, 0.9594, 1.3309, 0.7236, 2.5471, 0.6351, 0.5279,
        1.2915, 1.9115, 1.0960, 0.7055, 0.8292, 1.0112, 1.2054, 0.9364, 1.6211,
        0.9152, 0.6984, 2.7628, 1.4201, 3.5390, 1.0406, 2.2860, 1.1901, 4.6269,
        3.7565, 1.9637, 0.6080, 0.6917, 0.6624, 0.6171, 0.7782, 0.9292, 0.7440,
        0.6250, 0.6895, 0.5328, 0.6405, 0.5331, 0.6874, 0.6052, 0.6939, 1.2379,
        0.6312, 0.6449, 0.6052, 0.6772, 0.5409, 0.5297, 0.6150, 1.2214, 0.5957,
        0.6033, 0.7236, 0.8021, 0.8493, 0.6299, 1.3963, 0.5638, 1.1336, 0.6939,
        0.6714, 0.7637, 0.8108, 2.2120, 1.6211, 0.5332, 0.5498, 0.7409, 0.8493,
        0.6961, 1.8624, 2.7628, 0.5511, 0.6853, 0.7263, 0.7031, 1.2551, 1.0207,
        0.5965, 0.6791, 0.6449, 0.5780, 0.7008, 0.5882, 0.6984, 0.5868, 1.1081,
        0.5486, 0.5278, 0.6007, 0.5397, 0.5331, 0.5926, 0.6494, 0.8341, 0.6984,
        2.0792, 0.9594, 0.6541, 0.5889, 0.5430, 0.5377, 0.6642, 0.5552, 0.9842,
        0.5367, 3.3471, 0.7409, 0.5380, 0.5418, 0.6677, 3.3471, 1.6211, 0.5889],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  31 199 142 157 190 112  83 122 183 143 429 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  22 306 145 128 137  54  72
 212 148 168 239 138 223 139 225  64 316 549 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1763, 0.5736, 1.0315, 1.0520, 0.7542, 0.7679, 0.5774, 0.6305, 0.5741,
        1.0738, 0.7715, 0.5462, 0.9602, 1.3321, 0.7242, 2.5494, 0.6356, 0.5284,
        1.2927, 1.9132, 1.0969, 0.7062, 0.8299, 1.0121, 1.2065, 0.9373, 1.6226,
        0.9160, 0.6991, 2.7653, 1.4214, 3.5421, 1.0416, 2.2881, 1.1911, 4.6311,
        3.7598, 1.9655, 0.6085, 0.6923, 0.6630, 0.6177, 0.7789, 0.9300, 0.7447,
        0.6256, 0.6901, 0.5333, 0.6411, 0.5336, 0.6880, 0.6057, 0.6945, 1.2391,
        0.6317, 0.6454, 0.6057, 0.6778, 0.5414, 0.5302, 0.6155, 1.2225, 0.5963,
        0.6039, 0.7242, 0.8028, 0.8501, 0.6305, 1.3976, 0.5643, 1.1346, 0.6945,
        0.6720, 0.7644, 0.8115, 2.2139, 1.6226, 0.5337, 0.5503, 0.7416, 0.8501,
        0.6968, 1.8640, 2.6524, 0.5516, 0.6859, 0.7270, 0.7038, 1.2562, 1.0216,
        0.5971, 0.6797, 0.6454, 0.5785, 0.7014, 0.5888, 0.6991, 0.5874, 1.1091,
        0.5491, 0.5283, 0.6012, 0.5402, 0.5335, 0.5931, 0.6499, 0.8348, 0.6991,
        2.0811, 0.9602, 0.6547, 0.5895, 0.5435, 0.5382, 0.6648, 0.5557, 0.9851,
        0.5371, 3.3501, 0.7416, 0.5385, 0.5422, 0.6683, 3.3501, 1.6226, 0.5895],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  34 199 142 157 190 112  83 122 183 143 428 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  22 306 145 128 137  54  72
 212 148 168 239 138 223 139 225  64 314 549 207 363 426 217 165  99 139
  29  79 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1776, 0.5743, 1.0327, 1.0532, 0.7551, 0.7688, 0.5781, 0.6312, 0.5748,
        1.0750, 0.7724, 0.5468, 0.9613, 1.3336, 0.7251, 2.5524, 0.6364, 0.5290,
        1.2942, 1.9154, 1.0982, 0.7070, 0.8309, 1.0133, 1.2079, 0.9383, 1.6245,
        0.9171, 0.6999, 2.7685, 1.4230, 3.5463, 1.0428, 2.2907, 1.1925, 4.6365,
        3.7642, 1.8199, 0.6092, 0.6931, 0.6638, 0.6184, 0.7798, 0.9311, 0.7455,
        0.6263, 0.6909, 0.5340, 0.6419, 0.5342, 0.6888, 0.6064, 0.6953, 1.2405,
        0.6325, 0.6462, 0.6064, 0.6786, 0.5421, 0.5308, 0.6163, 1.2239, 0.5970,
        0.6046, 0.7251, 0.8038, 0.8511, 0.6312, 1.3992, 0.5650, 1.1359, 0.6953,
        0.6728, 0.7653, 0.8124, 2.2165, 1.6245, 0.5343, 0.5510, 0.7424, 0.8511,
        0.6976, 1.8662, 2.6555, 0.5523, 0.6867, 0.7278, 0.7046, 1.2577, 1.0228,
        0.5978, 0.6805, 0.6462, 0.5792, 0.7022, 0.5894, 0.6999, 0.5881, 1.1104,
        0.5502, 0.5289, 0.6019, 0.5409, 0.5342, 0.5938, 0.6507, 0.8358, 0.6999,
        2.0835, 0.9613, 0.6554, 0.5902, 0.5441, 0.5388, 0.6655, 0.5563, 0.9862,
        0.5378, 3.3540, 0.7424, 0.5391, 0.5429, 0.6691, 3.3540, 1.6245, 0.5902],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  35 199 142 157 190 112  83 122 183 143 428 171 425 144 202 141  55
 178 168 202 149 355 486 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  22 306 144 128 137  54  72
 212 148 168 239 138 223 139 225  64 314 549 207 363 426 217 165  99 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1781, 0.5745, 1.0331, 1.0536, 0.7554, 0.7691, 0.5783, 0.6315, 0.5750,
        1.0754, 0.7727, 0.5470, 0.9617, 1.3341, 0.7254, 2.5534, 0.6366, 0.5292,
        1.2947, 1.9162, 1.0987, 0.7073, 0.8312, 1.0137, 1.2084, 0.9387, 1.6251,
        0.9174, 0.7002, 2.7696, 1.4236, 3.5477, 1.0432, 2.2916, 1.1930, 4.6383,
        3.7657, 1.7770, 0.6095, 0.6934, 0.6640, 0.6186, 0.7801, 0.9314, 0.7458,
        0.6266, 0.6912, 0.5342, 0.6421, 0.5344, 0.6891, 0.6066, 0.6956, 1.2410,
        0.6327, 0.6464, 0.6066, 0.6788, 0.5423, 0.5310, 0.6165, 1.2244, 0.5972,
        0.6048, 0.7254, 0.8041, 0.8514, 0.6315, 1.3998, 0.5652, 1.1364, 0.6956,
        0.6731, 0.7656, 0.8127, 2.2174, 1.6251, 0.5345, 0.5512, 0.7427, 0.8514,
        0.6979, 1.8669, 2.6566, 0.5525, 0.6891, 0.7281, 0.7049, 1.2582, 1.0232,
        0.5980, 0.6808, 0.6464, 0.5794, 0.7025, 0.5897, 0.7002, 0.5883, 1.1108,
        0.5504, 0.5291, 0.6022, 0.5411, 0.5344, 0.5941, 0.6510, 0.8361, 0.7002,
        2.0843, 0.9538, 0.6557, 0.5904, 0.5443, 0.5390, 0.6658, 0.5566, 0.9866,
        0.5380, 3.3553, 0.7427, 0.5393, 0.5431, 0.6694, 3.3553, 1.6251, 0.5904],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  36 199 142 157 190 112  83 122 183 143 428 171 425 144 202 141  55
 178 168 202 149 355 485 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  23 306 144 128 137  55  72
 212 147 168 239 138 223 139 225  64 314 549 207 363 426 217 165  99 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1796, 0.5752, 1.0344, 1.0550, 0.7564, 0.7701, 0.5790, 0.6323, 0.5757,
        1.0768, 0.7737, 0.5477, 0.9629, 1.3358, 0.7263, 2.5566, 0.6374, 0.5299,
        1.2963, 1.9186, 1.1000, 0.7082, 0.8323, 1.0150, 1.2099, 0.9399, 1.6272,
        0.9186, 0.7010, 2.7731, 1.4254, 3.5522, 1.0445, 2.2945, 1.1945, 4.6442,
        3.7705, 1.7380, 0.6102, 0.6943, 0.6649, 0.6194, 0.7811, 0.9326, 0.7468,
        0.6274, 0.6921, 0.5349, 0.6429, 0.5351, 0.6899, 0.6074, 0.6965, 1.2426,
        0.6335, 0.6473, 0.6074, 0.6797, 0.5430, 0.5317, 0.6173, 1.2259, 0.5979,
        0.6056, 0.7263, 0.8051, 0.8525, 0.6323, 1.4015, 0.5659, 1.1378, 0.6965,
        0.6739, 0.7666, 0.8138, 2.2202, 1.6272, 0.5352, 0.5519, 0.7437, 0.8525,
        0.6987, 1.8693, 2.5566, 0.5532, 0.6899, 0.7290, 0.7058, 1.2426, 1.0245,
        0.5988, 0.6837, 0.6473, 0.5802, 0.7034, 0.5904, 0.7010, 0.5890, 1.1122,
        0.5511, 0.5298, 0.6029, 0.5418, 0.5350, 0.5948, 0.6518, 0.8372, 0.7010,
        2.0870, 0.9551, 0.6565, 0.5911, 0.5450, 0.5397, 0.6666, 0.5573, 0.9879,
        0.5387, 3.3596, 0.7437, 0.5400, 0.5438, 0.6702, 3.3596, 1.6272, 0.5911],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  67 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  37 199 142 157 190 112  83 122 183 143 428 171 425 144 202 141  55
 178 168 202 149 355 485 192  56 213 204 129 106  96 179  47 268  62 141
 152 116 104  27  39 424 311 123  96 140  33  23 306 144 128 137  56  72
 212 147 168 239 138 223 139 225  64 314 549 207 363 426 217 165  99 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1801, 0.5755, 1.0348, 1.0554, 0.7567, 0.7704, 0.5793, 0.6325, 0.5760,
        1.0773, 0.7740, 0.5480, 0.9634, 1.3364, 0.7266, 2.5577, 0.6377, 0.5301,
        1.2969, 1.9194, 1.1005, 0.7085, 0.8327, 1.0154, 1.2105, 0.9403, 1.6279,
        0.9190, 0.7014, 2.7743, 1.4260, 3.5537, 1.0450, 2.2956, 1.1950, 4.6462,
        3.7721, 1.6998, 0.6105, 0.6946, 0.6652, 0.6197, 0.7814, 0.9330, 0.7471,
        0.6276, 0.6924, 0.5351, 0.6432, 0.5354, 0.6902, 0.6077, 0.6968, 1.2431,
        0.6338, 0.6476, 0.6077, 0.6800, 0.5432, 0.5319, 0.6175, 1.2265, 0.5982,
        0.6059, 0.7266, 0.8054, 0.8529, 0.6325, 1.4022, 0.5662, 1.1383, 0.6968,
        0.6742, 0.7669, 0.8141, 2.2212, 1.6279, 0.5354, 0.5521, 0.7440, 0.8529,
        0.6991, 1.8701, 2.5577, 0.5534, 0.6902, 0.7294, 0.7061, 1.2265, 1.0250,
        0.5990, 0.6840, 0.6476, 0.5804, 0.7037, 0.5907, 0.7014, 0.5893, 1.1127,
        0.5514, 0.5300, 0.6032, 0.5420, 0.5353, 0.5951, 0.6521, 0.8375, 0.7014,
        2.0879, 0.9555, 0.6568, 0.5914, 0.5452, 0.5400, 0.6669, 0.5575, 0.9883,
        0.5389, 3.3611, 0.7440, 0.5402, 0.5440, 0.6705, 3.3611, 1.6279, 0.5914],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  66 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  12
  15  40 199 142 157 189 112  83 122 183 143 428 171 425 144 202 141  55
 178 168 202 149 355 485 192  56 213 204 129 106  96 179  47 268  62 141
 152 115 104  27  39 424 311 123  96 140  33  23 306 144 128 137  56  72
 212 147 168 239 138 223 139 225  64 314 549 207 363 426 217 165  99 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1809, 0.5759, 1.0356, 1.0562, 0.7572, 0.7710, 0.5797, 0.6330, 0.5764,
        1.0895, 0.7746, 0.5483, 0.9640, 1.3374, 0.7271, 2.5595, 0.6382, 0.5305,
        1.2978, 1.9208, 1.1013, 0.7090, 0.8332, 1.0161, 1.2113, 0.9410, 1.6290,
        0.9196, 0.7018, 2.7763, 1.4270, 3.5563, 1.0457, 2.2972, 1.1959, 4.6495,
        3.7748, 1.5958, 0.6109, 0.6951, 0.6656, 0.6212, 0.7820, 0.9337, 0.7476,
        0.6281, 0.6929, 0.5355, 0.6437, 0.5357, 0.6907, 0.6081, 0.6973, 1.2440,
        0.6343, 0.6480, 0.6081, 0.6805, 0.5436, 0.5323, 0.6180, 1.2274, 0.5986,
        0.6063, 0.7271, 0.8060, 0.8535, 0.6330, 1.4032, 0.5666, 1.1391, 0.6973,
        0.6747, 0.7710, 0.8147, 2.2228, 1.6290, 0.5358, 0.5525, 0.7445, 0.8535,
        0.6995, 1.8715, 2.5595, 0.5538, 0.6907, 0.7299, 0.7066, 1.2274, 1.0257,
        0.5994, 0.6845, 0.6480, 0.5808, 0.7042, 0.5911, 0.7018, 0.5897, 1.1135,
        0.5518, 0.5304, 0.6036, 0.5424, 0.5357, 0.5955, 0.6525, 0.8381, 0.7018,
        2.0894, 0.9562, 0.6573, 0.5918, 0.5456, 0.5404, 0.6674, 0.5579, 0.9890,
        0.5393, 3.3635, 0.7445, 0.5406, 0.5444, 0.6710, 3.3635, 1.6290, 0.5918],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  66 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  13
  15  43 199 142 157 189 112  83 122 183 143 428 170 425 144 202 141  55
 178 168 202 149 355 484 192  56 213 204 129 106  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  56  72
 212 147 168 239 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1850, 0.5778, 1.0391, 1.0598, 0.7598, 0.7736, 0.5817, 0.6351, 0.5784,
        1.0932, 0.7772, 0.5502, 0.9673, 1.3419, 0.7296, 2.5682, 0.6403, 0.5323,
        1.3022, 1.9273, 1.1051, 0.7114, 0.8361, 1.0196, 1.2154, 0.9442, 1.6346,
        0.9228, 0.7042, 2.7857, 1.4319, 3.5683, 1.0493, 2.3050, 1.1999, 4.3277,
        3.7876, 1.5106, 0.6130, 0.6974, 0.6679, 0.6233, 0.7846, 0.9369, 0.7502,
        0.6302, 0.6952, 0.5373, 0.6473, 0.5376, 0.6931, 0.6102, 0.6997, 1.2482,
        0.6364, 0.6502, 0.6102, 0.6828, 0.5454, 0.5342, 0.6201, 1.2315, 0.6007,
        0.6083, 0.7296, 0.8088, 0.8564, 0.6351, 1.4079, 0.5685, 1.1430, 0.6997,
        0.6770, 0.7736, 0.8175, 2.2303, 1.6346, 0.5376, 0.5544, 0.7502, 0.8564,
        0.7019, 1.8778, 2.5682, 0.5557, 0.6931, 0.7324, 0.7090, 1.2315, 1.0292,
        0.6015, 0.6868, 0.6502, 0.5828, 0.7066, 0.5931, 0.7042, 0.5917, 1.1173,
        0.5539, 0.5322, 0.6057, 0.5442, 0.5375, 0.5975, 0.6548, 0.8361, 0.7042,
        2.0965, 0.9594, 0.6595, 0.5938, 0.5475, 0.5422, 0.6697, 0.5598, 0.9924,
        0.5411, 3.3749, 0.7471, 0.5424, 0.5463, 0.6733, 3.3749, 1.6346, 0.5938],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  69 119 115 241 179 247  66 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  13
  15  46 199 142 157 189 113  83 122 183 143 428 170 425 144 202 141  55
 178 168 202 149 355 484 192  56 213 204 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  56  72
 212 147 168 239 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  29  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1857, 0.5782, 1.0397, 1.0604, 0.7603, 0.7741, 0.5820, 0.6355, 0.5787,
        1.0939, 0.7777, 0.5506, 0.9679, 1.3428, 0.7300, 2.5698, 0.6407, 0.5326,
        1.3030, 1.9285, 1.1057, 0.7118, 0.8366, 1.0202, 1.2162, 0.9448, 1.6356,
        0.9233, 0.7047, 2.7875, 1.4328, 3.5706, 1.0499, 2.3064, 1.2007, 4.3304,
        3.7900, 1.4328, 0.6134, 0.6979, 0.6683, 0.6237, 0.7813, 0.9374, 0.7506,
        0.6306, 0.6957, 0.5377, 0.6477, 0.5379, 0.6935, 0.6106, 0.7001, 1.2490,
        0.6368, 0.6506, 0.6106, 0.6832, 0.5458, 0.5345, 0.6205, 1.2323, 0.6010,
        0.6087, 0.7300, 0.8136, 0.8569, 0.6355, 1.4088, 0.5689, 1.1437, 0.7001,
        0.6774, 0.7741, 0.8180, 2.2317, 1.6356, 0.5380, 0.5547, 0.7506, 0.8569,
        0.7024, 1.8790, 2.5698, 0.5561, 0.6935, 0.7328, 0.7094, 1.2323, 1.0298,
        0.6019, 0.6872, 0.6506, 0.5832, 0.7070, 0.5935, 0.7047, 0.5921, 1.1180,
        0.5542, 0.5325, 0.6061, 0.5446, 0.5378, 0.5979, 0.6552, 0.8366, 0.7047,
        2.0978, 0.9600, 0.6599, 0.5942, 0.5478, 0.5425, 0.6701, 0.5601, 0.9930,
        0.5415, 3.3770, 0.7475, 0.5428, 0.5466, 0.6737, 3.3770, 1.6356, 0.5942],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 118 115 241 179 247  66 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  14
  15  47 199 142 157 189 113  83 122 183 143 428 170 425 144 202 141  55
 178 168 202 149 355 484 192  56 213 204 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  56  72
 212 147 168 238 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  30  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1891, 0.5798, 1.0427, 1.0743, 0.7658, 0.7763, 0.5837, 0.6374, 0.5804,
        1.0970, 0.7799, 0.5521, 0.9707, 1.3466, 0.7321, 2.5772, 0.6426, 0.5342,
        1.3068, 1.9340, 1.1089, 0.7139, 0.8390, 1.0232, 1.2197, 0.9475, 1.6403,
        0.9260, 0.7067, 2.7954, 1.4369, 3.5808, 1.0529, 2.3130, 1.2041, 4.0524,
        3.8008, 1.4128, 0.6151, 0.6999, 0.6702, 0.6255, 0.7836, 0.9401, 0.7528,
        0.6324, 0.6976, 0.5392, 0.6495, 0.5394, 0.6955, 0.6123, 0.7021, 1.2526,
        0.6386, 0.6525, 0.6123, 0.6852, 0.5473, 0.5360, 0.6222, 1.2358, 0.6028,
        0.6105, 0.7321, 0.8159, 0.8593, 0.6374, 1.4128, 0.5705, 1.1470, 0.7021,
        0.6793, 0.7763, 0.8203, 2.2381, 1.6403, 0.5395, 0.5563, 0.7528, 0.8593,
        0.7044, 1.8843, 2.5772, 0.5576, 0.6955, 0.7349, 0.7114, 1.2358, 1.0328,
        0.6036, 0.6892, 0.6525, 0.5854, 0.7090, 0.5952, 0.7067, 0.5938, 1.1212,
        0.5558, 0.5340, 0.6078, 0.5461, 0.5393, 0.5996, 0.6570, 0.8390, 0.7067,
        2.0434, 0.9627, 0.6618, 0.5959, 0.5494, 0.5441, 0.6720, 0.5617, 0.9958,
        0.5430, 3.3866, 0.7497, 0.5443, 0.5482, 0.6756, 3.3866, 1.6403, 0.5959],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 329  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  14
  15  48 199 142 157 189 113  83 122 183 143 428 170 425 144 202 141  55
 178 168 202 149 355 484 192  56 213 204 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  56  72
 212 147 168 238 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  31  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1897, 0.5801, 1.0432, 1.0748, 0.7696, 0.7767, 0.5840, 0.6377, 0.5807,
        1.1095, 0.7803, 0.5524, 0.9712, 1.3473, 0.7325, 2.5785, 0.6429, 0.5344,
        1.3074, 1.9350, 1.1095, 0.7142, 0.8394, 1.0237, 1.2203, 0.9480, 1.6411,
        0.9265, 0.7070, 2.7969, 1.4376, 3.5826, 1.0535, 2.3142, 1.2047, 4.0545,
        3.8028, 1.3905, 0.6155, 0.7002, 0.6706, 0.6258, 0.7840, 0.9406, 0.7532,
        0.6327, 0.6980, 0.5395, 0.6499, 0.5397, 0.6958, 0.6126, 0.7024, 1.2532,
        0.6390, 0.6528, 0.6126, 0.6855, 0.5476, 0.5363, 0.6226, 1.2364, 0.6031,
        0.6108, 0.7325, 0.8163, 0.8598, 0.6377, 1.4135, 0.5708, 1.1476, 0.7024,
        0.6797, 0.7767, 0.8207, 2.2392, 1.6411, 0.5398, 0.5566, 0.7532, 0.8598,
        0.7047, 1.8853, 2.5785, 0.5579, 0.6958, 0.7353, 0.7118, 1.2364, 1.0333,
        0.6039, 0.6895, 0.6528, 0.5857, 0.7094, 0.5955, 0.7070, 0.5941, 1.1218,
        0.5561, 0.5343, 0.6081, 0.5464, 0.5396, 0.5999, 0.6574, 0.8394, 0.7070,
        1.9879, 0.9632, 0.6621, 0.5962, 0.5497, 0.5444, 0.6723, 0.5620, 0.9963,
        0.5433, 3.3884, 0.7500, 0.5446, 0.5484, 0.6760, 3.3884, 1.6411, 0.5962],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  14
  15  50 199 142 157 189 113  83 122 183 143 428 170 425 144 202 141  55
 178 168 202 149 355 483 192  56 213 204 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  57  72
 212 147 168 238 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  31  80 162 222 343 378 156 292  76 387  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1902, 0.5804, 1.0437, 1.0753, 0.7700, 0.7770, 0.5843, 0.6380, 0.5809,
        1.1100, 0.7807, 0.5529, 0.9716, 1.3479, 0.7328, 2.5797, 0.6432, 0.5347,
        1.3080, 1.9359, 1.1100, 0.7146, 0.8398, 1.0242, 1.2209, 0.9484, 1.6419,
        0.9269, 0.7074, 2.7982, 1.4383, 3.5843, 1.0539, 2.3153, 1.2053, 4.0564,
        3.8045, 1.3479, 0.6157, 0.7005, 0.6709, 0.6261, 0.7843, 0.9410, 0.7535,
        0.6330, 0.6983, 0.5397, 0.6502, 0.5400, 0.6962, 0.6129, 0.7028, 1.2538,
        0.6393, 0.6531, 0.6129, 0.6858, 0.5479, 0.5366, 0.6229, 1.2370, 0.6034,
        0.6111, 0.7328, 0.8167, 0.8602, 0.6380, 1.4142, 0.5710, 1.1481, 0.7028,
        0.6800, 0.7770, 0.8211, 2.2403, 1.6419, 0.5400, 0.5569, 0.7535, 0.8602,
        0.7051, 1.8862, 2.5797, 0.5582, 0.6962, 0.7356, 0.7121, 1.2209, 1.0338,
        0.6042, 0.6899, 0.6531, 0.5860, 0.7097, 0.5958, 0.7074, 0.5944, 1.1223,
        0.5564, 0.5346, 0.6084, 0.5466, 0.5399, 0.6002, 0.6577, 0.8398, 0.7074,
        1.9889, 0.9637, 0.6624, 0.5965, 0.5499, 0.5446, 0.6727, 0.5623, 0.9968,
        0.5435, 3.3899, 0.7504, 0.5449, 0.5487, 0.6763, 3.3899, 1.6419, 0.5965],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  19
  15  50 199 142 157 189 113  83 122 183 143 428 170 425 144 202 140  55
 178 168 202 149 355 483 192  56 212 204 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 144 128 137  57  72
 212 147 168 238 138 223 139 225  64 313 549 207 363 426 217 165 100 139
  31  80 162 222 343 378 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.1997, 0.5850, 1.0520, 1.0839, 0.7761, 0.7832, 0.5889, 0.6430, 0.5855,
        1.1188, 0.7868, 0.5573, 0.9793, 1.3586, 0.7386, 2.6001, 0.6483, 0.5389,
        1.3184, 1.9512, 1.1188, 0.7202, 0.8465, 1.0323, 1.2305, 0.9559, 1.6549,
        0.9342, 0.7130, 2.8203, 1.4497, 3.6127, 1.0623, 2.3336, 1.2148, 3.0871,
        3.8347, 1.3586, 0.6206, 0.7061, 0.6762, 0.6311, 0.7906, 0.9485, 0.7595,
        0.6380, 0.7039, 0.5440, 0.6553, 0.5442, 0.7017, 0.6178, 0.7106, 1.2637,
        0.6443, 0.6583, 0.6178, 0.6913, 0.5522, 0.5408, 0.6278, 1.2468, 0.6089,
        0.6159, 0.7386, 0.8232, 0.8670, 0.6430, 1.4254, 0.5756, 1.1572, 0.7083,
        0.6854, 0.7832, 0.8276, 2.2580, 1.6549, 0.5443, 0.5613, 0.7595, 0.8670,
        0.7106, 1.9011, 2.6001, 0.5626, 0.7017, 0.7415, 0.7178, 1.2305, 1.0420,
        0.6089, 0.6953, 0.6583, 0.5906, 0.7154, 0.6005, 0.7130, 0.5991, 1.1312,
        0.5608, 0.5388, 0.6132, 0.5510, 0.5442, 0.6050, 0.6629, 0.8465, 0.7130,
        2.0046, 0.9713, 0.6677, 0.6012, 0.5543, 0.5489, 0.6780, 0.5668, 1.0047,
        0.5480, 3.4168, 0.7563, 0.5492, 0.5530, 0.6816, 3.4168, 1.6549, 0.6012],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  58  24
  15  51 199 142 157 189 113  83 122 183 143 428 170 425 144 202 140  55
 178 168 202 149 355 483 192  56 212 205 129 105  96 179  47 268  62 141
 152 115 104  27  39 424 311 122  96 140  33  23 306 143 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 549 207 363 426 217 165 100 139
  31  80 162 222 343 378 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2054, 0.5878, 1.0570, 1.0891, 0.7798, 0.7869, 0.5917, 0.6461, 0.5884,
        1.1241, 0.7906, 0.5599, 0.9840, 1.3651, 0.7422, 2.6126, 0.6514, 0.5415,
        1.3247, 1.9606, 1.1241, 0.7237, 0.8505, 1.0372, 1.2364, 0.9605, 1.6628,
        0.9387, 0.7164, 2.8339, 1.4566, 3.6300, 1.0674, 2.3448, 1.2207, 2.5159,
        3.8531, 1.3445, 0.6236, 0.7095, 0.6795, 0.6341, 0.7944, 0.9531, 0.7631,
        0.6411, 0.7072, 0.5466, 0.6585, 0.5468, 0.7050, 0.6207, 0.7141, 1.2698,
        0.6474, 0.6614, 0.6207, 0.6946, 0.5549, 0.5434, 0.6308, 1.2528, 0.6119,
        0.6179, 0.7422, 0.8271, 0.8712, 0.6461, 1.4323, 0.5783, 1.1628, 0.7117,
        0.6887, 0.7869, 0.8316, 2.2689, 1.6628, 0.5469, 0.5640, 0.7631, 0.8712,
        0.7141, 1.9103, 2.6126, 0.5653, 0.7072, 0.7450, 0.7212, 1.2364, 1.0470,
        0.6119, 0.6987, 0.6614, 0.5935, 0.7188, 0.6034, 0.7164, 0.6019, 1.1366,
        0.5637, 0.5414, 0.6162, 0.5536, 0.5468, 0.6079, 0.6661, 0.8505, 0.7164,
        2.0143, 0.9760, 0.6709, 0.6041, 0.5569, 0.5516, 0.6812, 0.5695, 1.0095,
        0.5506, 3.4332, 0.7600, 0.5518, 0.5557, 0.6849, 3.4332, 1.6628, 0.6041],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  85 139  21  46  16  70  26  57  29
  15  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  55
 178 168 202 149 355 483 192  56 212 204 129 105  96 179  47 268  62 141
 152 115 104  28  39 424 311 122  96 140  33  23 306 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 207 363 427 217 165 100 139
  31  80 162 222 343 378 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2096, 0.5899, 1.0607, 1.0928, 0.7825, 0.7897, 0.5938, 0.6483, 0.5904,
        1.1280, 0.7933, 0.5619, 0.9874, 1.3698, 0.7448, 2.6216, 0.6537, 0.5434,
        1.3293, 1.9674, 1.1280, 0.7262, 0.8535, 1.0408, 1.2407, 0.9638, 1.6686,
        0.9420, 0.7189, 2.8437, 1.4617, 3.6425, 1.0711, 2.3529, 1.2407, 2.1401,
        3.8664, 1.3492, 0.6258, 0.7119, 0.6818, 0.6363, 0.7971, 0.9563, 0.7658,
        0.6433, 0.7097, 0.5485, 0.6622, 0.5487, 0.7075, 0.6229, 0.7165, 1.2742,
        0.6496, 0.6637, 0.6229, 0.6970, 0.5568, 0.5453, 0.6330, 1.2571, 0.6140,
        0.6210, 0.7448, 0.8300, 0.8742, 0.6483, 1.4372, 0.5803, 1.1668, 0.7142,
        0.6911, 0.7897, 0.8345, 2.2059, 1.6686, 0.5488, 0.5659, 0.7658, 0.8742,
        0.7165, 1.9169, 2.6216, 0.5673, 0.7119, 0.7476, 0.7237, 1.2407, 1.0506,
        0.6140, 0.7011, 0.6637, 0.5955, 0.7213, 0.6054, 0.7189, 0.6040, 1.1405,
        0.5657, 0.5433, 0.6183, 0.5555, 0.5486, 0.6100, 0.6684, 0.8535, 0.7189,
        2.0212, 0.9794, 0.6732, 0.6062, 0.5589, 0.5535, 0.6836, 0.5714, 1.0130,
        0.5525, 3.4451, 0.7626, 0.5537, 0.5576, 0.6873, 3.4451, 1.6686, 0.6062],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  21  46  16  70  26  57  31
  15  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  55
 178 168 202 149 355 483 192  56 211 204 129 105  96 179  47 268  62 141
 152 115 104  28  39 424 311 122  96 140  33  23 306 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 207 363 427 217 165 100 139
  31  80 162 222 343 378 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2107, 0.5904, 1.0616, 1.0938, 0.7832, 0.7904, 0.5943, 0.6489, 0.5909,
        1.1290, 0.7940, 0.5624, 0.9883, 1.3710, 0.7454, 2.6240, 0.6542, 0.5439,
        1.3305, 1.9691, 1.1290, 0.7268, 0.8542, 1.0417, 1.2418, 0.9647, 1.6700,
        0.9499, 0.7195, 2.8462, 1.4629, 3.6457, 1.0720, 2.3550, 1.2418, 2.0230,
        3.8698, 1.3503, 0.6263, 0.7126, 0.6824, 0.6368, 0.7978, 0.9572, 0.7664,
        0.6439, 0.7103, 0.5490, 0.6628, 0.5492, 0.7081, 0.6234, 0.7172, 1.2753,
        0.6502, 0.6643, 0.6234, 0.6976, 0.5573, 0.5458, 0.6335, 1.2582, 0.6154,
        0.6215, 0.7454, 0.8307, 0.8749, 0.6489, 1.4385, 0.5808, 1.1678, 0.7148,
        0.6917, 0.7904, 0.8352, 2.2079, 1.6700, 0.5493, 0.5664, 0.7664, 0.8749,
        0.7172, 1.9185, 2.6240, 0.5678, 0.7126, 0.7483, 0.7243, 1.2418, 1.0515,
        0.6145, 0.7017, 0.6643, 0.5961, 0.7219, 0.6060, 0.7195, 0.6045, 1.1415,
        0.5662, 0.5438, 0.6188, 0.5560, 0.5491, 0.6105, 0.6690, 0.8542, 0.7195,
        2.0230, 0.9802, 0.6738, 0.6067, 0.5594, 0.5540, 0.6842, 0.5719, 1.0139,
        0.5530, 3.4481, 0.7633, 0.5542, 0.5581, 0.6879, 3.4481, 1.6700, 0.6067],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  71  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  21  46  16  70  26  57  32
  15  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  55
 178 168 202 149 355 483 192  56 211 204 129 105  96 179  47 268  62 141
 152 115 104  28  39 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 207 363 427 217 165 100 139
  31  80 162 222 343 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2112, 0.5906, 1.0621, 1.0943, 0.7835, 0.7907, 0.5945, 0.6492, 0.5912,
        1.1295, 0.7944, 0.5626, 0.9887, 1.3716, 0.7457, 2.6251, 0.6545, 0.5441,
        1.3310, 1.9700, 1.1295, 0.7271, 0.8546, 1.0422, 1.2423, 0.9651, 1.6708,
        0.9503, 0.7198, 2.8474, 1.4636, 3.6473, 1.0725, 2.3560, 1.2423, 1.9700,
        3.8715, 1.3509, 0.6266, 0.7129, 0.6827, 0.6371, 0.7981, 0.9576, 0.7668,
        0.6442, 0.7106, 0.5492, 0.6631, 0.5495, 0.7084, 0.6237, 0.7175, 1.2758,
        0.6505, 0.6646, 0.6237, 0.6979, 0.5575, 0.5460, 0.6338, 1.2588, 0.6156,
        0.6218, 0.7457, 0.8311, 0.8753, 0.6492, 1.4391, 0.5811, 1.1683, 0.7151,
        0.6920, 0.7907, 0.8356, 2.2088, 1.6708, 0.5495, 0.5667, 0.7668, 0.8753,
        0.7175, 1.9194, 2.6251, 0.5677, 0.7129, 0.7486, 0.7247, 1.2423, 1.0520,
        0.6148, 0.7020, 0.6646, 0.5963, 0.7222, 0.6062, 0.7198, 0.6048, 1.1420,
        0.5664, 0.5440, 0.6191, 0.5563, 0.5493, 0.6108, 0.6692, 0.8546, 0.7198,
        2.0239, 0.9806, 0.6741, 0.6070, 0.5596, 0.5543, 0.6845, 0.5722, 1.0143,
        0.5532, 3.4496, 0.7636, 0.5544, 0.5583, 0.6882, 3.4496, 1.6708, 0.6070],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  20  46  16  70  26  57  33
  15  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  55
 178 168 202 149 355 483 192  56 211 204 129 105  96 179  47 268  62 141
 152 115 104  28  39 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 207 363 427 217 165 100 139
  31  80 162 222 343 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2105, 0.5903, 1.0514, 1.0937, 0.7831, 0.7903, 0.5942, 0.6489, 0.5908,
        1.1289, 0.7940, 0.5623, 0.9882, 1.3709, 0.7453, 2.6237, 0.6542, 0.5438,
        1.3303, 1.9689, 1.1289, 0.7267, 0.8541, 1.0416, 1.2417, 0.9646, 1.6699,
        0.9498, 0.7194, 2.9737, 1.4628, 3.6454, 1.0719, 2.3547, 1.2417, 1.9183,
        3.8694, 1.3502, 0.6262, 0.7125, 0.6823, 0.6368, 0.7977, 0.9571, 0.7664,
        0.6438, 0.7102, 0.5489, 0.6627, 0.5492, 0.7080, 0.6233, 0.7171, 1.2752,
        0.6502, 0.6642, 0.6233, 0.6975, 0.5572, 0.5457, 0.6335, 1.2581, 0.6153,
        0.6215, 0.7453, 0.8306, 0.8748, 0.6489, 1.4383, 0.5808, 1.1677, 0.7148,
        0.6916, 0.7903, 0.8351, 2.2076, 1.6699, 0.5492, 0.5664, 0.7664, 0.8748,
        0.7171, 1.9183, 2.6237, 0.5674, 0.7125, 0.7482, 0.7243, 1.2417, 1.0514,
        0.6145, 0.7016, 0.6642, 0.5960, 0.7218, 0.6059, 0.7194, 0.6045, 1.1414,
        0.5661, 0.5437, 0.6188, 0.5560, 0.5490, 0.6104, 0.6689, 0.8541, 0.7194,
        2.0228, 0.9801, 0.6737, 0.6066, 0.5593, 0.5540, 0.6841, 0.5719, 1.0138,
        0.5529, 3.4477, 0.7632, 0.5542, 0.5580, 0.6878, 3.4477, 1.6699, 0.6066],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  20  46  16  70  26  57  35
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  28  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 207 363 427 217 165 100 139
  31  80 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2137, 0.5919, 1.0542, 1.0966, 0.7852, 0.7924, 0.5958, 0.6506, 0.5924,
        1.1319, 0.7961, 0.5638, 0.9908, 1.3745, 0.7473, 2.6306, 0.6559, 0.5452,
        1.3338, 1.9741, 1.1319, 0.7287, 0.8564, 1.0444, 1.2450, 0.9671, 1.6743,
        0.9523, 0.7213, 2.9815, 1.4666, 3.6550, 1.0747, 2.3610, 1.2450, 1.8308,
        3.6550, 1.3538, 0.6279, 0.7144, 0.6841, 0.6385, 0.7998, 0.9596, 0.7684,
        0.6455, 0.7121, 0.5504, 0.6645, 0.5506, 0.7099, 0.6250, 0.7190, 1.2963,
        0.6519, 0.6660, 0.6250, 0.6994, 0.5587, 0.5472, 0.6351, 1.2614, 0.6169,
        0.6231, 0.7473, 0.8328, 0.8772, 0.6519, 1.4421, 0.5823, 1.1708, 0.7166,
        0.6934, 0.7924, 0.8373, 2.2135, 1.6401, 0.5507, 0.5679, 0.7684, 0.8772,
        0.7190, 1.9234, 2.6306, 0.5689, 0.7144, 0.7501, 0.7262, 1.2450, 1.0542,
        0.6161, 0.7035, 0.6660, 0.5976, 0.7237, 0.6075, 0.7213, 0.6061, 1.1444,
        0.5676, 0.5451, 0.6204, 0.5574, 0.5505, 0.6120, 0.6707, 0.8564, 0.7213,
        2.0281, 0.9827, 0.6755, 0.6082, 0.5610, 0.5555, 0.6859, 0.5734, 1.0165,
        0.5544, 3.4568, 0.7652, 0.5556, 0.5595, 0.6896, 3.4568, 1.6743, 0.6082],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  20  46  16  70  26  57  37
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  28  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 208 363 427 217 165 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2144, 0.5922, 1.0548, 1.0972, 0.7857, 0.7928, 0.5961, 0.6510, 0.5928,
        1.1326, 0.7965, 0.5641, 0.9914, 1.3753, 0.7477, 2.6322, 0.6563, 0.5456,
        1.3346, 1.9753, 1.1326, 0.7291, 0.8569, 1.0450, 1.2457, 0.9677, 1.6753,
        0.9529, 0.7218, 2.9833, 1.4675, 3.6572, 1.0754, 2.3624, 1.2457, 1.7493,
        3.6572, 1.3546, 0.6283, 0.7148, 0.6845, 0.6388, 0.8003, 0.9602, 0.7688,
        0.6459, 0.7125, 0.5507, 0.6649, 0.5509, 0.7103, 0.6254, 0.7194, 1.2970,
        0.6523, 0.6664, 0.6254, 0.6998, 0.5590, 0.5475, 0.6355, 1.2622, 0.6173,
        0.6235, 0.7477, 0.8333, 0.8777, 0.6523, 1.4430, 0.5827, 1.1715, 0.7171,
        0.6938, 0.7928, 0.8378, 2.2148, 1.6411, 0.5510, 0.5682, 0.7688, 0.8777,
        0.7194, 1.9246, 2.6322, 0.5693, 0.7148, 0.7506, 0.7266, 1.2457, 1.0548,
        0.6165, 0.7039, 0.6664, 0.5979, 0.7242, 0.6079, 0.7218, 0.6064, 1.1451,
        0.5679, 0.5455, 0.6199, 0.5578, 0.5508, 0.6124, 0.6711, 0.8569, 0.7218,
        2.0293, 0.9914, 0.6759, 0.6086, 0.5613, 0.5558, 0.6863, 0.5737, 1.0171,
        0.5547, 3.4589, 0.7657, 0.5559, 0.5599, 0.6900, 3.4589, 1.6753, 0.6086],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  57  82  39  84 139  20  46  16  70  26  57  38
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  28  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 147 168 238 138 223 139 225  64 312 548 208 363 427 217 165 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2148, 0.5924, 1.0551, 1.0975, 0.7859, 0.7931, 0.5963, 0.6511, 0.5929,
        1.1329, 0.7968, 0.5643, 0.9917, 1.3757, 0.7480, 2.6330, 0.6565, 0.5457,
        1.3350, 1.9759, 1.1329, 0.7293, 0.8572, 1.0453, 1.2461, 0.9680, 1.6758,
        0.9532, 0.7220, 2.9842, 1.4680, 3.6583, 1.0757, 2.3631, 1.2461, 1.7118,
        3.6583, 1.3550, 0.6285, 0.7150, 0.6847, 0.6390, 0.8005, 0.9605, 0.7691,
        0.6461, 0.7128, 0.5509, 0.6651, 0.5511, 0.7105, 0.6255, 0.7196, 1.2974,
        0.6525, 0.6666, 0.6255, 0.7000, 0.5592, 0.5477, 0.6357, 1.2626, 0.6175,
        0.6237, 0.7480, 0.8336, 0.8779, 0.6525, 1.4434, 0.5828, 1.1718, 0.7173,
        0.6940, 0.7931, 0.8381, 2.2154, 1.6416, 0.5512, 0.5684, 0.7691, 0.8779,
        0.7196, 1.9251, 2.6330, 0.5694, 0.7150, 0.7508, 0.7268, 1.2461, 1.0551,
        0.6166, 0.7041, 0.6666, 0.5981, 0.7244, 0.6081, 0.7220, 0.6066, 1.1455,
        0.5681, 0.5456, 0.6201, 0.5579, 0.5509, 0.6126, 0.6713, 0.8572, 0.7220,
        2.0299, 0.9917, 0.6761, 0.6088, 0.5615, 0.5560, 0.6865, 0.5739, 1.0174,
        0.5549, 3.4599, 0.7659, 0.5561, 0.5600, 0.6902, 3.4599, 1.6758, 0.6088],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  56  82  39  84 139  20  46  16  70  26  57  40
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  28  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 146 168 238 138 223 139 225  64 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2153, 0.5927, 1.0556, 1.0980, 0.7862, 0.7934, 0.5966, 0.6514, 0.5932,
        1.1334, 0.7971, 0.5645, 0.9921, 1.3763, 0.7483, 2.6341, 0.6568, 0.5460,
        1.3356, 1.9767, 1.1334, 0.7296, 0.8575, 1.0457, 1.2631, 0.9684, 1.6765,
        0.9536, 0.7223, 2.9855, 1.4686, 3.6598, 1.0762, 2.3641, 1.2466, 1.6423,
        3.6598, 1.3556, 0.6287, 0.7153, 0.6850, 0.6393, 0.8009, 0.9609, 0.7694,
        0.6464, 0.7131, 0.5511, 0.6654, 0.5513, 0.7108, 0.6258, 0.7199, 1.2980,
        0.6527, 0.6669, 0.6258, 0.7003, 0.5594, 0.5479, 0.6360, 1.2631, 0.6177,
        0.6239, 0.7483, 0.8339, 0.8783, 0.6527, 1.4440, 0.5831, 1.1723, 0.7176,
        0.6943, 0.7934, 0.8384, 2.2164, 1.6423, 0.5514, 0.5686, 0.7694, 0.8783,
        0.7199, 1.9259, 2.6341, 0.5697, 0.7153, 0.7511, 0.7271, 1.2466, 1.0556,
        0.6169, 0.7065, 0.6669, 0.5984, 0.7247, 0.6083, 0.7223, 0.6069, 1.1459,
        0.5683, 0.5458, 0.6203, 0.5582, 0.5512, 0.6128, 0.6700, 0.8575, 0.7223,
        2.0308, 0.9921, 0.6764, 0.6090, 0.5617, 0.5562, 0.6868, 0.5742, 1.0178,
        0.5551, 3.4614, 0.7662, 0.5563, 0.5603, 0.6905, 3.4614, 1.6765, 0.6090],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  56  82  39  84 139  20  46  16  70  26  57  40
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  28  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 146 168 238 138 223 139 225  64 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2153, 0.5927, 1.0556, 1.0980, 0.7862, 0.7934, 0.5966, 0.6514, 0.5932,
        1.1334, 0.7971, 0.5645, 0.9921, 1.3763, 0.7483, 2.6341, 0.6568, 0.5460,
        1.3356, 1.9767, 1.1334, 0.7296, 0.8575, 1.0457, 1.2631, 0.9684, 1.6765,
        0.9536, 0.7223, 2.9855, 1.4686, 3.6598, 1.0762, 2.3641, 1.2466, 1.6423,
        3.6598, 1.3556, 0.6287, 0.7153, 0.6850, 0.6393, 0.8009, 0.9609, 0.7694,
        0.6464, 0.7131, 0.5511, 0.6654, 0.5513, 0.7108, 0.6258, 0.7199, 1.2980,
        0.6527, 0.6669, 0.6258, 0.7003, 0.5594, 0.5479, 0.6360, 1.2631, 0.6177,
        0.6239, 0.7483, 0.8339, 0.8783, 0.6527, 1.4440, 0.5831, 1.1723, 0.7176,
        0.6943, 0.7934, 0.8384, 2.2164, 1.6423, 0.5514, 0.5686, 0.7694, 0.8783,
        0.7199, 1.9259, 2.6341, 0.5697, 0.7153, 0.7511, 0.7271, 1.2466, 1.0556,
        0.6169, 0.7065, 0.6669, 0.5984, 0.7247, 0.6083, 0.7223, 0.6069, 1.1459,
        0.5683, 0.5458, 0.6203, 0.5582, 0.5512, 0.6128, 0.6700, 0.8575, 0.7223,
        2.0308, 0.9921, 0.6764, 0.6090, 0.5617, 0.5562, 0.6868, 0.5742, 1.0178,
        0.5551, 3.4614, 0.7662, 0.5563, 0.5603, 0.6905, 3.4614, 1.6765, 0.6090],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  56  82  39  84 139  20  46  16  70  26  57  40
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 144 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  29  40 424 311 122  96 140  33  23 307 142 128 137  57  72
 212 146 168 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2161, 0.5930, 1.0562, 1.0987, 0.7867, 0.7939, 0.5969, 0.6518, 0.5936,
        1.1341, 0.7976, 0.5649, 0.9927, 1.3772, 0.7488, 2.6357, 0.6572, 0.5463,
        1.3364, 1.9780, 1.1341, 0.7301, 0.8580, 1.0464, 1.2639, 0.9690, 1.6775,
        0.9542, 0.7227, 2.9874, 1.4695, 3.6621, 1.0768, 2.3656, 1.2474, 1.6433,
        3.6621, 1.3564, 0.6291, 0.7158, 0.6855, 0.6397, 0.8014, 0.9615, 0.7699,
        0.6468, 0.7135, 0.5514, 0.6658, 0.5517, 0.7113, 0.6262, 0.7204, 1.2988,
        0.6531, 0.6673, 0.6262, 0.7007, 0.5598, 0.5482, 0.6364, 1.2639, 0.6181,
        0.6243, 0.7488, 0.8344, 0.8789, 0.6531, 1.4449, 0.5834, 1.1730, 0.7180,
        0.6948, 0.7939, 0.8390, 2.1516, 1.6433, 0.5518, 0.5690, 0.7699, 0.8789,
        0.7204, 1.9272, 2.6357, 0.5700, 0.7158, 0.7516, 0.7276, 1.2474, 1.0562,
        0.6173, 0.7070, 0.6673, 0.5987, 0.7251, 0.6087, 0.7227, 0.6073, 1.1341,
        0.5687, 0.5462, 0.6207, 0.5585, 0.5515, 0.6132, 0.6704, 0.8580, 0.7227,
        2.0321, 0.9927, 0.6768, 0.6094, 0.5620, 0.5566, 0.6873, 0.5745, 1.0185,
        0.5555, 3.4636, 0.7667, 0.5567, 0.5606, 0.6910, 3.4636, 1.6775, 0.6094],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  41
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 143 202 140  54
 178 168 202 149 355 483 192  56 211 204 129 105  96 178  47 268  62 141
 152 115 104  30  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 212 146 169 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2168, 0.5934, 1.0568, 1.0993, 0.7872, 0.7943, 0.5973, 0.6522, 0.5939,
        1.1347, 0.7981, 0.5652, 0.9933, 1.3779, 0.7492, 2.6372, 0.6575, 0.5466,
        1.3372, 1.9791, 1.1347, 0.7305, 0.8585, 1.0470, 1.2646, 0.9695, 1.6785,
        0.9547, 0.7231, 2.9890, 1.4960, 3.6641, 1.0774, 2.3669, 1.2481, 1.6116,
        3.6641, 1.3572, 0.6295, 0.7161, 0.6858, 0.6401, 0.8018, 0.9620, 0.7703,
        0.6471, 0.7139, 0.5518, 0.6662, 0.5520, 0.7139, 0.6266, 0.7208, 1.2995,
        0.6535, 0.6677, 0.6266, 0.7011, 0.5601, 0.5486, 0.6367, 1.2646, 0.6185,
        0.6247, 0.7492, 0.8349, 0.8794, 0.6535, 1.4457, 0.5838, 1.1737, 0.7184,
        0.6952, 0.7943, 0.8394, 2.0910, 1.6442, 0.5521, 0.5693, 0.7703, 0.8794,
        0.7184, 1.9282, 2.6372, 0.5703, 0.7161, 0.7520, 0.7280, 1.2481, 1.0568,
        0.6176, 0.7073, 0.6662, 0.5991, 0.7255, 0.6090, 0.7231, 0.6076, 1.1347,
        0.5690, 0.5465, 0.6211, 0.5588, 0.5518, 0.6136, 0.6708, 0.8585, 0.7231,
        2.0332, 0.9933, 0.6772, 0.6098, 0.5624, 0.5569, 0.6876, 0.5748, 1.0190,
        0.5558, 3.4655, 0.7671, 0.5570, 0.5609, 0.6913, 3.4655, 1.6785, 0.6098],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 543
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  16  51 199 142 157 189 113  83 122 183 143 428 169 425 143 202 140  54
 178 168 202 149 355 483 192  56 210 204 129 105  96 178  47 268  62 141
 152 115 104  33  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 212 146 169 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2186, 0.5943, 1.0585, 1.1010, 0.7884, 0.7956, 0.5982, 0.6532, 0.5948,
        1.1365, 0.7993, 0.5661, 0.9948, 1.3801, 0.7503, 2.6412, 0.6585, 0.5474,
        1.3392, 1.9821, 1.1365, 0.7316, 0.8598, 1.0486, 1.2665, 0.9710, 1.6810,
        0.9562, 0.7242, 2.9936, 1.4983, 3.6698, 1.0791, 2.3705, 1.2500, 1.5831,
        3.6698, 1.3592, 0.6304, 0.7172, 0.6869, 0.6410, 0.8031, 0.9635, 0.7715,
        0.6481, 0.7150, 0.5526, 0.6672, 0.5528, 0.7150, 0.6275, 0.7219, 1.3015,
        0.6545, 0.6687, 0.6275, 0.7022, 0.5609, 0.5494, 0.6377, 1.2665, 0.6203,
        0.6256, 0.7503, 0.8362, 0.8807, 0.6545, 1.4479, 0.5847, 1.1755, 0.7195,
        0.6962, 0.7956, 0.8407, 1.9312, 1.6467, 0.5529, 0.5701, 0.7715, 0.8807,
        0.7195, 1.9312, 2.6412, 0.5712, 0.7172, 0.7532, 0.7291, 1.2500, 1.0585,
        0.6186, 0.7084, 0.6672, 0.6000, 0.7267, 0.6100, 0.7242, 0.6085, 1.1365,
        0.5699, 0.5473, 0.6220, 0.5597, 0.5527, 0.6145, 0.6718, 0.8598, 0.7242,
        2.0363, 0.9948, 0.6782, 0.6107, 0.5632, 0.5577, 0.6887, 0.5757, 1.0206,
        0.5566, 3.4708, 0.7683, 0.5579, 0.5618, 0.6924, 3.4708, 1.6810, 0.6107],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 542
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  17  51 199 142 157 189 113  82 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 105  96 177  47 268  62 141
 152 115 104  36  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 212 146 169 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2218, 0.5958, 1.0612, 1.1039, 0.7904, 0.7976, 0.5998, 0.6549, 0.5964,
        1.1394, 0.8014, 0.5675, 0.9974, 1.3837, 0.7523, 2.6481, 0.6603, 0.5489,
        1.3427, 1.9873, 1.1394, 0.7335, 0.8621, 1.0513, 1.2698, 0.9736, 1.6854,
        0.9586, 0.7261, 3.0014, 1.5022, 3.6793, 1.0819, 2.3767, 1.2532, 1.5872,
        3.4799, 1.3628, 0.6321, 0.7191, 0.6887, 0.6427, 0.8052, 0.9736, 0.7703,
        0.6498, 0.7169, 0.5540, 0.6689, 0.5542, 0.7169, 0.6292, 0.7238, 1.3049,
        0.6562, 0.6704, 0.6292, 0.7040, 0.5624, 0.5508, 0.6405, 1.2698, 0.6219,
        0.6273, 0.7523, 0.8384, 0.8830, 0.6575, 1.4517, 0.5862, 1.1786, 0.7214,
        0.6980, 0.7976, 0.8429, 1.8003, 1.6510, 0.5544, 0.5716, 0.7735, 0.8830,
        0.7214, 1.9362, 2.6481, 0.5727, 0.7191, 0.7551, 0.7310, 1.2532, 1.0612,
        0.6202, 0.7103, 0.6689, 0.6015, 0.7286, 0.6116, 0.7261, 0.6101, 1.1394,
        0.5714, 0.5488, 0.6236, 0.5611, 0.5541, 0.6161, 0.6735, 0.8621, 0.7261,
        2.0416, 0.9974, 0.6800, 0.6123, 0.5647, 0.5592, 0.6905, 0.5772, 1.0232,
        0.5581, 3.4799, 0.7703, 0.5593, 0.5632, 0.6942, 3.4799, 1.6854, 0.6123],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 542
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  17  51 199 142 157 189 113  82 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 105  96 177  47 268  62 141
 152 115 104  37  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 212 146 169 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2222, 0.5960, 1.0616, 1.1042, 0.7907, 0.7979, 0.5999, 0.6551, 0.5965,
        1.1398, 0.8016, 0.5677, 0.9977, 1.3841, 0.7525, 2.6490, 0.6605, 0.5491,
        1.3432, 1.9879, 1.1398, 0.7338, 0.8624, 1.0517, 1.2702, 0.9739, 1.6860,
        0.9590, 0.7264, 3.0024, 1.5027, 3.6805, 1.0823, 2.3775, 1.2537, 1.5877,
        3.4810, 1.3632, 0.6323, 0.7193, 0.6889, 0.6429, 0.8054, 0.9739, 0.7705,
        0.6500, 0.7171, 0.5542, 0.6691, 0.5544, 0.7171, 0.6294, 0.7240, 1.3053,
        0.6564, 0.6707, 0.6294, 0.7042, 0.5626, 0.5510, 0.6407, 1.2702, 0.6221,
        0.6275, 0.7525, 0.8386, 0.8833, 0.6578, 1.4522, 0.5864, 1.1789, 0.7217,
        0.6983, 0.7979, 0.8432, 1.7605, 1.6516, 0.5545, 0.5718, 0.7737, 0.8833,
        0.7217, 1.9368, 2.6490, 0.5729, 0.7193, 0.7554, 0.7312, 1.2537, 1.0616,
        0.6204, 0.7105, 0.6691, 0.6017, 0.7288, 0.6118, 0.7264, 0.6103, 1.1398,
        0.5716, 0.5489, 0.6238, 0.5613, 0.5543, 0.6163, 0.6738, 0.8624, 0.7264,
        2.0423, 0.9977, 0.6802, 0.6125, 0.5649, 0.5594, 0.6907, 0.5774, 1.0236,
        0.5582, 3.4810, 0.7705, 0.5595, 0.5634, 0.6944, 3.4810, 1.6860, 0.6125],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 542
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 199 142 157 189 113  82 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 104  96 176  47 268  62 141
 152 115 104  38  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 208 363 427 217 166 100 139
  31  79 162 222 342 377 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2242, 0.5970, 1.0633, 1.1061, 0.7920, 0.7992, 0.6009, 0.6562, 0.5975,
        1.1417, 0.8030, 0.5687, 0.9994, 1.3864, 0.7538, 2.6534, 0.6616, 0.5500,
        1.3454, 1.9912, 1.1417, 0.7350, 0.8638, 1.0534, 1.2724, 0.9755, 1.6888,
        0.9606, 0.7276, 3.0074, 1.5052, 3.6867, 1.0841, 2.3814, 1.2557, 1.5904,
        3.3092, 1.3655, 0.6333, 0.7206, 0.6901, 0.6440, 0.8068, 0.9755, 0.7718,
        0.6511, 0.7183, 0.5551, 0.6703, 0.5553, 0.7183, 0.6304, 0.7252, 1.3075,
        0.6575, 0.6718, 0.6304, 0.7054, 0.5635, 0.5519, 0.6417, 1.2724, 0.6231,
        0.6285, 0.7538, 0.8446, 0.8848, 0.6602, 1.4546, 0.5874, 1.1809, 0.7229,
        0.6994, 0.7992, 0.8446, 1.7251, 1.6543, 0.5555, 0.5728, 0.7750, 0.8848,
        0.7229, 1.9401, 2.6534, 0.5739, 0.7206, 0.7567, 0.7325, 1.2557, 1.0633,
        0.6206, 0.7117, 0.6703, 0.6027, 0.7300, 0.6128, 0.7276, 0.6113, 1.1417,
        0.5725, 0.5499, 0.6249, 0.5623, 0.5552, 0.6173, 0.6749, 0.8638, 0.7276,
        2.0457, 0.9994, 0.6814, 0.6135, 0.5658, 0.5603, 0.6919, 0.5784, 1.0253,
        0.5592, 3.4868, 0.7718, 0.5604, 0.5644, 0.6956, 3.4868, 1.6888, 0.6135],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 114 328  79  50 129  23 175 542
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 199 142 157 189 113  82 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 104  96 176  47 268  62 141
 152 115 104  41  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 208 362 427 217 166 100 139
  31  79 162 222 342 376 156 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2253, 0.5975, 1.0642, 1.1070, 0.7926, 0.7999, 0.6014, 0.6567, 0.5980,
        1.1426, 0.8036, 0.5691, 1.0002, 1.3876, 0.7544, 2.6556, 0.6621, 0.5504,
        1.3465, 1.9929, 1.1426, 0.7356, 0.8645, 1.0543, 1.2734, 0.9763, 1.6902,
        0.9613, 0.7282, 3.0099, 1.5065, 3.6897, 1.0850, 2.3834, 1.2568, 1.5917,
        3.3119, 1.3666, 0.6339, 0.7211, 0.6906, 0.6445, 0.8074, 0.9763, 0.7725,
        0.6517, 0.7189, 0.5556, 0.6708, 0.5558, 0.7189, 0.6309, 0.7258, 1.3086,
        0.6581, 0.6723, 0.6309, 0.7060, 0.5640, 0.5524, 0.6423, 1.2734, 0.6236,
        0.6290, 0.7544, 0.8453, 0.8855, 0.6608, 1.4558, 0.5878, 1.1819, 0.7235,
        0.7000, 0.7999, 0.8453, 1.6229, 1.6557, 0.5559, 0.5732, 0.7757, 0.8855,
        0.7235, 1.9417, 2.6556, 0.5743, 0.7211, 0.7573, 0.7331, 1.2568, 1.0642,
        0.6211, 0.7123, 0.6708, 0.6032, 0.7306, 0.6133, 0.7282, 0.6118, 1.1426,
        0.5730, 0.5503, 0.6254, 0.5629, 0.5557, 0.6179, 0.6754, 0.8645, 0.7282,
        2.0474, 1.0002, 0.6819, 0.6140, 0.5663, 0.5609, 0.6924, 0.5788, 1.0261,
        0.5596, 3.4897, 0.7725, 0.5609, 0.5648, 0.6962, 3.4897, 1.6902, 0.6140],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 199 142 157 189 113  82 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 104  96 175  47 268  62 141
 152 115 104  46  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 208 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2266, 0.5981, 1.0654, 1.1082, 0.7935, 0.8008, 0.6021, 0.6575, 0.5987,
        1.1439, 0.8083, 0.5698, 1.0013, 1.3891, 0.7552, 2.6585, 0.6629, 0.5511,
        1.3480, 1.9951, 1.1439, 0.7364, 0.8655, 1.0554, 1.2748, 0.9774, 1.6920,
        0.9624, 0.7290, 3.0132, 1.5081, 3.6938, 1.0861, 2.3860, 1.2582, 1.5934,
        3.3156, 1.3681, 0.6346, 0.7219, 0.6914, 0.6452, 0.8083, 0.9774, 0.7733,
        0.6524, 0.7197, 0.5562, 0.6715, 0.5564, 0.7197, 0.6316, 0.7266, 1.3100,
        0.6588, 0.6731, 0.6316, 0.7068, 0.5646, 0.5530, 0.6430, 1.2748, 0.6243,
        0.6297, 0.7552, 0.8462, 0.8865, 0.6629, 1.4574, 0.5885, 1.1832, 0.7242,
        0.7008, 0.8008, 0.8462, 1.4822, 1.6575, 0.5565, 0.5739, 0.7765, 0.8865,
        0.7242, 1.9438, 2.6585, 0.5750, 0.7219, 0.7581, 0.7339, 1.2582, 1.0654,
        0.6218, 0.7131, 0.6715, 0.6039, 0.7314, 0.6140, 0.7290, 0.6125, 1.1439,
        0.5736, 0.5509, 0.6261, 0.5637, 0.5563, 0.6185, 0.6762, 0.8655, 0.7290,
        2.0496, 1.0013, 0.6827, 0.6147, 0.5669, 0.5615, 0.6914, 0.5795, 1.0273,
        0.5603, 3.4935, 0.7733, 0.5615, 0.5655, 0.6969, 3.4935, 1.6920, 0.6147],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 198 142 157 189 113  81 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 483 191  56 210 204 129 104  96 175  47 268  62 141
 152 115 104  48  40 424 311 122  96 141  33  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 208 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2270, 0.5983, 1.0657, 1.1085, 0.7938, 0.8010, 0.6023, 0.6577, 0.5989,
        1.1443, 0.8086, 0.5699, 1.0016, 1.3895, 0.7555, 2.6594, 0.6631, 0.5513,
        1.3484, 1.9957, 1.1443, 0.7366, 0.8657, 1.0558, 1.2752, 0.9777, 1.6926,
        0.9627, 0.7292, 3.0141, 1.5086, 3.6949, 1.0865, 2.3868, 1.2586, 1.5939,
        3.3166, 1.3686, 0.6358, 0.7222, 0.6916, 0.6454, 0.8086, 0.9855, 0.7736,
        0.6526, 0.7199, 0.5564, 0.6718, 0.5565, 0.7199, 0.6318, 0.7268, 1.3104,
        0.6590, 0.6733, 0.6318, 0.7070, 0.5648, 0.5532, 0.6432, 1.2752, 0.6245,
        0.6299, 0.7555, 0.8465, 0.8867, 0.6631, 1.4579, 0.5887, 1.1836, 0.7245,
        0.7010, 0.8010, 0.8465, 1.4341, 1.6580, 0.5567, 0.5741, 0.7768, 0.8867,
        0.7245, 1.9444, 2.6594, 0.5751, 0.7222, 0.7583, 0.7341, 1.2586, 1.0657,
        0.6220, 0.7133, 0.6718, 0.6041, 0.7316, 0.6142, 0.7292, 0.6127, 1.1443,
        0.5738, 0.5511, 0.6263, 0.5638, 0.5565, 0.6187, 0.6764, 0.8657, 0.7292,
        2.0503, 1.0016, 0.6829, 0.6149, 0.5671, 0.5617, 0.6916, 0.5797, 1.0276,
        0.5604, 3.4946, 0.7736, 0.5617, 0.5656, 0.6972, 3.4946, 1.6926, 0.6149],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 247  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 198 142 157 189 113  81 123 183 143 428 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 204 129 104  96 175  47 268  62 141
 152 115 104  49  40 424 311 122  97 141  33  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 208 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2273, 0.5985, 1.0660, 1.1088, 0.7939, 0.8012, 0.6024, 0.6578, 0.5990,
        1.1445, 0.8087, 0.5701, 1.0019, 1.3898, 0.7556, 2.6599, 0.6632, 0.5514,
        1.3487, 1.9961, 1.1445, 0.7368, 0.8659, 1.0560, 1.2755, 0.9779, 1.6930,
        0.9629, 0.7294, 3.0148, 1.5089, 3.6958, 1.0867, 2.3873, 1.2588, 1.5943,
        3.3173, 1.3689, 0.6359, 0.7223, 0.6918, 0.6456, 0.8087, 0.9857, 0.7737,
        0.6527, 0.7201, 0.5565, 0.6719, 0.5567, 0.7201, 0.6320, 0.7270, 1.3107,
        0.6591, 0.6734, 0.6320, 0.7072, 0.5649, 0.5533, 0.6433, 1.2755, 0.6247,
        0.6301, 0.7556, 0.8467, 0.8869, 0.6632, 1.4582, 0.5888, 1.1838, 0.7246,
        0.7012, 0.8012, 0.8467, 1.4117, 1.6584, 0.5568, 0.5742, 0.7769, 0.8815,
        0.7246, 1.9449, 2.6599, 0.5753, 0.7223, 0.7585, 0.7343, 1.2588, 1.0660,
        0.6221, 0.7135, 0.6719, 0.6042, 0.7318, 0.6143, 0.7294, 0.6128, 1.1445,
        0.5739, 0.5512, 0.6264, 0.5640, 0.5566, 0.6189, 0.6765, 0.8659, 0.7294,
        2.0507, 1.0019, 0.6831, 0.6150, 0.5672, 0.5618, 0.6918, 0.5798, 1.0278,
        0.5606, 3.4954, 0.7737, 0.5618, 0.5658, 0.6973, 3.4954, 1.6930, 0.6150],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 198 142 157 189 113  81 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 204 129 104  96 175  47 268  62 141
 152 115 104  51  40 424 311 122  97 141  32  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2272, 0.5984, 1.0659, 1.1087, 0.7939, 0.8011, 0.6024, 0.6578, 0.5984,
        1.1444, 0.8087, 0.5700, 1.0018, 1.3897, 0.7556, 2.6598, 0.6632, 0.5513,
        1.3486, 1.9960, 1.1444, 0.7367, 0.8659, 1.0559, 1.2754, 0.9778, 1.6928,
        0.9629, 0.7293, 3.0146, 1.5088, 3.6955, 1.0867, 2.3871, 1.2588, 1.5942,
        3.3171, 1.3688, 0.6359, 0.7223, 0.6917, 0.6455, 0.8087, 0.9856, 0.7737,
        0.6527, 0.7200, 0.5566, 0.6719, 0.5566, 0.7200, 0.6319, 0.7269, 1.3106,
        0.6591, 0.6734, 0.6319, 0.7071, 0.5649, 0.5533, 0.6433, 1.2754, 0.6246,
        0.6300, 0.7556, 0.8466, 0.8869, 0.6632, 1.4581, 0.5888, 1.1837, 0.7246,
        0.7011, 0.8011, 0.8466, 1.3688, 1.6583, 0.5568, 0.5741, 0.7769, 0.8815,
        0.7246, 1.9960, 2.6598, 0.5752, 0.7223, 0.7585, 0.7342, 1.2588, 1.0659,
        0.6221, 0.7134, 0.6719, 0.6042, 0.7318, 0.6142, 0.7293, 0.6128, 1.1444,
        0.5739, 0.5512, 0.6273, 0.5639, 0.5566, 0.6188, 0.6765, 0.8659, 0.7293,
        2.0506, 1.0018, 0.6830, 0.6150, 0.5672, 0.5618, 0.6917, 0.5797, 1.0277,
        0.5605, 3.4951, 0.7737, 0.5618, 0.5657, 0.6973, 3.4951, 1.6928, 0.6150],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  42
  18  51 198 142 157 189 113  81 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 204 129 104  96 175  47 268  62 141
 152 115 104  51  40 424 311 122  97 141  32  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2272, 0.5984, 1.0659, 1.1087, 0.7939, 0.8011, 0.6024, 0.6578, 0.5984,
        1.1444, 0.8087, 0.5700, 1.0018, 1.3897, 0.7556, 2.6598, 0.6632, 0.5513,
        1.3486, 1.9960, 1.1444, 0.7367, 0.8659, 1.0559, 1.2754, 0.9778, 1.6928,
        0.9629, 0.7293, 3.0146, 1.5088, 3.6955, 1.0867, 2.3871, 1.2588, 1.5942,
        3.3171, 1.3688, 0.6359, 0.7223, 0.6917, 0.6455, 0.8087, 0.9856, 0.7737,
        0.6527, 0.7200, 0.5566, 0.6719, 0.5566, 0.7200, 0.6319, 0.7269, 1.3106,
        0.6591, 0.6734, 0.6319, 0.7071, 0.5649, 0.5533, 0.6433, 1.2754, 0.6246,
        0.6300, 0.7556, 0.8466, 0.8869, 0.6632, 1.4581, 0.5888, 1.1837, 0.7246,
        0.7011, 0.8011, 0.8466, 1.3688, 1.6583, 0.5568, 0.5741, 0.7769, 0.8815,
        0.7246, 1.9960, 2.6598, 0.5752, 0.7223, 0.7585, 0.7342, 1.2588, 1.0659,
        0.6221, 0.7134, 0.6719, 0.6042, 0.7318, 0.6142, 0.7293, 0.6128, 1.1444,
        0.5739, 0.5512, 0.6273, 0.5639, 0.5566, 0.6188, 0.6765, 0.8659, 0.7293,
        2.0506, 1.0018, 0.6830, 0.6150, 0.5672, 0.5618, 0.6917, 0.5797, 1.0277,
        0.5605, 3.4951, 0.7737, 0.5618, 0.5657, 0.6973, 3.4951, 1.6928, 0.6150],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  32  65 136 100  73  56  82  39  84 139  20  45  16  70  26  57  43
  18  51 198 142 157 189 113  81 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 205 129 104  95 175  47 268  62 141
 152 115 104  51  40 424 311 122  97 141  32  23 307 142 128 137  57  72
 213 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 350 154  17  39 222]
CBFL per class weights: tensor([1.2274, 0.5985, 1.0661, 1.1089, 0.7940, 0.8013, 0.6025, 0.6579, 0.5985,
        1.1447, 0.8088, 0.5701, 1.0020, 1.3900, 0.7557, 2.6603, 0.6633, 0.5514,
        1.3489, 1.9964, 1.1447, 0.7369, 0.8660, 1.0561, 1.2757, 0.9780, 1.6932,
        0.9631, 0.7295, 3.0152, 1.5091, 3.6962, 1.0869, 2.3876, 1.2590, 1.5647,
        3.3178, 1.3690, 0.6360, 0.7224, 0.6918, 0.6457, 0.8088, 0.9858, 0.7738,
        0.6528, 0.7201, 0.5567, 0.6720, 0.5567, 0.7201, 0.6320, 0.7271, 1.3109,
        0.6592, 0.6735, 0.6320, 0.7072, 0.5650, 0.5534, 0.6434, 1.2757, 0.6247,
        0.6292, 0.7557, 0.8468, 0.8926, 0.6633, 1.4584, 0.5889, 1.1840, 0.7247,
        0.7012, 0.8013, 0.8468, 1.3690, 1.6586, 0.5569, 0.5743, 0.7771, 0.8816,
        0.7247, 1.9964, 2.6603, 0.5753, 0.7224, 0.7586, 0.7344, 1.2590, 1.0661,
        0.6222, 0.7135, 0.6720, 0.6043, 0.7319, 0.6144, 0.7295, 0.6129, 1.1447,
        0.5740, 0.5513, 0.6274, 0.5640, 0.5567, 0.6189, 0.6766, 0.8660, 0.7295,
        2.0510, 1.0020, 0.6831, 0.6151, 0.5673, 0.5619, 0.6918, 0.5799, 1.0279,
        0.5606, 3.4958, 0.7738, 0.5619, 0.5658, 0.6974, 3.4958, 1.6932, 0.6151],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  51 198 142 157 189 113  81 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 205 129 104  95 175  47 268  62 141
 152 115 104  51  40 424 311 122  97 141  32  23 307 142 128 137  57  71
 214 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2279, 0.5988, 1.0665, 1.1093, 0.7943, 0.8016, 0.6027, 0.6581, 0.5988,
        1.1451, 0.8091, 0.5703, 1.0023, 1.3905, 0.7560, 2.6612, 0.6635, 0.5516,
        1.3494, 1.9458, 1.1451, 0.7371, 0.8664, 1.0565, 1.2761, 0.9784, 1.6938,
        0.9634, 0.7273, 3.0162, 1.5097, 3.6975, 1.0873, 2.3884, 1.2594, 1.5652,
        3.3189, 1.3695, 0.6362, 0.7227, 0.6921, 0.6459, 0.8091, 0.9861, 0.7741,
        0.6530, 0.7204, 0.5569, 0.6722, 0.5569, 0.7204, 0.6323, 0.7273, 1.3114,
        0.6595, 0.6738, 0.6323, 0.7075, 0.5652, 0.5536, 0.6436, 1.2761, 0.6250,
        0.6294, 0.7560, 0.8471, 0.8929, 0.6635, 1.4589, 0.5891, 1.1844, 0.7250,
        0.7015, 0.8016, 0.8471, 1.3695, 1.6592, 0.5571, 0.5745, 0.7773, 0.8819,
        0.7250, 1.9971, 2.6612, 0.5755, 0.7227, 0.7589, 0.7346, 1.2594, 1.0767,
        0.6216, 0.7138, 0.6722, 0.6045, 0.7322, 0.6146, 0.7297, 0.6131, 1.1451,
        0.5742, 0.5515, 0.6276, 0.5642, 0.5569, 0.6192, 0.6769, 0.8664, 0.7297,
        2.0517, 1.0023, 0.6834, 0.6153, 0.5675, 0.5621, 0.6921, 0.5801, 1.0283,
        0.5608, 3.4971, 0.7741, 0.5621, 0.5662, 0.6976, 3.4971, 1.6938, 0.6153],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  51 198 142 157 189 113  81 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 205 129 104  95 175  47 268  62 141
 152 115 104  51  40 424 311 122  97 141  32  23 307 142 128 137  57  71
 214 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2279, 0.5988, 1.0665, 1.1093, 0.7943, 0.8016, 0.6027, 0.6581, 0.5988,
        1.1451, 0.8091, 0.5703, 1.0023, 1.3905, 0.7560, 2.6612, 0.6635, 0.5516,
        1.3494, 1.9458, 1.1451, 0.7371, 0.8664, 1.0565, 1.2761, 0.9784, 1.6938,
        0.9634, 0.7273, 3.0162, 1.5097, 3.6975, 1.0873, 2.3884, 1.2594, 1.5652,
        3.3189, 1.3695, 0.6362, 0.7227, 0.6921, 0.6459, 0.8091, 0.9861, 0.7741,
        0.6530, 0.7204, 0.5569, 0.6722, 0.5569, 0.7204, 0.6323, 0.7273, 1.3114,
        0.6595, 0.6738, 0.6323, 0.7075, 0.5652, 0.5536, 0.6436, 1.2761, 0.6250,
        0.6294, 0.7560, 0.8471, 0.8929, 0.6635, 1.4589, 0.5891, 1.1844, 0.7250,
        0.7015, 0.8016, 0.8471, 1.3695, 1.6592, 0.5571, 0.5745, 0.7773, 0.8819,
        0.7250, 1.9971, 2.6612, 0.5755, 0.7227, 0.7589, 0.7346, 1.2594, 1.0767,
        0.6216, 0.7138, 0.6722, 0.6045, 0.7322, 0.6146, 0.7297, 0.6131, 1.1451,
        0.5742, 0.5515, 0.6276, 0.5642, 0.5569, 0.6192, 0.6769, 0.8664, 0.7297,
        2.0517, 1.0023, 0.6834, 0.6153, 0.5675, 0.5621, 0.6921, 0.5801, 1.0283,
        0.5608, 3.4971, 0.7741, 0.5621, 0.5662, 0.6976, 3.4971, 1.6938, 0.6153],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  51 198 142 157 189 113  80 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 205 129 104  95 175  47 268  62 141
 152 115 104  53  40 424 311 122  97 141  32  23 307 142 128 137  57  71
 214 146 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 386  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2282, 0.5989, 1.0667, 1.1096, 0.7945, 0.8018, 0.6029, 0.6583, 0.5989,
        1.1453, 0.8093, 0.5705, 1.0026, 1.3908, 0.7562, 2.6619, 0.6637, 0.5518,
        1.3497, 1.9463, 1.1453, 0.7373, 0.8666, 1.0568, 1.2764, 0.9786, 1.6942,
        0.9636, 0.7275, 3.0170, 1.5100, 3.6984, 1.0875, 2.3890, 1.2598, 1.5656,
        3.3198, 1.3699, 0.6364, 0.7229, 0.6923, 0.6461, 0.8093, 0.9944, 0.7743,
        0.6532, 0.7206, 0.5570, 0.6724, 0.5571, 0.7206, 0.6324, 0.7275, 1.3117,
        0.6596, 0.6739, 0.6324, 0.7077, 0.5653, 0.5537, 0.6438, 1.2764, 0.6251,
        0.6296, 0.7562, 0.8473, 0.8931, 0.6637, 1.4593, 0.5892, 1.1847, 0.7252,
        0.7017, 0.8018, 0.8473, 1.3303, 1.6596, 0.5572, 0.5746, 0.7775, 0.8822,
        0.7252, 1.9976, 2.6619, 0.5757, 0.7229, 0.7591, 0.7348, 1.2598, 1.0770,
        0.6217, 0.7140, 0.6724, 0.6047, 0.7323, 0.6147, 0.7299, 0.6133, 1.1453,
        0.5743, 0.5516, 0.6278, 0.5644, 0.5570, 0.6193, 0.6770, 0.8666, 0.7299,
        2.0522, 1.0026, 0.6836, 0.6155, 0.5676, 0.5622, 0.6923, 0.5802, 1.0286,
        0.5610, 3.4979, 0.7743, 0.5622, 0.5663, 0.6978, 3.4979, 1.6942, 0.6155],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  23 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  51 198 142 157 189 113  80 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 482 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  54  40 424 311 122  97 141  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 312 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2285, 0.5991, 1.0670, 1.1099, 0.7947, 0.8020, 0.6030, 0.6585, 0.5991,
        1.1457, 0.8096, 0.5706, 1.0029, 1.3912, 0.7564, 2.6626, 0.6639, 0.5519,
        1.3501, 1.9468, 1.1457, 0.7375, 0.8668, 1.0571, 1.2768, 0.9789, 1.6946,
        0.9639, 0.7277, 3.0178, 1.5105, 3.6995, 1.0878, 2.3897, 1.2601, 1.5661,
        3.3207, 1.3702, 0.6365, 0.7231, 0.6925, 0.6462, 0.8096, 0.9947, 0.7745,
        0.6534, 0.7208, 0.5571, 0.6726, 0.5572, 0.7208, 0.6326, 0.7277, 1.3120,
        0.6598, 0.6741, 0.6326, 0.7079, 0.5655, 0.5539, 0.6440, 1.2768, 0.6253,
        0.6298, 0.7564, 0.8475, 0.8934, 0.6639, 1.4597, 0.5894, 1.1715, 0.7254,
        0.7019, 0.8020, 0.8475, 1.3120, 1.6601, 0.5574, 0.5748, 0.7777, 0.8824,
        0.7254, 1.9981, 2.6626, 0.5758, 0.7231, 0.7593, 0.7350, 1.2601, 1.0773,
        0.6219, 0.7120, 0.6726, 0.6048, 0.7325, 0.6149, 0.7301, 0.6135, 1.1457,
        0.5745, 0.5518, 0.6279, 0.5645, 0.5571, 0.6195, 0.6772, 0.8668, 0.7301,
        2.0528, 1.0029, 0.6837, 0.6156, 0.5678, 0.5624, 0.6925, 0.5804, 1.0288,
        0.5612, 3.4989, 0.7745, 0.5624, 0.5665, 0.6980, 3.4989, 1.6946, 0.6156],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 183 143 427 169 426 143 202 140  54
 178 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  54  40 424 311 122  98 141  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2293, 0.5995, 1.0677, 1.1106, 0.7953, 0.8025, 0.6034, 0.6589, 0.5995,
        1.1464, 0.8101, 0.5710, 1.0035, 1.3921, 0.7569, 2.5657, 0.6643, 0.5523,
        1.3510, 1.9481, 1.1464, 0.7380, 0.8674, 1.0578, 1.2776, 0.9795, 1.6958,
        0.9645, 0.7282, 3.0198, 1.5115, 3.7019, 1.0885, 2.3913, 1.2609, 1.5671,
        3.3229, 1.3921, 0.6370, 0.7235, 0.6929, 0.6467, 0.8101, 0.9953, 0.7750,
        0.6538, 0.7213, 0.5575, 0.6730, 0.5576, 0.7213, 0.6330, 0.7282, 1.3129,
        0.6602, 0.6745, 0.6330, 0.7083, 0.5659, 0.5543, 0.6444, 1.2776, 0.6257,
        0.6302, 0.7569, 0.8481, 0.8940, 0.6643, 1.4606, 0.5898, 1.1722, 0.7258,
        0.7023, 0.8025, 0.8481, 1.3129, 1.6612, 0.5578, 0.5751, 0.7782, 0.8777,
        0.7258, 1.9994, 2.6644, 0.5762, 0.7235, 0.7598, 0.7355, 1.2609, 1.0780,
        0.6223, 0.7125, 0.6730, 0.6052, 0.7330, 0.6153, 0.7306, 0.6139, 1.1464,
        0.5746, 0.5521, 0.6284, 0.5649, 0.5575, 0.6199, 0.6777, 0.8674, 0.7306,
        2.0541, 1.0035, 0.6842, 0.6161, 0.5682, 0.5627, 0.6929, 0.5808, 1.0295,
        0.5616, 3.5012, 0.7750, 0.5627, 0.5669, 0.6985, 3.5012, 1.6958, 0.6161],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 328  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 183 143 427 169 426 143 202 140  54
 177 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  54  40 424 311 122  98 142  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2293, 0.5995, 1.0677, 1.1106, 0.7953, 0.8025, 0.6034, 0.6589, 0.5995,
        1.1464, 0.8101, 0.5710, 1.0035, 1.3922, 0.7569, 2.5657, 0.6643, 0.5523,
        1.3510, 1.9481, 1.1464, 0.7380, 0.8674, 1.0578, 1.2776, 0.9795, 1.6958,
        0.9645, 0.7282, 3.0198, 1.5115, 3.7019, 1.0885, 2.3913, 1.2609, 1.5671,
        3.3229, 1.3922, 0.6370, 0.7235, 0.6929, 0.6467, 0.8101, 0.9953, 0.7750,
        0.6538, 0.7213, 0.5575, 0.6730, 0.5576, 0.7213, 0.6330, 0.7282, 1.3129,
        0.6616, 0.6746, 0.6330, 0.7083, 0.5659, 0.5543, 0.6444, 1.2776, 0.6257,
        0.6302, 0.7569, 0.8481, 0.8940, 0.6643, 1.4606, 0.5898, 1.1722, 0.7259,
        0.7023, 0.8025, 0.8481, 1.3129, 1.6612, 0.5578, 0.5751, 0.7782, 0.8777,
        0.7235, 1.9995, 2.6644, 0.5762, 0.7235, 0.7598, 0.7355, 1.2609, 1.0780,
        0.6223, 0.7125, 0.6730, 0.6052, 0.7330, 0.6153, 0.7306, 0.6139, 1.1464,
        0.5746, 0.5521, 0.6284, 0.5649, 0.5575, 0.6199, 0.6777, 0.8674, 0.7306,
        2.0542, 1.0035, 0.6842, 0.6161, 0.5682, 0.5627, 0.6929, 0.5808, 1.0295,
        0.5616, 3.5012, 0.7750, 0.5627, 0.5669, 0.6985, 3.5012, 1.6958, 0.6161],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 427 169 426 143 202 140  54
 177 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  54  40 424 311 122  98 142  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2293, 0.5995, 1.0677, 1.1106, 0.7953, 0.8025, 0.6034, 0.6589, 0.5995,
        1.1464, 0.8101, 0.5708, 1.0035, 1.3921, 0.7569, 2.5657, 0.6643, 0.5523,
        1.3510, 1.9481, 1.1464, 0.7380, 0.8674, 1.0578, 1.2776, 0.9795, 1.6958,
        0.9645, 0.7282, 3.0198, 1.5114, 3.7019, 1.0885, 2.3913, 1.2609, 1.5671,
        3.3229, 1.3921, 0.6370, 0.7235, 0.6929, 0.6467, 0.8101, 0.9953, 0.7750,
        0.6551, 0.7213, 0.5575, 0.6730, 0.5576, 0.7213, 0.6330, 0.7282, 1.3129,
        0.6616, 0.6745, 0.6330, 0.7083, 0.5659, 0.5543, 0.6444, 1.2776, 0.6257,
        0.6302, 0.7569, 0.8481, 0.8940, 0.6643, 1.4606, 0.5898, 1.1722, 0.7258,
        0.7023, 0.8025, 0.8481, 1.3129, 1.6611, 0.5578, 0.5751, 0.7782, 0.8777,
        0.7235, 1.9994, 2.6644, 0.5762, 0.7235, 0.7598, 0.7355, 1.2609, 1.0780,
        0.6223, 0.7125, 0.6730, 0.6052, 0.7330, 0.6153, 0.7306, 0.6139, 1.1464,
        0.5746, 0.5521, 0.6284, 0.5649, 0.5575, 0.6199, 0.6777, 0.8674, 0.7306,
        2.0541, 1.0035, 0.6842, 0.6161, 0.5682, 0.5627, 0.6929, 0.5808, 1.0295,
        0.5616, 3.5012, 0.7750, 0.5627, 0.5669, 0.6985, 3.5012, 1.6958, 0.6161],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  54  40 424 311 122  98 142  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2293, 0.5995, 1.0677, 1.1106, 0.7953, 0.8025, 0.6034, 0.6589, 0.5995,
        1.1464, 0.8101, 0.5708, 1.0035, 1.3921, 0.7569, 2.5657, 0.6643, 0.5523,
        1.3510, 1.9481, 1.1464, 0.7380, 0.8674, 1.0578, 1.2776, 0.9795, 1.6958,
        0.9645, 0.7282, 3.0198, 1.5115, 3.7019, 1.0885, 2.3913, 1.2609, 1.5671,
        3.3229, 1.3921, 0.6370, 0.7235, 0.6929, 0.6467, 0.8101, 0.9953, 0.7750,
        0.6551, 0.7213, 0.5574, 0.6730, 0.5576, 0.7213, 0.6330, 0.7282, 1.3129,
        0.6616, 0.6745, 0.6330, 0.7083, 0.5659, 0.5543, 0.6444, 1.2776, 0.6257,
        0.6302, 0.7569, 0.8481, 0.8940, 0.6643, 1.4606, 0.5898, 1.1722, 0.7258,
        0.7023, 0.8025, 0.8481, 1.3129, 1.6612, 0.5578, 0.5751, 0.7782, 0.8777,
        0.7235, 1.9994, 2.6644, 0.5762, 0.7235, 0.7598, 0.7355, 1.2609, 1.0780,
        0.6223, 0.7125, 0.6730, 0.6052, 0.7330, 0.6153, 0.7306, 0.6139, 1.1464,
        0.5746, 0.5521, 0.6284, 0.5649, 0.5575, 0.6199, 0.6777, 0.8674, 0.7306,
        2.0541, 1.0035, 0.6842, 0.6161, 0.5682, 0.5627, 0.6929, 0.5808, 1.0295,
        0.5616, 3.5012, 0.7750, 0.5627, 0.5669, 0.6985, 3.5012, 1.6958, 0.6161],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  55  40 424 311 122  98 142  32  23 307 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2295, 0.5996, 1.0679, 1.1108, 0.7954, 0.8026, 0.6035, 0.6590, 0.5996,
        1.1466, 0.8102, 0.5709, 1.0037, 1.3923, 0.7570, 2.5661, 0.6644, 0.5524,
        1.3512, 1.9484, 1.1466, 0.7381, 0.8675, 1.0579, 1.2778, 0.9797, 1.6960,
        0.9647, 0.7283, 3.0202, 1.5117, 3.7024, 1.0887, 2.3916, 1.2611, 1.5673,
        3.3233, 1.3923, 0.6371, 0.7236, 0.6930, 0.6467, 0.8102, 0.9955, 0.7751,
        0.6551, 0.7214, 0.5575, 0.6731, 0.5577, 0.7214, 0.6331, 0.7283, 1.3131,
        0.6617, 0.6746, 0.6331, 0.7084, 0.5659, 0.5544, 0.6445, 1.2778, 0.6258,
        0.6303, 0.7570, 0.8482, 0.8941, 0.6644, 1.4608, 0.5899, 1.1724, 0.7259,
        0.7024, 0.8026, 0.8482, 1.2951, 1.6614, 0.5578, 0.5752, 0.7784, 0.8778,
        0.7236, 1.9997, 2.6647, 0.5763, 0.7236, 0.7599, 0.7356, 1.2611, 1.0781,
        0.6224, 0.7126, 0.6731, 0.6053, 0.7331, 0.6154, 0.7307, 0.6139, 1.1466,
        0.5747, 0.5522, 0.6284, 0.5650, 0.5576, 0.6200, 0.6778, 0.8675, 0.7307,
        2.0544, 1.0037, 0.6843, 0.6161, 0.5682, 0.5628, 0.6930, 0.5808, 1.0297,
        0.5617, 3.5017, 0.7751, 0.5628, 0.5670, 0.6986, 3.5017, 1.6960, 0.6161],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  56 210 205 129 104  95 175  47 268  63 141
 152 115 104  57  40 424 311 122  98 142  32  23 308 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2298, 0.5997, 1.0682, 1.1111, 0.7956, 0.8029, 0.6037, 0.6592, 0.5997,
        1.1469, 0.8104, 0.5710, 1.0039, 1.3927, 0.7572, 2.5668, 0.6646, 0.5525,
        1.3515, 1.9489, 1.1469, 0.7383, 0.8677, 1.0582, 1.2782, 0.9799, 1.6965,
        0.9649, 0.7285, 3.0211, 1.5121, 3.7034, 1.0890, 2.3923, 1.2615, 1.5677,
        3.3242, 1.3927, 0.6372, 0.7238, 0.6932, 0.6469, 0.8104, 0.9957, 0.7753,
        0.6553, 0.7216, 0.5577, 0.6733, 0.5578, 0.7216, 0.6333, 0.7285, 1.3134,
        0.6619, 0.6748, 0.6333, 0.7086, 0.5661, 0.5545, 0.6447, 1.2782, 0.6260,
        0.6304, 0.7572, 0.8484, 0.8943, 0.6646, 1.4612, 0.5900, 1.1727, 0.7261,
        0.7026, 0.8029, 0.8484, 1.2615, 1.6618, 0.5580, 0.5754, 0.7786, 0.8780,
        0.7238, 2.0003, 2.6655, 0.5762, 0.7238, 0.7601, 0.7358, 1.2615, 1.0784,
        0.6226, 0.7128, 0.6733, 0.6055, 0.7333, 0.6156, 0.7309, 0.6141, 1.1469,
        0.5749, 0.5524, 0.6286, 0.5651, 0.5577, 0.6202, 0.6779, 0.8677, 0.7309,
        2.0550, 1.0039, 0.6845, 0.6163, 0.5684, 0.5630, 0.6932, 0.5810, 1.0299,
        0.5618, 3.5027, 0.7753, 0.5630, 0.5671, 0.6988, 3.5027, 1.6965, 0.6163],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  95 175  47 268  63 141
 152 115 104  59  40 424 311 122  98 142  32  23 308 142 128 137  57  71
 214 147 169 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  32  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2308, 0.6002, 1.0690, 1.1120, 0.7962, 0.8035, 0.6042, 0.6597, 0.6002,
        1.1478, 0.8111, 0.5715, 1.0048, 1.3939, 0.7578, 2.5689, 0.6651, 0.5530,
        1.3526, 1.9505, 1.1478, 0.7389, 0.8684, 1.0591, 1.2792, 0.9807, 1.6979,
        0.9657, 0.7291, 3.0235, 1.5133, 3.7065, 1.0899, 2.3942, 1.2625, 1.5690,
        3.3270, 1.3939, 0.6377, 0.7244, 0.6938, 0.6475, 0.8111, 0.9965, 0.7760,
        0.6559, 0.7221, 0.5581, 0.6739, 0.5583, 0.7221, 0.6338, 0.7291, 1.3145,
        0.6624, 0.6754, 0.6338, 0.7092, 0.5666, 0.5550, 0.6452, 1.2625, 0.6265,
        0.6310, 0.7578, 0.8491, 0.8951, 0.6651, 1.4624, 0.5905, 1.1737, 0.7267,
        0.7032, 0.8035, 0.8491, 1.2308, 1.6632, 0.5584, 0.5759, 0.7792, 0.8787,
        0.7244, 2.0019, 2.6677, 0.5767, 0.7244, 0.7607, 0.7364, 1.2625, 1.0793,
        0.6231, 0.7134, 0.6739, 0.6060, 0.7339, 0.6161, 0.7315, 0.6146, 1.1478,
        0.5753, 0.5528, 0.6291, 0.5656, 0.5582, 0.6207, 0.6785, 0.8684, 0.7315,
        2.0019, 1.0048, 0.6850, 0.6168, 0.5689, 0.5634, 0.6938, 0.5815, 1.0308,
        0.5623, 3.5055, 0.7760, 0.5634, 0.5676, 0.6993, 3.5055, 1.6979, 0.6168],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  72  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  95 175  47 269  63 141
 152 115 104  59  40 424 311 122  98 142  32  23 308 142 128 137  57  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  32  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2308, 0.6002, 1.0690, 1.1120, 0.7962, 0.8035, 0.6042, 0.6597, 0.6002,
        1.1478, 0.8111, 0.5715, 1.0048, 1.3938, 0.7578, 2.5689, 0.6651, 0.5530,
        1.3526, 1.9505, 1.1478, 0.7389, 0.8684, 1.0591, 1.2792, 0.9807, 1.6978,
        0.9657, 0.7291, 3.0235, 1.5133, 3.7064, 1.0899, 2.3942, 1.2625, 1.5690,
        3.3269, 1.3938, 0.6377, 0.7244, 0.6938, 0.6474, 0.8111, 0.9965, 0.7760,
        0.6559, 0.7221, 0.5581, 0.6738, 0.5583, 0.7221, 0.6338, 0.7291, 1.3145,
        0.6624, 0.6754, 0.6338, 0.7092, 0.5665, 0.5550, 0.6452, 1.2625, 0.6265,
        0.6310, 0.7578, 0.8491, 0.8951, 0.6651, 1.4624, 0.5901, 1.1737, 0.7267,
        0.7032, 0.8035, 0.8491, 1.2308, 1.6632, 0.5584, 0.5758, 0.7792, 0.8787,
        0.7244, 2.0019, 2.6676, 0.5767, 0.7244, 0.7607, 0.7364, 1.2625, 1.0793,
        0.6231, 0.7134, 0.6754, 0.6060, 0.7339, 0.6161, 0.7315, 0.6146, 1.1478,
        0.5753, 0.5528, 0.6291, 0.5656, 0.5582, 0.6207, 0.6785, 0.8684, 0.7315,
        2.0019, 1.0048, 0.6850, 0.6168, 0.5689, 0.5634, 0.6938, 0.5815, 1.0308,
        0.5623, 3.5055, 0.7760, 0.5634, 0.5676, 0.6993, 3.5055, 1.6978, 0.6168],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  95 175  47 269  63 141
 152 115 104  59  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  32  79 162 222 342 376 157 292  76 385  17 123 376 349 154  17  39 222]
CBFL per class weights: tensor([1.2311, 0.6003, 1.0593, 1.1122, 0.7964, 0.8037, 0.6043, 0.6599, 0.6003,
        1.1480, 0.8112, 0.5716, 1.0050, 1.3941, 0.7580, 2.5694, 0.6653, 0.5531,
        1.3529, 1.9509, 1.1480, 0.7391, 0.8686, 1.0593, 1.2794, 0.9809, 1.6982,
        0.9659, 0.7292, 3.0241, 1.5136, 3.7072, 1.0901, 2.3947, 1.2627, 1.5693,
        3.3276, 1.3941, 0.6379, 0.7246, 0.6939, 0.6476, 0.8112, 0.9967, 0.7761,
        0.6560, 0.7223, 0.5582, 0.6740, 0.5584, 0.7223, 0.6339, 0.7292, 1.3148,
        0.6625, 0.6755, 0.6339, 0.7093, 0.5667, 0.5551, 0.6453, 1.2627, 0.6266,
        0.6311, 0.7580, 0.8493, 0.8952, 0.6653, 1.4627, 0.5902, 1.1739, 0.7269,
        0.7033, 0.8037, 0.8493, 1.2311, 1.6635, 0.5585, 0.5762, 0.7793, 0.8789,
        0.7246, 2.0023, 2.6682, 0.5768, 0.7246, 0.7609, 0.7365, 1.2466, 1.0795,
        0.6232, 0.7135, 0.6755, 0.6061, 0.7341, 0.6162, 0.7316, 0.6147, 1.1480,
        0.5754, 0.5529, 0.6293, 0.5657, 0.5583, 0.6216, 0.6786, 0.8686, 0.7316,
        2.0023, 1.0050, 0.6852, 0.6169, 0.5690, 0.5635, 0.6939, 0.5816, 1.0310,
        0.5624, 3.5062, 0.7761, 0.5635, 0.5677, 0.6995, 3.5062, 1.6982, 0.6169],
       device='cuda:0')
S real T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.440349 Loss T 0.086367 Method MME

Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  95 175  47 269  63 141
 152 115 104  60  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  32  79 162 222 342 376 157 292  76 386  17 123 376 349 154  17  39 221]
CBFL per class weights: tensor([1.2312, 0.6004, 1.0594, 1.1123, 0.7965, 0.8038, 0.6044, 0.6599, 0.6004,
        1.1482, 0.8113, 0.5717, 1.0051, 1.3943, 0.7581, 2.5697, 0.6653, 0.5531,
        1.3530, 1.9511, 1.1482, 0.7392, 0.8687, 1.0594, 1.2796, 0.9810, 1.6984,
        0.9660, 0.7293, 3.0245, 1.5138, 3.7076, 1.0902, 2.3949, 1.2629, 1.5695,
        3.3280, 1.3943, 0.6379, 0.7246, 0.6940, 0.6476, 0.8113, 0.9968, 0.7762,
        0.6561, 0.7224, 0.5583, 0.6741, 0.5585, 0.7224, 0.6340, 0.7293, 1.3149,
        0.6626, 0.6756, 0.6340, 0.7094, 0.5667, 0.5551, 0.6454, 1.2629, 0.6267,
        0.6312, 0.7581, 0.8494, 0.8954, 0.6653, 1.4629, 0.5903, 1.1740, 0.7270,
        0.7034, 0.8038, 0.8494, 1.2162, 1.6637, 0.5586, 0.5763, 0.7794, 0.8790,
        0.7246, 2.0025, 2.6685, 0.5768, 0.7246, 0.7609, 0.7366, 1.2468, 1.0796,
        0.6233, 0.7136, 0.6756, 0.6062, 0.7342, 0.6163, 0.7317, 0.6148, 1.1482,
        0.5755, 0.5530, 0.6293, 0.5658, 0.5584, 0.6217, 0.6787, 0.8687, 0.7317,
        2.0025, 1.0051, 0.6852, 0.6170, 0.5690, 0.5636, 0.6940, 0.5816, 1.0311,
        0.5624, 3.5066, 0.7762, 0.5636, 0.5677, 0.6995, 3.5066, 1.6984, 0.6178],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  70  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  94 175  47 269  63 141
 152 115 104  60  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  32  79 162 222 342 376 157 292  76 386  17 123 376 349 155  17  39 221]
CBFL per class weights: tensor([1.2312, 0.6004, 1.0594, 1.1123, 0.7965, 0.8037, 0.6043, 0.6599, 0.6004,
        1.1481, 0.8113, 0.5717, 1.0050, 1.3942, 0.7580, 2.5696, 0.6653, 0.5531,
        1.3530, 1.9510, 1.1481, 0.7391, 0.8687, 1.0594, 1.2796, 0.9810, 1.6983,
        0.9660, 0.7293, 3.0244, 1.5137, 3.7075, 1.0902, 2.3949, 1.2628, 1.5695,
        3.3279, 1.3942, 0.6379, 0.7246, 0.6940, 0.6476, 0.8113, 0.9968, 0.7762,
        0.6560, 0.7223, 0.5583, 0.6740, 0.5584, 0.7223, 0.6340, 0.7293, 1.3149,
        0.6626, 0.6756, 0.6340, 0.7094, 0.5667, 0.5551, 0.6454, 1.2628, 0.6266,
        0.6311, 0.7580, 0.8494, 0.9010, 0.6653, 1.4628, 0.5902, 1.1740, 0.7269,
        0.7034, 0.8037, 0.8494, 1.2161, 1.6637, 0.5586, 0.5763, 0.7794, 0.8790,
        0.7246, 2.0025, 2.6684, 0.5768, 0.7246, 0.7609, 0.7366, 1.2467, 1.0796,
        0.6233, 0.7136, 0.6756, 0.6061, 0.7341, 0.6162, 0.7317, 0.6148, 1.1481,
        0.5755, 0.5530, 0.6293, 0.5657, 0.5584, 0.6216, 0.6787, 0.8687, 0.7317,
        2.0025, 1.0050, 0.6852, 0.6170, 0.5690, 0.5636, 0.6940, 0.5816, 1.0311,
        0.5623, 3.5065, 0.7762, 0.5636, 0.5677, 0.6976, 3.5065, 1.6983, 0.6177],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  94 175  47 269  63 141
 152 115 104  61  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  32  79 162 221 342 376 157 292  76 386  17 123 376 349 155  17  39 221]
CBFL per class weights: tensor([1.2314, 0.6005, 1.0596, 1.1125, 0.7966, 0.8039, 0.6045, 0.6600, 0.6005,
        1.1484, 0.8115, 0.5718, 1.0052, 1.3945, 0.7582, 2.5701, 0.6654, 0.5532,
        1.3533, 1.9514, 1.1484, 0.7393, 0.8689, 1.0596, 1.2798, 0.9812, 1.6987,
        0.9662, 0.7294, 3.0250, 1.5140, 3.7082, 1.0798, 2.3953, 1.2631, 1.5698,
        3.3285, 1.3945, 0.6380, 0.7248, 0.6941, 0.6478, 0.8115, 0.9970, 0.7763,
        0.6562, 0.7225, 0.5584, 0.6742, 0.5585, 0.7225, 0.6341, 0.7294, 1.3151,
        0.6627, 0.6757, 0.6341, 0.7095, 0.5668, 0.5552, 0.6455, 1.2631, 0.6268,
        0.6313, 0.7582, 0.8495, 0.9012, 0.6654, 1.4631, 0.5904, 1.1742, 0.7271,
        0.7035, 0.8039, 0.8495, 1.2018, 1.6640, 0.5587, 0.5764, 0.7796, 0.8792,
        0.7248, 2.0029, 2.6689, 0.5769, 0.7248, 0.7611, 0.7368, 1.2470, 1.0798,
        0.6234, 0.7137, 0.6757, 0.6063, 0.7343, 0.6164, 0.7318, 0.6149, 1.1484,
        0.5756, 0.5531, 0.6294, 0.5659, 0.5585, 0.6218, 0.6788, 0.8689, 0.7318,
        2.0029, 1.0052, 0.6854, 0.6179, 0.5691, 0.5637, 0.6941, 0.5817, 1.0313,
        0.5624, 3.5072, 0.7763, 0.5637, 0.5678, 0.6978, 3.5072, 1.6987, 0.6179],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  94 175  47 269  63 141
 152 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  32  79 162 221 342 376 157 292  76 387  17 123 376 349 155  17  39 220]
CBFL per class weights: tensor([1.2315, 0.6006, 1.0597, 1.1126, 0.7967, 0.8040, 0.6045, 0.6601, 0.6006,
        1.1485, 0.8116, 0.5718, 1.0053, 1.3947, 0.7583, 2.5703, 0.6655, 0.5533,
        1.3534, 1.9516, 1.1485, 0.7393, 0.8689, 1.0597, 1.2799, 0.9813, 1.6988,
        0.9663, 0.7295, 3.0253, 1.5142, 3.7086, 1.0799, 2.3956, 1.2632, 1.5699,
        3.3289, 1.3947, 0.6381, 0.7248, 0.6942, 0.6478, 0.8116, 0.9971, 0.7764,
        0.6562, 0.7226, 0.5584, 0.6742, 0.5586, 0.7226, 0.6342, 0.7295, 1.3153,
        0.6628, 0.6758, 0.6342, 0.7096, 0.5669, 0.5553, 0.6456, 1.2632, 0.6268,
        0.6313, 0.7583, 0.8496, 0.9013, 0.6655, 1.4633, 0.5904, 1.1744, 0.7272,
        0.7036, 0.8040, 0.8496, 1.1879, 1.6642, 0.5588, 0.5764, 0.7796, 0.8793,
        0.7248, 2.0031, 2.6692, 0.5770, 0.7248, 0.7612, 0.7368, 1.2471, 1.0799,
        0.6234, 0.7138, 0.6758, 0.6063, 0.7343, 0.6164, 0.7319, 0.6150, 1.1485,
        0.5757, 0.5531, 0.6295, 0.5659, 0.5585, 0.6218, 0.6789, 0.8689, 0.7319,
        2.0031, 1.0053, 0.6854, 0.6179, 0.5692, 0.5638, 0.6942, 0.5818, 1.0314,
        0.5624, 3.5075, 0.7764, 0.5638, 0.5679, 0.6978, 3.5075, 1.6988, 0.6187],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 143 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  94 175  47 269  63 141
 152 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 214 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 157 292  76 387  17 123 377 349 155  17  39 220]
CBFL per class weights: tensor([1.2310, 0.6003, 1.0592, 1.1122, 0.7964, 0.8036, 0.6043, 0.6598, 0.6003,
        1.1480, 0.8112, 0.5716, 1.0049, 1.3941, 0.7579, 2.5692, 0.6652, 0.5530,
        1.3528, 1.9508, 1.1480, 0.7390, 0.8686, 1.0592, 1.2794, 0.9809, 1.6981,
        0.9659, 0.7292, 3.0240, 1.5135, 3.7070, 1.0795, 2.3945, 1.2627, 1.5692,
        3.3274, 1.3941, 0.6378, 0.7245, 0.6939, 0.6475, 0.8112, 0.9967, 0.7761,
        0.6560, 0.7222, 0.5582, 0.6739, 0.5584, 0.7222, 0.6339, 0.7292, 1.3147,
        0.6625, 0.6755, 0.6339, 0.7093, 0.5666, 0.5551, 0.6453, 1.2627, 0.6266,
        0.6310, 0.7579, 0.8492, 0.9009, 0.6652, 1.4626, 0.5902, 1.1738, 0.7268,
        0.7033, 0.8036, 0.8492, 1.1874, 1.6634, 0.5585, 0.5762, 0.7793, 0.8789,
        0.7245, 2.0022, 2.6680, 0.5767, 0.7245, 0.7608, 0.7365, 1.2465, 1.0795,
        0.6232, 0.7135, 0.6755, 0.6061, 0.7340, 0.6162, 0.7316, 0.6147, 1.1480,
        0.5754, 0.5529, 0.6292, 0.5657, 0.5583, 0.6215, 0.6786, 0.8686, 0.7316,
        2.0570, 1.0049, 0.6851, 0.6177, 0.5689, 0.5635, 0.6939, 0.5816, 1.0309,
        0.5621, 3.5060, 0.7761, 0.5634, 0.5677, 0.6975, 3.5060, 1.6981, 0.6184],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 428 169 426 144 202 140  54
 177 168 202 149 355 481 191  57 210 205 129 104  94 175  47 269  63 141
 152 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 157 292  76 387  17 123 377 349 155  17  39 220]
CBFL per class weights: tensor([1.2310, 0.6003, 1.0592, 1.1122, 0.7964, 0.8037, 0.6043, 0.6598, 0.6003,
        1.1480, 0.8112, 0.5716, 1.0049, 1.3941, 0.7579, 2.5693, 0.6652, 0.5531,
        1.3529, 1.9508, 1.1480, 0.7390, 0.8686, 1.0592, 1.2794, 0.9809, 1.6981,
        0.9659, 0.7292, 3.0240, 1.5136, 3.7071, 1.0795, 2.3946, 1.2627, 1.5693,
        3.3275, 1.3941, 0.6379, 0.7245, 0.6939, 0.6476, 0.8112, 0.9967, 0.7761,
        0.6560, 0.7223, 0.5582, 0.6740, 0.5584, 0.7200, 0.6339, 0.7292, 1.3147,
        0.6625, 0.6755, 0.6339, 0.7093, 0.5666, 0.5551, 0.6453, 1.2627, 0.6266,
        0.6311, 0.7579, 0.8493, 0.9009, 0.6652, 1.4627, 0.5902, 1.1739, 0.7269,
        0.7033, 0.8037, 0.8493, 1.1874, 1.6635, 0.5585, 0.5762, 0.7793, 0.8789,
        0.7245, 2.0022, 2.6681, 0.5768, 0.7245, 0.7608, 0.7365, 1.2466, 1.0795,
        0.6224, 0.7135, 0.6755, 0.6061, 0.7340, 0.6162, 0.7316, 0.6147, 1.1480,
        0.5754, 0.5529, 0.6292, 0.5657, 0.5583, 0.6216, 0.6786, 0.8686, 0.7316,
        2.0570, 1.0049, 0.6851, 0.6177, 0.5690, 0.5635, 0.6939, 0.5816, 1.0310,
        0.5622, 3.5061, 0.7761, 0.5634, 0.5677, 0.6976, 3.5061, 1.6981, 0.6184],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  50 198 142 157 189 113  80 123 182 143 427 169 426 144 202 140  54
 177 168 202 149 356 481 191  57 210 205 129 104  94 175  47 269  63 141
 153 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 292  76 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2310, 0.6003, 1.0592, 1.1122, 0.7964, 0.8037, 0.6043, 0.6598, 0.6003,
        1.1480, 0.8112, 0.5716, 1.0049, 1.3941, 0.7579, 2.5693, 0.6652, 0.5531,
        1.3528, 1.9508, 1.1480, 0.7390, 0.8686, 1.0592, 1.2794, 0.9809, 1.6981,
        0.9659, 0.7292, 3.0240, 1.5136, 3.7071, 1.0795, 2.3946, 1.2627, 1.5693,
        3.3275, 1.3941, 0.6378, 0.7245, 0.6939, 0.6476, 0.8112, 0.9967, 0.7761,
        0.6560, 0.7223, 0.5583, 0.6740, 0.5584, 0.7200, 0.6339, 0.7292, 1.3147,
        0.6625, 0.6755, 0.6339, 0.7093, 0.5665, 0.5551, 0.6453, 1.2627, 0.6266,
        0.6311, 0.7579, 0.8493, 0.9009, 0.6652, 1.4627, 0.5902, 1.1739, 0.7269,
        0.7014, 0.8037, 0.8493, 1.1874, 1.6635, 0.5585, 0.5762, 0.7793, 0.8789,
        0.7245, 2.0022, 2.6681, 0.5768, 0.7245, 0.7608, 0.7365, 1.2466, 1.0795,
        0.6224, 0.7135, 0.6755, 0.6061, 0.7340, 0.6162, 0.7316, 0.6147, 1.1480,
        0.5754, 0.5529, 0.6292, 0.5657, 0.5583, 0.6216, 0.6786, 0.8686, 0.7316,
        2.0570, 1.0049, 0.6851, 0.6177, 0.5689, 0.5635, 0.6957, 0.5816, 1.0310,
        0.5620, 3.5061, 0.7761, 0.5634, 0.5677, 0.6976, 3.5061, 1.6981, 0.6192],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  71  26  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 144 202 140  54
 177 168 202 149 356 481 191  57 210 205 128 104  94 175  47 269  63 141
 153 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 292  76 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2314, 0.6005, 1.0596, 1.1125, 0.7966, 0.8039, 0.6045, 0.6600, 0.6005,
        1.1484, 0.8115, 0.5718, 1.0052, 1.3945, 0.7582, 2.5700, 0.6654, 0.5532,
        1.3532, 1.9514, 1.1484, 0.7393, 0.8688, 1.0596, 1.2798, 0.9812, 1.6986,
        0.9662, 0.7294, 3.0249, 1.5140, 3.7082, 1.0798, 2.3953, 1.2631, 1.5697,
        3.3285, 1.3532, 0.6380, 0.7248, 0.6941, 0.6489, 0.8115, 0.9970, 0.7763,
        0.6562, 0.7225, 0.5585, 0.6742, 0.5585, 0.7202, 0.6341, 0.7294, 1.3151,
        0.6627, 0.6757, 0.6341, 0.7095, 0.5666, 0.5552, 0.6455, 1.2631, 0.6268,
        0.6312, 0.7611, 0.8495, 0.9012, 0.6654, 1.4631, 0.5904, 1.1742, 0.7271,
        0.7016, 0.8039, 0.8495, 1.1878, 1.6640, 0.5587, 0.5764, 0.7796, 0.8791,
        0.7248, 2.0028, 2.6689, 0.5769, 0.7248, 0.7611, 0.7367, 1.2469, 1.0798,
        0.6226, 0.7137, 0.6757, 0.6063, 0.7343, 0.6164, 0.7318, 0.6149, 1.1484,
        0.5756, 0.5531, 0.6294, 0.5658, 0.5585, 0.6217, 0.6788, 0.8688, 0.7318,
        2.0576, 1.0052, 0.6853, 0.6178, 0.5691, 0.5637, 0.6959, 0.5817, 1.0313,
        0.5622, 3.5071, 0.7763, 0.5636, 0.5678, 0.6978, 3.5071, 1.6986, 0.6194],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  73  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  72  26  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 144 202 140  54
 177 168 202 149 356 481 191  57 210 205 128 104  94 175  47 269  63 141
 153 115 104  62  40 424 310 122  98 142  32  23 308 142 128 137  58  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 292  76 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2315, 0.6005, 1.0596, 1.1126, 0.7967, 0.8040, 0.6045, 0.6601, 0.6005,
        1.1484, 0.8115, 0.5718, 1.0053, 1.3946, 0.7582, 2.5703, 0.6655, 0.5533,
        1.3534, 1.9515, 1.1484, 0.7393, 0.8689, 1.0596, 1.2799, 0.9813, 1.6988,
        0.9662, 0.7295, 3.0252, 1.5141, 3.7085, 1.0696, 2.3955, 1.2632, 1.5699,
        3.3287, 1.3534, 0.6381, 0.7248, 0.6941, 0.6490, 0.8115, 0.9971, 0.7764,
        0.6562, 0.7225, 0.5585, 0.6742, 0.5586, 0.7203, 0.6341, 0.7295, 1.3152,
        0.6627, 0.6757, 0.6341, 0.7096, 0.5667, 0.5553, 0.6455, 1.2632, 0.6268,
        0.6313, 0.7611, 0.8496, 0.9013, 0.6655, 1.4632, 0.5904, 1.1743, 0.7271,
        0.7016, 0.8040, 0.8496, 1.1879, 1.6641, 0.5587, 0.5764, 0.7796, 0.8792,
        0.7248, 2.0030, 2.6691, 0.5770, 0.7248, 0.7611, 0.7368, 1.2470, 1.0799,
        0.6226, 0.7138, 0.6757, 0.6063, 0.7343, 0.6164, 0.7319, 0.6149, 1.1484,
        0.5756, 0.5531, 0.6295, 0.5659, 0.5585, 0.6218, 0.6789, 0.8689, 0.7319,
        2.0578, 1.0053, 0.6854, 0.6179, 0.5692, 0.5637, 0.6960, 0.5818, 1.0313,
        0.5622, 3.5074, 0.7764, 0.5636, 0.5679, 0.6978, 3.5074, 1.6988, 0.6194],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  72  26  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 144 202 140  54
 177 168 202 149 356 481 191  57 210 205 128 104  94 175  47 269  63 141
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 292  76 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2317, 0.6006, 1.0502, 1.1128, 0.7968, 0.8041, 0.6046, 0.6602, 0.6006,
        1.1487, 0.8117, 0.5719, 1.0055, 1.3949, 0.7584, 2.5708, 0.6656, 0.5534,
        1.3536, 1.9519, 1.1487, 0.7395, 0.8691, 1.0599, 1.2801, 0.9815, 1.6991,
        0.9664, 0.7296, 3.0258, 1.5144, 3.7092, 1.0698, 2.3960, 1.2634, 1.5702,
        3.3294, 1.3536, 0.6382, 0.7250, 0.6943, 0.6491, 0.8117, 0.9973, 0.7766,
        0.6563, 0.7227, 0.5586, 0.6743, 0.5587, 0.7204, 0.6343, 0.7296, 1.3155,
        0.6629, 0.6759, 0.6343, 0.7097, 0.5668, 0.5554, 0.6457, 1.2634, 0.6269,
        0.6314, 0.7613, 0.8498, 0.9014, 0.6656, 1.4635, 0.5905, 1.1745, 0.7273,
        0.7018, 0.8041, 0.8498, 1.1881, 1.6644, 0.5589, 0.5765, 0.7798, 0.8794,
        0.7250, 2.0034, 2.6696, 0.5771, 0.7250, 0.7613, 0.7369, 1.2317, 1.0801,
        0.6227, 0.7139, 0.6759, 0.6064, 0.7345, 0.6165, 0.7320, 0.6151, 1.1487,
        0.5757, 0.5532, 0.6296, 0.5660, 0.5586, 0.6219, 0.6790, 0.8691, 0.7320,
        2.0582, 1.0055, 0.6855, 0.6180, 0.5693, 0.5639, 0.6961, 0.5819, 1.0316,
        0.5624, 3.5081, 0.7766, 0.5637, 0.5680, 0.6980, 3.5081, 1.6991, 0.6195],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  72  27  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 425 144 202 140  54
 177 168 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 141
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 291  76 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2327, 0.6011, 1.0510, 1.1137, 0.7975, 0.8048, 0.6051, 0.6607, 0.6011,
        1.1496, 0.8123, 0.5724, 1.0063, 1.3960, 0.7590, 2.5728, 0.6662, 0.5538,
        1.3547, 1.9535, 1.1496, 0.7401, 0.8698, 1.0607, 1.2812, 0.9822, 1.7005,
        0.9672, 0.7302, 3.0282, 1.5156, 3.7122, 1.0707, 2.3202, 1.2644, 1.5714,
        3.3321, 1.3547, 0.6387, 0.7255, 0.6948, 0.6496, 0.8123, 0.9981, 0.7772,
        0.6569, 0.7233, 0.5591, 0.6749, 0.5592, 0.7210, 0.6348, 0.7302, 1.3165,
        0.6634, 0.6764, 0.6348, 0.7103, 0.5673, 0.5558, 0.6462, 1.2644, 0.6274,
        0.6319, 0.7619, 0.8504, 0.9022, 0.6662, 1.4408, 0.5910, 1.1755, 0.7279,
        0.7023, 0.8048, 0.8504, 1.1891, 1.6658, 0.5594, 0.5770, 0.7804, 0.8801,
        0.7255, 2.0050, 2.6718, 0.5775, 0.7255, 0.7619, 0.7375, 1.2327, 1.0810,
        0.6232, 0.7145, 0.6764, 0.6069, 0.7351, 0.6170, 0.7326, 0.6156, 1.1496,
        0.5762, 0.5537, 0.6301, 0.5665, 0.5591, 0.6224, 0.6795, 0.8698, 0.7326,
        2.0598, 1.0063, 0.6861, 0.6185, 0.5697, 0.5643, 0.6967, 0.5827, 1.0324,
        0.5628, 3.5109, 0.7772, 0.5642, 0.5685, 0.6985, 3.5109, 1.7005, 0.6200],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  84 140  20  45  16  72  27  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 144 203 140  54
 177 168 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 141
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 239 138 223 139 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 291  77 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2328, 0.6012, 1.0511, 1.1138, 0.7975, 0.8048, 0.6052, 0.6608, 0.6012,
        1.1497, 0.8124, 0.5724, 1.0064, 1.3961, 0.7591, 2.5730, 0.6662, 0.5539,
        1.3548, 1.9537, 1.1497, 0.7401, 0.8699, 1.0608, 1.2813, 0.9823, 1.7006,
        0.9673, 0.7303, 3.0285, 1.5158, 3.7125, 1.0708, 2.3204, 1.2645, 1.5716,
        3.3324, 1.3548, 0.6388, 0.7256, 0.6949, 0.6497, 0.8124, 0.9982, 0.7772,
        0.6569, 0.7233, 0.5591, 0.6749, 0.5592, 0.7211, 0.6339, 0.7303, 1.3167,
        0.6635, 0.6765, 0.6348, 0.7104, 0.5673, 0.5559, 0.6462, 1.2645, 0.6275,
        0.6320, 0.7620, 0.8505, 0.9022, 0.6662, 1.4409, 0.5910, 1.1756, 0.7279,
        0.7024, 0.8048, 0.8505, 1.1892, 1.6659, 0.5594, 0.5771, 0.7805, 0.8802,
        0.7256, 2.0052, 2.6720, 0.5776, 0.7256, 0.7620, 0.7376, 1.2328, 1.0811,
        0.6233, 0.7145, 0.6765, 0.6064, 0.7351, 0.6171, 0.7327, 0.6156, 1.1497,
        0.5763, 0.5537, 0.6302, 0.5665, 0.5591, 0.6225, 0.6796, 0.8699, 0.7327,
        2.0600, 1.0064, 0.6861, 0.6186, 0.5698, 0.5644, 0.6967, 0.5827, 1.0235,
        0.5629, 3.5112, 0.7772, 0.5642, 0.5685, 0.6986, 3.5112, 1.7006, 0.6201],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  83 140  20  45  16  72  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 145 203 140  54
 177 167 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 141
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 221 342 376 156 291  77 388  17 123 377 349 155  17  39 219]
CBFL per class weights: tensor([1.2335, 0.6015, 1.0516, 1.1144, 0.7980, 0.8053, 0.6055, 0.6612, 0.6015,
        1.1503, 0.8128, 0.5727, 1.0069, 1.3969, 0.7595, 2.5744, 0.6666, 0.5542,
        1.3556, 1.9547, 1.1503, 0.7405, 0.8703, 1.0614, 1.2820, 0.9829, 1.7015,
        0.9752, 0.7307, 3.0301, 1.5166, 3.7145, 1.0714, 2.2495, 1.2652, 1.5724,
        3.3342, 1.3556, 0.6391, 0.7260, 0.6953, 0.6500, 0.8128, 0.9987, 0.7777,
        0.6573, 0.7237, 0.5594, 0.6753, 0.5595, 0.7192, 0.6342, 0.7307, 1.3174,
        0.6638, 0.6784, 0.6352, 0.7107, 0.5676, 0.5562, 0.6466, 1.2652, 0.6278,
        0.6323, 0.7624, 0.8510, 0.9027, 0.6666, 1.4417, 0.5914, 1.1762, 0.7283,
        0.7028, 0.8053, 0.8510, 1.1898, 1.6668, 0.5597, 0.5774, 0.7809, 0.8806,
        0.7260, 2.0062, 2.6734, 0.5779, 0.7260, 0.7624, 0.7380, 1.2335, 1.0816,
        0.6236, 0.7149, 0.6768, 0.6067, 0.7355, 0.6174, 0.7307, 0.6159, 1.1503,
        0.5766, 0.5540, 0.6305, 0.5668, 0.5594, 0.6228, 0.6800, 0.8703, 0.7331,
        2.0611, 1.0069, 0.6865, 0.6189, 0.5701, 0.5647, 0.6971, 0.5831, 1.0241,
        0.5632, 3.5131, 0.7777, 0.5645, 0.5688, 0.6990, 3.5131, 1.7015, 0.6204],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  39  83 140  20  45  16  73  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 145 203 140  54
 176 167 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 141
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 220 342 376 156 291  77 388  18 123 377 349 156  17  39 219]
CBFL per class weights: tensor([1.2353, 0.6024, 1.0532, 1.1161, 0.7992, 0.8065, 0.6064, 0.6621, 0.6024,
        1.1520, 0.8141, 0.5736, 1.0084, 1.3990, 0.7606, 2.5783, 0.6676, 0.5550,
        1.3576, 1.9577, 1.1520, 0.7416, 0.8716, 1.0630, 1.2839, 0.9843, 1.7041,
        0.9767, 0.7318, 3.0346, 1.5189, 3.7201, 1.0630, 2.2529, 1.2671, 1.5748,
        3.3392, 1.3576, 0.6401, 0.7271, 0.6963, 0.6510, 0.8141, 1.0002, 0.7788,
        0.6583, 0.7248, 0.5603, 0.6763, 0.5603, 0.7203, 0.6352, 0.7318, 1.3193,
        0.6662, 0.6794, 0.6361, 0.7118, 0.5685, 0.5570, 0.6476, 1.2671, 0.6288,
        0.6333, 0.7635, 0.8522, 0.9041, 0.6676, 1.4439, 0.5922, 1.1780, 0.7294,
        0.7038, 0.8065, 0.8522, 1.1916, 1.6693, 0.5606, 0.5782, 0.7821, 0.8820,
        0.7271, 2.0093, 2.6774, 0.5788, 0.7271, 0.7635, 0.7391, 1.2353, 1.0833,
        0.6246, 0.7160, 0.6779, 0.6076, 0.7366, 0.6183, 0.7318, 0.6169, 1.1520,
        0.5774, 0.5548, 0.6314, 0.5677, 0.5603, 0.6237, 0.6810, 0.8716, 0.7342,
        2.0642, 1.0084, 0.6875, 0.6206, 0.5709, 0.5655, 0.6981, 0.5839, 1.0256,
        0.5640, 3.3392, 0.7788, 0.5654, 0.5697, 0.6981, 3.5184, 1.7041, 0.6214],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 175 541
  52  33  65 136 100  73  56  82  40  83 140  20  45  16  73  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 145 203 140  54
 176 167 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 140
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  59  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 216 166 100 139
  31  79 162 220 342 376 156 291  77 388  18 123 377 349 156  17  39 219]
CBFL per class weights: tensor([1.2357, 0.6026, 1.0535, 1.1164, 0.7994, 0.8067, 0.6065, 0.6623, 0.6026,
        1.1523, 0.8143, 0.5738, 1.0087, 1.3993, 0.7608, 2.5790, 0.6677, 0.5551,
        1.3579, 1.9582, 1.1523, 0.7418, 0.8719, 1.0632, 1.2842, 0.9846, 1.6697,
        0.9769, 0.7320, 3.0354, 1.5193, 3.7210, 1.0632, 2.2534, 1.2674, 1.5752,
        3.3400, 1.3579, 0.6402, 0.7273, 0.6965, 0.6512, 0.8143, 1.0005, 0.7790,
        0.6584, 0.7250, 0.5604, 0.6765, 0.5605, 0.7205, 0.6353, 0.7320, 1.3197,
        0.6664, 0.6796, 0.6363, 0.7120, 0.5686, 0.5572, 0.6477, 1.2674, 0.6289,
        0.6334, 0.7637, 0.8525, 0.9043, 0.6677, 1.4442, 0.5924, 1.1783, 0.7320,
        0.7040, 0.8067, 0.8525, 1.1919, 1.6697, 0.5607, 0.5784, 0.7823, 0.8822,
        0.7273, 2.0098, 2.6781, 0.5789, 0.7273, 0.7637, 0.7393, 1.2357, 1.0835,
        0.6247, 0.7162, 0.6780, 0.6077, 0.7368, 0.6185, 0.7320, 0.6170, 1.1523,
        0.5776, 0.5550, 0.6316, 0.5678, 0.5604, 0.6239, 0.6812, 0.8719, 0.7344,
        2.0648, 1.0087, 0.6877, 0.6208, 0.5711, 0.5657, 0.6983, 0.5841, 1.0259,
        0.5642, 3.3400, 0.7790, 0.5655, 0.5698, 0.6983, 3.5193, 1.7045, 0.6215],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  56  82  40  83 140  20  45  16  73  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 145 203 140  54
 176 167 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 140
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  60  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 376 156 291  77 388  18 123 378 349 156  17  39 219]
CBFL per class weights: tensor([1.2358, 0.6026, 1.0536, 1.1165, 0.7995, 0.8068, 0.6066, 0.6624, 0.6026,
        1.1525, 0.8144, 0.5738, 1.0088, 1.3995, 0.7609, 2.5793, 0.6692, 0.5552,
        1.3581, 1.9584, 1.1525, 0.7419, 0.8720, 1.0633, 1.2844, 0.9847, 1.6699,
        0.9771, 0.7320, 3.0358, 1.5194, 3.7214, 1.0633, 2.2537, 1.2676, 1.5754,
        3.3404, 1.3581, 0.6403, 0.7273, 0.6966, 0.6512, 0.8144, 1.0006, 0.7791,
        0.6585, 0.7251, 0.5605, 0.6766, 0.5605, 0.7206, 0.6354, 0.7320, 1.3198,
        0.6664, 0.6797, 0.6364, 0.7121, 0.5687, 0.5572, 0.6478, 1.2676, 0.6290,
        0.6335, 0.7638, 0.8526, 0.9044, 0.6678, 1.4444, 0.5925, 1.1784, 0.7320,
        0.7041, 0.8068, 0.8526, 1.1920, 1.6699, 0.5608, 0.5784, 0.7824, 0.8823,
        0.7273, 2.0100, 2.6784, 0.5790, 0.7273, 0.7638, 0.7394, 1.2207, 1.0837,
        0.6248, 0.7163, 0.6781, 0.6078, 0.7369, 0.6186, 0.7320, 0.6171, 1.1525,
        0.5777, 0.5550, 0.6317, 0.5679, 0.5605, 0.6232, 0.6812, 0.8720, 0.7344,
        2.0650, 1.0088, 0.6878, 0.6208, 0.5712, 0.5657, 0.6984, 0.5842, 1.0260,
        0.5642, 3.3404, 0.7791, 0.5655, 0.5699, 0.6984, 3.5197, 1.7047, 0.6216],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  56  82  40  83 140  20  45  16  73  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 175 167 202 149 356 481 191  57 210 205 128 104  94 175  48 269  63 140
 153 115 104  62  40 423 310 122  98 142  32  23 308 142 128 137  60  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 376 156 291  77 388  20 123 378 349 156  17  39 219]
CBFL per class weights: tensor([1.2388, 0.6041, 1.0562, 1.1192, 0.8014, 0.8087, 0.6081, 0.6640, 0.6041,
        1.1553, 0.8163, 0.5752, 1.0113, 1.4029, 0.7627, 2.5855, 0.6709, 0.5566,
        1.3614, 1.9631, 1.1553, 0.7437, 0.8741, 1.0659, 1.2875, 0.9871, 1.6740,
        0.9794, 0.7338, 3.0431, 1.5231, 3.7305, 1.0659, 2.2592, 1.2707, 1.5792,
        3.3485, 1.3614, 0.6419, 0.7291, 0.6983, 0.6528, 0.8163, 1.0030, 0.7810,
        0.6601, 0.7268, 0.5618, 0.6782, 0.5619, 0.7202, 0.6369, 0.7338, 1.3230,
        0.6694, 0.6813, 0.6379, 0.7138, 0.5701, 0.5586, 0.6494, 1.2707, 0.6305,
        0.6350, 0.7656, 0.8546, 0.9066, 0.6694, 1.4479, 0.5939, 1.1813, 0.7338,
        0.7058, 0.8087, 0.8546, 1.1949, 1.6740, 0.5621, 0.5799, 0.7843, 0.8844,
        0.7291, 2.0149, 2.6849, 0.5804, 0.7291, 0.7656, 0.7412, 1.2237, 1.0863,
        0.6263, 0.7180, 0.6798, 0.6093, 0.7387, 0.6201, 0.7338, 0.6186, 1.1553,
        0.5791, 0.5564, 0.6332, 0.5693, 0.5618, 0.6247, 0.6829, 0.8741, 0.7362,
        2.0700, 1.0113, 0.6895, 0.6223, 0.5725, 0.5671, 0.7001, 0.5856, 1.0285,
        0.5656, 3.0431, 0.7810, 0.5668, 0.5713, 0.7001, 3.5282, 1.7089, 0.6231],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  28  57  43
  18  52 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 175 167 201 149 356 481 191  57 210 205 128 104  94 175  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 308 142 128 137  61  71
 215 147 168 239 138 223 140 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 376 157 291  77 388  20 123 377 349 156  17  39 219]
CBFL per class weights: tensor([1.2391, 0.6042, 1.0564, 1.1194, 0.8016, 0.8089, 0.6082, 0.6641, 0.6042,
        1.1555, 0.8165, 0.5753, 1.0115, 1.4032, 0.7629, 2.5861, 0.6710, 0.5567,
        1.3617, 1.9636, 1.1555, 0.7439, 0.8743, 1.0662, 1.2709, 0.9873, 1.6743,
        0.9796, 0.7340, 3.0438, 1.5234, 3.7313, 1.0662, 2.2597, 1.2709, 1.5795,
        3.3492, 1.3617, 0.6420, 0.7293, 0.6984, 0.6529, 0.8165, 1.0032, 0.7812,
        0.6603, 0.7270, 0.5619, 0.6784, 0.5620, 0.7203, 0.6371, 0.7340, 1.3233,
        0.6696, 0.6815, 0.6390, 0.7140, 0.5702, 0.5587, 0.6495, 1.2709, 0.6307,
        0.6352, 0.7658, 0.8548, 0.9068, 0.6696, 1.4482, 0.5940, 1.1815, 0.7340,
        0.7059, 0.8089, 0.8548, 1.1952, 1.6743, 0.5623, 0.5800, 0.7844, 0.8900,
        0.7293, 2.0153, 2.6855, 0.5805, 0.7293, 0.7658, 0.7413, 1.2093, 1.0865,
        0.6264, 0.7182, 0.6799, 0.6094, 0.7388, 0.6202, 0.7340, 0.6187, 1.1555,
        0.5792, 0.5565, 0.6333, 0.5694, 0.5619, 0.6248, 0.6830, 0.8743, 0.7364,
        2.0704, 1.0115, 0.6896, 0.6225, 0.5727, 0.5672, 0.6984, 0.5857, 1.0287,
        0.5657, 3.0438, 0.7812, 0.5671, 0.5714, 0.7002, 3.5290, 1.7092, 0.6232],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  19  52 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 174 167 201 149 357 480 191  57 210 205 128 104  94 174  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 308 142 128 137  62  71
 215 147 168 239 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 376 157 291  77 388  21 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2430, 0.6062, 1.0598, 1.1230, 0.8041, 0.8115, 0.6102, 0.6663, 0.6062,
        1.1592, 0.8191, 0.5772, 1.0147, 1.4077, 0.7653, 2.5944, 0.6732, 0.5585,
        1.3661, 1.9699, 1.1592, 0.7463, 0.8771, 1.0696, 1.2750, 0.9905, 1.6797,
        0.9828, 0.7363, 3.0536, 1.5283, 3.7432, 1.0696, 2.1992, 1.2750, 1.5846,
        3.1987, 1.3661, 0.6441, 0.7316, 0.7007, 0.6550, 0.8191, 1.0064, 0.7837,
        0.6624, 0.7293, 0.5637, 0.6805, 0.5638, 0.7226, 0.6391, 0.7363, 1.3276,
        0.6732, 0.6836, 0.6411, 0.7162, 0.5718, 0.5605, 0.6516, 1.2750, 0.6327,
        0.6372, 0.7683, 0.8576, 0.9097, 0.6732, 1.4529, 0.5959, 1.1853, 0.7363,
        0.7082, 0.8115, 0.8576, 1.1990, 1.6797, 0.5641, 0.5818, 0.7869, 0.8928,
        0.7316, 2.0218, 2.6941, 0.5824, 0.7316, 0.7683, 0.7437, 1.1990, 1.0900,
        0.6284, 0.7205, 0.6821, 0.6114, 0.7412, 0.6222, 0.7388, 0.6207, 1.1592,
        0.5810, 0.5583, 0.6354, 0.5712, 0.5637, 0.6268, 0.6852, 0.8771, 0.7388,
        2.0771, 1.0147, 0.6918, 0.6245, 0.5745, 0.5690, 0.7007, 0.5876, 1.0320,
        0.5675, 2.9223, 0.7837, 0.5689, 0.5732, 0.7025, 3.5403, 1.6797, 0.6252],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  19  52 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 128 104  94 174  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 307 142 129 137  63  71
 215 147 168 239 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 375 157 291  77 388  23 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2454, 0.6073, 1.0618, 1.1252, 0.8057, 0.8131, 0.6113, 0.6676, 0.6073,
        1.1614, 0.8207, 0.5783, 1.0167, 1.4104, 0.7668, 2.5994, 0.6744, 0.5595,
        1.3687, 1.9736, 1.1614, 0.7477, 0.8787, 1.0716, 1.2775, 0.9924, 1.6829,
        0.9847, 0.7377, 3.0594, 1.5313, 3.7504, 1.0716, 2.2035, 1.2775, 1.5876,
        3.2048, 1.3687, 0.6453, 0.7330, 0.7020, 0.6563, 0.8207, 1.0084, 0.7852,
        0.6636, 0.7307, 0.5648, 0.6818, 0.5649, 0.7240, 0.6403, 0.7377, 1.3301,
        0.6773, 0.6850, 0.6423, 0.7176, 0.5729, 0.5616, 0.6528, 1.2775, 0.6339,
        0.6384, 0.7697, 0.8592, 0.9115, 0.6744, 1.4557, 0.5971, 1.1876, 0.7377,
        0.7096, 0.8131, 0.8592, 1.2013, 1.6829, 0.5651, 0.5830, 0.7884, 0.8946,
        0.7330, 2.0257, 2.6993, 0.5838, 0.7330, 0.7668, 0.7451, 1.1876, 1.0921,
        0.6297, 0.7218, 0.6834, 0.6126, 0.7426, 0.6234, 0.7402, 0.6219, 1.1614,
        0.5822, 0.5594, 0.6366, 0.5723, 0.5648, 0.6280, 0.6866, 0.8787, 0.7402,
        2.0811, 1.0167, 0.6932, 0.6257, 0.5756, 0.5703, 0.7020, 0.5887, 1.0340,
        0.5686, 2.6993, 0.7852, 0.5700, 0.5743, 0.7038, 3.5471, 1.6829, 0.6264],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 329  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  20  52 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 128 104  94 173  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 307 142 129 137  63  71
 215 147 168 239 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 375 157 291  77 388  23 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2468, 0.6080, 1.0630, 1.1265, 0.8066, 0.8140, 0.6120, 0.6683, 0.6080,
        1.1628, 0.8217, 0.5789, 1.0178, 1.4120, 0.7677, 2.6023, 0.6752, 0.5602,
        1.3702, 1.9759, 1.1628, 0.7485, 0.8798, 1.0729, 1.2789, 0.9935, 1.6849,
        0.9858, 0.7386, 3.0629, 1.5330, 3.7547, 1.0729, 2.2060, 1.2789, 1.5895,
        3.0629, 1.3702, 0.6461, 0.7339, 0.7028, 0.6571, 0.8217, 1.0095, 0.7861,
        0.6644, 0.7315, 0.5655, 0.6826, 0.5656, 0.7248, 0.6411, 0.7386, 1.3316,
        0.6781, 0.6857, 0.6430, 0.7184, 0.5736, 0.5623, 0.6536, 1.2789, 0.6346,
        0.6392, 0.7706, 0.8602, 0.9125, 0.6767, 1.4573, 0.5978, 1.1890, 0.7386,
        0.7104, 0.8140, 0.8602, 1.2027, 1.6849, 0.5658, 0.5836, 0.7893, 0.8956,
        0.7339, 2.0280, 2.7024, 0.5845, 0.7339, 0.7677, 0.7460, 1.1890, 1.0934,
        0.6304, 0.7227, 0.6842, 0.6133, 0.7435, 0.6241, 0.7410, 0.6226, 1.1628,
        0.5828, 0.5600, 0.6373, 0.5730, 0.5655, 0.6287, 0.6873, 0.8798, 0.7410,
        2.0835, 1.0178, 0.6940, 0.6264, 0.5763, 0.5709, 0.7028, 0.5894, 1.0352,
        0.5693, 2.7024, 0.7861, 0.5706, 0.5750, 0.7046, 3.5512, 1.6849, 0.6272],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  20  53 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 128 104  94 173  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 307 142 129 137  63  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 375 157 291  77 388  23 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2470, 0.6081, 1.0632, 1.1267, 0.8067, 0.8141, 0.6121, 0.6684, 0.6081,
        1.1630, 0.8218, 0.5788, 1.0180, 1.4122, 0.7678, 2.6027, 0.6753, 0.5603,
        1.3705, 1.9762, 1.1630, 0.7487, 0.8799, 1.0730, 1.2791, 0.9937, 1.6851,
        0.9860, 0.7387, 3.0634, 1.5333, 3.7553, 1.0730, 2.2063, 1.2791, 1.5897,
        3.0634, 1.3508, 0.6461, 0.7340, 0.7029, 0.6572, 0.8218, 1.0097, 0.7862,
        0.6645, 0.7317, 0.5656, 0.6827, 0.5656, 0.7249, 0.6412, 0.7387, 1.3318,
        0.6782, 0.6858, 0.6431, 0.7186, 0.5737, 0.5623, 0.6537, 1.2791, 0.6347,
        0.6393, 0.7707, 0.8603, 0.9126, 0.6768, 1.4576, 0.5979, 1.1891, 0.7387,
        0.7105, 0.8141, 0.8603, 1.2029, 1.6851, 0.5659, 0.5837, 0.7895, 0.8957,
        0.7340, 2.0283, 2.7028, 0.5845, 0.7340, 0.7678, 0.7461, 1.1891, 1.0935,
        0.6305, 0.7228, 0.6843, 0.6140, 0.7436, 0.6242, 0.7411, 0.6227, 1.1630,
        0.5829, 0.5601, 0.6374, 0.5730, 0.5656, 0.6288, 0.6874, 0.8799, 0.7411,
        2.0838, 1.0180, 0.6941, 0.6265, 0.5764, 0.5710, 0.7029, 0.5895, 1.0353,
        0.5694, 2.7028, 0.7862, 0.5707, 0.5751, 0.7048, 3.5517, 1.6851, 0.6273],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  21  53 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 128 104  94 172  48 269  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 306 142 129 137  63  71
 215 147 168 238 138 223 139 225  65 313 548 207 361 427 217 166 100 139
  31  79 162 220 342 375 157 291  77 388  24 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2493, 0.6092, 1.0651, 1.1287, 0.8082, 0.8156, 0.6133, 0.6696, 0.6092,
        1.1651, 0.8233, 0.5799, 1.0199, 1.4148, 0.7692, 2.6075, 0.6766, 0.5613,
        1.3730, 1.9798, 1.1651, 0.7500, 0.8815, 1.0750, 1.2815, 0.9955, 1.6882,
        0.9878, 0.7401, 3.0690, 1.5361, 3.7622, 1.0750, 2.2104, 1.2815, 1.5926,
        2.9371, 1.3532, 0.6473, 0.7353, 0.7042, 0.6584, 0.8233, 1.0115, 0.7876,
        0.6657, 0.7330, 0.5666, 0.6840, 0.5667, 0.7263, 0.6423, 0.7401, 1.3343,
        0.6795, 0.6871, 0.6443, 0.7199, 0.5747, 0.5634, 0.6549, 1.2815, 0.6359,
        0.6404, 0.7721, 0.8619, 0.9143, 0.6795, 1.4602, 0.5990, 1.1913, 0.7401,
        0.7118, 0.8156, 0.8619, 1.2051, 1.6882, 0.5669, 0.5848, 0.7909, 0.8974,
        0.7353, 2.0320, 2.7078, 0.5859, 0.7353, 0.7692, 0.7475, 1.1913, 1.0955,
        0.6316, 0.7241, 0.6855, 0.6151, 0.7450, 0.6253, 0.7425, 0.6239, 1.1651,
        0.5840, 0.5611, 0.6386, 0.5741, 0.5666, 0.6300, 0.6887, 0.8815, 0.7425,
        2.0876, 1.0199, 0.6953, 0.6276, 0.5774, 0.5720, 0.7042, 0.5905, 1.0372,
        0.5704, 2.6075, 0.7876, 0.5718, 0.5761, 0.7060, 3.5582, 1.6882, 0.6284],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  21  53 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 127 104  94 172  48 270  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 306 142 129 137  63  71
 215 147 168 238 138 223 139 225  65 314 548 207 361 427 217 166 100 139
  31  79 162 220 342 375 157 291  77 387  24 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2493, 0.6092, 1.0651, 1.1287, 0.8082, 0.8156, 0.6132, 0.6696, 0.6092,
        1.1651, 0.8233, 0.5799, 1.0198, 1.4148, 0.7692, 2.6074, 0.6765, 0.5613,
        1.3729, 1.9798, 1.1651, 0.7500, 0.8815, 1.0750, 1.2814, 0.9955, 1.6882,
        0.9877, 0.7400, 3.0689, 1.5360, 3.7621, 1.0750, 2.2103, 1.2814, 1.5926,
        2.9370, 1.3532, 0.6473, 0.7353, 0.7042, 0.6583, 0.8233, 1.0115, 0.7876,
        0.6657, 0.7330, 0.5666, 0.6840, 0.5667, 0.7263, 0.6423, 0.7400, 1.3343,
        0.6794, 0.6871, 0.6443, 0.7199, 0.5747, 0.5634, 0.6549, 1.2814, 0.6359,
        0.6404, 0.7751, 0.8619, 0.9143, 0.6794, 1.4602, 0.5985, 1.1913, 0.7400,
        0.7118, 0.8156, 0.8619, 1.2051, 1.6882, 0.5669, 0.5848, 0.7909, 0.8973,
        0.7353, 2.0320, 2.7077, 0.5859, 0.7353, 0.7692, 0.7475, 1.1913, 1.0955,
        0.6316, 0.7241, 0.6855, 0.6151, 0.7449, 0.6253, 0.7425, 0.6238, 1.1651,
        0.5837, 0.5611, 0.6386, 0.5741, 0.5666, 0.6300, 0.6887, 0.8815, 0.7425,
        2.0876, 1.0198, 0.6953, 0.6276, 0.5774, 0.5720, 0.7042, 0.5905, 1.0372,
        0.5705, 2.6074, 0.7876, 0.5718, 0.5761, 0.7060, 3.5581, 1.6882, 0.6284],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 117 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  21  53 198 142 157 188 113  80 123 182 143 427 169 426 146 203 140  54
 172 167 201 149 357 480 191  57 210 205 127 104  94 172  48 270  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 306 142 129 137  63  71
 215 147 168 238 138 223 139 225  65 314 548 207 361 428 217 166 100 139
  30  79 162 220 342 375 157 291  77 387  26 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2505, 0.6098, 1.0661, 1.1297, 0.8090, 0.8163, 0.6138, 0.6703, 0.6098,
        1.1661, 0.8240, 0.5804, 1.0208, 1.4161, 0.7699, 2.6099, 0.6772, 0.5618,
        1.3742, 1.9816, 1.1661, 0.7507, 0.8823, 1.0760, 1.2826, 0.9964, 1.6897,
        0.9887, 0.7407, 3.0718, 1.5375, 3.7656, 1.0760, 2.2124, 1.2826, 1.5941,
        2.9398, 1.3545, 0.6479, 0.7360, 0.7048, 0.6590, 0.8240, 1.0124, 0.7884,
        0.6663, 0.7337, 0.5671, 0.6846, 0.5672, 0.7269, 0.6429, 0.7407, 1.3355,
        0.6801, 0.6877, 0.6449, 0.7205, 0.5753, 0.5639, 0.6555, 1.2826, 0.6365,
        0.6410, 0.7758, 0.8627, 0.9152, 0.6801, 1.4616, 0.5991, 1.1924, 0.7407,
        0.7124, 0.8163, 0.8627, 1.2062, 1.6897, 0.5674, 0.5853, 0.7916, 0.8982,
        0.7360, 2.0339, 2.7102, 0.5864, 0.7360, 0.7699, 0.7482, 1.1924, 1.0965,
        0.6322, 0.7248, 0.6862, 0.6157, 0.7456, 0.6259, 0.7432, 0.6244, 1.1661,
        0.5842, 0.5616, 0.6392, 0.5746, 0.5670, 0.6306, 0.6893, 0.8823, 0.7432,
        2.1489, 1.0208, 0.6960, 0.6282, 0.5779, 0.5726, 0.7048, 0.5911, 1.0382,
        0.5710, 2.4324, 0.7884, 0.5723, 0.5766, 0.7067, 3.5615, 1.6897, 0.6290],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  21  53 198 142 157 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 480 191  57 210 205 127 104  94 172  48 270  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 306 142 129 137  63  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  31  79 162 220 342 375 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2519, 0.6105, 1.0673, 1.1310, 0.8135, 0.8173, 0.6145, 0.6710, 0.6105,
        1.1675, 0.8250, 0.5811, 1.0220, 1.4177, 0.7708, 2.6129, 0.6779, 0.5624,
        1.3758, 1.9839, 1.1675, 0.7516, 0.8833, 1.0772, 1.2841, 0.9975, 1.6917,
        0.9898, 0.7416, 3.0753, 1.5392, 3.7699, 1.0673, 2.2149, 1.2841, 1.5959,
        2.9431, 1.3560, 0.6487, 0.7368, 0.7056, 0.6597, 0.8250, 1.0136, 0.7893,
        0.6671, 0.7345, 0.5678, 0.6854, 0.5678, 0.7278, 0.6427, 0.7416, 1.3370,
        0.6823, 0.6885, 0.6456, 0.7214, 0.5759, 0.5645, 0.6562, 1.2841, 0.6372,
        0.6418, 0.7767, 0.8637, 0.9162, 0.6809, 1.4632, 0.5998, 1.1938, 0.7416,
        0.7133, 0.8173, 0.8637, 1.2076, 1.6917, 0.5681, 0.5860, 0.7925, 0.8992,
        0.7368, 2.0362, 2.7133, 0.5871, 0.7368, 0.7708, 0.7490, 1.1938, 1.0978,
        0.6329, 0.7256, 0.6869, 0.6164, 0.7465, 0.6266, 0.7440, 0.6251, 1.1675,
        0.5849, 0.5623, 0.6399, 0.5754, 0.5677, 0.6313, 0.6901, 0.8833, 0.7440,
        2.0919, 1.0220, 0.6968, 0.6289, 0.5786, 0.5732, 0.7056, 0.5918, 1.0394,
        0.5717, 2.3563, 0.7893, 0.5730, 0.5773, 0.7075, 3.5655, 1.6917, 0.6297],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  22  53 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 171  48 270  63 140
 153 115 104  62  40 423 310 122  97 142  32  23 306 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  31  80 162 220 342 375 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2533, 0.6112, 1.0685, 1.1323, 0.8144, 0.8182, 0.6152, 0.6718, 0.6112,
        1.1688, 0.8259, 0.5817, 1.0231, 1.4193, 0.7716, 2.6157, 0.6787, 0.5631,
        1.3773, 1.9861, 1.1688, 0.7524, 0.8843, 1.0784, 1.2855, 0.9986, 1.6935,
        0.9909, 0.7424, 3.0787, 1.5409, 3.7741, 1.0685, 2.2174, 1.2855, 1.5976,
        2.8261, 1.3575, 0.6494, 0.7376, 0.7083, 0.6604, 0.8259, 1.0147, 0.7901,
        0.6678, 0.7353, 0.5684, 0.6861, 0.5685, 0.7286, 0.6434, 0.7424, 1.3385,
        0.6831, 0.6893, 0.6463, 0.7221, 0.5766, 0.5652, 0.6570, 1.2855, 0.6379,
        0.6425, 0.7776, 0.8646, 0.9172, 0.6831, 1.4648, 0.6004, 1.1951, 0.7424,
        0.7140, 0.8182, 0.8646, 1.2089, 1.6935, 0.5687, 0.5866, 0.7934, 0.9002,
        0.7376, 2.0384, 2.7163, 0.5877, 0.7376, 0.7716, 0.7498, 1.1817, 1.0990,
        0.6336, 0.7264, 0.6877, 0.6170, 0.7473, 0.6273, 0.7448, 0.6258, 1.1688,
        0.5856, 0.5629, 0.6406, 0.5761, 0.5683, 0.6320, 0.6909, 0.8843, 0.7448,
        2.0942, 1.0147, 0.6975, 0.6296, 0.5792, 0.5739, 0.7064, 0.5924, 1.0405,
        0.5723, 2.3589, 0.7901, 0.5736, 0.5779, 0.7083, 3.5695, 1.6935, 0.6304],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  22  53 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 171  48 270  63 140
 153 115 104  62  40 423 310 123  97 142  32  23 306 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  31  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2533, 0.6112, 1.0685, 1.1323, 0.8145, 0.8182, 0.6152, 0.6718, 0.6112,
        1.1688, 0.8259, 0.5817, 1.0231, 1.4193, 0.7717, 2.6158, 0.6787, 0.5631,
        1.3773, 1.9861, 1.1688, 0.7524, 0.8843, 1.0784, 1.2856, 0.9986, 1.6936,
        0.9909, 0.7424, 3.0788, 1.5410, 3.7742, 1.0685, 2.2174, 1.2856, 1.5977,
        2.8262, 1.3576, 0.6494, 0.7377, 0.7083, 0.6605, 0.8259, 1.0147, 0.7902,
        0.6678, 0.7353, 0.5684, 0.6862, 0.5685, 0.7286, 0.6434, 0.7424, 1.3385,
        0.6831, 0.6893, 0.6464, 0.7222, 0.5766, 0.5652, 0.6570, 1.2856, 0.6379,
        0.6425, 0.7776, 0.8646, 0.9172, 0.6831, 1.4649, 0.6004, 1.1951, 0.7424,
        0.7141, 0.8182, 0.8646, 1.2089, 1.6936, 0.5687, 0.5866, 0.7902, 0.9002,
        0.7377, 2.0385, 2.7164, 0.5878, 0.7377, 0.7717, 0.7499, 1.1817, 1.0990,
        0.6336, 0.7264, 0.6877, 0.6171, 0.7473, 0.6273, 0.7449, 0.6258, 1.1688,
        0.5856, 0.5629, 0.6406, 0.5761, 0.5683, 0.6320, 0.6909, 0.8843, 0.7449,
        2.0942, 1.0147, 0.6975, 0.6296, 0.5792, 0.5740, 0.7064, 0.5924, 1.0405,
        0.5723, 2.3590, 0.7902, 0.5736, 0.5779, 0.7083, 3.5696, 1.6936, 0.6304],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  23  53 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 170  48 270  63 140
 153 115 104  62  40 423 310 123  97 142  32  23 306 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  31  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2544, 0.6117, 1.0695, 1.1333, 0.8152, 0.8189, 0.6157, 0.6724, 0.6117,
        1.1698, 0.8266, 0.5822, 1.0240, 1.4205, 0.7723, 2.6180, 0.6793, 0.5636,
        1.3785, 1.9878, 1.1698, 0.7531, 0.8851, 1.0793, 1.2867, 0.9995, 1.6950,
        0.9918, 0.7431, 3.0814, 1.5423, 3.7774, 1.0695, 2.2193, 1.2867, 1.5991,
        2.7187, 1.3587, 0.6500, 0.7383, 0.7089, 0.6610, 0.8266, 1.0156, 0.7908,
        0.6684, 0.7360, 0.5689, 0.6868, 0.5690, 0.7292, 0.6440, 0.7431, 1.3397,
        0.6837, 0.6899, 0.6469, 0.7228, 0.5771, 0.5657, 0.6575, 1.2867, 0.6385,
        0.6430, 0.7783, 0.8654, 0.9180, 0.6852, 1.4661, 0.6009, 1.1961, 0.7431,
        0.7147, 0.8189, 0.8654, 1.2100, 1.6950, 0.5692, 0.5871, 0.7908, 0.9010,
        0.7383, 2.0402, 2.7187, 0.5883, 0.7383, 0.7723, 0.7505, 1.1828, 1.1000,
        0.6342, 0.7270, 0.6883, 0.6176, 0.7480, 0.6279, 0.7455, 0.6264, 1.1698,
        0.5861, 0.5634, 0.6412, 0.5766, 0.5688, 0.6325, 0.6915, 0.8851, 0.7455,
        2.0960, 1.0156, 0.6981, 0.6302, 0.5797, 0.5745, 0.7070, 0.5929, 1.0414,
        0.5728, 2.3610, 0.7908, 0.5741, 0.5784, 0.7089, 3.5726, 1.6950, 0.6309],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  23  53 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 170  48 270  63 140
 153 115 104  62  40 423 310 123  97 143  32  23 305 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  31  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2544, 0.6117, 1.0695, 1.1333, 0.8152, 0.8189, 0.6158, 0.6724, 0.6117,
        1.1698, 0.8266, 0.5822, 1.0240, 1.4206, 0.7723, 2.6181, 0.6793, 0.5636,
        1.3785, 1.9879, 1.1698, 0.7531, 0.8851, 1.0794, 1.2867, 0.9995, 1.6951,
        0.9918, 0.7431, 3.0815, 1.5423, 3.7775, 1.0695, 2.2194, 1.2867, 1.5991,
        2.7188, 1.3588, 0.6500, 0.7383, 0.7089, 0.6610, 0.8266, 1.0156, 0.7908,
        0.6684, 0.7360, 0.5689, 0.6868, 0.5690, 0.7292, 0.6440, 0.7431, 1.3397,
        0.6837, 0.6899, 0.6469, 0.7228, 0.5771, 0.5657, 0.6576, 1.2867, 0.6385,
        0.6430, 0.7783, 0.8654, 0.9180, 0.6852, 1.4662, 0.6010, 1.1962, 0.7431,
        0.7147, 0.8189, 0.8654, 1.2100, 1.6951, 0.5692, 0.5872, 0.7908, 0.9010,
        0.7360, 2.0403, 2.7188, 0.5886, 0.7383, 0.7723, 0.7505, 1.1828, 1.1000,
        0.6342, 0.7270, 0.6883, 0.6176, 0.7480, 0.6279, 0.7455, 0.6264, 1.1698,
        0.5861, 0.5634, 0.6412, 0.5766, 0.5688, 0.6326, 0.6915, 0.8851, 0.7455,
        2.0961, 1.0156, 0.6982, 0.6302, 0.5798, 0.5745, 0.7071, 0.5929, 1.0415,
        0.5728, 2.3610, 0.7908, 0.5741, 0.5785, 0.7089, 3.5727, 1.6951, 0.6310],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  74  68 116 115 241 179 248  65 113 330  79  50 129  24 174 541
  52  33  65 136 100  73  57  82  40  83 140  20  45  16  74  29  57  43
  23  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 170  48 270  63 140
 153 115 104  62  40 423 310 123  97 143  32  23 305 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  32  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2551, 0.6121, 1.0701, 1.1340, 0.8157, 0.8194, 0.6161, 0.6728, 0.6121,
        1.1705, 0.8271, 0.5826, 1.0246, 1.4214, 0.7728, 2.6196, 0.6797, 0.5639,
        1.3794, 1.9890, 1.1705, 0.7535, 0.8856, 1.0800, 1.2874, 1.0001, 1.6961,
        0.9924, 0.7435, 3.0833, 1.5432, 3.7797, 1.0701, 2.2207, 1.2874, 1.6000,
        2.7204, 1.3405, 0.6504, 0.7387, 0.7093, 0.6614, 0.8271, 1.0162, 0.7913,
        0.6688, 0.7364, 0.5692, 0.6872, 0.5693, 0.7297, 0.6444, 0.7435, 1.3405,
        0.6841, 0.6903, 0.6473, 0.7232, 0.5774, 0.5660, 0.6579, 1.2874, 0.6389,
        0.6434, 0.7788, 0.8659, 0.9186, 0.6856, 1.4670, 0.6013, 1.1969, 0.7435,
        0.7151, 0.8194, 0.8659, 1.2107, 1.6961, 0.5696, 0.5875, 0.7913, 0.9015,
        0.7364, 2.0415, 2.7204, 0.5889, 0.7387, 0.7728, 0.7510, 1.1835, 1.1006,
        0.6346, 0.7275, 0.6887, 0.6180, 0.7484, 0.6282, 0.7460, 0.6268, 1.1705,
        0.5864, 0.5637, 0.6416, 0.5769, 0.5692, 0.6329, 0.6919, 0.8856, 0.7460,
        2.0415, 1.0162, 0.6986, 0.6305, 0.5801, 0.5748, 0.7075, 0.5933, 1.0421,
        0.5732, 2.3624, 0.7913, 0.5744, 0.5788, 0.7093, 3.5748, 1.6961, 0.6313],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 116 115 241 179 248  65 113 330  79  51 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  24  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 169  48 270  63 140
 153 115 104  62  40 423 310 123  97 143  32  23 305 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  32  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2561, 0.6126, 1.0613, 1.1349, 0.8163, 0.8201, 0.6166, 0.6733, 0.6126,
        1.1714, 0.8278, 0.5830, 1.0254, 1.4011, 0.7734, 2.6217, 0.6802, 0.5643,
        1.4011, 1.9906, 1.1714, 0.7541, 0.8863, 1.0809, 1.2885, 1.0009, 1.6974,
        0.9931, 0.7441, 3.0857, 1.5444, 3.7827, 1.0809, 2.2224, 1.2885, 1.6013,
        2.6217, 1.3416, 0.6509, 0.7393, 0.7099, 0.6619, 0.8278, 1.0170, 0.7919,
        0.6694, 0.7370, 0.5697, 0.6877, 0.5698, 0.7302, 0.6449, 0.7441, 1.3416,
        0.6847, 0.6909, 0.6478, 0.7238, 0.5779, 0.5665, 0.6585, 1.2885, 0.6394,
        0.6439, 0.7794, 0.8666, 0.9193, 0.6877, 1.4682, 0.6018, 1.1978, 0.7441,
        0.7157, 0.8201, 0.8666, 1.2117, 1.6974, 0.5700, 0.5880, 0.7919, 0.9023,
        0.7370, 2.0431, 2.7225, 0.5894, 0.7393, 0.7734, 0.7516, 1.1844, 1.1015,
        0.6351, 0.7281, 0.6893, 0.6184, 0.7490, 0.6287, 0.7465, 0.6273, 1.1714,
        0.5869, 0.5642, 0.6421, 0.5774, 0.5696, 0.6334, 0.6925, 0.8863, 0.7465,
        2.0431, 1.0170, 0.6991, 0.6310, 0.5806, 0.5753, 0.7080, 0.5938, 1.0429,
        0.5736, 2.3643, 0.7919, 0.5749, 0.5793, 0.7099, 3.5776, 1.6974, 0.6318],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 116 115 241 179 248  65 113 330  79  51 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  16  73  29  57  43
  24  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 169  48 270  63 140
 153 115 104  62  40 423 310 123  97 143  32  23 305 142 129 137  64  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  32  80 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2561, 0.6126, 1.0613, 1.1349, 0.8163, 0.8201, 0.6166, 0.6733, 0.6126,
        1.1714, 0.8278, 0.5830, 1.0254, 1.4011, 0.7734, 2.6217, 0.6802, 0.5643,
        1.4011, 1.9906, 1.1714, 0.7541, 0.8863, 1.0809, 1.2885, 1.0009, 1.6974,
        0.9931, 0.7441, 3.0857, 1.5444, 3.7827, 1.0809, 2.2224, 1.2885, 1.6013,
        2.6217, 1.3416, 0.6509, 0.7393, 0.7099, 0.6619, 0.8278, 1.0170, 0.7919,
        0.6694, 0.7370, 0.5697, 0.6877, 0.5698, 0.7302, 0.6449, 0.7441, 1.3416,
        0.6847, 0.6909, 0.6478, 0.7238, 0.5779, 0.5665, 0.6585, 1.2885, 0.6394,
        0.6439, 0.7794, 0.8666, 0.9193, 0.6877, 1.4682, 0.6018, 1.1978, 0.7441,
        0.7157, 0.8201, 0.8666, 1.2117, 1.6974, 0.5700, 0.5880, 0.7919, 0.9023,
        0.7370, 2.0431, 2.7225, 0.5894, 0.7393, 0.7734, 0.7516, 1.1844, 1.1015,
        0.6351, 0.7281, 0.6893, 0.6184, 0.7490, 0.6287, 0.7465, 0.6273, 1.1714,
        0.5869, 0.5642, 0.6421, 0.5774, 0.5696, 0.6334, 0.6925, 0.8863, 0.7465,
        2.0431, 1.0170, 0.6991, 0.6310, 0.5806, 0.5753, 0.7080, 0.5938, 1.0429,
        0.5736, 2.3643, 0.7919, 0.5749, 0.5793, 0.7099, 3.5776, 1.6974, 0.6318],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 115 115 241 179 248  65 113 330  79  51 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  17  73  29  57  43
  24  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 169  48 270  63 140
 153 115 104  61  40 423 310 123  97 143  32  23 305 142 129 137  65  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 428 217 166 100 139
  33  79 162 220 342 374 157 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2586, 0.6137, 1.0634, 1.1371, 0.8216, 0.8216, 0.6178, 0.6746, 0.6137,
        1.1737, 0.8294, 0.5842, 1.0274, 1.4038, 0.7749, 2.6268, 0.6816, 0.5654,
        1.4038, 1.9945, 1.1737, 0.7556, 0.8880, 1.0830, 1.2910, 1.0029, 1.7007,
        0.9951, 0.7455, 3.0917, 1.5474, 3.5846, 1.0830, 2.2267, 1.2910, 1.6044,
        2.6268, 1.3442, 0.6521, 0.7408, 0.7113, 0.6632, 0.8294, 1.0190, 0.7935,
        0.6707, 0.7384, 0.5708, 0.6890, 0.5709, 0.7317, 0.6461, 0.7455, 1.3442,
        0.6860, 0.6922, 0.6491, 0.7252, 0.5790, 0.5676, 0.6597, 1.2910, 0.6406,
        0.6452, 0.7809, 0.8683, 0.9211, 0.6890, 1.4710, 0.6030, 1.2001, 0.7455,
        0.7171, 0.8216, 0.8683, 1.2284, 1.7007, 0.5711, 0.5891, 0.7935, 0.9040,
        0.7384, 2.0471, 2.7278, 0.5905, 0.7408, 0.7749, 0.7530, 1.1737, 1.1037,
        0.6363, 0.7295, 0.6906, 0.6196, 0.7505, 0.6300, 0.7480, 0.6285, 1.1737,
        0.5880, 0.5653, 0.6433, 0.5785, 0.5707, 0.6347, 0.6938, 0.8880, 0.7480,
        1.9945, 1.0274, 0.7005, 0.6323, 0.5817, 0.5764, 0.7094, 0.5949, 1.0449,
        0.5747, 2.3689, 0.7935, 0.5760, 0.5804, 0.7113, 3.5846, 1.7007, 0.6331],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 115 115 241 179 248  65 113 330  79  51 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  18  73  29  57  43
  24  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 169  48 270  63 140
 153 115 104  61  40 423 310 123  97 143  32  23 305 142 129 137  65  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 429 217 166 100 139
  33  79 162 220 342 374 156 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2604, 0.6146, 1.0649, 1.1387, 0.8228, 0.8228, 0.6187, 0.6756, 0.6146,
        1.1754, 0.8306, 0.5850, 1.0289, 1.4058, 0.7760, 2.6306, 0.6825, 0.5663,
        1.4058, 1.9974, 1.1754, 0.7567, 0.8893, 1.0845, 1.2928, 1.0043, 1.7032,
        0.9965, 0.7466, 3.0962, 1.5497, 3.4069, 1.0845, 2.2299, 1.2928, 1.6067,
        2.6306, 1.3461, 0.6531, 0.7418, 0.7123, 0.6642, 0.8306, 1.0205, 0.7946,
        0.6716, 0.7395, 0.5716, 0.6900, 0.5717, 0.7327, 0.6471, 0.7466, 1.3461,
        0.6870, 0.6932, 0.6500, 0.7262, 0.5798, 0.5684, 0.6607, 1.2928, 0.6415,
        0.6461, 0.7820, 0.8695, 0.9224, 0.6900, 1.4732, 0.6038, 1.2019, 0.7466,
        0.7181, 0.8228, 0.8695, 1.2301, 1.7032, 0.5719, 0.5900, 0.7946, 0.9053,
        0.7395, 2.0500, 2.7317, 0.5914, 0.7418, 0.7760, 0.7541, 1.1754, 1.1052,
        0.6372, 0.7305, 0.6916, 0.6205, 0.7516, 0.6309, 0.7491, 0.6294, 1.1754,
        0.5889, 0.5661, 0.6442, 0.5793, 0.5715, 0.6356, 0.6948, 0.8893, 0.7491,
        1.9974, 1.0289, 0.7015, 0.6332, 0.5825, 0.5772, 0.7123, 0.5958, 1.0464,
        0.5756, 2.3723, 0.7946, 0.5768, 0.5812, 0.7123, 3.5897, 1.7032, 0.6340],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 115 115 241 179 248  65 113 330  79  50 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  19  73  29  57  43
  25  54 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 168  48 270  63 140
 153 115 104  61  40 423 310 123  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 139 225  65 314 548 207 360 429 217 166 100 139
  33  79 162 220 342 374 156 291  77 387  27 123 377 349 156  17  40 219]
CBFL per class weights: tensor([1.2629, 0.6158, 1.0670, 1.1409, 0.8244, 0.8244, 0.6199, 0.6769, 0.6158,
        1.1777, 0.8322, 0.5862, 1.0309, 1.4301, 0.7775, 2.6357, 0.6839, 0.5674,
        1.4086, 2.0013, 1.1777, 0.7582, 0.8910, 1.0866, 1.2954, 1.0063, 1.7065,
        0.9985, 0.7481, 3.1022, 1.5527, 3.2497, 1.0866, 2.2343, 1.2954, 1.6099,
        2.5425, 1.3487, 0.6543, 0.7433, 0.7137, 0.6655, 0.8322, 1.0225, 0.7962,
        0.6729, 0.7409, 0.5727, 0.6914, 0.5728, 0.7341, 0.6483, 0.7481, 1.3487,
        0.6883, 0.6945, 0.6513, 0.7277, 0.5810, 0.5695, 0.6620, 1.2954, 0.6428,
        0.6474, 0.7835, 0.8712, 0.9242, 0.6930, 1.4760, 0.6050, 1.2042, 0.7481,
        0.7195, 0.8244, 0.8712, 1.2325, 1.7065, 0.5731, 0.5911, 0.7962, 0.9071,
        0.7409, 2.0540, 2.7371, 0.5925, 0.7433, 0.7775, 0.7556, 1.1651, 1.1074,
        0.6385, 0.7319, 0.6930, 0.6218, 0.7530, 0.6321, 0.7505, 0.6306, 1.1777,
        0.5900, 0.5672, 0.6455, 0.5805, 0.5726, 0.6368, 0.6962, 0.8910, 0.7505,
        2.0013, 1.0309, 0.7029, 0.6344, 0.5837, 0.5784, 0.7137, 0.5969, 1.0485,
        0.5767, 2.3769, 0.7962, 0.5780, 0.5823, 0.7137, 3.5968, 1.7065, 0.6352],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 115 115 241 179 248  65 113 330  79  50 129  24 174 541
  51  33  65 136 100  73  57  82  40  83 140  20  45  19  73  29  57  44
  25  55 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 168  48 270  63 140
 153 115 104  61  40 423 310 123  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 139 225  65 313 548 207 360 429 217 166 100 139
  33  79 162 220 342 374 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2633, 0.6161, 1.0674, 1.1414, 0.8247, 0.8247, 0.6201, 0.6772, 0.6161,
        1.1781, 0.8325, 0.5864, 1.0313, 1.4307, 0.7778, 2.6367, 0.6841, 0.5676,
        1.4091, 2.0020, 1.1781, 0.7584, 0.8914, 1.0870, 1.2958, 1.0066, 1.7071,
        0.9988, 0.7484, 3.1034, 1.5533, 3.2509, 1.0870, 2.2351, 1.2958, 1.5812,
        2.5435, 1.3308, 0.6546, 0.7436, 0.7140, 0.6657, 0.8325, 1.0229, 0.7965,
        0.6732, 0.7412, 0.5729, 0.6916, 0.5730, 0.7344, 0.6486, 0.7484, 1.3492,
        0.6886, 0.6948, 0.6515, 0.7279, 0.5812, 0.5697, 0.6622, 1.2958, 0.6430,
        0.6476, 0.7838, 0.8716, 0.9246, 0.6932, 1.4766, 0.6052, 1.2047, 0.7484,
        0.7198, 0.8247, 0.8716, 1.2330, 1.7071, 0.5733, 0.5913, 0.7965, 0.9074,
        0.7412, 2.0548, 2.7381, 0.5928, 0.7436, 0.7778, 0.7559, 1.1655, 1.1078,
        0.6387, 0.7322, 0.6932, 0.6220, 0.7533, 0.6323, 0.7508, 0.6308, 1.1781,
        0.5905, 0.5674, 0.6457, 0.5807, 0.5728, 0.6371, 0.6964, 0.8914, 0.7508,
        2.0020, 1.0313, 0.7031, 0.6347, 0.5839, 0.5786, 0.7140, 0.5972, 1.0489,
        0.5769, 2.3778, 0.7965, 0.5782, 0.5827, 0.7140, 3.5981, 1.7071, 0.6354],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 114 115 241 179 248  65 113 330  79  50 129  24 174 541
  51  33  65 136 100  73  57  81  40  83 140  20  45  20  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 427 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 104  94 167  48 270  63 140
 153 115 104  61  40 423 310 123  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 139 225  65 313 548 207 360 429 217 166 100 139
  34  79 162 220 342 374 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2660, 0.6174, 1.0697, 1.1438, 0.8304, 0.8265, 0.6215, 0.6786, 0.6174,
        1.1807, 0.8343, 0.5876, 1.0335, 1.4337, 0.7795, 2.6424, 0.6856, 0.5688,
        1.4121, 2.0063, 1.1807, 0.7601, 0.8933, 1.0894, 1.2986, 1.0168, 1.7108,
        1.0010, 0.7500, 3.1101, 1.5566, 3.1101, 1.0894, 2.2399, 1.2986, 1.5846,
        2.4627, 1.3336, 0.6560, 0.7452, 0.7155, 0.6672, 0.8343, 1.0251, 0.7982,
        0.6746, 0.7428, 0.5742, 0.6931, 0.5743, 0.7360, 0.6500, 0.7500, 1.3521,
        0.6901, 0.6963, 0.6529, 0.7295, 0.5824, 0.5710, 0.6637, 1.2986, 0.6444,
        0.6490, 0.7855, 0.8734, 0.9265, 0.6963, 1.4798, 0.6065, 1.2073, 0.7500,
        0.7213, 0.8265, 0.8734, 1.2357, 1.7108, 0.5745, 0.5926, 0.7982, 0.9094,
        0.7428, 2.0592, 2.7440, 0.5940, 0.7452, 0.7795, 0.7575, 1.1680, 1.1102,
        0.6401, 0.7338, 0.6947, 0.6233, 0.7549, 0.6337, 0.7524, 0.6322, 1.1807,
        0.5918, 0.5686, 0.6471, 0.5819, 0.5740, 0.6384, 0.6979, 0.8933, 0.7524,
        1.9566, 1.0335, 0.7046, 0.6360, 0.5851, 0.5798, 0.7155, 0.5984, 1.0511,
        0.5781, 2.3829, 0.7982, 0.5794, 0.5840, 0.7155, 3.6058, 1.7108, 0.6368],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 114 115 241 179 248  65 113 330  79  50 129  24 174 541
  51  33  65 136 100  73  57  81  40  83 140  20  45  20  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 426 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 139 225  65 313 548 207 360 429 217 166 100 139
  34  79 162 220 342 373 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2661, 0.6174, 1.0698, 1.1439, 0.8304, 0.8266, 0.6215, 0.6786, 0.6174,
        1.1807, 0.8343, 0.5877, 1.0336, 1.4338, 0.7796, 2.6425, 0.6857, 0.5688,
        1.4122, 2.0064, 1.1807, 0.7601, 0.8933, 1.0894, 1.2987, 1.0169, 1.7109,
        1.0010, 0.7500, 3.1102, 1.5567, 3.1102, 1.0894, 2.2401, 1.2987, 1.5847,
        2.4629, 1.3337, 0.6560, 0.7452, 0.7155, 0.6672, 0.8343, 1.0251, 0.7982,
        0.6747, 0.7429, 0.5743, 0.6932, 0.5743, 0.7360, 0.6500, 0.7500, 1.3522,
        0.6901, 0.6963, 0.6530, 0.7295, 0.5825, 0.5710, 0.6637, 1.2987, 0.6444,
        0.6491, 0.7856, 0.8688, 0.9266, 0.6963, 1.4799, 0.6066, 1.2073, 0.7500,
        0.7214, 0.8266, 0.8735, 1.2357, 1.7109, 0.5745, 0.5926, 0.7950, 0.9094,
        0.7429, 2.0593, 2.7442, 0.5941, 0.7452, 0.7796, 0.7575, 1.1681, 1.1103,
        0.6401, 0.7338, 0.6947, 0.6234, 0.7550, 0.6337, 0.7525, 0.6322, 1.1807,
        0.5918, 0.5687, 0.6472, 0.5820, 0.5741, 0.6385, 0.6980, 0.8933, 0.7525,
        1.9567, 1.0336, 0.7047, 0.6361, 0.5852, 0.5800, 0.7155, 0.5985, 1.0512,
        0.5782, 2.3831, 0.7982, 0.5795, 0.5840, 0.7155, 3.6060, 1.7109, 0.6368],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 174 541
  51  33  65 136 100  73  57  81  40  83 140  20  45  20  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 426 169 426 146 204 140  54
 171 167 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 139 224  65 313 548 207 360 429 217 166 100 139
  35  79 162 220 342 373 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2666, 0.6177, 1.0702, 1.1443, 0.8347, 0.8269, 0.6218, 0.6789, 0.6177,
        1.1812, 0.8347, 0.5879, 1.0255, 1.4344, 0.7799, 2.6436, 0.6859, 0.5691,
        1.4128, 2.0072, 1.1812, 0.7604, 0.8937, 1.0899, 1.2992, 1.0173, 1.7116,
        1.0014, 0.7503, 3.1115, 1.5573, 3.1115, 1.0899, 2.2410, 1.2992, 1.5853,
        2.4639, 1.3342, 0.6563, 0.7455, 0.7158, 0.6675, 0.8347, 1.0255, 0.7986,
        0.6749, 0.7431, 0.5745, 0.6935, 0.5745, 0.7363, 0.6503, 0.7503, 1.3528,
        0.6904, 0.6966, 0.6532, 0.7298, 0.5827, 0.5712, 0.6640, 1.2992, 0.6447,
        0.6493, 0.7859, 0.8691, 0.9270, 0.6966, 1.4804, 0.6068, 1.2078, 0.7503,
        0.7216, 0.8269, 0.8738, 1.2362, 1.7116, 0.5748, 0.5929, 0.7953, 0.9098,
        0.7431, 2.0602, 2.7453, 0.5943, 0.7455, 0.7799, 0.7578, 1.1685, 1.1107,
        0.6404, 0.7341, 0.6950, 0.6236, 0.7553, 0.6340, 0.7528, 0.6332, 1.1812,
        0.5921, 0.5689, 0.6474, 0.5822, 0.5743, 0.6387, 0.6982, 0.8937, 0.7528,
        1.9106, 1.0340, 0.7050, 0.6363, 0.5854, 0.5802, 0.7158, 0.5987, 1.0516,
        0.5784, 2.3840, 0.7986, 0.5797, 0.5843, 0.7158, 3.6075, 1.7116, 0.6371],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 174 540
  51  33  65 136 100  73  57  81  40  83 140  20  45  24  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 425 169 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 140 223  65 313 548 207 360 429 217 166 100 139
  35  79 162 220 342 373 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2713, 0.6200, 1.0742, 1.1486, 0.8378, 0.8300, 0.6241, 0.6814, 0.6200,
        1.1856, 0.8378, 0.5901, 1.0294, 1.4398, 0.7828, 2.6535, 0.6885, 0.5712,
        1.4180, 2.0147, 1.1856, 0.7633, 0.8970, 1.0939, 1.3041, 1.0211, 1.7180,
        1.0052, 0.7531, 3.1231, 1.5631, 2.6535, 1.0939, 2.2493, 1.3041, 1.5912,
        2.4730, 1.3392, 0.6587, 0.7483, 0.7185, 0.6700, 0.8378, 1.0294, 0.8015,
        0.6775, 0.7459, 0.5767, 0.6960, 0.5767, 0.7391, 0.6527, 0.7531, 1.3578,
        0.6930, 0.7008, 0.6557, 0.7326, 0.5849, 0.5733, 0.6664, 1.3041, 0.6471,
        0.6517, 0.7888, 0.8724, 0.9304, 0.6992, 1.4860, 0.6091, 1.2123, 0.7531,
        0.7243, 0.8300, 0.8771, 1.2408, 1.7180, 0.5769, 0.5951, 0.7983, 0.9132,
        0.7459, 2.0678, 2.7555, 0.5965, 0.7483, 0.7828, 0.7607, 1.1729, 1.1148,
        0.6428, 0.7369, 0.6976, 0.6259, 0.7581, 0.6364, 0.7531, 0.6364, 1.1856,
        0.5943, 0.5710, 0.6498, 0.5844, 0.5764, 0.6411, 0.7008, 0.8970, 0.7556,
        1.9177, 1.0378, 0.7076, 0.6387, 0.5876, 0.5824, 0.7185, 0.6010, 1.0555,
        0.5806, 2.3929, 0.8015, 0.5819, 0.5864, 0.7185, 3.6209, 1.7180, 0.6395],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 174 540
  51  33  65 136 100  73  57  81  40  83 140  20  46  28  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 425 169 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 140 223  65 313 548 207 360 428 217 166 100 139
  35  79 162 220 342 373 156 291  77 387  27 123 377 348 156  17  40 219]
CBFL per class weights: tensor([1.2750, 0.6218, 1.0773, 1.1519, 0.8402, 0.8324, 0.6259, 0.6834, 0.6218,
        1.1890, 0.8402, 0.5918, 1.0323, 1.4439, 0.7850, 2.6611, 0.6905, 0.5728,
        1.4221, 2.0205, 1.1890, 0.7655, 0.8996, 1.0971, 1.3078, 1.0240, 1.7229,
        1.0081, 0.7553, 3.1321, 1.5407, 2.3252, 1.0971, 2.2558, 1.3078, 1.5958,
        2.4802, 1.3431, 0.6606, 0.7504, 0.7206, 0.6719, 0.8402, 1.0323, 0.8038,
        0.6794, 0.7481, 0.5784, 0.6980, 0.5783, 0.7412, 0.6546, 0.7553, 1.3617,
        0.6949, 0.7029, 0.6575, 0.7347, 0.5866, 0.5750, 0.6684, 1.3078, 0.6490,
        0.6536, 0.7911, 0.8749, 0.9331, 0.7012, 1.4902, 0.6108, 1.2158, 0.7553,
        0.7264, 0.8324, 0.8796, 1.2444, 1.7229, 0.5786, 0.5968, 0.8006, 0.9158,
        0.7481, 2.0738, 2.7634, 0.5982, 0.7504, 0.7850, 0.7628, 1.1763, 1.1181,
        0.6446, 0.7390, 0.6996, 0.6277, 0.7603, 0.6382, 0.7553, 0.6382, 1.1890,
        0.5960, 0.5727, 0.6517, 0.5861, 0.5782, 0.6429, 0.7029, 0.8996, 0.7578,
        1.9232, 1.0408, 0.7096, 0.6405, 0.5893, 0.5841, 0.7206, 0.6027, 1.0586,
        0.5822, 2.3998, 0.8038, 0.5835, 0.5881, 0.7206, 3.6314, 1.7229, 0.6413],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 174 540
  51  33  65 136 100  73  57  81  40  83 140  20  46  29  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 425 169 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 220 343 373 156 291  77 387  27 123 377 348 155  17  40 219]
CBFL per class weights: tensor([1.2757, 0.6221, 1.0779, 1.1525, 0.8407, 0.8328, 0.6262, 0.6838, 0.6221,
        1.1897, 0.8407, 0.5921, 1.0329, 1.4447, 0.7854, 2.6625, 0.6908, 0.5732,
        1.4229, 2.0216, 1.1897, 0.7659, 0.9001, 1.0977, 1.3085, 1.0246, 1.7238,
        1.0086, 0.7557, 3.1337, 1.5415, 2.2570, 1.0977, 2.2570, 1.3085, 1.5967,
        2.4815, 1.3438, 0.6610, 0.7508, 0.7209, 0.6722, 0.8407, 1.0329, 0.8043,
        0.6798, 0.7485, 0.5787, 0.6984, 0.5786, 0.7416, 0.6549, 0.7557, 1.3624,
        0.6953, 0.7032, 0.6579, 0.7351, 0.5869, 0.5753, 0.6687, 1.3085, 0.6493,
        0.6540, 0.7915, 0.8753, 0.9336, 0.7016, 1.4910, 0.6112, 1.2165, 0.7557,
        0.7268, 0.8328, 0.8801, 1.2451, 1.7238, 0.5789, 0.5971, 0.8010, 0.9163,
        0.7485, 2.0749, 2.7649, 0.5985, 0.7508, 0.7854, 0.7632, 1.1769, 1.1186,
        0.6450, 0.7394, 0.7000, 0.6281, 0.7607, 0.6385, 0.7557, 0.6385, 1.1897,
        0.5963, 0.5730, 0.6530, 0.5864, 0.5785, 0.6433, 0.7032, 0.9001, 0.7582,
        1.9242, 1.0414, 0.7100, 0.6409, 0.5894, 0.5844, 0.7209, 0.6030, 1.0591,
        0.5826, 2.4011, 0.8043, 0.5838, 0.5884, 0.7229, 3.6333, 1.7238, 0.6417],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 175 540
  51  33  65 136 100  73  57  81  40  83 140  20  46  31  73  29  57  44
  26  55 198 142 156 188 113  80 123 182 143 425 169 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 167  48 270  63 140
 153 115 104  61  40 423 310 124  97 143  32  23 305 142 129 137  66  71
 215 147 168 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 373 156 291  77 387  27 123 376 348 155  17  40 219]
CBFL per class weights: tensor([1.2770, 0.6227, 1.0789, 1.1537, 0.8415, 0.8336, 0.6268, 0.6845, 0.6227,
        1.1909, 0.8415, 0.5927, 1.0339, 1.4461, 0.7862, 2.6652, 0.6901, 0.5737,
        1.4243, 2.0236, 1.1909, 0.7666, 0.9010, 1.0988, 1.3098, 1.0256, 1.7255,
        1.0096, 0.7564, 3.1369, 1.5431, 2.1338, 1.0988, 2.2593, 1.3098, 1.5983,
        2.4840, 1.3451, 0.6617, 0.7516, 0.7217, 0.6729, 0.8415, 1.0339, 0.8051,
        0.6804, 0.7492, 0.5793, 0.6991, 0.5792, 0.7423, 0.6556, 0.7564, 1.3638,
        0.6960, 0.7039, 0.6586, 0.7358, 0.5874, 0.5759, 0.6694, 1.3098, 0.6500,
        0.6546, 0.7923, 0.8762, 0.9345, 0.7023, 1.4925, 0.6118, 1.2177, 0.7564,
        0.7275, 0.8336, 0.8810, 1.2463, 1.7255, 0.5795, 0.5977, 0.8018, 0.9172,
        0.7492, 2.0770, 2.7677, 0.5991, 0.7516, 0.7862, 0.7640, 1.1781, 1.1198,
        0.6456, 0.7401, 0.7007, 0.6287, 0.7614, 0.6392, 0.7564, 0.6392, 1.1909,
        0.5969, 0.5735, 0.6537, 0.5870, 0.5790, 0.6439, 0.7039, 0.9010, 0.7589,
        1.9262, 1.0424, 0.7107, 0.6423, 0.5900, 0.5850, 0.7217, 0.6036, 1.0602,
        0.5831, 2.4035, 0.8051, 0.5846, 0.5890, 0.7236, 3.6369, 1.7255, 0.6423],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 175 540
  51  33  65 136 100  73  57  80  40  83 140  20  46  36  73  29  57  44
  27  55 198 142 156 188 113  80 123 182 143 425 168 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 270  63 140
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 169 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 373 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2800, 0.6242, 1.0815, 1.1565, 0.8435, 0.8357, 0.6283, 0.6861, 0.6242,
        1.1937, 0.8435, 0.5941, 1.0364, 1.4496, 0.7881, 2.6716, 0.6917, 0.5751,
        1.4277, 2.0285, 1.1937, 0.7685, 0.9032, 1.1014, 1.3130, 1.0364, 1.7297,
        1.0120, 0.7583, 3.1445, 1.5468, 1.8861, 1.1014, 2.2647, 1.3130, 1.6021,
        2.4093, 1.3484, 0.6633, 0.7534, 0.7234, 0.6745, 0.8435, 1.0364, 0.8070,
        0.6821, 0.7510, 0.5807, 0.7024, 0.5806, 0.7441, 0.6572, 0.7583, 1.3671,
        0.6977, 0.7056, 0.6601, 0.7376, 0.5889, 0.5773, 0.6710, 1.3130, 0.6515,
        0.6562, 0.7942, 0.8783, 0.9368, 0.7056, 1.4961, 0.6132, 1.2206, 0.7583,
        0.7293, 0.8396, 0.8831, 1.2644, 1.7297, 0.5809, 0.5989, 0.8037, 0.9194,
        0.7510, 2.0820, 2.7743, 0.6006, 0.7534, 0.7881, 0.7659, 1.1809, 1.1225,
        0.6472, 0.7419, 0.7008, 0.6302, 0.7633, 0.6407, 0.7583, 0.6407, 1.1937,
        0.5983, 0.5749, 0.6552, 0.5884, 0.5804, 0.6455, 0.7056, 0.9032, 0.7607,
        1.9308, 1.0449, 0.7124, 0.6439, 0.5914, 0.5864, 0.7234, 0.6051, 1.0627,
        0.5845, 2.4093, 0.8070, 0.5860, 0.5906, 0.7253, 3.6457, 1.7297, 0.6439],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 179 248  65 113 330  80  50 129  24 175 540
  51  33  65 136 100  73  57  80  40  83 140  20  46  37  73  29  57  44
  28  55 198 142 156 188 113  80 123 182 143 425 168 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 270  63 140
 153 114 104  60  40 422 311 125  97 143  32  23 305 142 129 137  66  71
 215 147 169 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2813, 0.6248, 1.0826, 1.1576, 0.8443, 0.8365, 0.6289, 0.6868, 0.6248,
        1.1949, 0.8443, 0.5947, 1.0374, 1.4510, 0.7889, 2.6742, 0.6924, 0.5757,
        1.4291, 2.0304, 1.1949, 0.7692, 0.9040, 1.1025, 1.3142, 1.0374, 1.7314,
        1.0130, 0.7590, 3.1475, 1.5483, 1.8455, 1.1025, 2.2669, 1.3142, 1.6037,
        2.3366, 1.3497, 0.6639, 0.7541, 0.7241, 0.6752, 0.8443, 1.0374, 0.8078,
        0.6827, 0.7517, 0.5812, 0.7031, 0.5812, 0.7448, 0.6578, 0.7590, 1.3684,
        0.6984, 0.7063, 0.6608, 0.7383, 0.5894, 0.5778, 0.6716, 1.3142, 0.6522,
        0.6568, 0.7950, 0.8792, 0.9377, 0.7063, 1.4976, 0.6138, 1.2218, 0.7590,
        0.7300, 0.8404, 0.8839, 1.2656, 1.7314, 0.5815, 0.5995, 0.8013, 0.9203,
        0.7517, 2.0840, 2.7770, 0.6012, 0.7541, 0.7889, 0.7666, 1.1821, 1.1235,
        0.6478, 0.7426, 0.7015, 0.6308, 0.7640, 0.6413, 0.7590, 0.6413, 1.1949,
        0.5989, 0.5755, 0.6559, 0.5889, 0.5810, 0.6461, 0.7063, 0.9040, 0.7615,
        1.9327, 1.0459, 0.7131, 0.6445, 0.5920, 0.5871, 0.7241, 0.6056, 1.0638,
        0.5851, 2.4116, 0.8078, 0.5865, 0.5912, 0.7260, 3.6492, 1.7314, 0.6445],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  51  33  65 136 100  73  57  80  40  83 140  20  46  39  73  29  57  44
  28  55 198 142 156 188 113  80 123 182 144 425 167 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 270  63 140
 153 114 104  60  40 422 311 125  97 143  32  23 305 142 129 137  66  71
 215 147 169 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2821, 0.6252, 1.0832, 1.1583, 0.8449, 0.8370, 0.6293, 0.6886, 0.6252,
        1.1956, 0.8449, 0.5951, 1.0380, 1.4519, 0.7894, 2.6758, 0.6928, 0.5760,
        1.4300, 2.0317, 1.1956, 0.7697, 0.9046, 1.1032, 1.3150, 1.0380, 1.7324,
        1.0136, 0.7594, 3.1494, 1.5492, 1.7685, 1.1032, 2.2683, 1.3150, 1.6047,
        2.3381, 1.3505, 0.6643, 0.7546, 0.7245, 0.6756, 0.8449, 1.0380, 0.8083,
        0.6832, 0.7499, 0.5816, 0.7051, 0.5815, 0.7453, 0.6582, 0.7594, 1.3692,
        0.6988, 0.7067, 0.6612, 0.7387, 0.5898, 0.5782, 0.6720, 1.3150, 0.6526,
        0.6572, 0.7954, 0.8797, 0.9383, 0.7067, 1.4985, 0.6142, 1.2225, 0.7594,
        0.7304, 0.8409, 0.8845, 1.2664, 1.7324, 0.5819, 0.5998, 0.8017, 0.9209,
        0.7522, 2.0852, 2.7787, 0.6015, 0.7546, 0.7894, 0.7671, 1.1828, 1.1242,
        0.6482, 0.7431, 0.7019, 0.6312, 0.7645, 0.6417, 0.7594, 0.6417, 1.1956,
        0.5993, 0.5758, 0.6563, 0.5893, 0.5814, 0.6465, 0.7067, 0.9046, 0.7619,
        1.9338, 1.0466, 0.7135, 0.6449, 0.5923, 0.5875, 0.7245, 0.6060, 1.0644,
        0.5855, 2.4131, 0.8083, 0.5869, 0.5916, 0.7265, 3.6514, 1.7324, 0.6449],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  51  33  65 136 100  73  57  80  40  83 140  20  46  39  73  29  57  44
  28  55 198 142 156 188 113  80 123 182 144 425 167 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 270  63 140
 153 114 104  60  40 422 311 125  97 143  32  23 305 142 129 137  66  71
 215 147 169 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2821, 0.6252, 1.0832, 1.1583, 0.8449, 0.8370, 0.6293, 0.6886, 0.6252,
        1.1956, 0.8449, 0.5951, 1.0380, 1.4519, 0.7894, 2.6758, 0.6928, 0.5760,
        1.4300, 2.0317, 1.1956, 0.7697, 0.9046, 1.1032, 1.3150, 1.0380, 1.7324,
        1.0136, 0.7594, 3.1494, 1.5492, 1.7685, 1.1032, 2.2683, 1.3150, 1.6047,
        2.3381, 1.3505, 0.6643, 0.7546, 0.7245, 0.6756, 0.8449, 1.0380, 0.8083,
        0.6832, 0.7499, 0.5816, 0.7051, 0.5815, 0.7453, 0.6582, 0.7594, 1.3692,
        0.6988, 0.7067, 0.6612, 0.7387, 0.5898, 0.5782, 0.6720, 1.3150, 0.6526,
        0.6572, 0.7954, 0.8797, 0.9383, 0.7067, 1.4985, 0.6142, 1.2225, 0.7594,
        0.7304, 0.8409, 0.8845, 1.2664, 1.7324, 0.5819, 0.5998, 0.8017, 0.9209,
        0.7522, 2.0852, 2.7787, 0.6015, 0.7546, 0.7894, 0.7671, 1.1828, 1.1242,
        0.6482, 0.7431, 0.7019, 0.6312, 0.7645, 0.6417, 0.7594, 0.6417, 1.1956,
        0.5993, 0.5758, 0.6563, 0.5893, 0.5814, 0.6465, 0.7067, 0.9046, 0.7619,
        1.9338, 1.0466, 0.7135, 0.6449, 0.5923, 0.5875, 0.7245, 0.6060, 1.0644,
        0.5855, 2.4131, 0.8083, 0.5869, 0.5916, 0.7265, 3.6514, 1.7324, 0.6449],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  40  83 140  20  46  43  73  29  57  44
  29  55 198 142 156 188 113  80 123 182 144 425 167 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2839, 0.6261, 1.0848, 1.1600, 0.8461, 0.8382, 0.6302, 0.6896, 0.6261,
        1.1973, 0.8461, 0.5959, 1.0395, 1.4540, 0.7905, 2.6797, 0.6938, 0.5769,
        1.4540, 2.0346, 1.1973, 0.7708, 0.9059, 1.1048, 1.3170, 1.0395, 1.7349,
        1.0151, 0.7605, 3.1540, 1.5515, 1.6367, 1.1048, 2.2716, 1.3170, 1.6070,
        2.2716, 1.3525, 0.6653, 0.7557, 0.7256, 0.6766, 0.8461, 1.0395, 0.8095,
        0.6842, 0.7510, 0.5824, 0.7061, 0.5824, 0.7464, 0.6591, 0.7605, 1.3712,
        0.6998, 0.7078, 0.6621, 0.7398, 0.5907, 0.5790, 0.6730, 1.3170, 0.6535,
        0.6582, 0.7966, 0.8810, 0.9396, 0.7078, 1.5007, 0.6155, 1.2243, 0.7581,
        0.7315, 0.8421, 0.8858, 1.2682, 1.7349, 0.5827, 0.6007, 0.8062, 0.9222,
        0.7533, 2.0883, 2.7827, 0.6024, 0.7557, 0.7905, 0.7682, 1.1845, 1.1259,
        0.6491, 0.7442, 0.7013, 0.6321, 0.7656, 0.6426, 0.7605, 0.6426, 1.1973,
        0.6001, 0.5767, 0.6572, 0.5902, 0.5822, 0.6474, 0.7078, 0.9059, 0.7630,
        1.9366, 1.0481, 0.7146, 0.6458, 0.5932, 0.5883, 0.7256, 0.6069, 1.0660,
        0.5863, 2.4166, 0.8095, 0.5877, 0.5924, 0.7275, 3.6567, 1.7349, 0.6458],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  40  83 140  20  46  45  73  29  57  43
  29  55 198 142 156 188 113  80 123 182 144 425 167 426 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 428 217 166 100 139
  35  79 162 219 343 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2842, 0.6262, 1.0851, 1.1602, 0.8463, 0.8384, 0.6304, 0.6897, 0.6262,
        1.1976, 0.8463, 0.5961, 1.0398, 1.4543, 0.7907, 2.6803, 0.6940, 0.5770,
        1.4543, 2.0351, 1.1976, 0.7710, 0.9061, 1.1050, 1.3172, 1.0398, 1.7353,
        1.0153, 0.7607, 3.1547, 1.5518, 1.5790, 1.1050, 2.2721, 1.3172, 1.6371,
        2.2721, 1.3528, 0.6654, 0.7558, 0.7258, 0.6767, 0.8463, 1.0398, 0.8096,
        0.6843, 0.7511, 0.5826, 0.7063, 0.5825, 0.7466, 0.6593, 0.7607, 1.3715,
        0.7000, 0.7079, 0.6623, 0.7400, 0.5908, 0.5791, 0.6732, 1.3172, 0.6536,
        0.6583, 0.7968, 0.8812, 0.9398, 0.7079, 1.5010, 0.6157, 1.2246, 0.7583,
        0.7317, 0.8423, 0.8860, 1.2685, 1.7353, 0.5828, 0.6008, 0.8063, 0.9224,
        0.7535, 2.0887, 2.7834, 0.6025, 0.7558, 0.7907, 0.7683, 1.1848, 1.1261,
        0.6493, 0.7443, 0.7015, 0.6323, 0.7658, 0.6428, 0.7607, 0.6428, 1.1976,
        0.6003, 0.5768, 0.6574, 0.5903, 0.5823, 0.6476, 0.7079, 0.9061, 0.7632,
        1.9371, 1.0483, 0.7147, 0.6459, 0.5933, 0.5884, 0.7258, 0.6070, 1.0662,
        0.5864, 2.4171, 0.8096, 0.5879, 0.5926, 0.7277, 3.6576, 1.7353, 0.6459],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  39  83 140  20  46  50  73  29  57  43
  30  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 427 217 166 100 139
  35  79 162 219 342 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2858, 0.6270, 1.0864, 1.1616, 0.8473, 0.8394, 0.6311, 0.6906, 0.6270,
        1.1991, 0.8473, 0.5968, 1.0410, 1.4561, 0.7917, 2.6836, 0.6948, 0.5777,
        1.4561, 2.0376, 1.1991, 0.7719, 0.9072, 1.1064, 1.3189, 1.0410, 1.7737,
        1.0166, 0.7616, 3.1585, 1.5537, 1.4561, 1.1064, 2.2748, 1.3189, 1.6391,
        2.2096, 1.3544, 0.6662, 0.7568, 0.7266, 0.6776, 0.8473, 1.0410, 0.8106,
        0.6851, 0.7520, 0.5833, 0.7072, 0.5833, 0.7475, 0.6601, 0.7616, 1.3732,
        0.7008, 0.7088, 0.6631, 0.7409, 0.5915, 0.5799, 0.6740, 1.3189, 0.6544,
        0.6591, 0.7978, 0.8823, 0.9410, 0.7088, 1.5028, 0.6164, 1.2261, 0.7592,
        0.7326, 0.8433, 0.8870, 1.2701, 1.7375, 0.5835, 0.6016, 0.8073, 0.9235,
        0.7544, 2.0913, 2.7868, 0.6033, 0.7568, 0.7917, 0.7693, 1.1862, 1.1275,
        0.6501, 0.7452, 0.7024, 0.6330, 0.7667, 0.6436, 0.7616, 0.6436, 1.1991,
        0.6010, 0.5775, 0.6582, 0.5910, 0.5831, 0.6484, 0.7088, 0.9072, 0.7641,
        1.9394, 1.0496, 0.7156, 0.6467, 0.5943, 0.5892, 0.7266, 0.6078, 1.0675,
        0.5872, 2.4201, 0.8106, 0.5886, 0.5933, 0.7286, 3.6620, 1.7375, 0.6467],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  39  83 140  20  46  50  73  29  57  43
  30  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 201 149 357 479 191  57 210 205 127 105  94 166  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 427 217 166 100 139
  35  79 162 219 342 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2858, 0.6270, 1.0864, 1.1616, 0.8473, 0.8394, 0.6311, 0.6906, 0.6270,
        1.1991, 0.8473, 0.5968, 1.0410, 1.4561, 0.7917, 2.6836, 0.6948, 0.5777,
        1.4561, 2.0376, 1.1991, 0.7719, 0.9072, 1.1064, 1.3189, 1.0410, 1.7737,
        1.0166, 0.7616, 3.1585, 1.5537, 1.4561, 1.1064, 2.2748, 1.3189, 1.6391,
        2.2096, 1.3544, 0.6662, 0.7568, 0.7266, 0.6776, 0.8473, 1.0410, 0.8106,
        0.6851, 0.7520, 0.5833, 0.7072, 0.5833, 0.7475, 0.6601, 0.7616, 1.3732,
        0.7008, 0.7088, 0.6631, 0.7409, 0.5915, 0.5799, 0.6740, 1.3189, 0.6544,
        0.6591, 0.7978, 0.8823, 0.9410, 0.7088, 1.5028, 0.6164, 1.2261, 0.7592,
        0.7326, 0.8433, 0.8870, 1.2701, 1.7375, 0.5835, 0.6016, 0.8073, 0.9235,
        0.7544, 2.0913, 2.7868, 0.6033, 0.7568, 0.7917, 0.7693, 1.1862, 1.1275,
        0.6501, 0.7452, 0.7024, 0.6330, 0.7667, 0.6436, 0.7616, 0.6436, 1.1991,
        0.6010, 0.5775, 0.6582, 0.5910, 0.5831, 0.6484, 0.7088, 0.9072, 0.7641,
        1.9394, 1.0496, 0.7156, 0.6467, 0.5943, 0.5892, 0.7266, 0.6078, 1.0675,
        0.5872, 2.4201, 0.8106, 0.5886, 0.5933, 0.7286, 3.6620, 1.7375, 0.6467],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  39  83 140  20  46  52  73  29  57  43
  30  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 200 149 357 479 191  57 210 205 127 105  94 166  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 427 217 166 100 139
  35  79 162 219 342 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2862, 0.6272, 1.0867, 1.1620, 0.8476, 0.8397, 0.6314, 0.6908, 0.6272,
        1.1995, 0.8476, 0.5970, 1.0414, 1.4566, 0.7919, 2.6845, 0.6951, 0.5779,
        1.4566, 2.0383, 1.1995, 0.7722, 0.9075, 1.1067, 1.3193, 1.0414, 1.7742,
        1.0169, 0.7619, 3.1596, 1.5542, 1.4135, 1.1067, 2.2756, 1.3193, 1.6396,
        2.2103, 1.3549, 0.6664, 0.7570, 0.7269, 0.6778, 0.8476, 1.0414, 0.8109,
        0.6854, 0.7523, 0.5835, 0.7074, 0.5835, 0.7477, 0.6603, 0.7619, 1.3737,
        0.7010, 0.7090, 0.6643, 0.7411, 0.5917, 0.5800, 0.6742, 1.3193, 0.6547,
        0.6593, 0.7980, 0.8825, 0.9413, 0.7090, 1.5033, 0.6166, 1.2265, 0.7594,
        0.7328, 0.8436, 0.8873, 1.2705, 1.7380, 0.5837, 0.6018, 0.8076, 0.9238,
        0.7546, 2.0920, 2.7877, 0.6035, 0.7570, 0.7919, 0.7695, 1.1866, 1.1279,
        0.6503, 0.7455, 0.7026, 0.6332, 0.7670, 0.6438, 0.7619, 0.6438, 1.1995,
        0.6012, 0.5777, 0.6584, 0.5912, 0.5833, 0.6486, 0.7090, 0.9075, 0.7644,
        1.9401, 1.0500, 0.7159, 0.6469, 0.5945, 0.5894, 0.7269, 0.6080, 1.0679,
        0.5874, 2.4209, 0.8109, 0.5888, 0.5935, 0.7288, 3.6632, 1.7380, 0.6469],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 129  24 175 540
  50  33  65 136 100  73  57  80  39  83 140  20  46  52  73  29  57  43
  31  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 200 149 357 479 191  57 210 205 127 105  94 165  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  66  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 427 217 166 100 139
  35  79 162 219 342 372 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2868, 0.6275, 1.0873, 1.1626, 0.8480, 0.8401, 0.6317, 0.6911, 0.6275,
        1.2000, 0.8480, 0.5973, 1.0419, 1.4573, 0.7923, 2.6857, 0.6954, 0.5782,
        1.4573, 2.0392, 1.2000, 0.7725, 0.9079, 1.1072, 1.3199, 1.0419, 1.7751,
        1.0174, 0.7623, 3.1611, 1.5550, 1.4142, 1.1072, 2.2767, 1.3199, 1.6404,
        2.1502, 1.3555, 0.6668, 0.7574, 0.7272, 0.6781, 0.8480, 1.0419, 0.8113,
        0.6857, 0.7526, 0.5838, 0.7077, 0.5838, 0.7481, 0.6606, 0.7623, 1.3743,
        0.7014, 0.7094, 0.6647, 0.7415, 0.5920, 0.5803, 0.6745, 1.3199, 0.6550,
        0.6597, 0.7984, 0.8830, 0.9417, 0.7110, 1.5040, 0.6169, 1.2271, 0.7598,
        0.7331, 0.8440, 0.8877, 1.2711, 1.7389, 0.5840, 0.6020, 0.8080, 0.9243,
        0.7550, 2.0930, 2.7890, 0.6038, 0.7574, 0.7923, 0.7699, 1.1872, 1.1284,
        0.6506, 0.7458, 0.7029, 0.6335, 0.7673, 0.6441, 0.7623, 0.6441, 1.2000,
        0.6015, 0.5780, 0.6587, 0.5915, 0.5836, 0.6489, 0.7094, 0.9079, 0.7648,
        1.9410, 1.0505, 0.7162, 0.6473, 0.5947, 0.5896, 0.7272, 0.6083, 1.0684,
        0.5876, 2.4220, 0.8113, 0.5891, 0.5938, 0.7292, 3.6650, 1.7389, 0.6473],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 113 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 100  73  57  80  39  83 140  20  46  52  73  29  57  43
  32  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 200 149 357 479 191  57 210 205 127 105  94 165  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  67  71
 215 147 170 238 138 223 140 223  65 313 548 206 360 427 217 166 100 139
  35  79 162 219 342 372 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2875, 0.6278, 1.0878, 1.1632, 0.8484, 0.8405, 0.6320, 0.6915, 0.6278,
        1.2007, 0.8484, 0.5976, 1.0424, 1.4580, 0.7957, 2.6871, 0.6957, 0.5784,
        1.4580, 2.0403, 1.2007, 0.7729, 0.9084, 1.1078, 1.3206, 1.0424, 1.7760,
        1.0179, 0.7627, 3.1627, 1.5558, 1.4149, 1.1078, 2.2779, 1.3206, 1.6412,
        2.0941, 1.3562, 0.6671, 0.7578, 0.7276, 0.6785, 0.8484, 1.0424, 0.8117,
        0.6860, 0.7530, 0.5841, 0.7081, 0.5841, 0.7484, 0.6610, 0.7627, 1.3750,
        0.7017, 0.7097, 0.6650, 0.7418, 0.5923, 0.5806, 0.6749, 1.3206, 0.6553,
        0.6600, 0.7988, 0.8834, 0.9422, 0.7114, 1.5048, 0.6172, 1.2277, 0.7602,
        0.7335, 0.8444, 0.8882, 1.2718, 1.7397, 0.5843, 0.6024, 0.8084, 0.9248,
        0.7554, 2.0941, 2.7904, 0.6041, 0.7578, 0.7927, 0.7703, 1.1753, 1.1290,
        0.6509, 0.7462, 0.7033, 0.6339, 0.7677, 0.6444, 0.7627, 0.6444, 1.2007,
        0.6018, 0.5783, 0.6590, 0.5918, 0.5839, 0.6492, 0.7097, 0.9084, 0.7652,
        1.9420, 1.0510, 0.7166, 0.6476, 0.5950, 0.5899, 0.7295, 0.6086, 1.0689,
        0.5879, 2.4233, 0.8117, 0.5894, 0.5941, 0.7295, 3.6669, 1.7397, 0.6476],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  52  73  29  57  43
  32  55 198 142 156 188 113  80 123 182 144 425 167 425 146 204 140  54
 171 166 200 149 357 479 191  57 210 205 127 105  94 165  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  67  71
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  36  79 162 219 342 372 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2879, 0.6281, 1.0882, 1.1636, 0.8528, 0.8408, 0.6322, 0.6917, 0.6281,
        1.2011, 0.8487, 0.5978, 1.0428, 1.4585, 0.7960, 2.6881, 0.6960, 0.5787,
        1.4585, 2.0410, 1.2011, 0.7732, 0.9035, 1.1082, 1.3211, 1.0428, 1.7766,
        1.0183, 0.7629, 3.1638, 1.5563, 1.4154, 1.1082, 2.2787, 1.3211, 1.6418,
        2.0948, 1.3567, 0.6673, 0.7580, 0.7279, 0.6787, 0.8487, 1.0428, 0.8120,
        0.6863, 0.7533, 0.5843, 0.7083, 0.5843, 0.7487, 0.6612, 0.7629, 1.3755,
        0.7020, 0.7100, 0.6652, 0.7421, 0.5925, 0.5808, 0.6751, 1.3211, 0.6555,
        0.6602, 0.7991, 0.8837, 0.9426, 0.7117, 1.5053, 0.6175, 1.2281, 0.7605,
        0.7338, 0.8447, 0.8885, 1.2722, 1.7404, 0.5845, 0.6026, 0.8087, 0.9251,
        0.7556, 2.0948, 2.7914, 0.6043, 0.7580, 0.7930, 0.7706, 1.1757, 1.1294,
        0.6511, 0.7465, 0.7035, 0.6341, 0.7680, 0.6447, 0.7629, 0.6447, 1.2011,
        0.6020, 0.5785, 0.6602, 0.5920, 0.5841, 0.6495, 0.7100, 0.9087, 0.7654,
        1.8977, 1.0514, 0.7168, 0.6478, 0.5953, 0.5901, 0.7298, 0.6088, 1.0693,
        0.5881, 2.4241, 0.8120, 0.5896, 0.5943, 0.7298, 3.6682, 1.7404, 0.6478],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  52  73  29  57  43
  33  55 198 141 156 188 113  80 123 182 144 425 167 425 146 205 140  54
 171 166 200 149 357 479 191  57 210 205 128 105  94 164  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  67  71
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  36  79 162 219 342 372 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2885, 0.6283, 1.0887, 1.1641, 0.8532, 0.8412, 0.6325, 0.6920, 0.6283,
        1.2016, 0.8491, 0.5981, 1.0432, 1.4592, 0.7964, 2.6892, 0.6963, 0.5789,
        1.4592, 2.0419, 1.2016, 0.7735, 0.9039, 1.1087, 1.3216, 1.0432, 1.7774,
        1.0187, 0.7633, 3.1652, 1.5570, 1.4160, 1.1087, 2.2796, 1.3216, 1.6425,
        2.0419, 1.3573, 0.6676, 0.7608, 0.7282, 0.6790, 0.8491, 1.0432, 0.8123,
        0.6866, 0.7536, 0.5845, 0.7086, 0.5845, 0.7490, 0.6605, 0.7633, 1.3761,
        0.7023, 0.7103, 0.6655, 0.7424, 0.5927, 0.5811, 0.6754, 1.3216, 0.6558,
        0.6605, 0.7964, 0.8841, 0.9430, 0.7137, 1.5060, 0.6177, 1.2287, 0.7608,
        0.7341, 0.8451, 0.8889, 1.2728, 1.7411, 0.5848, 0.6028, 0.8090, 0.9255,
        0.7560, 2.0957, 2.7926, 0.6046, 0.7584, 0.7933, 0.7709, 1.1762, 1.1299,
        0.6514, 0.7468, 0.7038, 0.6344, 0.7683, 0.6449, 0.7633, 0.6449, 1.2016,
        0.6023, 0.5787, 0.6605, 0.5922, 0.5844, 0.6497, 0.7103, 0.9091, 0.7658,
        1.8985, 1.0518, 0.7171, 0.6481, 0.5955, 0.5904, 0.7301, 0.6091, 1.0697,
        0.5884, 2.4252, 0.8123, 0.5898, 0.5945, 0.7301, 3.6697, 1.7411, 0.6481],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  53  73  29  57  43
  33  55 198 141 156 188 113  80 123 182 144 425 167 425 146 205 140  54
 171 166 200 149 357 479 191  57 210 205 128 105  94 164  48 269  63 141
 153 114 104  60  40 422 311 124  97 143  32  23 305 142 129 137  67  71
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  36  79 162 219 342 371 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2887, 0.6284, 1.0888, 1.1643, 0.8533, 0.8413, 0.6326, 0.6921, 0.6284,
        1.2018, 0.8492, 0.5981, 1.0434, 1.4594, 0.7965, 2.6896, 0.6964, 0.5790,
        1.4594, 2.0422, 1.2018, 0.7737, 0.9041, 1.1089, 1.3218, 1.0434, 1.7777,
        1.0189, 0.7634, 3.1657, 1.5572, 1.3959, 1.1089, 2.2800, 1.3218, 1.6428,
        2.0422, 1.3575, 0.6677, 0.7609, 0.7283, 0.6791, 0.8492, 1.0434, 0.8125,
        0.6867, 0.7537, 0.5846, 0.7088, 0.5846, 0.7492, 0.6606, 0.7634, 1.3763,
        0.7024, 0.7104, 0.6656, 0.7425, 0.5928, 0.5812, 0.6755, 1.3218, 0.6559,
        0.6606, 0.7965, 0.8843, 0.9431, 0.7138, 1.5062, 0.6178, 1.2289, 0.7609,
        0.7342, 0.8452, 0.8890, 1.2730, 1.7414, 0.5849, 0.6029, 0.8091, 0.9256,
        0.7561, 2.0960, 2.7931, 0.6046, 0.7585, 0.7934, 0.7710, 1.1764, 1.1301,
        0.6515, 0.7469, 0.7040, 0.6345, 0.7684, 0.6450, 0.7634, 0.6450, 1.2018,
        0.6024, 0.5788, 0.6606, 0.5923, 0.5844, 0.6498, 0.7104, 0.9093, 0.7659,
        1.8988, 1.0520, 0.7172, 0.6482, 0.5956, 0.5906, 0.7302, 0.6092, 1.0699,
        0.5885, 2.4256, 0.8125, 0.5899, 0.5946, 0.7302, 3.6703, 1.7414, 0.6482],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 248  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  53  73  29  56  43
  33  55 198 141 156 188 113  80 123 182 144 425 167 425 146 205 140  54
 171 166 200 149 357 479 191  57 210 205 128 105  94 164  48 269  63 141
 153 114 104  60  41 422 311 124  97 143  32  23 305 142 129 137  67  71
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  36  79 162 219 342 371 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2889, 0.6285, 1.0890, 1.1644, 0.8534, 0.8414, 0.6327, 0.6922, 0.6285,
        1.2020, 0.8493, 0.5982, 1.0435, 1.4596, 0.7966, 2.6900, 0.6965, 0.5791,
        1.4596, 2.0425, 1.2020, 0.7738, 0.9042, 1.1090, 1.3220, 1.0435, 1.7779,
        1.0190, 0.7635, 3.1661, 1.5574, 1.3961, 1.1090, 2.2803, 1.3395, 1.6430,
        2.0425, 1.3577, 0.6678, 0.7610, 0.7284, 0.6792, 0.8493, 1.0435, 0.8126,
        0.6868, 0.7538, 0.5847, 0.7088, 0.5847, 0.7493, 0.6607, 0.7635, 1.3765,
        0.7025, 0.7105, 0.6657, 0.7426, 0.5929, 0.5812, 0.6756, 1.3220, 0.6560,
        0.6607, 0.7966, 0.8844, 0.9432, 0.7139, 1.5064, 0.6179, 1.2290, 0.7610,
        0.7343, 0.8453, 0.8892, 1.2731, 1.7071, 0.5849, 0.6030, 0.8093, 0.9258,
        0.7562, 2.0963, 2.7934, 0.6047, 0.7586, 0.7936, 0.7711, 1.1766, 1.1302,
        0.6516, 0.7470, 0.7040, 0.6346, 0.7685, 0.6451, 0.7635, 0.6451, 1.2020,
        0.6025, 0.5789, 0.6607, 0.5924, 0.5845, 0.6499, 0.7105, 0.9094, 0.7660,
        1.8991, 1.0521, 0.7173, 0.6483, 0.5957, 0.5907, 0.7303, 0.6092, 1.0701,
        0.5886, 2.4259, 0.8126, 0.5900, 0.5947, 0.7303, 3.6708, 1.7416, 0.6483],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  53  73  29  56  43
  33  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 479 191  57 210 205 128 105  94 164  48 269  63 141
 153 114 104  60  41 422 311 124  97 143  32  24 305 142 129 137  67  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2904, 0.6298, 1.0903, 1.1659, 0.8545, 0.8424, 0.6334, 0.6931, 0.6293,
        1.2034, 0.8504, 0.5990, 1.0448, 1.4614, 0.7976, 2.6933, 0.6974, 0.5798,
        1.4614, 2.0450, 1.2034, 0.7747, 0.9053, 1.1104, 1.3236, 1.0448, 1.7801,
        1.0203, 0.7644, 3.1700, 1.5593, 1.3978, 1.1104, 2.2831, 1.3412, 1.6450,
        2.0450, 1.3593, 0.6686, 0.7619, 0.7293, 0.6800, 0.8504, 1.0448, 0.8136,
        0.6876, 0.7571, 0.5854, 0.7097, 0.5854, 0.7502, 0.6615, 0.7644, 1.3782,
        0.7034, 0.7114, 0.6665, 0.7436, 0.5936, 0.5820, 0.6764, 1.3236, 0.6568,
        0.6615, 0.7976, 0.8855, 0.9444, 0.7147, 1.5083, 0.6187, 1.2305, 0.7619,
        0.7352, 0.8464, 0.8903, 1.2747, 1.7092, 0.5857, 0.6037, 0.8102, 0.9269,
        0.7571, 2.0989, 2.6933, 0.6055, 0.7595, 0.7945, 0.7721, 1.1780, 1.1208,
        0.6524, 0.7479, 0.7049, 0.6353, 0.7695, 0.6459, 0.7644, 0.6459, 1.2034,
        0.6032, 0.5796, 0.6615, 0.5931, 0.5852, 0.6507, 0.7114, 0.9105, 0.7669,
        1.8587, 1.0534, 0.7182, 0.6491, 0.5964, 0.5914, 0.7312, 0.6100, 1.0714,
        0.5893, 2.4288, 0.8136, 0.5907, 0.5954, 0.7312, 3.6753, 1.7438, 0.6491],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  53  73  29  56  43
  33  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 479 191  57 210 205 128 105  94 164  48 269  63 141
 153 114 104  60  41 422 311 124  97 143  32  24 305 142 129 137  67  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 155 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2904, 0.6298, 1.0903, 1.1659, 0.8545, 0.8424, 0.6334, 0.6931, 0.6293,
        1.2034, 0.8504, 0.5990, 1.0448, 1.4614, 0.7976, 2.6933, 0.6974, 0.5798,
        1.4614, 2.0450, 1.2034, 0.7747, 0.9053, 1.1104, 1.3236, 1.0448, 1.7801,
        1.0203, 0.7644, 3.1700, 1.5593, 1.3978, 1.1104, 2.2831, 1.3412, 1.6450,
        2.0450, 1.3593, 0.6686, 0.7619, 0.7293, 0.6800, 0.8504, 1.0448, 0.8136,
        0.6876, 0.7571, 0.5854, 0.7097, 0.5854, 0.7502, 0.6615, 0.7644, 1.3782,
        0.7034, 0.7114, 0.6665, 0.7436, 0.5936, 0.5820, 0.6764, 1.3236, 0.6568,
        0.6615, 0.7976, 0.8855, 0.9444, 0.7147, 1.5083, 0.6187, 1.2305, 0.7619,
        0.7352, 0.8464, 0.8903, 1.2747, 1.7092, 0.5857, 0.6037, 0.8102, 0.9269,
        0.7571, 2.0989, 2.6933, 0.6055, 0.7595, 0.7945, 0.7721, 1.1780, 1.1208,
        0.6524, 0.7479, 0.7049, 0.6353, 0.7695, 0.6459, 0.7644, 0.6459, 1.2034,
        0.6032, 0.5796, 0.6615, 0.5931, 0.5852, 0.6507, 0.7114, 0.9105, 0.7669,
        1.8587, 1.0534, 0.7182, 0.6491, 0.5964, 0.5914, 0.7312, 0.6100, 1.0714,
        0.5893, 2.4288, 0.8136, 0.5907, 0.5954, 0.7312, 3.6753, 1.7438, 0.6491],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 113 330  80  50 128  24 175 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  34  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  94 163  48 269  63 141
 153 114 104  60  41 422 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 156 291  77 387  27 123 376 347 155  17  40 219]
CBFL per class weights: tensor([1.2913, 0.6303, 1.0910, 1.1666, 0.8550, 0.8430, 0.6339, 0.6935, 0.6297,
        1.2042, 0.8509, 0.5994, 1.0455, 1.4623, 0.7981, 2.6951, 0.6978, 0.5802,
        1.4623, 2.0463, 1.2042, 0.7752, 0.9059, 1.1111, 1.3245, 1.0455, 1.7813,
        1.0209, 0.7649, 3.1721, 1.5604, 1.3791, 1.1111, 2.2846, 1.3420, 1.6461,
        1.9956, 1.3602, 0.6691, 0.7624, 0.7298, 0.6805, 0.8509, 1.0455, 0.8141,
        0.6881, 0.7576, 0.5858, 0.7102, 0.5858, 0.7507, 0.6620, 0.7649, 1.3791,
        0.7038, 0.7118, 0.6670, 0.7440, 0.5940, 0.5824, 0.6769, 1.3245, 0.6572,
        0.6620, 0.7981, 0.8860, 0.9450, 0.7169, 1.5093, 0.6191, 1.2313, 0.7624,
        0.7357, 0.8469, 0.8908, 1.2755, 1.7103, 0.5860, 0.6041, 0.8108, 0.9275,
        0.7576, 2.1003, 2.6951, 0.6059, 0.7600, 0.7950, 0.7726, 1.1666, 1.1216,
        0.6528, 0.7484, 0.7054, 0.6357, 0.7700, 0.6463, 0.7649, 0.6463, 1.2042,
        0.6036, 0.5800, 0.6620, 0.5935, 0.5856, 0.6512, 0.7118, 0.9111, 0.7674,
        1.8600, 1.0541, 0.7187, 0.6495, 0.5968, 0.5918, 0.7298, 0.6104, 1.0721,
        0.5897, 2.4304, 0.8141, 0.5911, 0.5958, 0.7317, 3.6777, 1.7449, 0.6495],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 113 330  80  50 128  24 176 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  34  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  94 163  48 269  63 141
 153 114 104  60  41 422 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 123 375 347 155  17  40 219]
CBFL per class weights: tensor([1.2913, 0.6303, 1.0911, 1.1667, 0.8550, 0.8430, 0.6339, 0.6935, 0.6297,
        1.2042, 0.8510, 0.5994, 1.0455, 1.4624, 0.7981, 2.6951, 0.6964, 0.5802,
        1.4624, 2.0464, 1.2042, 0.7752, 0.9059, 1.1111, 1.3245, 1.0455, 1.7813,
        1.0210, 0.7649, 3.1721, 1.5604, 1.3791, 1.1111, 2.2847, 1.3421, 1.6461,
        1.9956, 1.3603, 0.6691, 0.7625, 0.7298, 0.6805, 0.8510, 1.0455, 0.8141,
        0.6881, 0.7576, 0.5858, 0.7102, 0.5858, 0.7507, 0.6620, 0.7649, 1.3791,
        0.7038, 0.7118, 0.6670, 0.7441, 0.5941, 0.5824, 0.6769, 1.3245, 0.6573,
        0.6620, 0.7981, 0.8861, 0.9450, 0.7169, 1.5093, 0.6191, 1.2314, 0.7625,
        0.7357, 0.8469, 0.8909, 1.2756, 1.7104, 0.5861, 0.6042, 0.8108, 0.9275,
        0.7576, 2.1003, 2.6951, 0.6059, 0.7600, 0.7951, 0.7726, 1.1667, 1.1216,
        0.6529, 0.7484, 0.7054, 0.6358, 0.7700, 0.6464, 0.7649, 0.6464, 1.2042,
        0.6036, 0.5800, 0.6620, 0.5936, 0.5856, 0.6512, 0.7118, 0.9111, 0.7674,
        1.8600, 1.0541, 0.7187, 0.6495, 0.5968, 0.5918, 0.7279, 0.6104, 1.0721,
        0.5897, 2.4305, 0.8141, 0.5913, 0.5958, 0.7317, 3.6778, 1.7449, 0.6495],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 113 330  80  50 128  25 176 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  34  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  94 163  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 123 375 347 155  17  40 219]
CBFL per class weights: tensor([1.2923, 0.6308, 1.0919, 1.1675, 0.8557, 0.8437, 0.6344, 0.6941, 0.6302,
        1.2052, 0.8516, 0.5998, 1.0463, 1.4635, 0.7987, 2.6018, 0.6969, 0.5806,
        1.4635, 2.0479, 1.2052, 0.7758, 0.9066, 1.1120, 1.3255, 1.0463, 1.7827,
        1.0217, 0.7655, 3.1745, 1.5616, 1.3802, 1.1120, 2.2864, 1.3431, 1.6474,
        1.9971, 1.3613, 0.6696, 0.7630, 0.7303, 0.6810, 0.8516, 1.0463, 0.8147,
        0.6886, 0.7582, 0.5862, 0.7107, 0.5862, 0.7513, 0.6625, 0.7655, 1.3802,
        0.7044, 0.7124, 0.6675, 0.7446, 0.5945, 0.5828, 0.6774, 1.3255, 0.6578,
        0.6625, 0.7987, 0.8867, 0.9458, 0.7175, 1.5104, 0.6196, 1.2323, 0.7630,
        0.7363, 0.8476, 0.8915, 1.2765, 1.7117, 0.5866, 0.6046, 0.8114, 0.9282,
        0.7582, 2.1019, 2.6972, 0.6063, 0.7606, 0.7957, 0.7732, 1.1675, 1.1224,
        0.6533, 0.7490, 0.7059, 0.6362, 0.7706, 0.6468, 0.7655, 0.6468, 1.2052,
        0.6041, 0.5804, 0.6625, 0.5940, 0.5861, 0.6517, 0.7124, 0.9118, 0.7680,
        1.8614, 1.0549, 0.7192, 0.6500, 0.5973, 0.5923, 0.7284, 0.6109, 1.0729,
        0.5901, 2.4323, 0.8147, 0.5917, 0.5963, 0.7323, 3.6806, 1.7463, 0.6500],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  36  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  94 162  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 123 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2932, 0.6312, 1.0927, 1.1684, 0.8563, 0.8443, 0.6348, 0.6946, 0.6312,
        1.2060, 0.8522, 0.6003, 1.0471, 1.4645, 0.7993, 2.6037, 0.6960, 0.5810,
        1.4645, 2.0494, 1.2060, 0.7764, 0.9072, 1.1128, 1.3265, 1.0471, 1.7840,
        1.0225, 0.7661, 3.1769, 1.5627, 1.3812, 1.1128, 2.2881, 1.3441, 1.6486,
        1.9055, 1.3623, 0.6701, 0.7636, 0.7309, 0.6815, 0.8522, 1.0471, 0.8153,
        0.6891, 0.7588, 0.5867, 0.7113, 0.5867, 0.7518, 0.6630, 0.7661, 1.3812,
        0.7049, 0.7129, 0.6680, 0.7452, 0.5949, 0.5833, 0.6779, 1.3265, 0.6582,
        0.6630, 0.7993, 0.8874, 0.9464, 0.7198, 1.5115, 0.6200, 1.2332, 0.7636,
        0.7368, 0.8482, 0.8922, 1.2775, 1.7129, 0.5870, 0.6051, 0.8120, 0.9289,
        0.7588, 2.1034, 2.6991, 0.6068, 0.7612, 0.7963, 0.7737, 1.1684, 1.1233,
        0.6538, 0.7496, 0.7064, 0.6367, 0.7711, 0.6473, 0.7661, 0.6473, 1.2060,
        0.6045, 0.5808, 0.6630, 0.5944, 0.5865, 0.6521, 0.7129, 0.9125, 0.7686,
        1.8628, 1.0557, 0.7198, 0.6505, 0.5977, 0.5927, 0.7289, 0.6113, 1.0737,
        0.5906, 2.4341, 0.8153, 0.5923, 0.5967, 0.7328, 3.6833, 1.7475, 0.6505],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  37  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  94 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 123 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2937, 0.6314, 1.0930, 1.1688, 0.8566, 0.8445, 0.6350, 0.6948, 0.6314,
        1.2064, 0.8525, 0.6005, 1.0474, 1.4650, 0.7996, 2.6045, 0.6962, 0.5812,
        1.4650, 2.0501, 1.2064, 0.7766, 0.9075, 1.1131, 1.3269, 1.0474, 1.7845,
        1.0228, 0.7663, 3.1779, 1.5632, 1.3816, 1.1131, 2.2888, 1.3445, 1.6491,
        1.8634, 1.3627, 0.6703, 0.7638, 0.7311, 0.6817, 0.8525, 1.0474, 0.8156,
        0.6893, 0.7590, 0.5869, 0.7115, 0.5869, 0.7520, 0.6632, 0.7663, 1.3816,
        0.7051, 0.7131, 0.6682, 0.7454, 0.5951, 0.5835, 0.6781, 1.3269, 0.6585,
        0.6632, 0.7996, 0.8877, 0.9468, 0.7218, 1.5120, 0.6202, 1.2336, 0.7638,
        0.7370, 0.8485, 0.8925, 1.2779, 1.7135, 0.5872, 0.6052, 0.8123, 0.9292,
        0.7590, 2.1041, 2.7000, 0.6070, 0.7614, 0.7965, 0.7740, 1.1688, 1.1236,
        0.6540, 0.7498, 0.7067, 0.6369, 0.7714, 0.6475, 0.7663, 0.6475, 1.2064,
        0.6047, 0.5810, 0.6632, 0.5946, 0.5867, 0.6523, 0.7131, 0.9128, 0.7688,
        1.8634, 1.0561, 0.7200, 0.6507, 0.5979, 0.5929, 0.7292, 0.6115, 1.0740,
        0.5908, 2.4349, 0.8156, 0.5925, 0.5969, 0.7331, 3.6845, 1.7481, 0.6507],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  37  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2937, 0.6314, 1.0931, 1.1688, 0.8566, 0.8446, 0.6350, 0.6948, 0.6314,
        1.2064, 0.8525, 0.6005, 1.0474, 1.4650, 0.7996, 2.6046, 0.6962, 0.5812,
        1.4650, 2.0501, 1.2064, 0.7767, 0.9076, 1.1132, 1.3270, 1.0474, 1.7846,
        1.0228, 0.7663, 3.1780, 1.5633, 1.3817, 1.1132, 2.2888, 1.3445, 1.6492,
        1.8634, 1.3627, 0.6703, 0.7639, 0.7311, 0.6817, 0.8525, 1.0474, 0.8156,
        0.6894, 0.7590, 0.5869, 0.7115, 0.5869, 0.7521, 0.6632, 0.7663, 1.3817,
        0.7051, 0.7132, 0.6682, 0.7454, 0.5951, 0.5835, 0.6781, 1.3270, 0.6585,
        0.6632, 0.7996, 0.8877, 0.9408, 0.7218, 1.5121, 0.6202, 1.2336, 0.7639,
        0.7371, 0.8485, 0.8925, 1.2779, 1.7135, 0.5872, 0.6053, 0.8123, 0.9292,
        0.7590, 2.1042, 2.7001, 0.6070, 0.7614, 0.7965, 0.7740, 1.1688, 1.1236,
        0.6541, 0.7498, 0.7067, 0.6369, 0.7714, 0.6475, 0.7663, 0.6475, 1.2064,
        0.6047, 0.5810, 0.6632, 0.5946, 0.5867, 0.6524, 0.7132, 0.9128, 0.7689,
        1.8634, 1.0561, 0.7200, 0.6507, 0.5979, 0.5929, 0.7292, 0.6115, 1.0741,
        0.5908, 2.4350, 0.8190, 0.5925, 0.5969, 0.7331, 3.6846, 1.7481, 0.6507],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  37  55 198 141 156 188 113  80 123 182 143 425 167 425 146 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  37  79 162 219 342 371 157 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2937, 0.6314, 1.0931, 1.1688, 0.8566, 0.8446, 0.6350, 0.6948, 0.6314,
        1.2064, 0.8525, 0.6005, 1.0474, 1.4650, 0.7996, 2.6046, 0.6962, 0.5812,
        1.4650, 2.0501, 1.2064, 0.7767, 0.9076, 1.1132, 1.3270, 1.0474, 1.7846,
        1.0228, 0.7663, 3.1780, 1.5633, 1.3817, 1.1132, 2.2888, 1.3445, 1.6492,
        1.8634, 1.3627, 0.6703, 0.7639, 0.7311, 0.6817, 0.8525, 1.0474, 0.8156,
        0.6894, 0.7590, 0.5869, 0.7115, 0.5869, 0.7521, 0.6632, 0.7663, 1.3817,
        0.7051, 0.7132, 0.6682, 0.7454, 0.5951, 0.5835, 0.6781, 1.3270, 0.6585,
        0.6632, 0.7996, 0.8877, 0.9408, 0.7218, 1.5121, 0.6202, 1.2336, 0.7639,
        0.7371, 0.8485, 0.8925, 1.2779, 1.7135, 0.5872, 0.6053, 0.8123, 0.9292,
        0.7590, 2.1042, 2.7001, 0.6070, 0.7614, 0.7965, 0.7740, 1.1688, 1.1236,
        0.6541, 0.7498, 0.7067, 0.6369, 0.7714, 0.6475, 0.7663, 0.6475, 1.2064,
        0.6047, 0.5810, 0.6632, 0.5946, 0.5867, 0.6524, 0.7132, 0.9128, 0.7689,
        1.8634, 1.0561, 0.7200, 0.6507, 0.5979, 0.5929, 0.7292, 0.6115, 1.0741,
        0.5908, 2.4350, 0.8190, 0.5925, 0.5969, 0.7331, 3.6846, 1.7481, 0.6507],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 182 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  38  79 162 219 342 371 157 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2945, 0.6318, 1.0938, 1.1695, 0.8571, 0.8451, 0.6354, 0.6952, 0.6318,
        1.2072, 0.8530, 0.6008, 1.0481, 1.4660, 0.8001, 2.6062, 0.6967, 0.5816,
        1.4660, 2.0514, 1.2072, 0.7771, 0.9081, 1.1139, 1.3278, 1.0481, 1.7857,
        1.0235, 0.7668, 3.1799, 1.5642, 1.3825, 1.1139, 2.2903, 1.3454, 1.6502,
        1.8241, 1.3636, 0.6707, 0.7643, 0.7316, 0.6822, 0.8530, 1.0481, 0.8161,
        0.6898, 0.7595, 0.5872, 0.7119, 0.5872, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7056, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6786, 1.3278, 0.6589,
        0.6636, 0.8001, 0.8882, 0.9414, 0.7223, 1.5130, 0.6206, 1.2344, 0.7643,
        0.7375, 0.8490, 0.8931, 1.2787, 1.7146, 0.5876, 0.6056, 0.8128, 0.9298,
        0.7595, 2.1055, 2.7018, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1243,
        0.6545, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5950, 0.5871, 0.6528, 0.7136, 0.9134, 0.7693,
        1.8241, 1.0567, 0.7205, 0.6511, 0.5983, 0.5933, 0.7297, 0.6119, 1.0747,
        0.5911, 2.4365, 0.8195, 0.5929, 0.5973, 0.7335, 3.6869, 1.7492, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 182 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 215 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  38  79 162 219 342 371 157 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2945, 0.6318, 1.0938, 1.1695, 0.8571, 0.8451, 0.6354, 0.6952, 0.6318,
        1.2072, 0.8530, 0.6008, 1.0481, 1.4660, 0.8001, 2.6062, 0.6967, 0.5816,
        1.4660, 2.0514, 1.2072, 0.7771, 0.9081, 1.1139, 1.3278, 1.0481, 1.7857,
        1.0235, 0.7668, 3.1799, 1.5642, 1.3825, 1.1139, 2.2903, 1.3454, 1.6502,
        1.8241, 1.3636, 0.6707, 0.7643, 0.7316, 0.6822, 0.8530, 1.0481, 0.8161,
        0.6898, 0.7595, 0.5872, 0.7119, 0.5872, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7056, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6786, 1.3278, 0.6589,
        0.6636, 0.8001, 0.8882, 0.9414, 0.7223, 1.5130, 0.6206, 1.2344, 0.7643,
        0.7375, 0.8490, 0.8931, 1.2787, 1.7146, 0.5876, 0.6056, 0.8128, 0.9298,
        0.7595, 2.1055, 2.7018, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1243,
        0.6545, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5950, 0.5871, 0.6528, 0.7136, 0.9134, 0.7693,
        1.8241, 1.0567, 0.7205, 0.6511, 0.5983, 0.5933, 0.7297, 0.6119, 1.0747,
        0.5911, 2.4365, 0.8195, 0.5929, 0.5973, 0.7335, 3.6869, 1.7492, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 182 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  97 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 360 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2945, 0.6318, 1.0938, 1.1695, 0.8571, 0.8451, 0.6354, 0.6953, 0.6318,
        1.2072, 0.8531, 0.6008, 1.0481, 1.4660, 0.8001, 2.6062, 0.6967, 0.5816,
        1.4660, 2.0514, 1.2072, 0.7772, 0.9081, 1.1139, 1.3278, 1.0481, 1.7857,
        1.0235, 0.7668, 3.1800, 1.5643, 1.3825, 1.1139, 2.2903, 1.3454, 1.6502,
        1.8241, 1.3636, 0.6707, 0.7643, 0.7316, 0.6822, 0.8531, 1.0481, 0.8161,
        0.6898, 0.7595, 0.5873, 0.7120, 0.5873, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7056, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6786, 1.3278, 0.6589,
        0.6636, 0.8001, 0.8882, 0.9414, 0.7223, 1.5130, 0.6206, 1.2344, 0.7643,
        0.7375, 0.8490, 0.8931, 1.2787, 1.7146, 0.5876, 0.6056, 0.8128, 0.9298,
        0.7595, 2.1055, 2.7018, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1244,
        0.6553, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5950, 0.5871, 0.6528, 0.7136, 0.9134, 0.7693,
        1.8241, 1.0567, 0.7205, 0.6511, 0.5983, 0.5933, 0.7278, 0.6119, 1.0747,
        0.5911, 2.4365, 0.8195, 0.5929, 0.5973, 0.7335, 3.6869, 1.7493, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 113 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 182 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2944, 0.6318, 1.0937, 1.1695, 0.8571, 0.8451, 0.6354, 0.6952, 0.6318,
        1.2072, 0.8530, 0.6008, 1.0481, 1.4659, 0.8000, 2.6061, 0.6966, 0.5816,
        1.4659, 2.0513, 1.2072, 0.7771, 0.9081, 1.1138, 1.3278, 1.0481, 1.7856,
        1.0234, 0.7668, 3.1798, 1.5642, 1.3825, 1.1138, 2.2902, 1.3453, 1.6501,
        1.8240, 1.3636, 0.6707, 0.7643, 0.7315, 0.6821, 0.8530, 1.0481, 0.8161,
        0.6898, 0.7595, 0.5872, 0.7119, 0.5872, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7055, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6785, 1.3278, 0.6589,
        0.6636, 0.8000, 0.8882, 0.9413, 0.7222, 1.5130, 0.6206, 1.2343, 0.7643,
        0.7375, 0.8490, 0.8930, 1.2786, 1.7145, 0.5876, 0.6056, 0.8128, 0.9355,
        0.7595, 2.1054, 2.7017, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1243,
        0.6553, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5948, 0.5871, 0.6527, 0.7136, 0.9133, 0.7693,
        1.8240, 1.0567, 0.7204, 0.6511, 0.5983, 0.5933, 0.7277, 0.6119, 1.0747,
        0.5911, 2.4364, 0.8195, 0.5928, 0.5973, 0.7335, 3.6867, 1.7492, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 330  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 182 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2945, 0.6318, 1.0937, 1.1695, 0.8571, 0.8451, 0.6354, 0.6952, 0.6318,
        1.2072, 0.8490, 0.6008, 1.0481, 1.4660, 0.8001, 2.6062, 0.6967, 0.5816,
        1.4660, 2.0514, 1.2072, 0.7771, 0.9081, 1.1138, 1.3278, 1.0481, 1.7857,
        1.0235, 0.7668, 3.1799, 1.5642, 1.3825, 1.1138, 2.2903, 1.3454, 1.6502,
        1.8241, 1.3636, 0.6707, 0.7643, 0.7316, 0.6822, 0.8530, 1.0481, 0.8161,
        0.6898, 0.7595, 0.5872, 0.7119, 0.5872, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7056, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6786, 1.3278, 0.6589,
        0.6636, 0.8001, 0.8882, 0.9414, 0.7222, 1.5130, 0.6206, 1.2344, 0.7643,
        0.7375, 0.8490, 0.8930, 1.2787, 1.7146, 0.5876, 0.6056, 0.8128, 0.9355,
        0.7595, 2.1055, 2.7018, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1243,
        0.6553, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5948, 0.5871, 0.6528, 0.7136, 0.9134, 0.7693,
        1.8241, 1.0567, 0.7205, 0.6511, 0.5983, 0.5933, 0.7278, 0.6119, 1.0747,
        0.5911, 2.4365, 0.8195, 0.5929, 0.5973, 0.7335, 3.6868, 1.7492, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  54  73  29  56  43
  38  55 198 141 156 188 113  80 123 183 143 425 167 425 145 205 140  54
 171 166 200 149 357 478 191  57 210 205 128 105  95 161  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  27 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2945, 0.6318, 1.0938, 1.1695, 0.8571, 0.8451, 0.6354, 0.6952, 0.6318,
        1.2072, 0.8490, 0.6011, 1.0481, 1.4660, 0.8001, 2.6062, 0.6967, 0.5816,
        1.4660, 2.0514, 1.2072, 0.7772, 0.9081, 1.1139, 1.3278, 1.0481, 1.7857,
        1.0235, 0.7668, 3.1800, 1.5643, 1.3825, 1.1139, 2.2903, 1.3454, 1.6502,
        1.8241, 1.3636, 0.6707, 0.7643, 0.7316, 0.6822, 0.8530, 1.0481, 0.8161,
        0.6885, 0.7595, 0.5872, 0.7119, 0.5872, 0.7548, 0.6636, 0.7668, 1.3825,
        0.7056, 0.7136, 0.6686, 0.7459, 0.5955, 0.5838, 0.6786, 1.3278, 0.6589,
        0.6636, 0.8001, 0.8882, 0.9414, 0.7223, 1.5130, 0.6206, 1.2344, 0.7643,
        0.7375, 0.8490, 0.8931, 1.2787, 1.7146, 0.5876, 0.6056, 0.8128, 0.9355,
        0.7595, 2.1055, 2.7018, 0.6074, 0.7619, 0.7970, 0.7745, 1.1695, 1.1243,
        0.6553, 0.7503, 0.7071, 0.6373, 0.7719, 0.6479, 0.7668, 0.6479, 1.2072,
        0.6051, 0.5814, 0.6636, 0.5949, 0.5871, 0.6528, 0.7136, 0.9134, 0.7693,
        1.8241, 1.0567, 0.7205, 0.6511, 0.5983, 0.5933, 0.7278, 0.6119, 1.0747,
        0.5911, 2.4365, 0.8195, 0.5929, 0.5973, 0.7335, 3.6869, 1.7492, 0.6511],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  20  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 183 143 425 167 425 145 205 140  54
 170 166 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  28 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2958, 0.6325, 1.0949, 1.1707, 0.8580, 0.8460, 0.6361, 0.6960, 0.6325,
        1.2085, 0.8499, 0.6017, 1.0492, 1.4675, 0.8009, 2.6089, 0.6974, 0.5822,
        1.4675, 2.0535, 1.2085, 0.7780, 0.9091, 1.1150, 1.3292, 1.0492, 1.7875,
        1.0245, 0.7676, 3.1832, 1.5659, 1.3650, 1.1150, 2.2926, 1.3468, 1.6519,
        1.7875, 1.3650, 0.6714, 0.7651, 0.7323, 0.6829, 0.8539, 1.0492, 0.8170,
        0.6892, 0.7603, 0.5879, 0.7127, 0.5879, 0.7556, 0.6643, 0.7676, 1.3840,
        0.7079, 0.7143, 0.6693, 0.7467, 0.5961, 0.5844, 0.6793, 1.3292, 0.6596,
        0.6643, 0.8009, 0.8892, 0.9424, 0.7248, 1.5146, 0.6212, 1.2357, 0.7651,
        0.7383, 0.8499, 0.8940, 1.2800, 1.7164, 0.5882, 0.6063, 0.8136, 0.9365,
        0.7603, 2.1077, 2.7046, 0.6080, 0.7627, 0.7978, 0.7753, 1.1707, 1.1255,
        0.6560, 0.7511, 0.7079, 0.6380, 0.7727, 0.6486, 0.7676, 0.6486, 1.2085,
        0.6057, 0.5820, 0.6643, 0.5955, 0.5877, 0.6534, 0.7143, 0.9143, 0.7701,
        1.8260, 1.0578, 0.7212, 0.6518, 0.5989, 0.5939, 0.7285, 0.6125, 1.0759,
        0.5918, 2.3632, 0.8204, 0.5935, 0.5979, 0.7343, 3.6907, 1.7510, 0.6518],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 183 143 425 167 425 145 205 140  54
 170 165 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  28 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2972, 0.6332, 1.0961, 1.1720, 0.8590, 0.8469, 0.6368, 0.6967, 0.6332,
        1.2098, 0.8508, 0.6023, 1.0503, 1.4691, 0.8018, 2.6117, 0.6981, 0.5828,
        1.4691, 2.0557, 1.2098, 0.7788, 0.9100, 1.1162, 1.3306, 1.0503, 1.7895,
        1.0256, 0.7684, 3.0497, 1.5675, 1.3665, 1.1162, 2.2951, 1.3482, 1.6537,
        1.7895, 1.3665, 0.6722, 0.7659, 0.7331, 0.6836, 0.8548, 1.0503, 0.8178,
        0.6899, 0.7611, 0.5885, 0.7134, 0.5885, 0.7564, 0.6650, 0.7684, 1.3854,
        0.7086, 0.7168, 0.6700, 0.7475, 0.5968, 0.5851, 0.6800, 1.3306, 0.6603,
        0.6650, 0.8018, 0.8901, 0.9434, 0.7256, 1.5162, 0.6219, 1.2370, 0.7659,
        0.7391, 0.8508, 0.8949, 1.2814, 1.7182, 0.5888, 0.6069, 0.8145, 0.9375,
        0.7611, 2.1099, 2.7075, 0.6087, 0.7635, 0.7987, 0.7761, 1.1720, 1.1267,
        0.6567, 0.7519, 0.7086, 0.6387, 0.7735, 0.6493, 0.7684, 0.6493, 1.2098,
        0.6064, 0.5826, 0.6650, 0.5961, 0.5883, 0.6541, 0.7151, 0.9153, 0.7710,
        1.8279, 1.0590, 0.7220, 0.6525, 0.5995, 0.5946, 0.7293, 0.6132, 1.0770,
        0.5924, 2.3657, 0.8212, 0.5941, 0.5986, 0.7351, 3.6946, 1.7529, 0.6525],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 170 165 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  28 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2972, 0.6332, 1.0961, 1.1720, 0.8590, 0.8469, 0.6368, 0.6967, 0.6332,
        1.2098, 0.8508, 0.6023, 1.0503, 1.4691, 0.8018, 2.6117, 0.6981, 0.5828,
        1.4691, 2.0557, 1.2098, 0.7788, 0.9101, 1.1162, 1.3306, 1.0503, 1.7895,
        1.0256, 0.7684, 3.0497, 1.5676, 1.3665, 1.1162, 2.2951, 1.3482, 1.6537,
        1.7895, 1.3665, 0.6722, 0.7660, 0.7331, 0.6836, 0.8549, 1.0503, 0.8179,
        0.6886, 0.7611, 0.5885, 0.7135, 0.5885, 0.7564, 0.6650, 0.7684, 1.3855,
        0.7086, 0.7168, 0.6700, 0.7475, 0.5968, 0.5851, 0.6800, 1.3306, 0.6603,
        0.6650, 0.8018, 0.8901, 0.9434, 0.7256, 1.5162, 0.6219, 1.2370, 0.7660,
        0.7391, 0.8508, 0.8949, 1.2814, 1.7182, 0.5888, 0.6069, 0.8145, 0.9375,
        0.7611, 2.1099, 2.7075, 0.6087, 0.7635, 0.7987, 0.7761, 1.1720, 1.1267,
        0.6567, 0.7519, 0.7086, 0.6387, 0.7735, 0.6493, 0.7684, 0.6493, 1.2098,
        0.6064, 0.5826, 0.6650, 0.5961, 0.5883, 0.6542, 0.7151, 0.9153, 0.7710,
        1.8279, 1.0590, 0.7220, 0.6525, 0.5996, 0.5946, 0.7293, 0.6132, 1.0770,
        0.5924, 2.3658, 0.8212, 0.5941, 0.5986, 0.7351, 3.6947, 1.7529, 0.6525],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 247  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 170 165 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  96 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 427 217 166 100 139
  38  79 162 219 342 371 158 291  77 387  29 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2980, 0.6335, 1.0967, 1.1727, 0.8594, 0.8474, 0.6371, 0.6971, 0.6335,
        1.2104, 0.8513, 0.6027, 1.0509, 1.4699, 0.8022, 2.6132, 0.6985, 0.5832,
        1.4699, 2.0569, 1.2104, 0.7792, 0.9106, 1.1168, 1.3314, 1.0509, 1.7905,
        1.0262, 0.7689, 3.0514, 1.5684, 1.3673, 1.1168, 2.2964, 1.3490, 1.6546,
        1.7905, 1.3673, 0.6725, 0.7664, 0.7335, 0.6840, 0.8553, 1.0509, 0.8183,
        0.6890, 0.7615, 0.5888, 0.7139, 0.5888, 0.7568, 0.6654, 0.7689, 1.3862,
        0.7090, 0.7172, 0.6704, 0.7479, 0.5971, 0.5854, 0.6804, 1.3314, 0.6606,
        0.6654, 0.8022, 0.8906, 0.9439, 0.7260, 1.5171, 0.6223, 1.2377, 0.7664,
        0.7395, 0.8513, 0.8954, 1.2821, 1.7192, 0.5892, 0.6073, 0.8150, 0.9380,
        0.7615, 2.1111, 2.7090, 0.6090, 0.7639, 0.7992, 0.7766, 1.1727, 1.1274,
        0.6571, 0.7523, 0.7090, 0.6390, 0.7740, 0.6497, 0.7689, 0.6497, 1.2104,
        0.6067, 0.5830, 0.6654, 0.5964, 0.5887, 0.6545, 0.7155, 0.9158, 0.7714,
        1.8290, 1.0596, 0.7224, 0.6529, 0.5999, 0.5949, 0.7297, 0.6135, 1.0776,
        0.5927, 2.2964, 0.8217, 0.5945, 0.5989, 0.7355, 3.6967, 1.7539, 0.6529],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 170 165 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  68  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  38  80 162 219 342 371 158 291  77 387  29 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2980, 0.6335, 1.0967, 1.1727, 0.8595, 0.8474, 0.6372, 0.6971, 0.6330,
        1.2105, 0.8513, 0.6027, 1.0509, 1.4699, 0.8022, 2.6133, 0.6985, 0.5832,
        1.4699, 2.0570, 1.2105, 0.7793, 0.9106, 1.1169, 1.3314, 1.0509, 1.7905,
        1.0262, 0.7689, 3.0515, 1.5685, 1.3673, 1.1169, 2.2965, 1.3490, 1.6547,
        1.7905, 1.3673, 0.6726, 0.7664, 0.7336, 0.6840, 0.8554, 1.0509, 0.8183,
        0.6890, 0.7616, 0.5888, 0.7139, 0.5888, 0.7569, 0.6654, 0.7689, 1.3863,
        0.7090, 0.7172, 0.6704, 0.7479, 0.5971, 0.5854, 0.6804, 1.3314, 0.6607,
        0.6654, 0.8022, 0.8906, 0.9439, 0.7260, 1.5171, 0.6223, 1.2377, 0.7664,
        0.7395, 0.8513, 0.8955, 1.2822, 1.7192, 0.5892, 0.6073, 0.8150, 0.9439,
        0.7616, 2.1112, 2.7091, 0.6090, 0.7640, 0.7992, 0.7766, 1.1727, 1.1274,
        0.6571, 0.7523, 0.7090, 0.6391, 0.7740, 0.6497, 0.7689, 0.6497, 1.2105,
        0.6067, 0.5830, 0.6654, 0.5965, 0.5888, 0.6545, 0.7155, 0.9158, 0.7714,
        1.8290, 1.0509, 0.7224, 0.6529, 0.5999, 0.5949, 0.7297, 0.6136, 1.0777,
        0.5927, 2.2965, 0.8217, 0.5945, 0.5989, 0.7355, 3.6968, 1.7540, 0.6529],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 112 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 170 165 200 149 357 478 191  57 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  67  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  38  80 162 219 342 372 158 291  77 387  29 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2979, 0.6335, 1.0966, 1.1726, 0.8594, 0.8473, 0.6371, 0.6971, 0.6329,
        1.2104, 0.8512, 0.6026, 1.0508, 1.4698, 0.8022, 2.6130, 0.6985, 0.5831,
        1.4698, 2.0568, 1.2104, 0.7792, 0.9105, 1.1168, 1.3313, 1.0508, 1.7904,
        1.0261, 0.7688, 3.0512, 1.5683, 1.3672, 1.1168, 2.2963, 1.3489, 1.6545,
        1.7904, 1.3672, 0.6725, 0.7663, 0.7335, 0.6839, 0.8553, 1.0508, 0.8183,
        0.6890, 0.7615, 0.5888, 0.7138, 0.5888, 0.7568, 0.6653, 0.7688, 1.3861,
        0.7090, 0.7171, 0.6704, 0.7478, 0.5971, 0.5854, 0.6803, 1.3313, 0.6606,
        0.6653, 0.8022, 0.8906, 0.9438, 0.7260, 1.5170, 0.6222, 1.2376, 0.7663,
        0.7394, 0.8512, 0.8954, 1.2820, 1.7191, 0.5891, 0.6072, 0.8149, 0.9438,
        0.7615, 2.1110, 2.7088, 0.6090, 0.7639, 0.7991, 0.7765, 1.1848, 1.1273,
        0.6570, 0.7522, 0.7090, 0.6390, 0.7739, 0.6496, 0.7688, 0.6496, 1.2104,
        0.6067, 0.5829, 0.6653, 0.5964, 0.5887, 0.6545, 0.7155, 0.9158, 0.7713,
        1.8288, 1.0508, 0.7224, 0.6528, 0.5998, 0.5947, 0.7297, 0.6135, 1.0775,
        0.5927, 2.2963, 0.8216, 0.5944, 0.5989, 0.7354, 3.6965, 1.7538, 0.6528],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 111 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 169 165 200 149 357 478 191  58 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  67  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  39  80 162 219 342 372 158 290  77 387  31 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.2997, 0.6344, 1.0982, 1.1742, 0.8648, 0.8485, 0.6380, 0.6980, 0.6338,
        1.2121, 0.8524, 0.6035, 1.0523, 1.4719, 0.8033, 2.6167, 0.6995, 0.5839,
        1.4719, 2.0596, 1.2121, 0.7803, 0.9118, 1.1183, 1.3331, 1.0523, 1.7929,
        1.0276, 0.7699, 3.0555, 1.5705, 1.3691, 1.1183, 2.2995, 1.3508, 1.6568,
        1.7929, 1.3691, 0.6734, 0.7674, 0.7345, 0.6849, 0.8565, 1.0523, 0.8194,
        0.6899, 0.7626, 0.5896, 0.7148, 0.5896, 0.7579, 0.6663, 0.7699, 1.3881,
        0.7116, 0.7182, 0.6713, 0.7489, 0.5979, 0.5862, 0.6813, 1.3161, 0.6615,
        0.6663, 0.8033, 0.8918, 0.9452, 0.7270, 1.5191, 0.6231, 1.2394, 0.7674,
        0.7405, 0.8524, 0.8966, 1.2838, 1.7215, 0.5900, 0.6081, 0.8161, 0.9452,
        0.7626, 2.1139, 2.7126, 0.6098, 0.7650, 0.8002, 0.7776, 1.1864, 1.1289,
        0.6580, 0.7533, 0.7100, 0.6399, 0.7750, 0.6505, 0.7699, 0.6505, 1.2121,
        0.6075, 0.5837, 0.6663, 0.5972, 0.5895, 0.6554, 0.7165, 0.9170, 0.7724,
        1.7929, 1.0523, 0.7234, 0.6537, 0.6007, 0.5955, 0.7307, 0.6147, 1.0791,
        0.5935, 2.1718, 0.8228, 0.5953, 0.5997, 0.7365, 3.7017, 1.7563, 0.6537],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 111 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 168 165 200 149 357 478 191  58 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  67  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  39  80 162 219 342 372 158 290  77 387  32 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.3003, 0.6347, 1.0986, 1.1747, 0.8652, 0.8489, 0.6383, 0.6984, 0.6341,
        1.2126, 0.8528, 0.6038, 1.0528, 1.4725, 0.8036, 2.6179, 0.6998, 0.5842,
        1.4725, 2.0606, 1.2126, 0.7806, 0.9122, 1.1188, 1.3337, 1.0528, 1.7937,
        1.0280, 0.7702, 3.0569, 1.5712, 1.3697, 1.1188, 2.3005, 1.3514, 1.6576,
        1.7937, 1.3697, 0.6737, 0.7678, 0.7348, 0.6852, 0.8569, 1.0528, 0.8198,
        0.6902, 0.7629, 0.5899, 0.7151, 0.5899, 0.7582, 0.6666, 0.7702, 1.3887,
        0.7135, 0.7185, 0.6716, 0.7492, 0.5982, 0.5864, 0.6816, 1.3167, 0.6618,
        0.6666, 0.8036, 0.8922, 0.9456, 0.7273, 1.5198, 0.6234, 1.2399, 0.7678,
        0.7408, 0.8528, 0.8970, 1.2844, 1.7223, 0.5902, 0.6083, 0.8164, 0.9456,
        0.7629, 2.1149, 2.7138, 0.6101, 0.7653, 0.8006, 0.7780, 1.1870, 1.1294,
        0.6583, 0.7536, 0.7103, 0.6402, 0.7753, 0.6508, 0.7702, 0.6508, 1.2126,
        0.6078, 0.5840, 0.6666, 0.5975, 0.5898, 0.6557, 0.7168, 0.9175, 0.7728,
        1.7937, 1.0528, 0.7237, 0.6540, 0.6010, 0.5958, 0.7310, 0.6150, 1.0795,
        0.5938, 2.1149, 0.8232, 0.5955, 0.6000, 0.7368, 3.7033, 1.7571, 0.6540],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 111 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 167 165 200 149 357 478 191  58 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  67  72
 214 147 170 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  39  80 162 219 342 372 158 290  77 387  33 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.3008, 0.6349, 1.0991, 1.1752, 0.8655, 0.8492, 0.6385, 0.6986, 0.6343,
        1.2131, 0.8532, 0.6040, 1.0532, 1.4731, 0.8040, 2.6190, 0.7001, 0.5844,
        1.4731, 2.0614, 1.2131, 0.7809, 0.9126, 1.1193, 1.3343, 1.0532, 1.7944,
        1.0285, 0.7706, 3.0581, 1.5719, 1.3703, 1.1193, 2.3015, 1.3520, 1.6583,
        1.7944, 1.3703, 0.6740, 0.7681, 0.7352, 0.6855, 0.8572, 1.0532, 0.8201,
        0.6905, 0.7632, 0.5901, 0.7154, 0.5901, 0.7585, 0.6668, 0.7706, 1.3893,
        0.7154, 0.7188, 0.6719, 0.7495, 0.5984, 0.5867, 0.6819, 1.3173, 0.6621,
        0.6668, 0.8040, 0.8926, 0.9460, 0.7276, 1.5204, 0.6236, 1.2404, 0.7681,
        0.7411, 0.8532, 0.8974, 1.2849, 1.7230, 0.5905, 0.6086, 0.8168, 0.9460,
        0.7632, 2.1158, 2.7150, 0.6103, 0.7656, 0.8009, 0.7783, 1.1875, 1.1298,
        0.6585, 0.7540, 0.7106, 0.6404, 0.7757, 0.6511, 0.7706, 0.6511, 1.2131,
        0.6080, 0.5842, 0.6668, 0.5978, 0.5900, 0.6560, 0.7171, 0.9178, 0.7731,
        1.7944, 1.0532, 0.7240, 0.6543, 0.6012, 0.5961, 0.7313, 0.6152, 1.0800,
        0.5940, 2.0614, 0.8235, 0.5958, 0.6002, 0.7371, 3.7049, 1.7578, 0.6543],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 425 145 205 140  54
 165 165 200 149 357 478 191  58 210 205 128 105  95 160  48 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  24 305 142 129 137  67  72
 214 147 171 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  40  80 162 219 342 372 158 290  77 387  35 122 374 347 155  17  40 219]
CBFL per class weights: tensor([1.3022, 0.6356, 1.1002, 1.1765, 0.8707, 0.8501, 0.6392, 0.6994, 0.6350,
        1.2144, 0.8541, 0.6046, 1.0543, 1.4747, 0.8048, 2.6217, 0.7008, 0.5850,
        1.4747, 2.0636, 1.2144, 0.7818, 0.9135, 1.1205, 1.3357, 1.0543, 1.7963,
        1.0295, 0.7714, 3.0613, 1.5735, 1.3717, 1.1205, 2.3039, 1.3533, 1.6600,
        1.7963, 1.3717, 0.6747, 0.7689, 0.7359, 0.6862, 0.8581, 1.0543, 0.8210,
        0.6912, 0.7640, 0.5907, 0.7162, 0.5907, 0.7593, 0.6675, 0.7714, 1.3907,
        0.7195, 0.7195, 0.6726, 0.7503, 0.5990, 0.5873, 0.6826, 1.3186, 0.6628,
        0.6675, 0.8048, 0.8935, 0.9470, 0.7284, 1.5220, 0.6243, 1.2417, 0.7689,
        0.7419, 0.8541, 0.8983, 1.2863, 1.7247, 0.5911, 0.6092, 0.8176, 0.9470,
        0.7640, 2.1180, 2.7178, 0.6110, 0.7664, 0.8017, 0.7791, 1.1887, 1.1310,
        0.6592, 0.7547, 0.7097, 0.6411, 0.7765, 0.6518, 0.7714, 0.6518, 1.2144,
        0.6087, 0.5849, 0.6675, 0.5984, 0.5906, 0.6566, 0.7178, 0.9188, 0.7739,
        1.7596, 1.0543, 0.7247, 0.6550, 0.6018, 0.5967, 0.7321, 0.6159, 1.0811,
        0.5946, 1.9642, 0.8244, 0.5964, 0.6009, 0.7379, 3.7087, 1.7596, 0.6550],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 115 241 178 248  65 114 329  80  50 128  25 177 540
  50  33  65 136 101  73  57  80  39  83 140  21  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 165 165 200 149 357 478 191  58 210 205 128 105  95 160  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  25 305 142 129 137  67  72
 214 147 171 238 138 223 140 223  65 313 548 205 361 426 217 166 100 139
  40  80 162 219 342 372 159 290  77 387  35 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3034, 0.6362, 1.1013, 1.1776, 0.8716, 0.8509, 0.6398, 0.7000, 0.6356,
        1.2155, 0.8549, 0.6052, 1.0553, 1.4761, 0.8056, 2.6242, 0.7015, 0.5856,
        1.4761, 2.0656, 1.2155, 0.7825, 0.9144, 1.1215, 1.3370, 1.0553, 1.7980,
        1.0305, 0.7721, 3.0643, 1.5750, 1.3730, 1.1215, 2.3061, 1.3547, 1.6616,
        1.7980, 1.3730, 0.6754, 0.7696, 0.7366, 0.6869, 0.8589, 1.0553, 0.8218,
        0.6919, 0.7647, 0.5913, 0.7169, 0.5914, 0.7600, 0.6682, 0.7721, 1.3921,
        0.7202, 0.7202, 0.6732, 0.7510, 0.5996, 0.5879, 0.6833, 1.3199, 0.6634,
        0.6682, 0.8056, 0.8944, 0.9479, 0.7291, 1.4993, 0.6249, 1.2429, 0.7696,
        0.7426, 0.8549, 0.8992, 1.2875, 1.7264, 0.5916, 0.6098, 0.8184, 0.9479,
        0.7647, 2.1200, 2.6242, 0.6116, 0.7672, 0.8025, 0.7798, 1.1898, 1.1321,
        0.6598, 0.7555, 0.7104, 0.6417, 0.7772, 0.6524, 0.7721, 0.6524, 1.2155,
        0.6093, 0.5854, 0.6682, 0.5990, 0.5912, 0.6573, 0.7185, 0.9197, 0.7746,
        1.7613, 1.0553, 0.7254, 0.6556, 0.6024, 0.5972, 0.7309, 0.6165, 1.0822,
        0.5952, 1.9661, 0.8252, 0.5971, 0.6014, 0.7386, 3.7123, 1.7613, 0.6556],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 115 241 178 248  65 114 329  80  50 128  25 177 539
  50  33  65 136 101  73  57  80  39  83 140  22  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 165 165 200 149 357 478 191  58 210 205 128 105  95 160  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  67  72
 214 146 171 238 138 223 140 223  65 313 548 205 361 426 217 167 100 139
  40  80 162 219 342 372 159 290  77 387  36 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3061, 0.6375, 1.1036, 1.1800, 0.8734, 0.8527, 0.6411, 0.7015, 0.6369,
        1.2180, 0.8566, 0.6065, 1.0575, 1.4791, 0.8072, 2.6296, 0.7029, 0.5868,
        1.4791, 2.0698, 1.2180, 0.7841, 0.9163, 1.1238, 1.3397, 1.0575, 1.8017,
        1.0327, 0.7737, 2.9452, 1.5783, 1.3758, 1.1238, 2.3108, 1.3574, 1.6650,
        1.8017, 1.3758, 0.6768, 0.7712, 0.7381, 0.6883, 0.8607, 1.0575, 0.8234,
        0.6933, 0.7663, 0.5925, 0.7183, 0.5926, 0.7616, 0.6696, 0.7737, 1.3949,
        0.7217, 0.7217, 0.6746, 0.7526, 0.6009, 0.5891, 0.6847, 1.3226, 0.6648,
        0.6696, 0.8072, 0.8962, 0.9498, 0.7306, 1.5024, 0.6262, 1.2455, 0.7712,
        0.7441, 0.8566, 0.9011, 1.2902, 1.7300, 0.5929, 0.6111, 0.8201, 0.9498,
        0.7663, 2.1244, 2.5407, 0.6128, 0.7687, 0.8042, 0.7814, 1.1923, 1.1344,
        0.6612, 0.7593, 0.7119, 0.6430, 0.7788, 0.6538, 0.7737, 0.6538, 1.2180,
        0.6105, 0.5866, 0.6696, 0.6002, 0.5924, 0.6586, 0.7183, 0.9216, 0.7762,
        1.7649, 1.0575, 0.7269, 0.6570, 0.6037, 0.5985, 0.7324, 0.6177, 1.0844,
        0.5964, 1.9245, 0.8269, 0.5983, 0.6027, 0.7401, 3.7199, 1.7649, 0.6570],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 115 241 178 248  65 114 329  80  50 128  25 177 539
  50  33  65 136 101  73  57  80  39  83 140  22  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 165 165 200 149 357 478 191  58 210 205 128 105  95 160  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  67  72
 214 146 171 238 138 223 140 223  65 313 548 205 361 426 217 167 100 139
  40  80 162 219 342 372 159 290  77 387  36 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3061, 0.6375, 1.1036, 1.1800, 0.8734, 0.8527, 0.6411, 0.7015, 0.6369,
        1.2180, 0.8566, 0.6065, 1.0575, 1.4791, 0.8072, 2.6296, 0.7029, 0.5868,
        1.4791, 2.0698, 1.2180, 0.7841, 0.9163, 1.1238, 1.3397, 1.0575, 1.8017,
        1.0327, 0.7737, 2.9452, 1.5783, 1.3758, 1.1238, 2.3108, 1.3574, 1.6650,
        1.8017, 1.3758, 0.6768, 0.7712, 0.7381, 0.6883, 0.8607, 1.0575, 0.8234,
        0.6933, 0.7663, 0.5925, 0.7183, 0.5926, 0.7616, 0.6696, 0.7737, 1.3949,
        0.7217, 0.7217, 0.6746, 0.7526, 0.6009, 0.5891, 0.6847, 1.3226, 0.6648,
        0.6696, 0.8072, 0.8962, 0.9498, 0.7306, 1.5024, 0.6262, 1.2455, 0.7712,
        0.7441, 0.8566, 0.9011, 1.2902, 1.7300, 0.5929, 0.6111, 0.8201, 0.9498,
        0.7663, 2.1244, 2.5407, 0.6128, 0.7687, 0.8042, 0.7814, 1.1923, 1.1344,
        0.6612, 0.7593, 0.7119, 0.6430, 0.7788, 0.6538, 0.7737, 0.6538, 1.2180,
        0.6105, 0.5866, 0.6696, 0.6002, 0.5924, 0.6586, 0.7183, 0.9216, 0.7762,
        1.7649, 1.0575, 0.7269, 0.6570, 0.6037, 0.5985, 0.7324, 0.6177, 1.0844,
        0.5964, 1.9245, 0.8269, 0.5983, 0.6027, 0.7401, 3.7199, 1.7649, 0.6570],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 116 241 178 248  65 114 329  80  50 128  25 177 539
  50  33  65 136 101  73  57  80  39  83 140  22  46  55  73  29  56  43
  39  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 164 165 200 149 357 478 191  57 210 205 128 105  95 160  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  67  72
 214 146 171 238 138 223 140 223  65 313 548 205 361 426 217 167 100 139
  40  80 162 219 342 372 159 290  77 387  37 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3064, 0.6376, 1.1038, 1.1803, 0.8735, 0.8490, 0.6413, 0.7016, 0.6371,
        1.2183, 0.8568, 0.6066, 1.0577, 1.4794, 0.8074, 2.6302, 0.7031, 0.5870,
        1.4794, 2.0703, 1.2183, 0.7843, 0.9165, 1.1241, 1.3400, 1.0577, 1.8021,
        1.0329, 0.7739, 2.9459, 1.5786, 1.3761, 1.1241, 2.3113, 1.3577, 1.6654,
        1.8021, 1.3761, 0.6769, 0.7714, 0.7383, 0.6884, 0.8609, 1.0577, 0.8236,
        0.6935, 0.7665, 0.5926, 0.7185, 0.5927, 0.7618, 0.6697, 0.7739, 1.3952,
        0.7236, 0.7219, 0.6748, 0.7528, 0.6010, 0.5892, 0.6848, 1.3400, 0.6649,
        0.6697, 0.8074, 0.8964, 0.9500, 0.7307, 1.5027, 0.6263, 1.2457, 0.7714,
        0.7443, 0.8568, 0.9013, 1.2905, 1.7304, 0.5930, 0.6112, 0.8203, 0.9500,
        0.7665, 2.1248, 2.5412, 0.6130, 0.7689, 0.8044, 0.7816, 1.1926, 1.1347,
        0.6614, 0.7595, 0.7121, 0.6432, 0.7790, 0.6539, 0.7739, 0.6539, 1.2183,
        0.6107, 0.5868, 0.6697, 0.6003, 0.5926, 0.6588, 0.7185, 0.9218, 0.7764,
        1.7653, 1.0577, 0.7271, 0.6571, 0.6038, 0.5986, 0.7326, 0.6179, 1.0846,
        0.5966, 1.8817, 0.8270, 0.5985, 0.6028, 0.7403, 3.7208, 1.7653, 0.6571],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 140  23  46  55  73  29  56  43
  40  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 163 165 200 149 357 478 191  57 210 205 128 105  95 159  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  67  72
 214 146 171 238 138 223 140 222  65 313 548 205 361 426 217 167 100 139
  40  80 162 219 342 372 159 290  77 387  40 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3094, 0.6391, 1.1063, 1.1830, 0.8755, 0.8509, 0.6427, 0.7032, 0.6385,
        1.2211, 0.8588, 0.6080, 1.0601, 1.4828, 0.8093, 2.6362, 0.7047, 0.5883,
        1.4604, 2.0750, 1.2211, 0.7861, 0.9186, 1.1267, 1.3431, 1.0601, 1.8062,
        1.0352, 0.7756, 2.8379, 1.5822, 1.3793, 1.1267, 2.3166, 1.3608, 1.6692,
        1.7693, 1.3793, 0.6784, 0.7731, 0.7400, 0.6900, 0.8628, 1.0601, 0.8255,
        0.6951, 0.7682, 0.5940, 0.7201, 0.5941, 0.7635, 0.6712, 0.7756, 1.3984,
        0.7270, 0.7235, 0.6763, 0.7545, 0.6024, 0.5905, 0.6864, 1.3431, 0.6665,
        0.6712, 0.8093, 0.8984, 0.9522, 0.7342, 1.5061, 0.6277, 1.2486, 0.7731,
        0.7460, 0.8588, 0.9033, 1.2934, 1.7343, 0.5943, 0.6126, 0.8221, 0.9522,
        0.7682, 2.1297, 2.5470, 0.6144, 0.7707, 0.8062, 0.7834, 1.1953, 1.1373,
        0.6629, 0.7612, 0.7137, 0.6447, 0.7808, 0.6554, 0.7756, 0.6562, 1.2211,
        0.6120, 0.5881, 0.6712, 0.6017, 0.5939, 0.6603, 0.7201, 0.9239, 0.7782,
        1.7693, 1.0601, 0.7287, 0.6586, 0.6052, 0.6000, 0.7342, 0.6193, 1.0871,
        0.5979, 1.7693, 0.8289, 0.5998, 0.6042, 0.7420, 3.7292, 1.7693, 0.6586],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 110 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 140  23  46  55  73  29  56  43
  40  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 161 165 200 149 357 478 191  57 210 205 128 105  95 159  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  67  72
 214 146 171 238 138 223 140 222  65 313 548 205 361 426 217 167 100 139
  40  80 162 219 342 372 159 290  77 387  43 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3104, 0.6396, 1.1072, 1.1839, 0.8762, 0.8515, 0.6432, 0.7038, 0.6390,
        1.2220, 0.8594, 0.6084, 1.0609, 1.4839, 0.8099, 2.6382, 0.7052, 0.5888,
        1.4616, 2.0766, 1.2220, 0.7867, 0.9193, 1.1275, 1.3441, 1.0609, 1.8076,
        1.0360, 0.7762, 2.8401, 1.5834, 1.3803, 1.1275, 2.3184, 1.3619, 1.6704,
        1.7707, 1.3803, 0.6790, 0.7737, 0.7405, 0.6905, 0.8635, 1.0609, 0.8261,
        0.6956, 0.7688, 0.5945, 0.7207, 0.5945, 0.7641, 0.6717, 0.7762, 1.3995,
        0.7311, 0.7241, 0.6768, 0.7550, 0.6028, 0.5910, 0.6869, 1.3441, 0.6670,
        0.6717, 0.8099, 0.8991, 0.9529, 0.7348, 1.5073, 0.6282, 1.2495, 0.7737,
        0.7466, 0.8594, 0.9040, 1.2944, 1.7356, 0.5948, 0.6131, 0.8228, 0.9529,
        0.7688, 2.1313, 2.5490, 0.6148, 0.7712, 0.8068, 0.7840, 1.1962, 1.1381,
        0.6634, 0.7618, 0.7142, 0.6451, 0.7814, 0.6559, 0.7762, 0.6567, 1.2220,
        0.6125, 0.5885, 0.6717, 0.6021, 0.5944, 0.6608, 0.7207, 0.9246, 0.7788,
        1.7707, 1.0609, 0.7293, 0.6591, 0.6056, 0.6004, 0.7348, 0.6198, 1.0879,
        0.5984, 1.6704, 0.8296, 0.6003, 0.6046, 0.7425, 3.7321, 1.7707, 0.6591],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 109 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 140  24  46  55  73  29  56  43
  40  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 205 128 105  95 159  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  32  26 305 142 129 137  68  72
 214 146 171 238 138 223 140 222  65 313 548 205 361 426 217 167 100 139
  41  80 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3122, 0.6405, 1.1087, 1.1855, 0.8818, 0.8527, 0.6441, 0.7048, 0.6399,
        1.2237, 0.8606, 0.6093, 1.0624, 1.4860, 0.8110, 2.6419, 0.7062, 0.5896,
        1.4636, 2.0795, 1.2237, 0.7878, 0.9206, 1.1291, 1.3460, 1.0624, 1.8101,
        1.0375, 0.7773, 2.7387, 1.5856, 1.3823, 1.1291, 2.3216, 1.3638, 1.6728,
        1.7732, 1.3823, 0.6799, 0.7748, 0.7416, 0.6915, 0.8647, 1.0624, 0.8273,
        0.6966, 0.7699, 0.5953, 0.7217, 0.5954, 0.7651, 0.6727, 0.7773, 1.4014,
        0.7340, 0.7251, 0.6778, 0.7561, 0.6037, 0.5918, 0.6879, 1.3460, 0.6688,
        0.6727, 0.8110, 0.9004, 0.9543, 0.7358, 1.5094, 0.6291, 1.2513, 0.7748,
        0.7476, 0.8606, 0.9053, 1.2962, 1.7380, 0.5956, 0.6139, 0.8239, 0.9543,
        0.7699, 2.1343, 2.5525, 0.6157, 0.7723, 0.8079, 0.7851, 1.1855, 1.1397,
        0.6643, 0.7628, 0.7152, 0.6460, 0.7825, 0.6568, 0.7773, 0.6576, 1.2237,
        0.6134, 0.5894, 0.6727, 0.6030, 0.5952, 0.6617, 0.7217, 0.9259, 0.7799,
        1.7380, 1.0624, 0.7303, 0.6600, 0.6065, 0.6013, 0.7358, 0.6206, 1.0894,
        0.5992, 1.6424, 0.8307, 0.6011, 0.6055, 0.7436, 3.7373, 1.7732, 0.6600],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 109 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 140  26  46  55  73  29  56  43
  40  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 205 128 105  95 159  49 269  63 140
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  68  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 426 217 167 100 139
  41  80 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3135, 0.6411, 1.1098, 1.1867, 0.8827, 0.8536, 0.6448, 0.7055, 0.6405,
        1.2249, 0.8615, 0.6099, 1.0635, 1.4875, 0.8118, 2.6445, 0.7069, 0.5902,
        1.4651, 2.0815, 1.2249, 0.7886, 0.9215, 1.1302, 1.3473, 1.0635, 1.8119,
        1.0385, 0.7781, 2.5550, 1.5872, 1.3836, 1.1302, 2.3239, 1.3651, 1.6744,
        1.7749, 1.3836, 0.6806, 0.7756, 0.7423, 0.6922, 0.8656, 1.0635, 0.8281,
        0.6973, 0.7707, 0.5959, 0.7224, 0.5960, 0.7659, 0.6733, 0.7781, 1.4028,
        0.7347, 0.7258, 0.6784, 0.7568, 0.6043, 0.5924, 0.6885, 1.3473, 0.6695,
        0.6733, 0.8118, 0.9013, 0.9552, 0.7366, 1.5109, 0.6297, 1.2525, 0.7781,
        0.7484, 0.8615, 0.9062, 1.2975, 1.7398, 0.5962, 0.6145, 0.8247, 0.9552,
        0.7707, 2.1948, 2.5550, 0.6163, 0.7731, 0.8087, 0.7859, 1.1867, 1.1409,
        0.6649, 0.7636, 0.7159, 0.6467, 0.7832, 0.6582, 0.7781, 0.6582, 1.2249,
        0.6140, 0.5899, 0.6733, 0.6034, 0.5958, 0.6624, 0.7224, 0.9268, 0.7806,
        1.7398, 1.0635, 0.7310, 0.6607, 0.6071, 0.6019, 0.7366, 0.6212, 1.0905,
        0.5998, 1.6440, 0.8315, 0.6017, 0.6061, 0.7443, 3.7410, 1.7749, 0.6607],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 108 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  26  46  55  73  29  56  43
  40  55 199 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 204 128 105  95 159  49 269  63 140
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  68  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 216 168 100 139
  43  81 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3142, 0.6415, 1.1104, 1.1873, 0.8877, 0.8540, 0.6451, 0.7058, 0.6409,
        1.2256, 0.8620, 0.6102, 1.0641, 1.4883, 0.8123, 2.6459, 0.7073, 0.5905,
        1.4658, 2.0826, 1.2256, 0.7890, 0.9220, 1.1308, 1.3480, 1.0641, 1.8129,
        1.0391, 0.7811, 2.5564, 1.5881, 1.3844, 1.1308, 2.3252, 1.3659, 1.6753,
        1.7759, 1.3844, 0.6799, 0.7760, 0.7427, 0.6925, 0.8660, 1.0641, 0.8286,
        0.6976, 0.7711, 0.5962, 0.7228, 0.5963, 0.7663, 0.6737, 0.7785, 1.4036,
        0.7351, 0.7262, 0.6788, 0.7573, 0.6046, 0.5927, 0.6889, 1.3480, 0.6699,
        0.6747, 0.8123, 0.9018, 0.9557, 0.7370, 1.5117, 0.6301, 1.2532, 0.7785,
        0.7488, 0.8620, 0.9067, 1.2982, 1.7407, 0.5965, 0.6149, 0.8252, 0.9557,
        0.7711, 2.1960, 2.5564, 0.6166, 0.7735, 0.8092, 0.7863, 1.1873, 1.1415,
        0.6653, 0.7640, 0.7163, 0.6470, 0.7837, 0.6586, 0.7785, 0.6586, 1.2256,
        0.6143, 0.5903, 0.6737, 0.6037, 0.5960, 0.6636, 0.7211, 0.9273, 0.7811,
        1.6753, 1.0555, 0.7314, 0.6610, 0.6074, 0.6022, 0.7370, 0.6216, 1.0911,
        0.6001, 1.6449, 0.8320, 0.6020, 0.6064, 0.7447, 3.7430, 1.7759, 0.6610],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  75  68 108 116 241 178 248  65 114 329  80  50 128  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  26  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 204 128 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  68  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 216 168 100 139
  43  81 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3146, 0.6416, 1.1107, 1.1877, 0.8879, 0.8543, 0.6453, 0.7060, 0.6410,
        1.2259, 0.8622, 0.6104, 1.0643, 1.4887, 0.8125, 2.6466, 0.7075, 0.5907,
        1.4662, 2.0832, 1.2259, 0.7892, 0.9222, 1.1311, 1.3484, 1.0643, 1.8134,
        1.0393, 0.7813, 2.5571, 1.5885, 1.3848, 1.1311, 2.3258, 1.3662, 1.6758,
        1.7412, 1.3848, 0.6811, 0.7762, 0.7429, 0.6927, 0.8663, 1.0643, 0.8288,
        0.6978, 0.7713, 0.5964, 0.7230, 0.5964, 0.7665, 0.6739, 0.7787, 1.4040,
        0.7353, 0.7264, 0.6790, 0.7575, 0.6048, 0.5929, 0.6891, 1.3484, 0.6700,
        0.6749, 0.8125, 0.9020, 0.9560, 0.7390, 1.5121, 0.6302, 1.2535, 0.7762,
        0.7490, 0.8622, 0.9069, 1.2985, 1.7412, 0.5967, 0.6150, 0.8254, 0.9560,
        0.7713, 2.1966, 2.5571, 0.6168, 0.7737, 0.8094, 0.7865, 1.1877, 1.1418,
        0.6655, 0.7642, 0.7165, 0.6472, 0.7839, 0.6588, 0.7787, 0.6588, 1.2259,
        0.6145, 0.5904, 0.6739, 0.6039, 0.5962, 0.6637, 0.7213, 0.9275, 0.7813,
        1.6758, 1.0558, 0.7316, 0.6612, 0.6076, 0.6024, 0.7372, 0.6217, 1.0914,
        0.6003, 1.6453, 0.8322, 0.6022, 0.6066, 0.7449, 3.7441, 1.7764, 0.6612],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  27  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 204 128 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  69  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 216 168 100 139
  43  81 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3154, 0.6420, 1.1215, 1.1884, 0.8885, 0.8548, 0.6457, 0.7065, 0.6415,
        1.2267, 0.8628, 0.6108, 1.0650, 1.4897, 0.8162, 2.6484, 0.7079, 0.5910,
        1.4672, 2.0846, 1.2267, 0.7897, 0.9228, 1.1319, 1.3493, 1.0650, 1.8146,
        1.0400, 0.7818, 2.4759, 1.5895, 1.3857, 1.1319, 2.3273, 1.3671, 1.6769,
        1.7423, 1.3857, 0.6816, 0.7767, 0.7434, 0.6932, 0.8668, 1.0650, 0.8293,
        0.6983, 0.7718, 0.5967, 0.7235, 0.5968, 0.7670, 0.6743, 0.7792, 1.4049,
        0.7358, 0.7268, 0.6794, 0.7580, 0.6051, 0.5933, 0.6895, 1.3493, 0.6705,
        0.6753, 0.8130, 0.9026, 0.9566, 0.7395, 1.5131, 0.6306, 1.2544, 0.7767,
        0.7494, 0.8628, 0.9075, 1.2994, 1.7423, 0.5971, 0.6154, 0.8259, 0.9566,
        0.7718, 2.1980, 2.5588, 0.6172, 0.7742, 0.8099, 0.7870, 1.1764, 1.1425,
        0.6659, 0.7647, 0.7170, 0.6476, 0.7844, 0.6592, 0.7792, 0.6592, 1.2267,
        0.6149, 0.5908, 0.6743, 0.6043, 0.5966, 0.6642, 0.7218, 0.9281, 0.7818,
        1.6769, 1.0565, 0.7321, 0.6616, 0.6080, 0.6027, 0.7376, 0.6221, 1.0921,
        0.6007, 1.6464, 0.8328, 0.6026, 0.6070, 0.7454, 3.7465, 1.7775, 0.6616],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  28  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 143 425 167 424 145 205 140  54
 160 165 200 149 357 478 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  69  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 215 168 100 139
  43  82 162 219 342 372 159 290  77 387  44 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3163, 0.6425, 1.1223, 1.1893, 0.8891, 0.8554, 0.6462, 0.7070, 0.6419,
        1.2276, 0.8634, 0.6112, 1.0658, 1.4907, 0.8167, 2.6502, 0.7084, 0.5914,
        1.4682, 2.0860, 1.2276, 0.7903, 0.9235, 1.1327, 1.3502, 1.0658, 1.8158,
        1.0407, 0.7823, 2.4006, 1.5906, 1.3866, 1.1327, 2.3289, 1.3681, 1.6780,
        1.7435, 1.3866, 0.6821, 0.7772, 0.7439, 0.6937, 0.8674, 1.0658, 0.8299,
        0.6988, 0.7723, 0.5972, 0.7240, 0.5972, 0.7676, 0.6748, 0.7798, 1.4059,
        0.7363, 0.7274, 0.6799, 0.7585, 0.6056, 0.5937, 0.6900, 1.3502, 0.6709,
        0.6758, 0.8105, 0.9032, 0.9573, 0.7400, 1.5141, 0.6311, 1.2552, 0.7772,
        0.7500, 0.8634, 0.9081, 1.3003, 1.7435, 0.5975, 0.6159, 0.8265, 0.9573,
        0.7723, 2.1996, 2.5606, 0.6176, 0.7748, 0.8105, 0.7876, 1.1773, 1.1433,
        0.6664, 0.7652, 0.7175, 0.6481, 0.7849, 0.6597, 0.7798, 0.6597, 1.2276,
        0.6153, 0.5912, 0.6748, 0.6047, 0.5970, 0.6655, 0.7223, 0.9288, 0.7823,
        1.6780, 1.0489, 0.7326, 0.6621, 0.6084, 0.6032, 0.7381, 0.6226, 1.0929,
        0.6011, 1.6476, 0.8333, 0.6030, 0.6074, 0.7459, 3.7491, 1.7788, 0.6621],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  28  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 142 425 167 424 146 205 140  54
 160 165 200 149 357 478 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  69  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 215 168 100 139
  43  82 162 219 342 372 159 290  77 387  45 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3166, 0.6426, 1.1225, 1.1895, 0.8893, 0.8556, 0.6463, 0.7071, 0.6421,
        1.2279, 0.8636, 0.6114, 1.0660, 1.4910, 0.8169, 2.6508, 0.7086, 0.5916,
        1.4686, 2.0865, 1.2279, 0.7904, 0.9237, 1.1329, 1.3505, 1.0660, 1.8162,
        1.0410, 0.7825, 2.4011, 1.5910, 1.3869, 1.1329, 2.3295, 1.3684, 1.6784,
        1.7439, 1.3869, 0.6822, 0.7774, 0.7441, 0.6938, 0.8676, 1.0660, 0.8301,
        0.6989, 0.7749, 0.5973, 0.7241, 0.5974, 0.7654, 0.6750, 0.7799, 1.4062,
        0.7364, 0.7275, 0.6801, 0.7587, 0.6057, 0.5938, 0.6902, 1.3505, 0.6711,
        0.6759, 0.8107, 0.9034, 0.9575, 0.7402, 1.5145, 0.6312, 1.2555, 0.7774,
        0.7501, 0.8636, 0.9083, 1.3006, 1.7439, 0.5976, 0.6160, 0.8267, 0.9575,
        0.7725, 2.2001, 2.5612, 0.6178, 0.7749, 0.8107, 0.7878, 1.1775, 1.1436,
        0.6665, 0.7654, 0.7176, 0.6482, 0.7851, 0.6598, 0.7799, 0.6598, 1.2279,
        0.6154, 0.5914, 0.6750, 0.6049, 0.5971, 0.6657, 0.7225, 0.9290, 0.7825,
        1.6784, 1.0491, 0.7328, 0.6623, 0.6085, 0.6033, 0.7383, 0.6227, 1.0931,
        0.6013, 1.6188, 0.8335, 0.6032, 0.6075, 0.7461, 3.7499, 1.7792, 0.6623],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 247  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  29  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 142 425 167 424 146 205 140  54
 160 165 200 149 357 478 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 137  69  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 214 168 100 139
  43  82 162 219 342 372 159 290  77 387  46 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3177, 0.6431, 1.1234, 1.1905, 0.8900, 0.8563, 0.6468, 0.7077, 0.6426,
        1.2288, 0.8642, 0.6118, 1.0669, 1.4922, 0.8175, 2.6529, 0.7091, 0.5920,
        1.4697, 2.0881, 1.2288, 0.7911, 0.9244, 1.1338, 1.3516, 1.0669, 1.8177,
        1.0418, 0.7831, 2.3313, 1.5923, 1.3880, 1.1338, 2.3313, 1.3695, 1.6797,
        1.7453, 1.3880, 0.6827, 0.7780, 0.7447, 0.6944, 0.8683, 1.0669, 0.8307,
        0.6995, 0.7755, 0.5978, 0.7247, 0.5978, 0.7660, 0.6755, 0.7805, 1.4073,
        0.7370, 0.7281, 0.6806, 0.7593, 0.6062, 0.5943, 0.6907, 1.3516, 0.6716,
        0.6765, 0.8113, 0.9041, 0.9582, 0.7408, 1.5157, 0.6317, 1.2565, 0.7780,
        0.7507, 0.8642, 0.9090, 1.3016, 1.7453, 0.5981, 0.6165, 0.8273, 0.9582,
        0.7731, 2.2018, 2.5632, 0.6182, 0.7755, 0.8113, 0.7884, 1.1784, 1.1445,
        0.6671, 0.7660, 0.7182, 0.6487, 0.7857, 0.6603, 0.7805, 0.6603, 1.2288,
        0.6159, 0.5918, 0.6755, 0.6053, 0.5976, 0.6671, 0.7230, 0.9297, 0.7831,
        1.6797, 1.0499, 0.7334, 0.6628, 0.6090, 0.6038, 0.7389, 0.6232, 1.0940,
        0.6017, 1.5923, 0.8342, 0.6036, 0.6080, 0.7467, 3.7529, 1.7806, 0.6628],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 246  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  30  46  55  73  29  56  43
  41  55 198 141 156 188 113  80 123 184 142 425 167 424 146 205 140  54
 160 165 200 149 357 479 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  26 305 142 129 136  70  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 214 168 100 139
  43  82 162 219 342 372 159 290  77 387  46 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3185, 0.6441, 1.1241, 1.1912, 0.8906, 0.8568, 0.6472, 0.7081, 0.6429,
        1.2296, 0.8647, 0.6122, 1.0675, 1.4931, 0.8180, 2.6545, 0.7096, 0.5924,
        1.4706, 2.0894, 1.2296, 0.7915, 0.9249, 1.1345, 1.3524, 1.0675, 1.8188,
        1.0424, 0.7836, 2.2657, 1.5932, 1.3888, 1.1345, 2.3327, 1.3703, 1.6807,
        1.7463, 1.3888, 0.6832, 0.7785, 0.7451, 0.6948, 0.8688, 1.0675, 0.8312,
        0.6999, 0.7760, 0.5981, 0.7251, 0.5982, 0.7665, 0.6759, 0.7810, 1.4081,
        0.7375, 0.7285, 0.6810, 0.7597, 0.6065, 0.5946, 0.6911, 1.3524, 0.6720,
        0.6769, 0.8118, 0.9047, 0.9588, 0.7412, 1.5166, 0.6321, 1.2572, 0.7785,
        0.7512, 0.8647, 0.9096, 1.3024, 1.7463, 0.5985, 0.6169, 0.8278, 0.9588,
        0.7736, 2.2031, 2.5647, 0.6186, 0.7760, 0.8118, 0.7915, 1.1675, 1.1452,
        0.6675, 0.7665, 0.7186, 0.6491, 0.7862, 0.6607, 0.7810, 0.6607, 1.2296,
        0.6163, 0.5922, 0.6759, 0.6057, 0.5980, 0.6675, 0.7235, 0.9303, 0.7836,
        1.6807, 1.0506, 0.7338, 0.6632, 0.6094, 0.6041, 0.7393, 0.6236, 1.0946,
        0.6021, 1.5932, 0.8347, 0.6040, 0.6084, 0.7471, 3.7551, 1.7816, 0.6632],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 246  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  31  46  55  73  29  56  43
  41  54 198 141 156 188 113  80 123 184 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  27 305 142 129 136  70  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 214 168 100 139
  43  82 162 219 342 371 159 290  77 387  46 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3198, 0.6448, 1.1252, 1.1924, 0.8914, 0.8576, 0.6478, 0.7088, 0.6436,
        1.2308, 0.8656, 0.6128, 1.0686, 1.4946, 0.8188, 2.6571, 0.7103, 0.5930,
        1.4720, 2.0914, 1.2308, 0.7923, 0.9259, 1.1356, 1.3537, 1.0686, 1.8205,
        1.0434, 0.7843, 2.2053, 1.5948, 1.3902, 1.1356, 2.3350, 1.3716, 1.6824,
        1.7481, 1.4095, 0.6838, 0.7793, 0.7459, 0.6955, 0.8697, 1.0686, 0.8321,
        0.7006, 0.7768, 0.5987, 0.7258, 0.5987, 0.7696, 0.6766, 0.7818, 1.4095,
        0.7382, 0.7292, 0.6817, 0.7605, 0.6071, 0.5952, 0.6918, 1.3537, 0.6727,
        0.6776, 0.8126, 0.9056, 0.9598, 0.7420, 1.5181, 0.6327, 1.2585, 0.7793,
        0.7519, 0.8656, 0.9105, 1.3037, 1.7481, 0.5991, 0.6175, 0.8287, 0.9598,
        0.7743, 2.2053, 2.4840, 0.6192, 0.7768, 0.8126, 0.7923, 1.1686, 1.1463,
        0.6681, 0.7672, 0.7193, 0.6498, 0.7870, 0.6614, 0.7818, 0.6614, 1.2308,
        0.6169, 0.5928, 0.6766, 0.6063, 0.5985, 0.6681, 0.7242, 0.9312, 0.7843,
        1.6824, 1.0516, 0.7345, 0.6638, 0.6100, 0.6049, 0.7401, 0.6242, 1.0957,
        0.6027, 1.5948, 0.8355, 0.6046, 0.6090, 0.7478, 3.7588, 1.7834, 0.6638],
       device='cuda:0')
S real T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.546600 Loss T 0.092798 Method MME

Pred num ex per class (pseudo labels + labelled target examples):  [ 59 246  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  31  46  55  73  29  56  43
  41  54 198 141 156 188 113  80 123 184 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  27 305 142 129 136  70  72
 214 146 171 238 138 222 140 222  65 313 548 205 362 427 214 168 100 139
  43  82 162 219 342 371 159 290  77 387  46 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3198, 0.6448, 1.1252, 1.1924, 0.8914, 0.8576, 0.6478, 0.7088, 0.6436,
        1.2308, 0.8656, 0.6128, 1.0686, 1.4946, 0.8188, 2.6571, 0.7103, 0.5930,
        1.4720, 2.0914, 1.2308, 0.7923, 0.9259, 1.1356, 1.3537, 1.0686, 1.8205,
        1.0434, 0.7843, 2.2053, 1.5948, 1.3902, 1.1356, 2.3350, 1.3716, 1.6824,
        1.7481, 1.4095, 0.6838, 0.7793, 0.7459, 0.6955, 0.8697, 1.0686, 0.8321,
        0.7006, 0.7768, 0.5987, 0.7258, 0.5987, 0.7696, 0.6766, 0.7818, 1.4095,
        0.7382, 0.7292, 0.6817, 0.7605, 0.6071, 0.5952, 0.6918, 1.3537, 0.6727,
        0.6776, 0.8126, 0.9056, 0.9598, 0.7420, 1.5181, 0.6327, 1.2585, 0.7793,
        0.7519, 0.8656, 0.9105, 1.3037, 1.7481, 0.5991, 0.6175, 0.8287, 0.9598,
        0.7743, 2.2053, 2.4840, 0.6192, 0.7768, 0.8126, 0.7923, 1.1686, 1.1463,
        0.6681, 0.7672, 0.7193, 0.6498, 0.7870, 0.6614, 0.7818, 0.6614, 1.2308,
        0.6169, 0.5928, 0.6766, 0.6063, 0.5985, 0.6681, 0.7242, 0.9312, 0.7843,
        1.6824, 1.0516, 0.7345, 0.6638, 0.6100, 0.6049, 0.7401, 0.6242, 1.0957,
        0.6027, 1.5948, 0.8355, 0.6046, 0.6090, 0.7478, 3.7588, 1.7834, 0.6638],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 246  74  68 108 116 241 178 248  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  32  46  55  73  29  56  43
  41  54 198 141 156 188 113  80 123 184 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 209 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  27 305 142 129 136  70  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 162 219 342 371 159 290  77 387  46 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3207, 0.6452, 1.1260, 1.1932, 0.8921, 0.8582, 0.6483, 0.7093, 0.6440,
        1.2316, 0.8662, 0.6132, 1.0693, 1.4956, 0.8194, 2.6589, 0.7108, 0.5934,
        1.4731, 2.0929, 1.2316, 0.7929, 0.9265, 1.1364, 1.3547, 1.0693, 1.8218,
        1.0442, 0.7849, 2.1481, 1.5959, 1.3912, 1.1364, 2.3366, 1.3726, 1.6836,
        1.7493, 1.4105, 0.6843, 0.7798, 0.7464, 0.6960, 0.8703, 1.0693, 0.8326,
        0.7011, 0.7773, 0.5991, 0.7263, 0.5991, 0.7701, 0.6770, 0.7823, 1.4105,
        0.7387, 0.7297, 0.6822, 0.7610, 0.6076, 0.5956, 0.6923, 1.3547, 0.6731,
        0.6780, 0.8131, 0.9062, 0.9604, 0.7425, 1.5191, 0.6332, 1.2594, 0.7798,
        0.7524, 0.8662, 0.9111, 1.3046, 1.7493, 0.5995, 0.6179, 0.8292, 0.9604,
        0.7749, 2.2068, 2.4858, 0.6197, 0.7773, 0.8131, 0.7929, 1.1694, 1.1471,
        0.6686, 0.7678, 0.7198, 0.6502, 0.7875, 0.6626, 0.7823, 0.6618, 1.2316,
        0.6173, 0.5932, 0.6770, 0.6067, 0.5990, 0.6695, 0.7247, 0.9318, 0.7849,
        1.6530, 1.0523, 0.7350, 0.6643, 0.6104, 0.6053, 0.7406, 0.6246, 1.0965,
        0.6031, 1.5959, 0.8361, 0.6050, 0.6094, 0.7484, 3.7614, 1.7846, 0.6643],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  34  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 184 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  27 305 142 129 136  70  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 162 219 342 371 159 290  77 387  47 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3224, 0.6466, 1.1274, 1.1947, 0.8932, 0.8593, 0.6491, 0.7102, 0.6454,
        1.2332, 0.8673, 0.6140, 1.0707, 1.4975, 0.8205, 2.6624, 0.7117, 0.5942,
        1.4750, 2.0956, 1.2332, 0.7939, 0.9277, 1.1379, 1.3564, 1.0707, 1.8242,
        1.0455, 0.7859, 2.0436, 1.5979, 1.3930, 1.1379, 2.3396, 1.3744, 1.6551,
        1.7515, 1.4123, 0.6852, 0.7808, 0.7473, 0.6969, 0.8714, 1.0707, 0.8337,
        0.7020, 0.7783, 0.5999, 0.7273, 0.5999, 0.7711, 0.6779, 0.7833, 1.4123,
        0.7397, 0.7307, 0.6830, 0.7620, 0.6083, 0.5964, 0.6932, 1.3564, 0.6750,
        0.6789, 0.8142, 0.9074, 0.9617, 0.7434, 1.5211, 0.6340, 1.2610, 0.7808,
        0.7534, 0.8673, 0.9123, 1.3062, 1.7515, 0.6002, 0.6187, 0.8303, 0.9617,
        0.7759, 2.2097, 2.4890, 0.6205, 0.7783, 0.8142, 0.7939, 1.1710, 1.1486,
        0.6694, 0.7687, 0.7208, 0.6511, 0.7885, 0.6635, 0.7833, 0.6627, 1.2332,
        0.6181, 0.5939, 0.6779, 0.6075, 0.5997, 0.6703, 0.7256, 0.9330, 0.7859,
        1.6551, 1.0537, 0.7360, 0.6651, 0.6112, 0.6061, 0.7415, 0.6254, 1.0979,
        0.6039, 1.5712, 0.8372, 0.6058, 0.6102, 0.7493, 3.7663, 1.7869, 0.6651],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  35  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  28 305 142 129 136  70  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 347 155  17  40 219]
CBFL per class weights: tensor([1.3237, 0.6473, 1.1286, 1.1959, 0.8941, 0.8602, 0.6498, 0.7109, 0.6461,
        1.2345, 0.8682, 0.6146, 1.0718, 1.4991, 0.8213, 2.6651, 0.7124, 0.5948,
        1.4764, 2.0977, 1.2345, 0.7947, 0.9286, 1.1390, 1.3578, 1.0718, 1.8260,
        1.0466, 0.7867, 1.9967, 1.5996, 1.3944, 1.1390, 2.3420, 1.3757, 1.6568,
        1.7533, 1.4137, 0.6859, 0.7816, 0.7481, 0.6976, 0.8723, 1.0718, 0.8345,
        0.7040, 0.7791, 0.6005, 0.7280, 0.6005, 0.7719, 0.6786, 0.7841, 1.4137,
        0.7404, 0.7314, 0.6837, 0.7627, 0.6090, 0.5970, 0.6939, 1.3578, 0.6756,
        0.6796, 0.8150, 0.9083, 0.9626, 0.7442, 1.5226, 0.6346, 1.2623, 0.7816,
        0.7542, 0.8682, 0.9132, 1.3076, 1.7533, 0.6009, 0.6193, 0.8311, 0.9626,
        0.7766, 2.2119, 2.4140, 0.6211, 0.7791, 0.8150, 0.7947, 1.1721, 1.1497,
        0.6701, 0.7695, 0.7215, 0.6517, 0.7893, 0.6642, 0.7841, 0.6634, 1.2345,
        0.6187, 0.5945, 0.6786, 0.6081, 0.6003, 0.6710, 0.7264, 0.9340, 0.7867,
        1.6568, 1.0547, 0.7349, 0.6658, 0.6118, 0.6067, 0.7423, 0.6261, 1.0990,
        0.6045, 1.5728, 0.8380, 0.6064, 0.6108, 0.7501, 3.7701, 1.7887, 0.6658],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  65 136 101  73  57  80  39  83 139  37  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 425 145 205 140  54
 160 165 200 149 357 479 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  28 305 142 129 136  70  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3247, 0.6478, 1.1294, 1.1968, 0.8947, 0.8608, 0.6502, 0.7114, 0.6466,
        1.2353, 0.8688, 0.6151, 1.0725, 1.5001, 0.8219, 2.6670, 0.7129, 0.5952,
        1.4775, 2.0992, 1.2353, 0.7953, 0.9293, 1.1398, 1.3587, 1.0725, 1.8273,
        1.0473, 0.7873, 1.9080, 1.6007, 1.3954, 1.1398, 2.3436, 1.3767, 1.6580,
        1.7545, 1.4147, 0.6864, 0.7821, 0.7486, 0.6981, 0.8729, 1.0725, 0.8351,
        0.7045, 0.7796, 0.6009, 0.7285, 0.6009, 0.7724, 0.6791, 0.7847, 1.4147,
        0.7409, 0.7319, 0.6842, 0.7633, 0.6094, 0.5974, 0.6944, 1.3587, 0.6761,
        0.6801, 0.8156, 0.9089, 0.9633, 0.7447, 1.5237, 0.6351, 1.2632, 0.7821,
        0.7547, 0.8688, 0.9139, 1.3085, 1.7545, 0.6013, 0.6198, 0.8317, 0.9633,
        0.7772, 2.2135, 2.4158, 0.6215, 0.7796, 0.8156, 0.7953, 1.1730, 1.1505,
        0.6706, 0.7701, 0.7220, 0.6522, 0.7899, 0.6646, 0.7847, 0.6638, 1.2353,
        0.6192, 0.5950, 0.6791, 0.6085, 0.6008, 0.6715, 0.7269, 0.9347, 0.7873,
        1.6580, 1.0555, 0.7355, 0.6663, 0.6122, 0.6071, 0.7428, 0.6265, 1.0998,
        0.6049, 1.5739, 0.8386, 0.6068, 0.6114, 0.7506, 3.7728, 1.7900, 0.6663],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 139  37  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 425 144 205 140  54
 160 165 200 149 357 478 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  29 305 142 129 136  71  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3256, 0.6482, 1.1302, 1.1977, 0.8954, 0.8615, 0.6507, 0.7120, 0.6470,
        1.2363, 0.8695, 0.6155, 1.0733, 1.5012, 0.8225, 2.6689, 0.7134, 0.5956,
        1.4786, 2.1008, 1.2230, 0.7959, 0.9300, 1.1407, 1.3598, 1.0733, 1.8287,
        1.0481, 0.7878, 1.9095, 1.6019, 1.3964, 1.1407, 2.3454, 1.3778, 1.6592,
        1.7559, 1.4158, 0.6869, 0.7827, 0.7492, 0.6986, 0.8736, 1.0733, 0.8358,
        0.7050, 0.7802, 0.6014, 0.7291, 0.6014, 0.7754, 0.6796, 0.7853, 1.4158,
        0.7415, 0.7325, 0.6847, 0.7638, 0.6098, 0.5979, 0.6949, 1.3598, 0.6766,
        0.6806, 0.8162, 0.9096, 0.9640, 0.7453, 1.5248, 0.6355, 1.2641, 0.7827,
        0.7553, 0.8695, 0.9145, 1.3095, 1.7559, 0.6017, 0.6202, 0.8324, 0.9640,
        0.7778, 2.2151, 2.3454, 0.6220, 0.7802, 0.8162, 0.7959, 1.1625, 1.1514,
        0.6711, 0.7706, 0.7225, 0.6527, 0.7905, 0.6651, 0.7853, 0.6643, 1.2363,
        0.6196, 0.5954, 0.6796, 0.6090, 0.6012, 0.6720, 0.7274, 0.9354, 0.7878,
        1.6592, 1.0563, 0.7360, 0.6668, 0.6127, 0.6076, 0.7434, 0.6270, 1.1006,
        0.6054, 1.5751, 0.8392, 0.6073, 0.6119, 0.7512, 3.7756, 1.7913, 0.6668],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 140  38  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 425 144 205 140  54
 160 165 200 149 357 478 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  95 143  31  29 305 142 129 136  71  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3261, 0.6485, 1.1306, 1.1981, 0.8957, 0.8618, 0.6510, 0.7122, 0.6473,
        1.2367, 0.8698, 0.6158, 1.0737, 1.5018, 0.8228, 2.6699, 0.7137, 0.5958,
        1.4791, 2.1015, 1.2234, 0.7961, 0.9303, 1.1411, 1.3602, 1.0737, 1.8293,
        1.0485, 0.7855, 1.8686, 1.6025, 1.3969, 1.1411, 2.3462, 1.3782, 1.6598,
        1.7565, 1.4163, 0.6871, 0.7830, 0.7494, 0.6988, 0.8739, 1.0737, 0.8361,
        0.7053, 0.7805, 0.6016, 0.7293, 0.6016, 0.7756, 0.6798, 0.7855, 1.4163,
        0.7417, 0.7328, 0.6850, 0.7641, 0.6101, 0.5981, 0.6951, 1.3602, 0.6769,
        0.6808, 0.8165, 0.9099, 0.9644, 0.7455, 1.5254, 0.6358, 1.2645, 0.7830,
        0.7555, 0.8698, 0.9149, 1.3099, 1.7565, 0.6019, 0.6204, 0.8326, 0.9644,
        0.7780, 2.2159, 2.3462, 0.6222, 0.7805, 0.8165, 0.7961, 1.1629, 1.1518,
        0.6713, 0.7709, 0.7228, 0.6529, 0.7907, 0.6654, 0.7855, 0.6646, 1.2367,
        0.6199, 0.5956, 0.6798, 0.6092, 0.6014, 0.6722, 0.7277, 0.9357, 0.7881,
        1.6598, 1.0567, 0.7363, 0.6670, 0.6129, 0.6078, 0.7436, 0.6272, 1.1010,
        0.6056, 1.5756, 0.8395, 0.6075, 0.6121, 0.7514, 3.7769, 1.7920, 0.6670],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 140  40  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 144 205 140  54
 160 165 200 149 357 478 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  29 305 142 129 136  71  72
 214 146 171 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3269, 0.6488, 1.1313, 1.1988, 0.8962, 0.8623, 0.6513, 0.7126, 0.6476,
        1.2374, 0.8703, 0.6161, 1.0743, 1.5026, 0.8232, 2.6714, 0.7141, 0.5962,
        1.4799, 2.1027, 1.2241, 0.7966, 0.9308, 1.1417, 1.3610, 1.0743, 1.8303,
        1.0491, 0.7860, 1.7930, 1.6034, 1.3977, 1.1417, 2.3475, 1.3790, 1.6607,
        1.7575, 1.4171, 0.6875, 0.7834, 0.7499, 0.6992, 0.8744, 1.0743, 0.8365,
        0.7057, 0.7809, 0.6019, 0.7297, 0.6020, 0.7761, 0.6802, 0.7860, 1.4171,
        0.7422, 0.7332, 0.6853, 0.7645, 0.6104, 0.5984, 0.6955, 1.3610, 0.6773,
        0.6812, 0.8169, 0.9104, 0.9649, 0.7460, 1.5262, 0.6361, 1.2653, 0.7834,
        0.7560, 0.8703, 0.9154, 1.3107, 1.7575, 0.6023, 0.6208, 0.8331, 0.9711,
        0.7785, 2.2171, 2.3475, 0.6226, 0.7809, 0.8169, 0.7966, 1.1635, 1.1525,
        0.6717, 0.7713, 0.7232, 0.6533, 0.7912, 0.6657, 0.7860, 0.6649, 1.2374,
        0.6202, 0.5959, 0.6802, 0.6096, 0.6018, 0.6726, 0.7281, 0.9362, 0.7886,
        1.6607, 1.0573, 0.7367, 0.6674, 0.6132, 0.6081, 0.7440, 0.6276, 1.1016,
        0.6059, 1.5765, 0.8400, 0.6078, 0.6124, 0.7519, 3.7790, 1.7930, 0.6674],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 140  40  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 144 205 140  54
 160 165 200 149 357 478 191  57 208 204 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  29 305 143 129 136  71  72
 214 146 170 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 159 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3269, 0.6488, 1.1313, 1.1988, 0.8962, 0.8623, 0.6513, 0.7126, 0.6476,
        1.2374, 0.8703, 0.6161, 1.0743, 1.5026, 0.8232, 2.6714, 0.7141, 0.5962,
        1.4800, 2.1027, 1.2241, 0.7966, 0.9308, 1.1417, 1.3610, 1.0743, 1.8303,
        1.0491, 0.7860, 1.7930, 1.6034, 1.3977, 1.1417, 2.3476, 1.3790, 1.6607,
        1.7575, 1.4171, 0.6875, 0.7834, 0.7499, 0.6992, 0.8744, 1.0743, 0.8365,
        0.7057, 0.7809, 0.6019, 0.7298, 0.6020, 0.7761, 0.6802, 0.7860, 1.4171,
        0.7422, 0.7332, 0.6853, 0.7645, 0.6104, 0.5984, 0.6955, 1.3610, 0.6773,
        0.6812, 0.8170, 0.9104, 0.9649, 0.7460, 1.5262, 0.6361, 1.2653, 0.7834,
        0.7560, 0.8703, 0.9154, 1.3107, 1.7575, 0.6023, 0.6208, 0.8331, 0.9711,
        0.7785, 2.2172, 2.3476, 0.6226, 0.7785, 0.8170, 0.7966, 1.1635, 1.1525,
        0.6717, 0.7714, 0.7248, 0.6533, 0.7912, 0.6658, 0.7860, 0.6649, 1.2374,
        0.6202, 0.5959, 0.6802, 0.6096, 0.6018, 0.6726, 0.7281, 0.9362, 0.7886,
        1.6607, 1.0573, 0.7367, 0.6674, 0.6132, 0.6081, 0.7440, 0.6276, 1.1016,
        0.6059, 1.5765, 0.8400, 0.6078, 0.6124, 0.7519, 3.7791, 1.7930, 0.6674],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 140  42  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 144 205 140  54
 160 165 200 149 357 478 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  30 305 143 129 136  71  72
 214 146 170 238 138 221 140 222  65 313 548 205 362 427 213 168 100 139
  44  82 163 219 342 371 158 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3283, 0.6495, 1.1325, 1.2000, 0.8972, 0.8632, 0.6520, 0.7134, 0.6483,
        1.2387, 0.8712, 0.6168, 1.0754, 1.5042, 0.8241, 2.6742, 0.7148, 0.5968,
        1.4815, 2.1049, 1.2254, 0.7974, 0.9318, 1.1429, 1.3624, 1.0754, 1.8323,
        1.0502, 0.7868, 1.7255, 1.6051, 1.3992, 1.1429, 2.3500, 1.3805, 1.6625,
        1.7593, 1.4186, 0.6882, 0.7843, 0.7507, 0.7000, 0.8753, 1.0754, 0.8374,
        0.7064, 0.7818, 0.6026, 0.7305, 0.6027, 0.7769, 0.6809, 0.7868, 1.4186,
        0.7429, 0.7339, 0.6861, 0.7654, 0.6111, 0.5991, 0.6963, 1.3624, 0.6789,
        0.6829, 0.8178, 0.9114, 0.9659, 0.7467, 1.5278, 0.6368, 1.2666, 0.7843,
        0.7568, 0.8712, 0.9164, 1.3121, 1.7593, 0.6029, 0.6214, 0.8340, 0.9721,
        0.7793, 2.2195, 2.2826, 0.6232, 0.7793, 0.8178, 0.7974, 1.1648, 1.1537,
        0.6724, 0.7722, 0.7256, 0.6540, 0.7920, 0.6665, 0.7868, 0.6656, 1.2387,
        0.6209, 0.5966, 0.6809, 0.6102, 0.6024, 0.6733, 0.7288, 0.9372, 0.7894,
        1.6625, 1.0584, 0.7375, 0.6681, 0.6139, 0.6088, 0.7467, 0.6282, 1.1028,
        0.6066, 1.5782, 0.8409, 0.6085, 0.6131, 0.7527, 3.7830, 1.7949, 0.6681],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  25 177 539
  51  33  66 136 101  73  57  80  39  83 140  43  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 144 205 140  54
 161 165 200 149 357 478 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  30 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 548 205 362 427 213 169 100 139
  44  82 163 219 342 371 158 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3286, 0.6497, 1.1328, 1.2004, 0.8974, 0.8634, 0.6522, 0.7136, 0.6485,
        1.2390, 0.8714, 0.6169, 1.0757, 1.5046, 0.8243, 2.6749, 0.7150, 0.5970,
        1.4819, 2.1055, 1.2257, 0.7976, 0.9321, 1.1432, 1.3628, 1.0757, 1.8328,
        1.0504, 0.7870, 1.6937, 1.6055, 1.3995, 1.1432, 2.3507, 1.3808, 1.6629,
        1.7598, 1.4190, 0.6884, 0.7845, 0.7509, 0.7001, 0.8755, 1.0757, 0.8376,
        0.7066, 0.7820, 0.6027, 0.7307, 0.6028, 0.7771, 0.6811, 0.7870, 1.4190,
        0.7413, 0.7341, 0.6863, 0.7656, 0.6112, 0.5992, 0.6965, 1.3628, 0.6791,
        0.6831, 0.8180, 0.9116, 0.9662, 0.7469, 1.5283, 0.6370, 1.2669, 0.7845,
        0.7570, 0.8714, 0.9166, 1.3124, 1.7598, 0.6031, 0.6216, 0.8342, 0.9723,
        0.7795, 2.2201, 2.2832, 0.6234, 0.7795, 0.8180, 0.7976, 1.1651, 1.1540,
        0.6726, 0.7747, 0.7258, 0.6541, 0.7922, 0.6666, 0.7870, 0.6658, 1.2390,
        0.6210, 0.5967, 0.6811, 0.6104, 0.6026, 0.6735, 0.7274, 0.9374, 0.7896,
        1.6629, 1.0587, 0.7377, 0.6683, 0.6141, 0.6089, 0.7469, 0.6284, 1.1031,
        0.6067, 1.5786, 0.8411, 0.6086, 0.6133, 0.7529, 3.7840, 1.7953, 0.6683],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  65 114 329  80  50 127  26 177 539
  51  33  66 136 101  73  57  80  39  83 140  45  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 477 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  31 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 548 205 362 427 213 169 100 139
  44  82 163 219 342 371 158 290  77 387  47 122 373 346 155  17  40 219]
CBFL per class weights: tensor([1.3308, 0.6508, 1.1347, 1.2024, 0.8989, 0.8648, 0.6533, 0.7148, 0.6496,
        1.2411, 0.8729, 0.6180, 1.0775, 1.5071, 0.8257, 2.5888, 0.7162, 0.5980,
        1.4844, 2.1090, 1.2278, 0.7990, 0.9336, 1.1451, 1.3651, 1.0775, 1.8358,
        1.0522, 0.7883, 1.6363, 1.6082, 1.4019, 1.1451, 2.3546, 1.3832, 1.6657,
        1.7627, 1.4213, 0.6896, 0.7858, 0.7521, 0.7013, 0.8770, 1.0775, 0.8390,
        0.7078, 0.7833, 0.6037, 0.7319, 0.6038, 0.7808, 0.6822, 0.7883, 1.4213,
        0.7425, 0.7354, 0.6874, 0.7668, 0.6122, 0.6003, 0.6976, 1.3651, 0.6803,
        0.6843, 0.8194, 0.9132, 0.9678, 0.7482, 1.5308, 0.6380, 1.2691, 0.7858,
        0.7582, 0.8729, 0.9181, 1.3146, 1.7627, 0.6041, 0.6226, 0.8356, 0.9740,
        0.7808, 2.2238, 2.2238, 0.6244, 0.7808, 0.8194, 0.7990, 1.1670, 1.1559,
        0.6737, 0.7760, 0.7270, 0.6552, 0.7936, 0.6678, 0.7883, 0.6669, 1.2411,
        0.6221, 0.5977, 0.6822, 0.6114, 0.6036, 0.6746, 0.7286, 0.9390, 0.7909,
        1.6657, 1.0604, 0.7389, 0.6694, 0.6151, 0.6100, 0.7482, 0.6294, 1.1049,
        0.6077, 1.5813, 0.8425, 0.6097, 0.6143, 0.7541, 3.7904, 1.7984, 0.6694],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  66 114 329  80  50 127  27 177 539
  51  33  66 136 101  73  57  80  39  83 140  45  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  31 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 548 205 362 427 213 169 100 139
  44  82 163 219 342 371 158 290  77 386  47 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3319, 0.6513, 1.1355, 1.2033, 0.8996, 0.8655, 0.6538, 0.7153, 0.6501,
        1.2287, 0.8736, 0.6184, 1.0784, 1.5083, 0.8264, 2.5069, 0.7168, 0.5984,
        1.4856, 2.1106, 1.2287, 0.7996, 0.9344, 1.1460, 1.3662, 1.0784, 1.8373,
        1.0530, 0.7890, 1.6376, 1.6094, 1.4030, 1.1460, 2.3564, 1.3842, 1.6670,
        1.7641, 1.4225, 0.6901, 0.7864, 0.7527, 0.7019, 0.8777, 1.0784, 0.8397,
        0.7084, 0.7839, 0.6042, 0.7325, 0.6043, 0.7814, 0.6828, 0.7890, 1.4225,
        0.7431, 0.7359, 0.6879, 0.7674, 0.6127, 0.6008, 0.6982, 1.3662, 0.6808,
        0.6848, 0.8200, 0.9139, 0.9686, 0.7488, 1.5320, 0.6385, 1.2700, 0.7864,
        0.7588, 0.8736, 0.9188, 1.3156, 1.7641, 0.6046, 0.6231, 0.8363, 0.9747,
        0.7814, 2.2255, 2.2255, 0.6249, 0.7814, 0.8200, 0.7996, 1.1679, 1.1568,
        0.6743, 0.7766, 0.7276, 0.6557, 0.7942, 0.6683, 0.7890, 0.6675, 1.2421,
        0.6226, 0.5982, 0.6828, 0.6119, 0.6040, 0.6751, 0.7292, 0.9398, 0.7916,
        1.6670, 1.0613, 0.7395, 0.6699, 0.6156, 0.6104, 0.7488, 0.6299, 1.1058,
        0.6083, 1.5825, 0.8432, 0.6101, 0.6148, 0.7547, 3.7934, 1.7998, 0.6691],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  66 114 329  80  50 127  27 177 539
  51  33  66 136 101  73  57  80  39  83 140  46  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 421 311 124  94 143  31  31 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 548 205 362 427 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  47 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3322, 0.6514, 1.1358, 1.2036, 0.8998, 0.8657, 0.6539, 0.7155, 0.6502,
        1.2290, 0.8737, 0.6186, 1.0786, 1.5086, 0.8265, 2.5074, 0.7169, 0.5986,
        1.4859, 2.1111, 1.2290, 0.7998, 0.9346, 1.1463, 1.3664, 1.0786, 1.8377,
        1.0533, 0.7891, 1.6098, 1.6098, 1.4033, 1.1463, 2.3569, 1.3845, 1.6674,
        1.7645, 1.4228, 0.6903, 0.7866, 0.7529, 0.7020, 0.8779, 1.0786, 0.8399,
        0.7085, 0.7841, 0.6043, 0.7327, 0.6044, 0.7816, 0.6829, 0.7891, 1.4228,
        0.7433, 0.7361, 0.6881, 0.7676, 0.6128, 0.6009, 0.6983, 1.3664, 0.6809,
        0.6849, 0.8202, 0.9141, 0.9688, 0.7489, 1.5323, 0.6387, 1.2703, 0.7866,
        0.7590, 0.8737, 0.9190, 1.3159, 1.7645, 0.6047, 0.6233, 0.8364, 0.9749,
        0.7816, 2.2260, 2.2260, 0.6251, 0.7816, 0.8202, 0.7998, 1.1682, 1.1571,
        0.6744, 0.7768, 0.7277, 0.6559, 0.7944, 0.6684, 0.7891, 0.6676, 1.2423,
        0.6227, 0.5983, 0.6829, 0.6120, 0.6042, 0.6762, 0.7293, 0.9400, 0.7917,
        1.6674, 1.0615, 0.7396, 0.6701, 0.6157, 0.6106, 0.7489, 0.6301, 1.1060,
        0.6085, 1.5828, 0.8434, 0.6103, 0.6149, 0.7549, 3.7942, 1.8001, 0.6692],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 108 116 241 178 247  66 114 329  80  50 127  28 177 539
  51  33  66 136 101  73  57  80  39  83 140  46  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 104  60  41 420 311 124  94 143  31  31 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 548 205 362 427 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  47 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3330, 0.6518, 1.1365, 1.2043, 0.9004, 0.8662, 0.6543, 0.7159, 0.6506,
        1.2298, 0.8743, 0.6189, 1.0793, 1.5096, 0.8271, 2.4310, 0.7174, 0.5989,
        1.4868, 2.1124, 1.2298, 0.8003, 0.9351, 1.1470, 1.3673, 1.0793, 1.8388,
        1.0539, 0.7896, 1.6108, 1.6108, 1.4042, 1.1470, 2.3584, 1.3854, 1.6684,
        1.7656, 1.4236, 0.6907, 0.7871, 0.7533, 0.7024, 0.8784, 1.0793, 0.8404,
        0.7090, 0.7846, 0.6047, 0.7331, 0.6048, 0.7821, 0.6833, 0.7896, 1.4236,
        0.7437, 0.7366, 0.6885, 0.7681, 0.6132, 0.6013, 0.6987, 1.3673, 0.6814,
        0.6854, 0.8207, 0.9147, 0.9694, 0.7494, 1.5333, 0.6391, 1.2711, 0.7871,
        0.7595, 0.8743, 0.9196, 1.3167, 1.7656, 0.6052, 0.6237, 0.8370, 0.9755,
        0.7821, 2.2274, 2.2274, 0.6254, 0.7821, 0.8207, 0.8003, 1.1689, 1.1578,
        0.6748, 0.7773, 0.7282, 0.6563, 0.7949, 0.6688, 0.7896, 0.6680, 1.2431,
        0.6231, 0.5987, 0.6833, 0.6124, 0.6045, 0.6766, 0.7298, 0.9405, 0.7922,
        1.6684, 1.0621, 0.7401, 0.6705, 0.6161, 0.6109, 0.7494, 0.6305, 1.1067,
        0.6088, 1.5838, 0.8439, 0.6106, 0.6153, 0.7553, 3.7965, 1.8013, 0.6697],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 107 115 241 178 247  66 114 329  80  50 127  28 177 539
  51  33  66 136 101  73  57  80  39  83 140  49  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  57 207 203 129 105  95 158  49 269  63 141
 153 114 102  60  41 420 311 124  94 143  31  32 305 143 129 136  71  72
 214 145 170 238 138 221 140 222  65 313 547 205 362 428 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  48 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3345, 0.6526, 1.1378, 1.2057, 0.9061, 0.8712, 0.6551, 0.7167, 0.6514,
        1.2312, 0.8753, 0.6197, 1.0805, 1.5113, 0.8280, 2.4337, 0.7182, 0.5996,
        1.4885, 2.1148, 1.2312, 0.8012, 0.9362, 1.1483, 1.3689, 1.0805, 1.8409,
        1.0551, 0.7905, 1.5350, 1.6126, 1.4058, 1.1483, 2.3611, 1.3870, 1.6703,
        1.7676, 1.4253, 0.6915, 0.7880, 0.7542, 0.7032, 0.8794, 1.0805, 0.8414,
        0.7098, 0.7855, 0.6054, 0.7340, 0.6055, 0.7830, 0.6841, 0.7905, 1.4253,
        0.7446, 0.7374, 0.6893, 0.7690, 0.6139, 0.6020, 0.6995, 1.3689, 0.6821,
        0.6861, 0.8217, 0.9157, 0.9705, 0.7503, 1.5350, 0.6398, 1.2726, 0.7880,
        0.7603, 0.8753, 0.9309, 1.3182, 1.7676, 0.6058, 0.6244, 0.8379, 0.9767,
        0.7830, 2.2299, 2.1706, 0.6262, 0.7830, 0.8217, 0.8012, 1.1702, 1.1591,
        0.6756, 0.7782, 0.7290, 0.6570, 0.7958, 0.6696, 0.7905, 0.6688, 1.2445,
        0.6238, 0.5994, 0.6841, 0.6131, 0.6051, 0.6774, 0.7306, 0.9416, 0.7931,
        1.6703, 1.0634, 0.7409, 0.6713, 0.6168, 0.6116, 0.7503, 0.6312, 1.1080,
        0.6095, 1.5598, 0.8448, 0.6113, 0.6160, 0.7562, 3.8009, 1.8033, 0.6704],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 107 115 241 178 247  66 114 329  80  50 127  28 177 539
  51  33  66 136 101  73  57  80  39  83 140  49  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  63 141
 153 114 102  60  41 420 311 124  94 143  31  32 305 144 129 136  71  72
 214 145 170 237 138 221 141 222  65 313 547 205 362 428 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  48 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3344, 0.6525, 1.1377, 1.2055, 0.9060, 0.8711, 0.6550, 0.7167, 0.6513,
        1.2310, 0.8752, 0.6196, 1.0804, 1.5111, 0.8279, 2.4335, 0.7181, 0.5995,
        1.4883, 2.1146, 1.2310, 0.8011, 0.9361, 1.1482, 1.3687, 1.0804, 1.8407,
        1.0550, 0.7904, 1.5349, 1.6124, 1.4056, 1.1482, 2.3608, 1.3868, 1.6701,
        1.7674, 1.4251, 0.6914, 0.7879, 0.7541, 0.7032, 0.8793, 1.0804, 0.8413,
        0.7097, 0.7854, 0.6053, 0.7339, 0.6054, 0.7829, 0.6840, 0.7904, 1.4251,
        0.7445, 0.7373, 0.6892, 0.7689, 0.6139, 0.6019, 0.6995, 1.3868, 0.6821,
        0.6861, 0.8216, 0.9156, 0.9704, 0.7502, 1.5349, 0.6397, 1.2724, 0.7879,
        0.7602, 0.8752, 0.9308, 1.3181, 1.7674, 0.6058, 0.6243, 0.8378, 0.9766,
        0.7829, 2.2297, 2.1703, 0.6261, 0.7805, 0.8216, 0.8011, 1.1701, 1.1590,
        0.6755, 0.7781, 0.7289, 0.6576, 0.7957, 0.6695, 0.7879, 0.6687, 1.2444,
        0.6237, 0.5993, 0.6840, 0.6130, 0.6051, 0.6773, 0.7305, 0.9415, 0.7930,
        1.6701, 1.0632, 0.7409, 0.6712, 0.6167, 0.6116, 0.7502, 0.6311, 1.1078,
        0.6095, 1.5596, 0.8448, 0.6113, 0.6159, 0.7561, 3.8004, 1.8031, 0.6703],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  74  68 107 115 241 178 247  66 114 329  80  50 127  29 177 539
  51  33  66 136 101  73  57  80  39  83 140  50  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  63 141
 153 114 102  60  41 420 311 124  94 143  31  32 305 144 129 136  71  72
 214 145 170 237 138 221 141 222  65 313 547 205 362 428 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  48 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3354, 0.6530, 1.1385, 1.2065, 0.9067, 0.8718, 0.6555, 0.7172, 0.6518,
        1.2320, 0.8759, 0.6201, 1.0812, 1.5123, 0.8285, 2.3626, 0.7187, 0.6000,
        1.4895, 2.1162, 1.2320, 0.8017, 0.9368, 1.1490, 1.3698, 1.0812, 1.8421,
        1.0558, 0.7910, 1.5123, 1.6137, 1.4067, 1.1490, 2.3626, 1.3879, 1.6714,
        1.7688, 1.4262, 0.6919, 0.7885, 0.7547, 0.7037, 0.8800, 1.0812, 0.8419,
        0.7102, 0.7860, 0.6058, 0.7344, 0.6059, 0.7835, 0.6846, 0.7910, 1.4262,
        0.7451, 0.7379, 0.6898, 0.7695, 0.6143, 0.6024, 0.7000, 1.3879, 0.6826,
        0.6866, 0.8222, 0.9163, 0.9711, 0.7508, 1.5360, 0.6402, 1.2734, 0.7885,
        0.7608, 0.8759, 0.9315, 1.3191, 1.7688, 0.6062, 0.6248, 0.8385, 0.9773,
        0.7835, 2.2314, 2.1720, 0.6266, 0.7811, 0.8222, 0.8017, 1.1710, 1.1599,
        0.6760, 0.7787, 0.7295, 0.6581, 0.7963, 0.6700, 0.7885, 0.6692, 1.2453,
        0.6242, 0.5998, 0.6846, 0.6135, 0.6055, 0.6778, 0.7311, 0.9422, 0.7936,
        1.6714, 1.0641, 0.7414, 0.6717, 0.6172, 0.6120, 0.7508, 0.6316, 1.1087,
        0.6099, 1.5608, 0.8454, 0.6117, 0.6164, 0.7567, 3.8033, 1.8045, 0.6709],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  30 177 539
  51  33  66 136 101  73  57  80  39  83 140  52  46  55  73  29  56  44
  41  54 198 141 156 188 113  80 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  63 141
 153 114 102  60  41 419 311 124  94 143  31  33 305 144 129 136  71  73
 214 145 170 237 138 221 141 222  65 313 547 205 362 428 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  49 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3374, 0.6540, 1.1508, 1.2083, 0.9081, 0.8731, 0.6565, 0.7183, 0.6528,
        1.2339, 0.8772, 0.6210, 1.0829, 1.5146, 0.8298, 2.2983, 0.7198, 0.6009,
        1.4918, 2.1195, 1.2339, 0.8029, 0.9383, 1.1508, 1.3719, 1.0829, 1.8449,
        1.0574, 0.7923, 1.4698, 1.6161, 1.4088, 1.1508, 2.3663, 1.3900, 1.6740,
        1.7715, 1.4284, 0.6930, 0.7897, 0.7558, 0.7048, 0.8813, 1.0829, 0.8432,
        0.7113, 0.7872, 0.6067, 0.7356, 0.6068, 0.7847, 0.6856, 0.7923, 1.4284,
        0.7462, 0.7390, 0.6908, 0.7706, 0.6153, 0.6033, 0.7011, 1.3900, 0.6836,
        0.6877, 0.8235, 0.9177, 0.9726, 0.7519, 1.5384, 0.6412, 1.2753, 0.7897,
        0.7620, 0.8772, 0.9330, 1.3211, 1.7715, 0.6073, 0.6257, 0.8398, 0.9788,
        0.7847, 2.2348, 2.1195, 0.6275, 0.7823, 0.8235, 0.8029, 1.1728, 1.1508,
        0.6771, 0.7799, 0.7306, 0.6591, 0.7975, 0.6711, 0.7897, 0.6702, 1.2473,
        0.6252, 0.6007, 0.6856, 0.6144, 0.6065, 0.6789, 0.7322, 0.9437, 0.7949,
        1.6740, 1.0657, 0.7426, 0.6727, 0.6181, 0.6130, 0.7519, 0.6326, 1.1104,
        0.6109, 1.5384, 0.8467, 0.6127, 0.6173, 0.7579, 3.8092, 1.8073, 0.6719],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  32 177 539
  51  33  66 136 101  73  57  80  39  83 140  54  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 417 311 124  94 143  31  34 305 144 129 136  71  73
 214 145 170 237 138 221 141 222  65 313 547 205 362 428 212 169 100 139
  44  82 163 219 342 371 158 290  77 386  49 122 373 346 155  17  40 220]
CBFL per class weights: tensor([1.3397, 0.6551, 1.1527, 1.2104, 0.9096, 0.8746, 0.6576, 0.7195, 0.6539,
        1.2359, 0.8787, 0.6221, 1.0847, 1.5171, 0.8312, 2.1790, 0.7210, 0.6019,
        1.4943, 2.1230, 1.2359, 0.8043, 0.9398, 1.1527, 1.3742, 1.0847, 1.8480,
        1.0592, 0.7936, 1.4308, 1.6189, 1.4112, 1.1527, 2.3702, 1.3923, 1.6768,
        1.7744, 1.4308, 0.6942, 0.7910, 0.7571, 0.7060, 0.8828, 1.0760, 0.8446,
        0.7125, 0.7885, 0.6077, 0.7368, 0.6078, 0.7860, 0.6868, 0.7936, 1.4308,
        0.7475, 0.7403, 0.6920, 0.7719, 0.6163, 0.6043, 0.7023, 1.3923, 0.6848,
        0.6888, 0.8248, 0.9192, 0.9742, 0.7532, 1.5410, 0.6423, 1.2923, 0.7910,
        0.7633, 0.8787, 0.9345, 1.3233, 1.7744, 0.6085, 0.6268, 0.8412, 0.9804,
        0.7860, 2.2386, 2.0704, 0.6286, 0.7836, 0.8248, 0.8043, 1.1748, 1.1527,
        0.6782, 0.7812, 0.7318, 0.6603, 0.7988, 0.6722, 0.7910, 0.6714, 1.2493,
        0.6262, 0.6017, 0.6868, 0.6154, 0.6075, 0.6800, 0.7335, 0.9453, 0.7962,
        1.6768, 1.0675, 0.7438, 0.6738, 0.6192, 0.6140, 0.7532, 0.6336, 1.1123,
        0.6119, 1.5410, 0.8481, 0.6137, 0.6184, 0.7591, 3.8156, 1.8103, 0.6730],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  32 177 538
  51  33  66 136 101  73  57  80  39  83 140  56  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 417 311 124  94 143  31  35 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 210 169 100 139
  44  82 163 219 342 371 158 290  77 386  50 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3409, 0.6557, 1.1538, 1.2114, 0.9104, 0.8754, 0.6582, 0.7202, 0.6545,
        1.2370, 0.8795, 0.6226, 1.0857, 1.5185, 0.8319, 2.1809, 0.7216, 0.6025,
        1.4956, 2.1249, 1.2370, 0.8050, 0.9407, 1.1538, 1.3754, 1.0857, 1.8497,
        1.0601, 0.7943, 1.3936, 1.6203, 1.4125, 1.1538, 2.3724, 1.3936, 1.6783,
        1.7760, 1.4321, 0.6948, 0.7917, 0.7578, 0.7066, 0.8836, 1.0769, 0.8454,
        0.7131, 0.7892, 0.6083, 0.7375, 0.6084, 0.7867, 0.6874, 0.7943, 1.4321,
        0.7481, 0.7409, 0.6926, 0.7726, 0.6169, 0.6049, 0.7029, 1.3936, 0.6854,
        0.6894, 0.8256, 0.9201, 0.9751, 0.7538, 1.5424, 0.6428, 1.2934, 0.7917,
        0.7640, 0.8795, 0.9354, 1.3245, 1.7760, 0.6090, 0.6273, 0.8419, 0.9813,
        0.7867, 2.2406, 2.0226, 0.6291, 0.7843, 0.8256, 0.8050, 1.1758, 1.1538,
        0.6788, 0.7819, 0.7325, 0.6608, 0.7996, 0.6720, 0.7917, 0.6720, 1.2505,
        0.6268, 0.6023, 0.6874, 0.6160, 0.6080, 0.6825, 0.7341, 0.9461, 0.7969,
        1.6783, 1.0684, 0.7445, 0.6745, 0.6197, 0.6146, 0.7538, 0.6342, 1.1133,
        0.6125, 1.5185, 0.8489, 0.6143, 0.6189, 0.7578, 3.8190, 1.8119, 0.6736],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  32 177 538
  51  33  66 136 101  73  57  80  39  83 140  57  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 161 165 200 149 357 476 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 417 311 124  94 143  31  35 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 210 169 100 139
  44  82 163 219 342 371 158 290  77 386  50 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3411, 0.6558, 1.1539, 1.2116, 0.9105, 0.8755, 0.6583, 0.7203, 0.6546,
        1.2372, 0.8796, 0.6227, 1.0858, 1.5187, 0.8321, 2.1812, 0.7217, 0.6026,
        1.4958, 2.1252, 1.2372, 0.8051, 0.9408, 1.1539, 1.3756, 1.0858, 1.8500,
        1.0603, 0.7944, 1.3756, 1.6205, 1.4127, 1.1539, 2.3727, 1.3938, 1.6785,
        1.7763, 1.4323, 0.6949, 0.7918, 0.7579, 0.7067, 0.8837, 1.0771, 0.8455,
        0.7133, 0.7893, 0.6084, 0.7376, 0.6085, 0.7868, 0.6875, 0.7944, 1.4323,
        0.7482, 0.7410, 0.6927, 0.7727, 0.6169, 0.6049, 0.7030, 1.3938, 0.6855,
        0.6895, 0.8257, 0.9202, 0.9753, 0.7540, 1.5426, 0.6429, 1.2936, 0.7918,
        0.7641, 0.8796, 0.9355, 1.3247, 1.7763, 0.6091, 0.6274, 0.8420, 0.9815,
        0.7868, 2.2409, 2.0229, 0.6292, 0.7844, 0.8257, 0.8051, 1.1760, 1.1539,
        0.6789, 0.7820, 0.7326, 0.6609, 0.7997, 0.6721, 0.7918, 0.6721, 1.2506,
        0.6269, 0.6024, 0.6875, 0.6161, 0.6081, 0.6826, 0.7342, 0.9462, 0.7970,
        1.6785, 1.0686, 0.7446, 0.6746, 0.6198, 0.6147, 0.7540, 0.6343, 1.1134,
        0.6125, 1.5187, 0.8490, 0.6144, 0.6190, 0.7579, 3.8195, 1.8122, 0.6737],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  32 177 538
  51  33  66 136 101  73  57  80  39  83 140  57  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 160 164 200 149 357 476 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 417 311 124  94 143  31  36 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 210 169 100 139
  44  82 163 219 342 371 158 290  77 386  51 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3418, 0.6561, 1.1545, 1.2122, 0.9110, 0.8760, 0.6586, 0.7206, 0.6549,
        1.2379, 0.8800, 0.6230, 1.0864, 1.5195, 0.8325, 2.1824, 0.7221, 0.6029,
        1.4966, 2.1263, 1.2379, 0.8055, 0.9413, 1.1545, 1.3763, 1.0864, 1.8509,
        1.0609, 0.7948, 1.3763, 1.6214, 1.4134, 1.1545, 2.3739, 1.3945, 1.6794,
        1.7772, 1.4330, 0.6952, 0.7923, 0.7583, 0.7071, 0.8842, 1.0777, 0.8459,
        0.7136, 0.7897, 0.6087, 0.7380, 0.6088, 0.7872, 0.6878, 0.7948, 1.4330,
        0.7505, 0.7432, 0.6931, 0.7731, 0.6173, 0.6053, 0.7034, 1.3945, 0.6858,
        0.6899, 0.8261, 0.9207, 0.9758, 0.7543, 1.5434, 0.6433, 1.2943, 0.7923,
        0.7645, 0.8800, 0.9360, 1.3254, 1.7772, 0.6094, 0.6278, 0.8425, 0.9820,
        0.7872, 2.2421, 1.9770, 0.6296, 0.7848, 0.8261, 0.8055, 1.1766, 1.1545,
        0.6793, 0.7824, 0.7330, 0.6613, 0.8001, 0.6724, 0.7923, 0.6724, 1.2513,
        0.6272, 0.6027, 0.6878, 0.6164, 0.6084, 0.6830, 0.7346, 0.9467, 0.7974,
        1.6794, 1.0691, 0.7450, 0.6749, 0.6201, 0.6150, 0.7543, 0.6346, 1.1140,
        0.6129, 1.4966, 0.8494, 0.6147, 0.6193, 0.7583, 3.8216, 1.8131, 0.6741],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  32 177 538
  51  33  66 136 101  73  57  80  39  83 140  57  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 357 476 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 417 311 124  94 143  31  36 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 210 169 100 139
  44  82 163 219 342 371 158 290  77 386  53 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3422, 0.6563, 1.1549, 1.2126, 0.9113, 0.8762, 0.6589, 0.7209, 0.6551,
        1.2383, 0.8803, 0.6232, 1.0867, 1.5200, 0.8328, 2.1831, 0.7223, 0.6031,
        1.4971, 2.1270, 1.2383, 0.8058, 0.9416, 1.1549, 1.3768, 1.0867, 1.8515,
        1.0612, 0.7951, 1.3768, 1.6219, 1.4139, 1.1549, 2.3747, 1.3950, 1.6800,
        1.7778, 1.4335, 0.6955, 0.7925, 0.7585, 0.7073, 0.8845, 1.0780, 0.8462,
        0.7139, 0.7900, 0.6089, 0.7382, 0.6090, 0.7875, 0.6881, 0.7951, 1.4335,
        0.7527, 0.7434, 0.6933, 0.7734, 0.6175, 0.6055, 0.7036, 1.3950, 0.6861,
        0.6901, 0.8264, 0.9210, 0.9761, 0.7546, 1.5439, 0.6435, 1.2947, 0.7925,
        0.7647, 0.8803, 0.9363, 1.3258, 1.7778, 0.6096, 0.6280, 0.8428, 0.9823,
        0.7875, 2.2428, 1.9777, 0.6298, 0.7851, 0.8264, 0.8058, 1.1770, 1.1549,
        0.6795, 0.7826, 0.7332, 0.6615, 0.8004, 0.6726, 0.7925, 0.6726, 1.2517,
        0.6274, 0.6029, 0.6881, 0.6166, 0.6086, 0.6832, 0.7348, 0.9470, 0.7977,
        1.6800, 1.0695, 0.7452, 0.6751, 0.6203, 0.6152, 0.7546, 0.6348, 1.1144,
        0.6131, 1.4539, 0.8497, 0.6149, 0.6195, 0.7585, 3.8228, 1.8137, 0.6743],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  33 177 538
  51  33  66 136 101  73  58  80  38  83 140  57  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 357 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 210 169 100 139
  44  82 163 219 342 371 158 290  77 386  54 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3427, 0.6566, 1.1554, 1.2131, 0.9116, 0.8766, 0.6591, 0.7212, 0.6554,
        1.2388, 0.8807, 0.6235, 1.0872, 1.5206, 0.8331, 2.1278, 0.7226, 0.6033,
        1.4977, 2.1278, 1.2388, 0.8061, 0.9420, 1.1554, 1.3597, 1.0872, 1.8921,
        1.0616, 0.7954, 1.3773, 1.6225, 1.4144, 1.1554, 2.3756, 1.3955, 1.6806,
        1.7785, 1.4340, 0.6957, 0.7928, 0.7588, 0.7076, 0.8848, 1.0784, 0.8465,
        0.7141, 0.7903, 0.6091, 0.7385, 0.6092, 0.7878, 0.6883, 0.7954, 1.4340,
        0.7529, 0.7437, 0.6935, 0.7737, 0.6177, 0.6056, 0.7039, 1.3955, 0.6863,
        0.6904, 0.8267, 0.9213, 0.9765, 0.7549, 1.5445, 0.6437, 1.2952, 0.7928,
        0.7650, 0.8807, 0.9366, 1.3263, 1.7785, 0.6099, 0.6282, 0.8431, 0.9890,
        0.7878, 2.2437, 1.9784, 0.6300, 0.7854, 0.8267, 0.8061, 1.1774, 1.1554,
        0.6797, 0.7829, 0.7335, 0.6618, 0.8007, 0.6729, 0.7928, 0.6729, 1.2522,
        0.6276, 0.6031, 0.6883, 0.6168, 0.6089, 0.6834, 0.7351, 0.9474, 0.7980,
        1.6806, 1.0699, 0.7455, 0.6754, 0.6206, 0.6154, 0.7549, 0.6351, 1.1148,
        0.6133, 1.4340, 0.8500, 0.6151, 0.6198, 0.7588, 3.8243, 1.8144, 0.6745],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  33 177 538
  51  33  66 136 101  73  58  80  38  83 140  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 357 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  65 313 547 205 362 428 209 169 100 139
  44  82 163 219 342 371 158 290  77 386  54 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3429, 0.6567, 1.1555, 1.2133, 0.9118, 0.8767, 0.6592, 0.7212, 0.6555,
        1.2389, 0.8808, 0.6236, 1.0873, 1.5208, 0.8332, 2.1281, 0.7227, 0.6034,
        1.4979, 2.1281, 1.2389, 0.8062, 0.9421, 1.1555, 1.3599, 1.0873, 1.8923,
        1.0617, 0.7955, 1.3599, 1.6228, 1.4146, 1.1555, 2.3759, 1.3957, 1.6808,
        1.7787, 1.4342, 0.6958, 0.7929, 0.7589, 0.7077, 0.8850, 1.0786, 0.8466,
        0.7142, 0.7904, 0.6092, 0.7386, 0.6093, 0.7879, 0.6884, 0.7955, 1.4342,
        0.7530, 0.7438, 0.6936, 0.7738, 0.6178, 0.6057, 0.7039, 1.3957, 0.6864,
        0.6905, 0.8268, 0.9215, 0.9766, 0.7550, 1.5447, 0.6438, 1.2954, 0.7929,
        0.7651, 0.8808, 0.9368, 1.3265, 1.7787, 0.6100, 0.6283, 0.8432, 0.9892,
        0.7879, 2.2440, 1.9787, 0.6301, 0.7855, 0.8268, 0.8062, 1.1776, 1.1555,
        0.6798, 0.7830, 0.7336, 0.6618, 0.8008, 0.6730, 0.7929, 0.6730, 1.2524,
        0.6277, 0.6032, 0.6884, 0.6169, 0.6090, 0.6845, 0.7352, 0.9475, 0.7981,
        1.6808, 1.0700, 0.7456, 0.6755, 0.6207, 0.6155, 0.7550, 0.6351, 1.1149,
        0.6134, 1.4342, 0.8502, 0.6152, 0.6198, 0.7589, 3.8248, 1.8147, 0.6746],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  33 177 538
  51  33  66 136 101  73  58  80  38  83 140  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 356 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 305 144 129 136  71  73
 214 145 170 237 138 222 141 222  66 313 547 205 362 428 209 169 100 139
  44  82 163 219 342 371 158 290  77 386  55 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3433, 0.6568, 1.1558, 1.2136, 0.9120, 0.8769, 0.6594, 0.7214, 0.6556,
        1.2392, 0.8810, 0.6237, 1.0876, 1.5212, 0.8334, 2.1287, 0.7229, 0.6036,
        1.4982, 2.1287, 1.2392, 0.8064, 0.9423, 1.1558, 1.3602, 1.0876, 1.8928,
        1.0620, 0.7957, 1.3602, 1.6232, 1.4150, 1.1558, 2.3766, 1.3961, 1.6813,
        1.7792, 1.4346, 0.6960, 0.7931, 0.7591, 0.7079, 0.8852, 1.0788, 0.8469,
        0.7144, 0.7906, 0.6094, 0.7388, 0.6095, 0.7881, 0.6886, 0.7957, 1.4346,
        0.7532, 0.7440, 0.6938, 0.7740, 0.6181, 0.6059, 0.7041, 1.3961, 0.6866,
        0.6906, 0.8271, 0.9217, 0.9768, 0.7552, 1.5451, 0.6440, 1.2957, 0.7931,
        0.7653, 0.8810, 0.9370, 1.3269, 1.7792, 0.6102, 0.6285, 0.8434, 0.9894,
        0.7881, 2.2446, 1.9792, 0.6303, 0.7857, 0.8271, 0.8064, 1.1779, 1.1558,
        0.6800, 0.7833, 0.7338, 0.6620, 0.8010, 0.6732, 0.7931, 0.6732, 1.2392,
        0.6279, 0.6033, 0.6886, 0.6171, 0.6091, 0.6847, 0.7354, 0.9478, 0.7983,
        1.6813, 1.0703, 0.7458, 0.6756, 0.6208, 0.6157, 0.7552, 0.6353, 1.1152,
        0.6135, 1.4150, 0.8504, 0.6154, 0.6200, 0.7591, 3.8258, 1.8151, 0.6748],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 178 247  66 114 329  80  50 127  33 177 538
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 356 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 306 144 129 136  71  73
 214 145 171 238 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 163 219 342 371 158 290  77 386  56 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3434, 0.6569, 1.1560, 1.2138, 0.9121, 0.8771, 0.6595, 0.7215, 0.6557,
        1.2394, 0.8811, 0.6238, 1.0877, 1.5214, 0.8335, 2.1290, 0.7230, 0.6037,
        1.4985, 2.1290, 1.2394, 0.8065, 0.9425, 1.1560, 1.3604, 1.0877, 1.8931,
        1.0622, 0.7984, 1.3604, 1.6234, 1.4152, 1.1560, 2.3769, 1.3963, 1.6815,
        1.7794, 1.4348, 0.6961, 0.7932, 0.7592, 0.7080, 0.8853, 1.0790, 0.8470,
        0.7145, 0.7907, 0.6095, 0.7389, 0.6095, 0.7882, 0.6887, 0.7958, 1.4348,
        0.7533, 0.7441, 0.6939, 0.7741, 0.6182, 0.6060, 0.7042, 1.3963, 0.6867,
        0.6907, 0.8272, 0.9218, 0.9770, 0.7553, 1.5453, 0.6441, 1.2959, 0.7932,
        0.7654, 0.8811, 0.9371, 1.3271, 1.7794, 0.6103, 0.6285, 0.8435, 0.9896,
        0.7882, 2.2449, 1.9795, 0.6300, 0.7858, 0.8272, 0.8065, 1.1781, 1.1560,
        0.6801, 0.7834, 0.7323, 0.6614, 0.8011, 0.6733, 0.7932, 0.6733, 1.2394,
        0.6280, 0.6034, 0.6897, 0.6172, 0.6092, 0.6848, 0.7355, 0.9479, 0.7984,
        1.6815, 1.0705, 0.7459, 0.6757, 0.6209, 0.6157, 0.7553, 0.6354, 1.1154,
        0.6136, 1.3963, 0.8505, 0.6154, 0.6201, 0.7592, 3.8263, 1.8154, 0.6749],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 177 247  66 114 329  80  50 127  34 177 538
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 356 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 306 144 129 137  71  73
 214 145 171 238 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 163 219 342 371 158 289  77 386  57 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3442, 0.6573, 1.1566, 1.2144, 0.9127, 0.8776, 0.6598, 0.7234, 0.6561,
        1.2401, 0.8816, 0.6242, 1.0884, 1.5223, 0.8340, 2.0774, 0.7234, 0.6040,
        1.4993, 2.1302, 1.2401, 0.8070, 0.9430, 1.1566, 1.3612, 1.0884, 1.8942,
        1.0628, 0.7989, 1.3612, 1.6243, 1.4160, 1.1566, 2.3783, 1.3971, 1.6825,
        1.7805, 1.4356, 0.6965, 0.7937, 0.7597, 0.7084, 0.8858, 1.0796, 0.8475,
        0.7149, 0.7912, 0.6098, 0.7393, 0.6099, 0.7887, 0.6891, 0.7963, 1.4356,
        0.7538, 0.7445, 0.6943, 0.7745, 0.6186, 0.6063, 0.7046, 1.3971, 0.6871,
        0.6911, 0.8276, 0.9224, 0.9775, 0.7557, 1.5462, 0.6444, 1.2966, 0.7937,
        0.7659, 0.8816, 0.9377, 1.3278, 1.7805, 0.6106, 0.6289, 0.8440, 0.9901,
        0.7887, 2.2462, 1.9806, 0.6304, 0.7862, 0.8276, 0.8043, 1.1787, 1.1566,
        0.6805, 0.7838, 0.7327, 0.6618, 0.8015, 0.6736, 0.7937, 0.6736, 1.2401,
        0.6283, 0.6038, 0.6901, 0.6175, 0.6095, 0.6851, 0.7359, 0.9485, 0.7989,
        1.6825, 1.0711, 0.7463, 0.6761, 0.6213, 0.6161, 0.7557, 0.6361, 1.1160,
        0.6140, 1.3788, 0.8510, 0.6158, 0.6205, 0.7597, 3.8285, 1.8164, 0.6753],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 177 247  66 114 329  80  50 127  34 177 538
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  54
 159 164 200 149 356 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 306 144 129 137  71  73
 214 145 171 238 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 163 219 342 371 158 289  77 386  57 122 373 346 156  17  40 220]
CBFL per class weights: tensor([1.3442, 0.6573, 1.1566, 1.2144, 0.9127, 0.8776, 0.6598, 0.7234, 0.6561,
        1.2401, 0.8816, 0.6242, 1.0884, 1.5223, 0.8340, 2.0774, 0.7234, 0.6040,
        1.4993, 2.1302, 1.2401, 0.8070, 0.9430, 1.1566, 1.3612, 1.0884, 1.8942,
        1.0628, 0.7989, 1.3612, 1.6243, 1.4160, 1.1566, 2.3783, 1.3971, 1.6825,
        1.7805, 1.4356, 0.6965, 0.7937, 0.7597, 0.7084, 0.8858, 1.0796, 0.8475,
        0.7149, 0.7912, 0.6098, 0.7393, 0.6099, 0.7887, 0.6891, 0.7963, 1.4356,
        0.7538, 0.7445, 0.6943, 0.7745, 0.6186, 0.6063, 0.7046, 1.3971, 0.6871,
        0.6911, 0.8276, 0.9224, 0.9775, 0.7557, 1.5462, 0.6444, 1.2966, 0.7937,
        0.7659, 0.8816, 0.9377, 1.3278, 1.7805, 0.6106, 0.6289, 0.8440, 0.9901,
        0.7887, 2.2462, 1.9806, 0.6304, 0.7862, 0.8276, 0.8043, 1.1787, 1.1566,
        0.6805, 0.7838, 0.7327, 0.6618, 0.8015, 0.6736, 0.7937, 0.6736, 1.2401,
        0.6283, 0.6038, 0.6901, 0.6175, 0.6095, 0.6851, 0.7359, 0.9485, 0.7989,
        1.6825, 1.0711, 0.7463, 0.6761, 0.6213, 0.6161, 0.7557, 0.6361, 1.1160,
        0.6140, 1.3788, 0.8510, 0.6158, 0.6205, 0.7597, 3.8285, 1.8164, 0.6753],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 177 247  66 114 329  80  50 127  34 177 539
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  53
 159 164 200 149 356 477 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  93 143  31  36 306 144 129 137  71  73
 214 145 171 238 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  57 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3440, 0.6572, 1.1565, 1.2143, 0.9125, 0.8774, 0.6597, 0.7233, 0.6560,
        1.2399, 0.8815, 0.6241, 1.0882, 1.5221, 0.8339, 2.0771, 0.7233, 0.6039,
        1.4991, 2.1299, 1.2399, 0.8069, 0.9429, 1.1565, 1.3610, 1.0882, 1.8939,
        1.0626, 0.7988, 1.3610, 1.6241, 1.4158, 1.1565, 2.3779, 1.3968, 1.6822,
        1.7802, 1.4354, 0.6964, 0.7936, 0.7596, 0.7083, 0.8857, 1.0795, 0.8473,
        0.7148, 0.7910, 0.6097, 0.7392, 0.6098, 0.7886, 0.6890, 0.7962, 1.4558,
        0.7537, 0.7444, 0.6942, 0.7744, 0.6185, 0.6062, 0.7045, 1.3968, 0.6870,
        0.6910, 0.8275, 0.9222, 0.9774, 0.7556, 1.5460, 0.6444, 1.2964, 0.7936,
        0.7657, 0.8815, 0.9375, 1.3276, 1.7802, 0.6105, 0.6288, 0.8439, 0.9900,
        0.7886, 2.2458, 1.9803, 0.6303, 0.7861, 0.8275, 0.8041, 1.1786, 1.1565,
        0.6804, 0.7837, 0.7326, 0.6617, 0.8014, 0.6735, 0.7936, 0.6735, 1.2399,
        0.6282, 0.6037, 0.6900, 0.6174, 0.6095, 0.6850, 0.7358, 0.9483, 0.7988,
        1.6822, 1.0709, 0.7444, 0.6760, 0.6212, 0.6160, 0.7556, 0.6360, 1.1159,
        0.6139, 1.3786, 0.8509, 0.6156, 0.6204, 0.7596, 3.8279, 1.8162, 0.6752],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 241 177 247  66 114 329  80  50 127  34 177 539
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 425 167 424 143 205 140  53
 159 164 200 149 356 478 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  73
 214 145 171 238 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  57 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3440, 0.6572, 1.1564, 1.2142, 0.9125, 0.8774, 0.6597, 0.7233, 0.6560,
        1.2399, 0.8815, 0.6240, 1.0881, 1.5220, 0.8339, 2.0770, 0.7233, 0.6039,
        1.4990, 2.1298, 1.2399, 0.8068, 0.9428, 1.1564, 1.3609, 1.0881, 1.8938,
        1.0626, 0.7987, 1.3609, 1.6240, 1.4157, 1.1564, 2.3778, 1.3968, 1.6821,
        1.7801, 1.4353, 0.6964, 0.7935, 0.7595, 0.7082, 0.8856, 1.0794, 0.8473,
        0.7148, 0.7910, 0.6097, 0.7391, 0.6098, 0.7885, 0.6890, 0.7961, 1.4557,
        0.7536, 0.7444, 0.6942, 0.7744, 0.6184, 0.6061, 0.7045, 1.3968, 0.6870,
        0.6910, 0.8275, 0.9222, 0.9773, 0.7556, 1.5459, 0.6443, 1.2964, 0.7935,
        0.7657, 0.8815, 0.9375, 1.3275, 1.7801, 0.6105, 0.6288, 0.8438, 0.9964,
        0.7885, 2.2457, 1.9802, 0.6303, 0.7861, 0.8275, 0.8041, 1.1785, 1.1564,
        0.6804, 0.7837, 0.7325, 0.6617, 0.8014, 0.6735, 0.7935, 0.6735, 1.2399,
        0.6282, 0.6036, 0.6900, 0.6174, 0.6094, 0.6850, 0.7358, 0.9483, 0.7987,
        1.6821, 1.0709, 0.7444, 0.6760, 0.6211, 0.6160, 0.7556, 0.6360, 1.1158,
        0.6139, 1.3785, 0.8508, 0.6155, 0.6203, 0.7595, 3.8277, 1.8161, 0.6752],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  34 177 539
  51  33  66 136 101  73  58  80  38  83 139  58  46  55  73  29  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 424 143 205 140  53
 158 164 200 149 356 478 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  73
 214 145 171 237 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  59 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3443, 0.6574, 1.1567, 1.2145, 0.9127, 0.8776, 0.6605, 0.7235, 0.6561,
        1.2402, 0.8817, 0.6242, 1.0884, 1.5224, 0.8341, 2.0775, 0.7235, 0.6040,
        1.4994, 2.1303, 1.2402, 0.8070, 0.9431, 1.1567, 1.3613, 1.0884, 1.8943,
        1.0628, 0.7989, 1.3613, 1.6244, 1.4161, 1.1567, 2.3784, 1.3971, 1.6825,
        1.7805, 1.4357, 0.6965, 0.7937, 0.7597, 0.7084, 0.8859, 1.0797, 0.8475,
        0.7150, 0.7912, 0.6097, 0.7393, 0.6099, 0.7887, 0.6891, 0.7963, 1.4561,
        0.7558, 0.7446, 0.6943, 0.7746, 0.6186, 0.6063, 0.7047, 1.3971, 0.6871,
        0.6912, 0.8277, 0.9224, 0.9776, 0.7558, 1.5463, 0.6445, 1.2967, 0.7937,
        0.7659, 0.8817, 0.9377, 1.3279, 1.7805, 0.6107, 0.6289, 0.8441, 0.9967,
        0.7887, 2.2463, 1.9807, 0.6304, 0.7863, 0.8277, 0.8043, 1.1788, 1.1567,
        0.6805, 0.7839, 0.7327, 0.6625, 0.8016, 0.6737, 0.7937, 0.6737, 1.2402,
        0.6284, 0.6038, 0.6901, 0.6176, 0.6096, 0.6852, 0.7360, 0.9485, 0.7989,
        1.6825, 1.0711, 0.7446, 0.6762, 0.6213, 0.6161, 0.7558, 0.6362, 1.1161,
        0.6140, 1.3443, 0.8510, 0.6157, 0.6205, 0.7597, 3.8287, 1.8165, 0.6753],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  34 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 424 143 205 140  53
 158 164 200 149 356 478 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  73
 214 145 171 237 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  59 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3449, 0.6577, 1.1573, 1.2151, 0.9131, 0.8780, 0.6608, 0.7238, 0.6564,
        1.2408, 0.8821, 0.6245, 1.0889, 1.5231, 0.8345, 2.0785, 0.7238, 0.6043,
        1.5001, 2.1313, 1.2408, 0.8074, 0.9435, 1.1573, 1.3619, 1.0889, 1.8952,
        1.0717, 0.7993, 1.3619, 1.6252, 1.4167, 1.1573, 2.3112, 1.3978, 1.6833,
        1.7814, 1.4364, 0.6969, 0.7941, 0.7601, 0.7087, 0.8863, 1.0802, 0.8479,
        0.7153, 0.7916, 0.6100, 0.7397, 0.6102, 0.7891, 0.6895, 0.7967, 1.4568,
        0.7561, 0.7449, 0.6947, 0.7750, 0.6189, 0.6066, 0.7050, 1.3978, 0.6875,
        0.6915, 0.8281, 0.9228, 0.9781, 0.7561, 1.5470, 0.6448, 1.2973, 0.7941,
        0.7663, 0.8821, 0.9382, 1.3285, 1.7814, 0.6109, 0.6292, 0.8445, 0.9972,
        0.7891, 2.2473, 1.9817, 0.6307, 0.7866, 0.8281, 0.8047, 1.1794, 1.1573,
        0.6809, 0.7842, 0.7331, 0.6628, 0.8020, 0.6740, 0.7941, 0.6740, 1.2408,
        0.6287, 0.6041, 0.6905, 0.6179, 0.6099, 0.6855, 0.7363, 0.9490, 0.7993,
        1.6833, 1.0717, 0.7449, 0.6765, 0.6216, 0.6164, 0.7561, 0.6365, 1.1166,
        0.6143, 1.3449, 0.8514, 0.6160, 0.6208, 0.7601, 3.8305, 1.8174, 0.6756],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 424 143 205 140  53
 158 164 200 149 356 478 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  73
 214 145 171 237 138 222 141 222  66 313 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  59 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3455, 0.6579, 1.1577, 1.2156, 0.9135, 0.8784, 0.6611, 0.7241, 0.6567,
        1.2413, 0.8825, 0.6247, 1.0894, 1.5237, 0.8348, 2.0295, 0.7241, 0.6045,
        1.5007, 2.1322, 1.2413, 0.8077, 0.9439, 1.1577, 1.3625, 1.0894, 1.8959,
        1.0721, 0.7996, 1.3625, 1.6258, 1.4173, 1.1577, 2.3121, 1.3983, 1.6840,
        1.7821, 1.4370, 0.6971, 0.7944, 0.7604, 0.7090, 0.8866, 1.0806, 0.8483,
        0.7156, 0.7919, 0.6103, 0.7400, 0.6105, 0.7894, 0.6897, 0.7970, 1.4574,
        0.7564, 0.7452, 0.6950, 0.7753, 0.6191, 0.6068, 0.7053, 1.3983, 0.6877,
        0.6918, 0.8284, 0.9232, 0.9784, 0.7564, 1.5476, 0.6450, 1.2978, 0.7944,
        0.7666, 0.8825, 0.9385, 1.3290, 1.7821, 0.6112, 0.6295, 0.8448, 0.9976,
        0.7894, 2.2482, 1.9824, 0.6310, 0.7869, 0.8284, 0.8050, 1.1798, 1.1577,
        0.6811, 0.7845, 0.7333, 0.6631, 0.8023, 0.6743, 0.7944, 0.6743, 1.2413,
        0.6289, 0.6043, 0.6907, 0.6181, 0.6101, 0.6858, 0.7366, 0.9493, 0.7996,
        1.6840, 1.0721, 0.7452, 0.6768, 0.6218, 0.6167, 0.7564, 0.6367, 1.1171,
        0.6145, 1.3455, 0.8518, 0.6162, 0.6210, 0.7604, 3.8320, 1.8181, 0.6759],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 424 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  49 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  73
 214 145 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  61 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3458, 0.6581, 1.1580, 1.2159, 0.9137, 0.8786, 0.6613, 0.7243, 0.6569,
        1.2416, 0.8827, 0.6249, 1.0896, 1.5241, 0.8350, 2.0300, 0.7243, 0.6047,
        1.5011, 2.1327, 1.2416, 0.8079, 0.9441, 1.1580, 1.3628, 1.0896, 1.8964,
        1.0723, 0.7998, 1.3628, 1.6262, 1.4176, 1.1580, 2.3127, 1.3987, 1.6844,
        1.7825, 1.4373, 0.6973, 0.7946, 0.7606, 0.7092, 0.8868, 1.0809, 0.8485,
        0.7158, 0.7921, 0.6104, 0.7402, 0.6106, 0.7896, 0.6899, 0.7972, 1.4577,
        0.7586, 0.7454, 0.6951, 0.7755, 0.6193, 0.6070, 0.7055, 1.3987, 0.6879,
        0.6919, 0.8286, 0.9234, 0.9787, 0.7566, 1.5480, 0.6452, 1.2981, 0.7946,
        0.7667, 0.8827, 0.9388, 1.3294, 1.7825, 0.6113, 0.6296, 0.8450, 0.9978,
        0.7896, 2.2488, 1.9829, 0.6311, 0.7871, 0.8286, 0.8052, 1.1801, 1.1580,
        0.6813, 0.7847, 0.7335, 0.6633, 0.8025, 0.6744, 0.7946, 0.6744, 1.2416,
        0.6288, 0.6045, 0.6909, 0.6183, 0.6103, 0.6859, 0.7368, 0.9496, 0.7998,
        1.6844, 1.0723, 0.7454, 0.6769, 0.6220, 0.6168, 0.7566, 0.6369, 1.1173,
        0.6147, 1.3135, 0.8520, 0.6164, 0.6212, 0.7606, 3.8330, 1.8186, 0.6761],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  62 141
 153 114 102  60  41 416 311 124  92 143  31  36 306 144 129 137  71  74
 214 145 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  61 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3462, 0.6583, 1.1583, 1.2162, 0.9140, 0.8788, 0.6614, 0.7245, 0.6570,
        1.2419, 0.8829, 0.6251, 1.0899, 1.5245, 0.8352, 2.0305, 0.7245, 0.6048,
        1.5015, 2.1333, 1.2419, 0.8082, 0.9444, 1.1583, 1.3632, 1.0899, 1.8969,
        1.0726, 0.8000, 1.3632, 1.6267, 1.4180, 1.1583, 2.3133, 1.3991, 1.6849,
        1.7830, 1.4377, 0.6975, 0.7948, 0.7608, 0.7094, 0.8871, 1.0812, 0.8487,
        0.7160, 0.7923, 0.6106, 0.7404, 0.6109, 0.7898, 0.6901, 0.7974, 1.4581,
        0.7588, 0.7456, 0.6953, 0.7757, 0.6195, 0.6071, 0.7056, 1.3991, 0.6881,
        0.6921, 0.8288, 0.9237, 0.9790, 0.7568, 1.5245, 0.6454, 1.2985, 0.7948,
        0.7670, 0.8829, 0.9390, 1.3297, 1.7830, 0.6115, 0.6298, 0.8452, 0.9981,
        0.7898, 2.2494, 1.9835, 0.6313, 0.7874, 0.8288, 0.8054, 1.1804, 1.1477,
        0.6815, 0.7849, 0.7337, 0.6634, 0.8027, 0.6746, 0.7948, 0.6746, 1.2419,
        0.6290, 0.6046, 0.6911, 0.6184, 0.6104, 0.6861, 0.7370, 0.9498, 0.8000,
        1.6849, 1.0726, 0.7456, 0.6771, 0.6222, 0.6170, 0.7568, 0.6370, 1.1176,
        0.6149, 1.3138, 0.8522, 0.6165, 0.6213, 0.7608, 3.8340, 1.8190, 0.6763],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 107 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  62 141
 153 114 102  59  41 416 311 124  92 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  44  82 164 219 342 371 158 289  77 386  61 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3461, 0.6582, 1.1583, 1.2162, 0.9139, 0.8788, 0.6614, 0.7244, 0.6570,
        1.2419, 0.8829, 0.6250, 1.0899, 1.5244, 0.8352, 2.0304, 0.7244, 0.6048,
        1.5014, 2.1332, 1.2419, 0.8081, 0.9443, 1.1583, 1.3631, 1.0899, 1.8968,
        1.0726, 0.8000, 1.3631, 1.6266, 1.4180, 1.1583, 2.3132, 1.3990, 1.6848,
        1.7829, 1.4376, 0.6975, 0.7948, 0.7607, 0.7094, 0.8871, 1.0811, 0.8487,
        0.7159, 0.7923, 0.6106, 0.7403, 0.6108, 0.7898, 0.6901, 0.7974, 1.4581,
        0.7587, 0.7456, 0.6953, 0.7756, 0.6194, 0.6071, 0.7056, 1.3990, 0.6881,
        0.6921, 0.8288, 0.9237, 0.9789, 0.7568, 1.5244, 0.6454, 1.2985, 0.7948,
        0.7669, 0.8829, 0.9390, 1.3461, 1.7829, 0.6115, 0.6298, 0.8452, 0.9980,
        0.7898, 2.2493, 1.9834, 0.6313, 0.7873, 0.8288, 0.8054, 1.1804, 1.1374,
        0.6824, 0.7825, 0.7337, 0.6634, 0.8027, 0.6746, 0.7948, 0.6746, 1.2419,
        0.6289, 0.6046, 0.6911, 0.6184, 0.6104, 0.6861, 0.7370, 0.9498, 0.8000,
        1.6848, 1.0726, 0.7456, 0.6771, 0.6221, 0.6170, 0.7568, 0.6370, 1.1176,
        0.6148, 1.3138, 0.8522, 0.6165, 0.6213, 0.7607, 3.8339, 1.8190, 0.6762],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  54 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  63 141
 153 114 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  45  82 164 219 342 371 158 289  77 386  61 122 374 346 156  17  40 220]
CBFL per class weights: tensor([1.3465, 0.6584, 1.1586, 1.2165, 0.9190, 0.8790, 0.6616, 0.7246, 0.6572,
        1.2422, 0.8831, 0.6252, 1.0902, 1.5248, 0.8354, 2.0310, 0.7246, 0.6050,
        1.5018, 2.1337, 1.2422, 0.8083, 0.9446, 1.1586, 1.3635, 1.0902, 1.8973,
        1.0729, 0.8002, 1.3635, 1.6270, 1.4183, 1.1586, 2.3138, 1.3994, 1.6853,
        1.7834, 1.4380, 0.6977, 0.7950, 0.7609, 0.7095, 0.8873, 1.0814, 0.8489,
        0.7161, 0.7925, 0.6107, 0.7405, 0.6110, 0.7900, 0.6902, 0.7976, 1.4585,
        0.7589, 0.7458, 0.6955, 0.7758, 0.6196, 0.6073, 0.7058, 1.3994, 0.6882,
        0.6923, 0.8290, 0.9239, 0.9792, 0.7570, 1.5248, 0.6455, 1.2839, 0.7950,
        0.7671, 0.8831, 0.9392, 1.3465, 1.7834, 0.6116, 0.6300, 0.8454, 1.0050,
        0.7900, 2.2499, 1.9839, 0.6314, 0.7875, 0.8290, 0.8056, 1.1807, 1.1377,
        0.6825, 0.7827, 0.7339, 0.6636, 0.8029, 0.6748, 0.7950, 0.6748, 1.2422,
        0.6291, 0.6048, 0.6913, 0.6186, 0.6106, 0.6863, 0.7372, 0.9500, 0.8002,
        1.6555, 1.0729, 0.7458, 0.6773, 0.6223, 0.6171, 0.7570, 0.6372, 1.1179,
        0.6150, 1.3141, 0.8524, 0.6167, 0.6215, 0.7609, 3.8349, 1.8195, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  63 141
 153 114 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  45  82 164 219 342 371 158 289  77 386  62 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3464, 0.6584, 1.1585, 1.2164, 0.9190, 0.8790, 0.6616, 0.7246, 0.6572,
        1.2422, 0.8831, 0.6252, 1.0901, 1.5248, 0.8354, 2.0309, 0.7246, 0.6050,
        1.5018, 2.1337, 1.2422, 0.8083, 0.9446, 1.1585, 1.3634, 1.0901, 1.8973,
        1.0728, 0.8002, 1.3634, 1.6270, 1.4183, 1.1585, 2.3138, 1.3993, 1.6852,
        1.7834, 1.4584, 0.6976, 0.7950, 0.7609, 0.7095, 0.8873, 1.0814, 0.8489,
        0.7161, 0.7925, 0.6107, 0.7405, 0.6110, 0.7900, 0.6902, 0.7976, 1.4584,
        0.7589, 0.7457, 0.6955, 0.7758, 0.6196, 0.6073, 0.7058, 1.3993, 0.6882,
        0.6923, 0.8290, 0.9239, 0.9791, 0.7570, 1.5248, 0.6455, 1.2839, 0.7950,
        0.7671, 0.8831, 0.9392, 1.3464, 1.7834, 0.6116, 0.6299, 0.8454, 1.0049,
        0.7900, 2.2499, 1.9839, 0.6314, 0.7875, 0.8290, 0.8056, 1.1807, 1.1376,
        0.6825, 0.7827, 0.7339, 0.6636, 0.8029, 0.6747, 0.7950, 0.6747, 1.2422,
        0.6291, 0.6048, 0.6912, 0.6185, 0.6105, 0.6863, 0.7371, 0.9500, 0.8002,
        1.6555, 1.0728, 0.7457, 0.6772, 0.6223, 0.6171, 0.7570, 0.6372, 1.1179,
        0.6150, 1.2988, 0.8524, 0.6167, 0.6215, 0.7589, 3.8348, 1.8194, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 157 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  63 141
 153 114 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  45  82 164 219 342 371 158 289  77 386  62 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3464, 0.6584, 1.1585, 1.2164, 0.9190, 0.8790, 0.6616, 0.7246, 0.6572,
        1.2422, 0.8831, 0.6252, 1.0901, 1.5248, 0.8354, 2.0309, 0.7246, 0.6050,
        1.5018, 2.1337, 1.2422, 0.8083, 0.9446, 1.1585, 1.3634, 1.0901, 1.8973,
        1.0728, 0.8002, 1.3634, 1.6270, 1.4183, 1.1585, 2.3138, 1.3993, 1.6852,
        1.7834, 1.4584, 0.6976, 0.7950, 0.7609, 0.7095, 0.8873, 1.0814, 0.8489,
        0.7161, 0.7925, 0.6107, 0.7405, 0.6110, 0.7900, 0.6902, 0.7976, 1.4584,
        0.7589, 0.7457, 0.6955, 0.7758, 0.6196, 0.6073, 0.7058, 1.3993, 0.6882,
        0.6923, 0.8290, 0.9239, 0.9791, 0.7570, 1.5248, 0.6455, 1.2839, 0.7950,
        0.7671, 0.8831, 0.9392, 1.3464, 1.7834, 0.6116, 0.6299, 0.8454, 1.0049,
        0.7900, 2.2499, 1.9839, 0.6314, 0.7875, 0.8290, 0.8056, 1.1807, 1.1376,
        0.6825, 0.7827, 0.7339, 0.6636, 0.8029, 0.6747, 0.7950, 0.6747, 1.2422,
        0.6291, 0.6048, 0.6912, 0.6185, 0.6105, 0.6863, 0.7371, 0.9500, 0.8002,
        1.6555, 1.0728, 0.7457, 0.6772, 0.6223, 0.6171, 0.7570, 0.6372, 1.1179,
        0.6150, 1.2988, 0.8524, 0.6167, 0.6215, 0.7589, 3.8348, 1.8194, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  35 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 156 164 200 149 356 478 191  56 207 203 129 105  95 158  50 269  63 141
 153 114 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 362 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  63 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3466, 0.6585, 1.1587, 1.2166, 0.9191, 0.8791, 0.6617, 0.7247, 0.6573,
        1.2424, 0.8832, 0.6253, 1.0903, 1.5250, 0.8355, 2.0313, 0.7247, 0.6051,
        1.5020, 2.1341, 1.2424, 0.8085, 0.9447, 1.1587, 1.3637, 1.0903, 1.8976,
        1.0730, 0.8003, 1.3637, 1.6273, 1.4185, 1.1587, 2.3142, 1.3996, 1.6855,
        1.7837, 1.4587, 0.6978, 0.7951, 0.7611, 0.7096, 0.8874, 1.0816, 0.8490,
        0.7162, 0.7926, 0.6108, 0.7406, 0.6111, 0.7901, 0.6903, 0.7977, 1.4587,
        0.7611, 0.7459, 0.6956, 0.7759, 0.6197, 0.6074, 0.7059, 1.3996, 0.6883,
        0.6924, 0.8291, 0.9240, 0.9793, 0.7571, 1.5250, 0.6456, 1.2841, 0.7951,
        0.7672, 0.8832, 0.9394, 1.3466, 1.7837, 0.6117, 0.6300, 0.8455, 1.0051,
        0.7901, 2.2502, 1.9842, 0.6315, 0.7876, 0.8291, 0.8057, 1.1809, 1.1378,
        0.6826, 0.7829, 0.7340, 0.6637, 0.8030, 0.6749, 0.7951, 0.6749, 1.2424,
        0.6292, 0.6049, 0.6914, 0.6186, 0.6107, 0.6864, 0.7373, 0.9502, 0.8003,
        1.6557, 1.0647, 0.7459, 0.6774, 0.6224, 0.6172, 0.7571, 0.6373, 1.1180,
        0.6151, 1.2841, 0.8525, 0.6168, 0.6216, 0.7591, 3.8354, 1.8197, 0.6765],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 426 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  50 269  63 141
 153 114 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 171 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3473, 0.6588, 1.1593, 1.2172, 0.9196, 0.8796, 0.6620, 0.7251, 0.6576,
        1.2430, 0.8837, 0.6256, 1.0909, 1.5258, 0.8359, 1.9852, 0.7251, 0.6054,
        1.5028, 2.1351, 1.2430, 0.8089, 0.9452, 1.1593, 1.3643, 1.0909, 1.8985,
        1.0736, 0.8007, 1.3643, 1.6281, 1.4192, 1.1593, 2.3153, 1.4003, 1.6863,
        1.7845, 1.4594, 0.6981, 0.7955, 0.7614, 0.7100, 0.8879, 1.0821, 0.8494,
        0.7166, 0.7930, 0.6111, 0.7410, 0.6114, 0.7905, 0.6907, 0.7981, 1.4594,
        0.7614, 0.7462, 0.6959, 0.7763, 0.6202, 0.6077, 0.7063, 1.4003, 0.6887,
        0.6927, 0.8295, 0.9245, 0.9798, 0.7575, 1.5258, 0.6459, 1.2848, 0.7955,
        0.7676, 0.8837, 0.9398, 1.3473, 1.7845, 0.6120, 0.6303, 0.8460, 1.0056,
        0.7905, 2.2513, 1.9852, 0.6318, 0.7880, 0.8295, 0.8061, 1.1815, 1.1384,
        0.6830, 0.7832, 0.7344, 0.6640, 0.8034, 0.6752, 0.7955, 0.6752, 1.2430,
        0.6295, 0.6052, 0.6917, 0.6188, 0.6109, 0.6867, 0.7376, 0.9506, 0.8007,
        1.6565, 1.0652, 0.7462, 0.6777, 0.6227, 0.6175, 0.7575, 0.6376, 1.1186,
        0.6154, 1.2704, 0.8529, 0.6171, 0.6219, 0.7594, 3.8373, 1.8206, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  50 269  63 141
 153 113 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3473, 0.6588, 1.1593, 1.2172, 0.9195, 0.8796, 0.6620, 0.7251, 0.6576,
        1.2429, 0.8837, 0.6256, 1.0908, 1.5257, 0.8359, 1.9851, 0.7251, 0.6053,
        1.5027, 2.1351, 1.2429, 0.8088, 0.9452, 1.1593, 1.3643, 1.0908, 1.8985,
        1.0735, 0.8007, 1.3643, 1.6280, 1.4192, 1.1593, 2.3153, 1.4002, 1.6863,
        1.7845, 1.4594, 0.6981, 0.7955, 0.7614, 0.7100, 0.8878, 1.0821, 0.8494,
        0.7166, 0.7930, 0.6110, 0.7410, 0.6114, 0.7905, 0.6907, 0.7981, 1.4594,
        0.7614, 0.7462, 0.6959, 0.7763, 0.6202, 0.6077, 0.7062, 1.4002, 0.6887,
        0.6927, 0.8295, 0.9245, 0.9798, 0.7574, 1.5257, 0.6459, 1.2847, 0.7955,
        0.7676, 0.8878, 0.9398, 1.3473, 1.7845, 0.6120, 0.6303, 0.8459, 1.0056,
        0.7905, 2.2513, 1.9851, 0.6318, 0.7880, 0.8295, 0.8061, 1.1814, 1.1384,
        0.6830, 0.7832, 0.7327, 0.6640, 0.8034, 0.6752, 0.7955, 0.6752, 1.2429,
        0.6295, 0.6051, 0.6917, 0.6188, 0.6109, 0.6867, 0.7376, 0.9506, 0.8007,
        1.6565, 1.0652, 0.7462, 0.6777, 0.6227, 0.6175, 0.7574, 0.6376, 1.1186,
        0.6154, 1.2704, 0.8529, 0.6170, 0.6219, 0.7594, 3.8372, 1.8206, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  50 269  63 141
 153 113 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  75
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3473, 0.6588, 1.1593, 1.2172, 0.9195, 0.8796, 0.6620, 0.7251, 0.6576,
        1.2429, 0.8837, 0.6256, 1.0908, 1.5257, 0.8359, 1.9851, 0.7251, 0.6053,
        1.5027, 2.1351, 1.2429, 0.8088, 0.9452, 1.1593, 1.3643, 1.0908, 1.8985,
        1.0735, 0.8007, 1.3643, 1.6280, 1.4192, 1.1593, 2.3153, 1.4002, 1.6863,
        1.7845, 1.4594, 0.6981, 0.7955, 0.7614, 0.7100, 0.8878, 1.0821, 0.8494,
        0.7166, 0.7930, 0.6110, 0.7410, 0.6114, 0.7905, 0.6907, 0.7981, 1.4594,
        0.7614, 0.7462, 0.6959, 0.7763, 0.6202, 0.6077, 0.7062, 1.4002, 0.6887,
        0.6927, 0.8295, 0.9245, 0.9798, 0.7574, 1.5257, 0.6459, 1.2847, 0.7955,
        0.7676, 0.8878, 0.9398, 1.3473, 1.7845, 0.6120, 0.6303, 0.8459, 1.0056,
        0.7905, 2.2513, 1.9851, 0.6318, 0.7880, 0.8295, 0.8061, 1.1814, 1.1384,
        0.6830, 0.7832, 0.7327, 0.6640, 0.8034, 0.6752, 0.7955, 0.6752, 1.2429,
        0.6295, 0.6051, 0.6917, 0.6188, 0.6109, 0.6867, 0.7376, 0.9506, 0.8007,
        1.6565, 1.0652, 0.7462, 0.6777, 0.6227, 0.6175, 0.7574, 0.6376, 1.1186,
        0.6154, 1.2704, 0.8529, 0.6170, 0.6219, 0.7594, 3.8372, 1.8206, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  50 269  63 141
 153 113 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  76
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3474, 0.6589, 1.1594, 1.2173, 0.9196, 0.8796, 0.6620, 0.7251, 0.6576,
        1.2430, 0.8837, 0.6256, 1.0909, 1.5259, 0.8360, 1.9853, 0.7251, 0.6054,
        1.5028, 2.1352, 1.2430, 0.8089, 0.9452, 1.1594, 1.3644, 1.0909, 1.8986,
        1.0736, 0.8008, 1.3644, 1.6282, 1.4193, 1.1594, 2.3154, 1.4003, 1.6864,
        1.7846, 1.4595, 0.6981, 0.7956, 0.7615, 0.7100, 0.8879, 1.0822, 0.8495,
        0.7166, 0.7930, 0.6111, 0.7410, 0.6114, 0.7905, 0.6907, 0.7981, 1.4595,
        0.7615, 0.7463, 0.6960, 0.7764, 0.6202, 0.6077, 0.7063, 1.4003, 0.6887,
        0.6928, 0.8296, 0.9245, 0.9798, 0.7575, 1.5259, 0.6460, 1.2848, 0.7956,
        0.7677, 0.8879, 0.9399, 1.3474, 1.7846, 0.6121, 0.6304, 0.8460, 1.0057,
        0.7905, 2.2515, 1.9853, 0.6319, 0.7881, 0.8296, 0.8061, 1.1815, 1.1284,
        0.6830, 0.7833, 0.7328, 0.6640, 0.8034, 0.6752, 0.7956, 0.6752, 1.2430,
        0.6295, 0.6052, 0.6917, 0.6188, 0.6110, 0.6868, 0.7377, 0.9507, 0.8008,
        1.6566, 1.0653, 0.7463, 0.6777, 0.6227, 0.6175, 0.7575, 0.6376, 1.1187,
        0.6154, 1.2705, 0.8530, 0.6171, 0.6219, 0.7595, 3.8375, 1.8207, 0.6769],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 539
  51  33  66 136 101  73  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  50 269  63 141
 153 113 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  76
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3474, 0.6589, 1.1594, 1.2173, 0.9196, 0.8796, 0.6620, 0.7251, 0.6576,
        1.2430, 0.8837, 0.6256, 1.0909, 1.5259, 0.8360, 1.9853, 0.7251, 0.6054,
        1.5028, 2.1352, 1.2430, 0.8089, 0.9452, 1.1594, 1.3644, 1.0909, 1.8986,
        1.0736, 0.8008, 1.3644, 1.6282, 1.4193, 1.1594, 2.3154, 1.4003, 1.6864,
        1.7846, 1.4595, 0.6981, 0.7956, 0.7615, 0.7100, 0.8879, 1.0822, 0.8495,
        0.7166, 0.7930, 0.6111, 0.7410, 0.6114, 0.7905, 0.6907, 0.7981, 1.4595,
        0.7615, 0.7463, 0.6960, 0.7764, 0.6202, 0.6077, 0.7063, 1.4003, 0.6887,
        0.6928, 0.8296, 0.9245, 0.9798, 0.7575, 1.5259, 0.6460, 1.2848, 0.7956,
        0.7677, 0.8879, 0.9399, 1.3474, 1.7846, 0.6121, 0.6304, 0.8460, 1.0057,
        0.7905, 2.2515, 1.9853, 0.6319, 0.7881, 0.8296, 0.8061, 1.1815, 1.1284,
        0.6830, 0.7833, 0.7328, 0.6640, 0.8034, 0.6752, 0.7956, 0.6752, 1.2430,
        0.6295, 0.6052, 0.6917, 0.6188, 0.6110, 0.6868, 0.7377, 0.9507, 0.8008,
        1.6566, 1.0653, 0.7463, 0.6777, 0.6227, 0.6175, 0.7575, 0.6376, 1.1187,
        0.6154, 1.2705, 0.8530, 0.6171, 0.6219, 0.7595, 3.8375, 1.8207, 0.6769],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 200 149 355 477 191  56 207 203 129 105  95 158  51 269  63 141
 153 113 102  59  41 416 311 124  91 143  31  36 306 144 129 137  71  76
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3477, 0.6590, 1.1597, 1.2176, 0.9199, 0.8799, 0.6622, 0.7253, 0.6578,
        1.2434, 0.8840, 0.6258, 1.0912, 1.5263, 0.8362, 1.9858, 0.7253, 0.6056,
        1.5032, 2.1358, 1.2434, 0.8091, 0.9455, 1.1491, 1.3648, 1.0912, 1.8991,
        1.0739, 0.8010, 1.3648, 1.6286, 1.4197, 1.1597, 2.3161, 1.4007, 1.6869,
        1.7851, 1.4599, 0.6983, 0.7958, 0.7617, 0.7102, 0.8881, 1.0824, 0.8497,
        0.7168, 0.7932, 0.6112, 0.7412, 0.6116, 0.7907, 0.6909, 0.7984, 1.4599,
        0.7617, 0.7465, 0.6961, 0.7766, 0.6204, 0.6079, 0.7065, 1.4007, 0.6889,
        0.6930, 0.8298, 0.9248, 0.9801, 0.7577, 1.5032, 0.6461, 1.2852, 0.7958,
        0.7679, 0.8881, 0.9401, 1.3477, 1.7851, 0.6122, 0.6306, 0.8462, 1.0059,
        0.7907, 2.2521, 1.9858, 0.6321, 0.7883, 0.8298, 0.8064, 1.1818, 1.1287,
        0.6832, 0.7835, 0.7330, 0.6642, 0.8037, 0.6754, 0.7958, 0.6754, 1.2434,
        0.6297, 0.6053, 0.6919, 0.6190, 0.6111, 0.6869, 0.7379, 0.9509, 0.8010,
        1.6571, 1.0656, 0.7465, 0.6779, 0.6229, 0.6177, 0.7577, 0.6378, 1.1190,
        0.6156, 1.2708, 0.8532, 0.6173, 0.6221, 0.7597, 3.8385, 1.8212, 0.6771],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  58  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 199 149 355 477 191  56 207 204 129 105  95 158  51 269  63 141
 153 113 102  60  41 416 311 124  91 143  31  36 306 144 129 137  71  76
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3479, 0.6591, 1.1598, 1.2178, 0.9200, 0.8800, 0.6623, 0.7254, 0.6579,
        1.2435, 0.8841, 0.6259, 1.0914, 1.5265, 0.8363, 1.9861, 0.7254, 0.6057,
        1.5034, 2.1361, 1.2435, 0.8092, 0.9456, 1.1492, 1.3650, 1.0914, 1.8994,
        1.0740, 0.8011, 1.3650, 1.6288, 1.4199, 1.1598, 2.3164, 1.4009, 1.6871,
        1.7854, 1.4601, 0.6984, 0.7959, 0.7618, 0.7103, 0.8883, 1.0826, 0.8498,
        0.7169, 0.7933, 0.6113, 0.7413, 0.6117, 0.7908, 0.6910, 0.7985, 1.4601,
        0.7618, 0.7466, 0.6973, 0.7767, 0.6205, 0.6080, 0.7066, 1.4009, 0.6890,
        0.6920, 0.8299, 0.9249, 0.9802, 0.7578, 1.5034, 0.6462, 1.2853, 0.7959,
        0.7680, 0.8883, 0.9403, 1.3315, 1.7854, 0.6123, 0.6306, 0.8463, 1.0061,
        0.7908, 2.2524, 1.9861, 0.6321, 0.7884, 0.8299, 0.8065, 1.1820, 1.1289,
        0.6833, 0.7836, 0.7331, 0.6643, 0.8038, 0.6755, 0.7959, 0.6755, 1.2435,
        0.6298, 0.6054, 0.6920, 0.6191, 0.6112, 0.6870, 0.7380, 0.9511, 0.8011,
        1.6573, 1.0657, 0.7466, 0.6780, 0.6230, 0.6178, 0.7578, 0.6379, 1.1191,
        0.6157, 1.2710, 0.8533, 0.6173, 0.6222, 0.7598, 3.8390, 1.8214, 0.6772],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  59  46  55  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 199 149 355 477 191  56 207 204 129 105  95 158  51 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  36 306 144 129 137  71  76
 213 146 172 237 138 222 141 222  66 314 547 204 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3480, 0.6592, 1.1599, 1.2179, 0.9201, 0.8801, 0.6624, 0.7255, 0.6580,
        1.2437, 0.8842, 0.6259, 1.0915, 1.5266, 0.8364, 1.9863, 0.7255, 0.6057,
        1.5036, 2.1363, 1.2437, 0.8093, 0.9457, 1.1493, 1.3651, 1.0915, 1.8996,
        1.0741, 0.8012, 1.3480, 1.6290, 1.4200, 1.1599, 2.3166, 1.4010, 1.6872,
        1.7855, 1.4602, 0.6985, 0.7960, 0.7618, 0.7104, 0.8883, 1.0827, 0.8499,
        0.7170, 0.7934, 0.6114, 0.7414, 0.6117, 0.7909, 0.6911, 0.7985, 1.4602,
        0.7618, 0.7466, 0.6974, 0.7768, 0.6205, 0.6080, 0.7066, 1.4010, 0.6891,
        0.6921, 0.8300, 0.9250, 0.9803, 0.7579, 1.5036, 0.6463, 1.2855, 0.7960,
        0.7680, 0.8883, 0.9457, 1.3316, 1.7855, 0.6124, 0.6307, 0.8464, 1.0062,
        0.7909, 2.2526, 1.9863, 0.6322, 0.7885, 0.8300, 0.8065, 1.1821, 1.1290,
        0.6833, 0.7837, 0.7332, 0.6644, 0.8038, 0.6756, 0.7960, 0.6756, 1.2437,
        0.6298, 0.6055, 0.6921, 0.6191, 0.6113, 0.6871, 0.7380, 0.9512, 0.8012,
        1.6574, 1.0658, 0.7466, 0.6781, 0.6230, 0.6178, 0.7579, 0.6379, 1.1192,
        0.6157, 1.2711, 0.8534, 0.6174, 0.6222, 0.7598, 3.8394, 1.8216, 0.6772],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 423 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  51 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  37 305 144 129 137  71  76
 214 146 172 237 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  83 164 219 342 371 158 289  77 386  64 122 374 346 157  17  40 220]
CBFL per class weights: tensor([1.3483, 0.6593, 1.1602, 1.2182, 0.9203, 0.8802, 0.6625, 0.7256, 0.6581,
        1.2439, 0.8843, 0.6261, 1.0917, 1.5269, 0.8366, 1.9867, 0.7256, 0.6059,
        1.5039, 2.1367, 1.2439, 0.8095, 0.9459, 1.1496, 1.3654, 1.0917, 1.9000,
        1.0744, 0.8013, 1.3483, 1.6293, 1.4400, 1.1602, 2.3171, 1.4013, 1.6876,
        1.7859, 1.4605, 0.6986, 0.7961, 0.7620, 0.7105, 0.8885, 1.0829, 0.8501,
        0.7171, 0.7936, 0.6115, 0.7416, 0.6119, 0.7911, 0.6912, 0.7987, 1.4605,
        0.7620, 0.7468, 0.6975, 0.7769, 0.6206, 0.6082, 0.7068, 1.4013, 0.6882,
        0.6922, 0.8302, 0.9252, 0.9805, 0.7580, 1.5039, 0.6464, 1.2857, 0.7961,
        0.7682, 0.8885, 0.9459, 1.3319, 1.7859, 0.6125, 0.6308, 0.8466, 1.0064,
        0.7911, 2.2531, 1.9421, 0.6326, 0.7886, 0.8302, 0.8067, 1.1824, 1.1292,
        0.6826, 0.7838, 0.7333, 0.6645, 0.8040, 0.6757, 0.7961, 0.6757, 1.2439,
        0.6300, 0.6056, 0.6912, 0.6193, 0.6114, 0.6872, 0.7382, 0.9514, 0.8013,
        1.6578, 1.0660, 0.7468, 0.6782, 0.6232, 0.6180, 0.7580, 0.6381, 1.1194,
        0.6159, 1.2714, 0.8536, 0.6175, 0.6224, 0.7600, 3.8402, 1.8220, 0.6774],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 156 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  37 305 144 129 137  71  76
 214 146 172 237 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 386  65 122 374 346 157  17  40 221]
CBFL per class weights: tensor([1.3488, 0.6596, 1.1606, 1.2186, 0.9206, 0.8806, 0.6628, 0.7259, 0.6583,
        1.2444, 0.8847, 0.6263, 1.0921, 1.5275, 0.8369, 1.9874, 0.7259, 0.6061,
        1.5044, 2.1375, 1.2444, 0.8098, 0.9462, 1.1500, 1.3659, 1.0921, 1.9006,
        1.0748, 0.8016, 1.3488, 1.6299, 1.4405, 1.1606, 2.3179, 1.4018, 1.6882,
        1.7865, 1.4610, 0.6989, 0.7964, 0.7623, 0.7108, 0.8888, 1.0833, 0.8504,
        0.7174, 0.7939, 0.6117, 0.7418, 0.6122, 0.7914, 0.6914, 0.7990, 1.4610,
        0.7623, 0.7471, 0.6978, 0.7772, 0.6209, 0.6084, 0.7070, 1.4018, 0.6885,
        0.6925, 0.8305, 0.9255, 0.9809, 0.7583, 1.4823, 0.6467, 1.2862, 0.7964,
        0.7685, 0.8888, 0.9462, 1.3324, 1.7865, 0.6127, 0.6311, 0.8469, 1.0067,
        0.7914, 2.2539, 1.9428, 0.6329, 0.7889, 0.8305, 0.8070, 1.1828, 1.1296,
        0.6828, 0.7841, 0.7336, 0.6648, 0.8043, 0.6759, 0.7964, 0.6759, 1.2444,
        0.6302, 0.6058, 0.6914, 0.6195, 0.6116, 0.6875, 0.7385, 0.9517, 0.8016,
        1.6584, 1.0583, 0.7471, 0.6784, 0.6234, 0.6182, 0.7583, 0.6383, 1.1198,
        0.6161, 1.2579, 0.8539, 0.6178, 0.6226, 0.7603, 3.8416, 1.8227, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  74  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  38 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3493, 0.6598, 1.1610, 1.2190, 0.9209, 0.8809, 0.6630, 0.7261, 0.6586,
        1.2448, 0.8850, 0.6265, 1.0925, 1.5280, 0.8372, 1.9881, 0.7261, 0.6063,
        1.5050, 2.1382, 1.2448, 0.8100, 0.9466, 1.1504, 1.3663, 1.0925, 1.9013,
        1.0751, 0.8019, 1.3493, 1.6304, 1.4410, 1.1610, 2.3187, 1.4023, 1.6888,
        1.7872, 1.4615, 0.6991, 0.7967, 0.7646, 0.7110, 0.8891, 1.0837, 0.8507,
        0.7176, 0.7941, 0.6119, 0.7421, 0.6124, 0.7916, 0.6917, 0.7993, 1.4615,
        0.7625, 0.7473, 0.6980, 0.7775, 0.6211, 0.6086, 0.7073, 1.4023, 0.6887,
        0.6927, 0.8308, 0.9258, 0.9812, 0.7586, 1.4828, 0.6469, 1.2866, 0.7967,
        0.7687, 0.8891, 0.9466, 1.3328, 1.7872, 0.6129, 0.6313, 0.8472, 1.0071,
        0.7916, 2.2546, 1.9013, 0.6331, 0.7868, 0.8308, 0.8073, 1.1832, 1.1300,
        0.6831, 0.7844, 0.7338, 0.6657, 0.8046, 0.6762, 0.7967, 0.6762, 1.2448,
        0.6304, 0.6060, 0.6917, 0.6197, 0.6118, 0.6877, 0.7387, 0.9520, 0.8019,
        1.6590, 1.0587, 0.7473, 0.6787, 0.6236, 0.6184, 0.7586, 0.6385, 1.1202,
        0.6164, 1.2583, 0.8542, 0.6180, 0.6228, 0.7605, 3.8429, 1.8233, 0.6762],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  38 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3494, 0.6598, 1.1611, 1.2191, 0.9210, 0.8809, 0.6630, 0.7262, 0.6586,
        1.2449, 0.8850, 0.6266, 1.0925, 1.5281, 0.8372, 1.9882, 0.7262, 0.6063,
        1.5051, 2.1384, 1.2449, 0.8101, 0.9466, 1.1401, 1.3664, 1.0925, 1.9014,
        1.0752, 0.8020, 1.3494, 1.6306, 1.4412, 1.1611, 2.3189, 1.4024, 1.6889,
        1.7873, 1.4616, 0.6992, 0.7967, 0.7646, 0.7111, 0.8892, 1.0838, 0.8507,
        0.7177, 0.7942, 0.6120, 0.7421, 0.6124, 0.7917, 0.6917, 0.7993, 1.4616,
        0.7626, 0.7474, 0.6981, 0.7775, 0.6211, 0.6086, 0.7073, 1.4024, 0.6888,
        0.6928, 0.8308, 0.9259, 0.9813, 0.7586, 1.4829, 0.6469, 1.2867, 0.7967,
        0.7688, 0.8892, 0.9466, 1.3329, 1.7873, 0.6130, 0.6313, 0.8473, 1.0072,
        0.7917, 2.2548, 1.9014, 0.6331, 0.7868, 0.8308, 0.8073, 1.1833, 1.1301,
        0.6831, 0.7844, 0.7339, 0.6657, 0.8046, 0.6762, 0.7967, 0.6762, 1.2449,
        0.6305, 0.6061, 0.6917, 0.6197, 0.6119, 0.6878, 0.7388, 0.9521, 0.8020,
        1.6591, 1.0587, 0.7474, 0.6787, 0.6237, 0.6185, 0.7586, 0.6386, 1.1203,
        0.6165, 1.2584, 0.8543, 0.6180, 0.6228, 0.7606, 3.8432, 1.8234, 0.6762],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  39 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3498, 0.6601, 1.1615, 1.2195, 0.9213, 0.8812, 0.6632, 0.7264, 0.6588,
        1.2453, 0.8853, 0.6268, 1.0929, 1.5286, 0.8375, 1.9889, 0.7264, 0.6065,
        1.5056, 2.1391, 1.2453, 0.8104, 0.9469, 1.1405, 1.3669, 1.0929, 1.9020,
        1.0756, 0.8022, 1.3498, 1.6311, 1.4416, 1.1615, 2.3196, 1.4029, 1.6895,
        1.7879, 1.4621, 0.6994, 0.7970, 0.7649, 0.7113, 0.8895, 1.0841, 0.8510,
        0.7179, 0.7945, 0.6122, 0.7424, 0.6126, 0.7920, 0.6920, 0.7996, 1.4621,
        0.7628, 0.7476, 0.6983, 0.7778, 0.6213, 0.6088, 0.7076, 1.4029, 0.6890,
        0.6930, 0.8311, 0.9262, 0.9816, 0.7589, 1.4834, 0.6471, 1.2872, 0.7970,
        0.7690, 0.8895, 0.9469, 1.3333, 1.7879, 0.6132, 0.6315, 0.8475, 1.0075,
        0.7920, 2.2555, 1.8620, 0.6333, 0.7871, 0.8311, 0.8076, 1.1837, 1.1305,
        0.6833, 0.7847, 0.7341, 0.6659, 0.8049, 0.6764, 0.7970, 0.6764, 1.2453,
        0.6307, 0.6063, 0.6920, 0.6199, 0.6121, 0.6880, 0.7390, 0.9524, 0.8022,
        1.6596, 1.0591, 0.7476, 0.6789, 0.6239, 0.6187, 0.7589, 0.6388, 1.1207,
        0.6167, 1.2588, 0.8545, 0.6182, 0.6230, 0.7608, 3.8444, 1.8240, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  39 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3498, 0.6601, 1.1615, 1.2195, 0.9213, 0.8812, 0.6632, 0.7264, 0.6588,
        1.2453, 0.8853, 0.6268, 1.0929, 1.5286, 0.8375, 1.9889, 0.7264, 0.6065,
        1.5056, 2.1391, 1.2453, 0.8104, 0.9469, 1.1405, 1.3669, 1.0929, 1.9020,
        1.0756, 0.8022, 1.3498, 1.6311, 1.4416, 1.1615, 2.3196, 1.4029, 1.6895,
        1.7879, 1.4621, 0.6994, 0.7970, 0.7649, 0.7113, 0.8895, 1.0841, 0.8510,
        0.7179, 0.7945, 0.6122, 0.7424, 0.6126, 0.7920, 0.6920, 0.7996, 1.4621,
        0.7628, 0.7476, 0.6983, 0.7778, 0.6213, 0.6088, 0.7076, 1.4029, 0.6890,
        0.6930, 0.8311, 0.9262, 0.9816, 0.7589, 1.4834, 0.6471, 1.2872, 0.7970,
        0.7690, 0.8895, 0.9469, 1.3333, 1.7879, 0.6132, 0.6315, 0.8475, 1.0075,
        0.7920, 2.2555, 1.8620, 0.6333, 0.7871, 0.8311, 0.8076, 1.1837, 1.1305,
        0.6833, 0.7847, 0.7341, 0.6659, 0.8049, 0.6764, 0.7970, 0.6764, 1.2453,
        0.6307, 0.6063, 0.6920, 0.6199, 0.6121, 0.6880, 0.7390, 0.9524, 0.8022,
        1.6596, 1.0591, 0.7476, 0.6789, 0.6239, 0.6187, 0.7589, 0.6388, 1.1207,
        0.6167, 1.2588, 0.8545, 0.6182, 0.6230, 0.7608, 3.8444, 1.8240, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  39 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3498, 0.6601, 1.1615, 1.2195, 0.9213, 0.8812, 0.6632, 0.7264, 0.6588,
        1.2453, 0.8853, 0.6268, 1.0929, 1.5286, 0.8375, 1.9889, 0.7264, 0.6065,
        1.5056, 2.1391, 1.2453, 0.8104, 0.9469, 1.1405, 1.3669, 1.0929, 1.9020,
        1.0756, 0.8022, 1.3498, 1.6311, 1.4416, 1.1615, 2.3196, 1.4029, 1.6895,
        1.7879, 1.4621, 0.6994, 0.7970, 0.7649, 0.7113, 0.8895, 1.0841, 0.8510,
        0.7179, 0.7945, 0.6122, 0.7424, 0.6126, 0.7920, 0.6920, 0.7996, 1.4621,
        0.7628, 0.7476, 0.6983, 0.7778, 0.6213, 0.6088, 0.7076, 1.4029, 0.6890,
        0.6930, 0.8311, 0.9262, 0.9816, 0.7589, 1.4834, 0.6471, 1.2872, 0.7970,
        0.7690, 0.8895, 0.9469, 1.3333, 1.7879, 0.6132, 0.6315, 0.8475, 1.0075,
        0.7920, 2.2555, 1.8620, 0.6333, 0.7871, 0.8311, 0.8076, 1.1837, 1.1305,
        0.6833, 0.7847, 0.7341, 0.6659, 0.8049, 0.6764, 0.7970, 0.6764, 1.2453,
        0.6307, 0.6063, 0.6920, 0.6199, 0.6121, 0.6880, 0.7390, 0.9524, 0.8022,
        1.6596, 1.0591, 0.7476, 0.6789, 0.6239, 0.6187, 0.7589, 0.6388, 1.1207,
        0.6167, 1.2588, 0.8545, 0.6182, 0.6230, 0.7608, 3.8444, 1.8240, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 247  66 114 329  80  50 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 427 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 105  95 158  52 269  63 141
 153 113 101  60  41 416 311 124  91 143  31  39 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  84 164 219 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3498, 0.6601, 1.1615, 1.2195, 0.9213, 0.8812, 0.6632, 0.7264, 0.6588,
        1.2453, 0.8853, 0.6268, 1.0929, 1.5286, 0.8375, 1.9889, 0.7264, 0.6065,
        1.5056, 2.1391, 1.2453, 0.8104, 0.9469, 1.1405, 1.3669, 1.0929, 1.9020,
        1.0756, 0.8022, 1.3498, 1.6311, 1.4416, 1.1615, 2.3196, 1.4029, 1.6895,
        1.7879, 1.4621, 0.6994, 0.7970, 0.7649, 0.7113, 0.8895, 1.0841, 0.8510,
        0.7179, 0.7945, 0.6122, 0.7424, 0.6126, 0.7920, 0.6920, 0.7996, 1.4621,
        0.7628, 0.7476, 0.6983, 0.7778, 0.6213, 0.6088, 0.7076, 1.4029, 0.6890,
        0.6930, 0.8311, 0.9262, 0.9816, 0.7589, 1.4834, 0.6471, 1.2872, 0.7970,
        0.7690, 0.8895, 0.9469, 1.3333, 1.7879, 0.6132, 0.6315, 0.8475, 1.0075,
        0.7920, 2.2555, 1.8620, 0.6333, 0.7871, 0.8311, 0.8076, 1.1837, 1.1305,
        0.6833, 0.7847, 0.7341, 0.6659, 0.8049, 0.6764, 0.7970, 0.6764, 1.2453,
        0.6307, 0.6063, 0.6920, 0.6199, 0.6121, 0.6880, 0.7390, 0.9524, 0.8022,
        1.6596, 1.0591, 0.7476, 0.6789, 0.6239, 0.6187, 0.7589, 0.6388, 1.1207,
        0.6167, 1.2588, 0.8545, 0.6182, 0.6230, 0.7608, 3.8444, 1.8240, 0.6764],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  51 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 106  95 158  52 269  63 141
 153 113 101  60  41 416 310 124  91 143  31  39 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3502, 0.6602, 1.1618, 1.2198, 0.9215, 0.8815, 0.6634, 0.7266, 0.6584,
        1.2456, 0.8856, 0.6269, 1.0932, 1.5060, 0.8377, 1.9894, 0.7266, 0.6067,
        1.5060, 2.1397, 1.2456, 0.8106, 0.9472, 1.1408, 1.3673, 1.0932, 1.9026,
        1.0759, 0.8024, 1.3502, 1.6316, 1.4420, 1.1618, 2.3203, 1.4033, 1.6899,
        1.7884, 1.4625, 0.6996, 0.7972, 0.7651, 0.7115, 0.8898, 1.0844, 0.8512,
        0.7181, 0.7947, 0.6124, 0.7426, 0.6128, 0.7922, 0.6922, 0.7998, 1.4625,
        0.7631, 0.7478, 0.6985, 0.7780, 0.6215, 0.6090, 0.7078, 1.4033, 0.6892,
        0.6932, 0.8313, 0.9215, 0.9819, 0.7591, 1.4838, 0.6473, 1.2875, 0.7972,
        0.7693, 0.8898, 0.9472, 1.3337, 1.7884, 0.6133, 0.6320, 0.8478, 1.0078,
        0.7922, 2.2562, 1.8625, 0.6335, 0.7873, 0.8313, 0.8078, 1.1840, 1.1308,
        0.6835, 0.7849, 0.7343, 0.6661, 0.8051, 0.6766, 0.7972, 0.6766, 1.2456,
        0.6308, 0.6064, 0.6922, 0.6201, 0.6123, 0.6882, 0.7392, 0.9527, 0.8024,
        1.6601, 1.0515, 0.7478, 0.6800, 0.6240, 0.6188, 0.7591, 0.6390, 1.1210,
        0.6168, 1.2592, 0.8548, 0.6184, 0.6232, 0.7611, 3.8455, 1.8245, 0.6766],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  51 127  36 177 538
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 106  95 158  52 269  63 141
 153 113 101  60  41 416 310 124  91 143  31  40 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3506, 0.6604, 1.1621, 1.2202, 0.9218, 0.8817, 0.6636, 0.7269, 0.6586,
        1.2460, 0.8858, 0.6271, 1.0935, 1.5064, 0.8380, 1.9900, 0.7269, 0.6069,
        1.5064, 2.1403, 1.2460, 0.8108, 0.9475, 1.1412, 1.3677, 1.0935, 1.9032,
        1.0762, 0.8027, 1.3506, 1.6321, 1.4425, 1.1621, 2.3210, 1.4037, 1.6904,
        1.7889, 1.4630, 0.6998, 0.7975, 0.7653, 0.7117, 0.8900, 1.0847, 0.8515,
        0.7183, 0.7949, 0.6126, 0.7428, 0.6130, 0.7924, 0.6924, 0.8001, 1.4630,
        0.7633, 0.7481, 0.6987, 0.7782, 0.6217, 0.6092, 0.7080, 1.4037, 0.6894,
        0.6934, 0.8316, 0.9218, 0.9822, 0.7593, 1.4843, 0.6475, 1.2879, 0.7975,
        0.7695, 0.8900, 0.9475, 1.3341, 1.7889, 0.6135, 0.6322, 0.8480, 1.0081,
        0.7924, 2.2568, 1.8251, 0.6337, 0.7875, 0.8316, 0.8081, 1.1843, 1.1311,
        0.6837, 0.7852, 0.7345, 0.6663, 0.8054, 0.6768, 0.7975, 0.6768, 1.2460,
        0.6310, 0.6066, 0.6924, 0.6203, 0.6124, 0.6884, 0.7394, 0.9530, 0.8027,
        1.6606, 1.0518, 0.7481, 0.6802, 0.6242, 0.6190, 0.7593, 0.6392, 1.1213,
        0.6170, 1.2595, 0.8550, 0.6186, 0.6234, 0.7613, 3.8467, 1.8251, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  51 127  36 177 537
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 188 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 106  95 158  53 269  63 141
 153 113 101  60  41 416 310 124  91 143  31  40 305 145 129 137  71  76
 214 146 172 236 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 222]
CBFL per class weights: tensor([1.3508, 0.6606, 1.1623, 1.2204, 0.9220, 0.8819, 0.6637, 0.7270, 0.6587,
        1.2462, 0.8860, 0.6272, 1.0937, 1.5067, 0.8381, 1.9904, 0.7270, 0.6070,
        1.5067, 2.1407, 1.2462, 0.8110, 0.9477, 1.1414, 1.3679, 1.0937, 1.9035,
        1.0764, 0.8028, 1.3508, 1.6323, 1.4427, 1.1623, 2.3214, 1.4039, 1.6907,
        1.7892, 1.4632, 0.6999, 0.7976, 0.7655, 0.7118, 0.8902, 1.0849, 0.8516,
        0.7184, 0.7951, 0.6127, 0.7429, 0.6131, 0.7926, 0.6925, 0.8002, 1.4632,
        0.7634, 0.7482, 0.6988, 0.7784, 0.6218, 0.6093, 0.7081, 1.4039, 0.6895,
        0.6935, 0.8317, 0.9220, 0.9824, 0.7594, 1.4632, 0.6476, 1.2881, 0.7976,
        0.7696, 0.8902, 0.9477, 1.3343, 1.7892, 0.6136, 0.6323, 0.8482, 1.0082,
        0.7926, 2.2572, 1.8254, 0.6338, 0.7877, 0.8317, 0.8082, 1.1845, 1.1313,
        0.6838, 0.7853, 0.7347, 0.6664, 0.8055, 0.6770, 0.7976, 0.6770, 1.2462,
        0.6311, 0.6067, 0.6925, 0.6204, 0.6125, 0.6885, 0.7396, 0.9531, 0.8028,
        1.6609, 1.0519, 0.7482, 0.6803, 0.6243, 0.6191, 0.7594, 0.6393, 1.1215,
        0.6171, 1.2597, 0.8552, 0.6187, 0.6235, 0.7614, 3.8473, 1.8254, 0.6770],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  51 127  36 177 537
  51  33  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 187 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 106  95 158  53 269  63 141
 153 113 101  60  41 416 310 125  91 143  31  40 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 223]
CBFL per class weights: tensor([1.3509, 0.6606, 1.1624, 1.2204, 0.9220, 0.8819, 0.6638, 0.7270, 0.6587,
        1.2462, 0.8860, 0.6272, 1.0937, 1.5067, 0.8381, 1.9904, 0.7270, 0.6070,
        1.5067, 2.1407, 1.2462, 0.8110, 0.9477, 1.1414, 1.3679, 1.0937, 1.9035,
        1.0764, 0.8028, 1.3509, 1.6324, 1.4427, 1.1624, 2.3214, 1.4040, 1.6908,
        1.7892, 1.4632, 0.6999, 0.7976, 0.7655, 0.7131, 0.8902, 1.0849, 0.8517,
        0.7185, 0.7951, 0.6127, 0.7429, 0.6131, 0.7926, 0.6925, 0.8002, 1.4632,
        0.7634, 0.7482, 0.6988, 0.7784, 0.6218, 0.6093, 0.7081, 1.4040, 0.6895,
        0.6935, 0.8317, 0.9220, 0.9824, 0.7594, 1.4632, 0.6476, 1.2881, 0.7976,
        0.7696, 0.8902, 0.9477, 1.3344, 1.7892, 0.6136, 0.6323, 0.8448, 1.0082,
        0.7926, 2.2573, 1.8254, 0.6338, 0.7877, 0.8317, 0.8082, 1.1846, 1.1313,
        0.6839, 0.7853, 0.7347, 0.6671, 0.8055, 0.6770, 0.7976, 0.6770, 1.2462,
        0.6311, 0.6067, 0.6925, 0.6204, 0.6126, 0.6885, 0.7396, 0.9531, 0.8028,
        1.6609, 1.0520, 0.7482, 0.6803, 0.6243, 0.6191, 0.7594, 0.6393, 1.1215,
        0.6171, 1.2598, 0.8552, 0.6187, 0.6235, 0.7614, 3.8474, 1.8254, 0.6762],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  52 127  36 177 537
  51  34  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 187 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  56 208 204 129 106  95 158  53 269  63 141
 153 113 101  60  41 416 309 125  91 143  31  40 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 223]
CBFL per class weights: tensor([1.3517, 0.6610, 1.1630, 1.2212, 0.9225, 0.8824, 0.6641, 0.7274, 0.6591,
        1.2470, 0.8865, 0.6276, 1.0944, 1.4854, 0.8386, 1.9916, 0.7274, 0.6074,
        1.5076, 2.0889, 1.2470, 0.8115, 0.9482, 1.1421, 1.3687, 1.0944, 1.9046,
        1.0770, 0.8033, 1.3517, 1.6333, 1.4436, 1.1630, 2.3228, 1.4048, 1.6918,
        1.7903, 1.4641, 0.7004, 0.7981, 0.7659, 0.7136, 0.8907, 1.0856, 0.8522,
        0.7189, 0.7955, 0.6131, 0.7434, 0.6134, 0.7930, 0.6929, 0.8007, 1.4641,
        0.7639, 0.7486, 0.6993, 0.7788, 0.6222, 0.6097, 0.7085, 1.4048, 0.6899,
        0.6939, 0.8322, 0.9225, 0.9830, 0.7599, 1.4641, 0.6480, 1.2889, 0.7981,
        0.7701, 0.8907, 0.9482, 1.3352, 1.7903, 0.6140, 0.6330, 0.8453, 1.0088,
        0.7930, 2.2586, 1.8265, 0.6342, 0.7882, 0.8322, 0.8087, 1.1853, 1.1320,
        0.6843, 0.7858, 0.7351, 0.6675, 0.8060, 0.6774, 0.7981, 0.6774, 1.2470,
        0.6315, 0.6071, 0.6929, 0.6208, 0.6129, 0.6889, 0.7400, 0.9537, 0.8033,
        1.6619, 1.0526, 0.7486, 0.6807, 0.6247, 0.6195, 0.7599, 0.6397, 1.1222,
        0.6175, 1.2605, 0.8557, 0.6190, 0.6239, 0.7619, 3.8497, 1.8265, 0.6766],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  52 127  36 177 537
  51  34  66 136 101  75  58  80  38  82 139  59  46  54  73  30  56  44
  41  53 198 141 155 187 113  81 123 183 142 426 167 422 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  53 269  63 141
 153 113 101  60  41 416 309 125  91 143  31  40 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 223]
CBFL per class weights: tensor([1.3519, 0.6611, 1.1632, 1.2213, 0.9227, 0.8825, 0.6642, 0.7275, 0.6592,
        1.2472, 0.8867, 0.6277, 1.0945, 1.4856, 0.8388, 1.9919, 0.7275, 0.6075,
        1.5078, 2.0892, 1.2472, 0.8116, 0.9484, 1.1422, 1.3689, 1.0945, 1.9049,
        1.0772, 0.8034, 1.3519, 1.6336, 1.4438, 1.1632, 2.3231, 1.4050, 1.6920,
        1.7906, 1.4643, 0.7005, 0.7982, 0.7660, 0.7137, 0.8908, 1.0857, 0.8523,
        0.7190, 0.7957, 0.6132, 0.7435, 0.6135, 0.7932, 0.6930, 0.8008, 1.4643,
        0.7640, 0.7488, 0.6994, 0.7789, 0.6223, 0.6098, 0.7086, 1.3866, 0.6900,
        0.6940, 0.8323, 0.9227, 0.9831, 0.7600, 1.4643, 0.6481, 1.2891, 0.7982,
        0.7702, 0.8908, 0.9484, 1.3354, 1.7906, 0.6141, 0.6331, 0.8454, 1.0090,
        0.7932, 2.2589, 1.8268, 0.6343, 0.7883, 0.8323, 0.8088, 1.1854, 1.1322,
        0.6844, 0.7859, 0.7352, 0.6676, 0.8061, 0.6775, 0.7982, 0.6775, 1.2472,
        0.6316, 0.6072, 0.6930, 0.6209, 0.6130, 0.6890, 0.7401, 0.9538, 0.8034,
        1.6621, 1.0527, 0.7488, 0.6808, 0.6248, 0.6196, 0.7600, 0.6397, 1.1224,
        0.6176, 1.2607, 0.8558, 0.6191, 0.6240, 0.7620, 3.8502, 1.8268, 0.6767],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  52 127  36 177 536
  51  34  66 136 101  75  58  80  37  82 139  60  46  54  73  30  56  44
  41  53 198 141 155 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  54 269  63 141
 153 113 101  60  41 416 309 125  91 143  31  41 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 223]
CBFL per class weights: tensor([1.3522, 0.6612, 1.1635, 1.2216, 0.9229, 0.8828, 0.6644, 0.7277, 0.6594,
        1.2475, 0.8869, 0.6279, 1.0948, 1.4860, 0.8390, 1.9924, 0.7277, 0.6076,
        1.5082, 2.0897, 1.2475, 0.8118, 0.9486, 1.1425, 1.3693, 1.0948, 1.9477,
        1.0774, 0.8036, 1.3357, 1.6340, 1.4441, 1.1635, 2.3237, 1.4053, 1.6924,
        1.7910, 1.4647, 0.7006, 0.7984, 0.7662, 0.7138, 0.8911, 1.0860, 0.8525,
        0.7192, 0.7959, 0.6133, 0.7437, 0.6138, 0.7933, 0.6932, 0.8010, 1.4647,
        0.7642, 0.7489, 0.6995, 0.7791, 0.6224, 0.6099, 0.7088, 1.3870, 0.6902,
        0.6942, 0.8325, 0.9229, 0.9833, 0.7602, 1.4441, 0.6483, 1.2894, 0.7984,
        0.7704, 0.8911, 0.9486, 1.3357, 1.7910, 0.6142, 0.6332, 0.8456, 1.0092,
        0.7933, 2.2595, 1.7910, 0.6344, 0.7885, 0.8325, 0.8090, 1.1857, 1.1324,
        0.6845, 0.7861, 0.7354, 0.6678, 0.8063, 0.6776, 0.7984, 0.6776, 1.2475,
        0.6318, 0.6073, 0.6932, 0.6210, 0.6132, 0.6892, 0.7403, 0.9541, 0.8036,
        1.6625, 1.0530, 0.7489, 0.6810, 0.6249, 0.6197, 0.7602, 0.6399, 1.1226,
        0.6177, 1.2610, 0.8560, 0.6193, 0.6241, 0.7622, 3.8512, 1.8272, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 245  73  68 106 115 240 177 248  66 114 329  80  52 127  36 177 536
  51  34  66 136 101  75  58  80  37  82 139  60  46  54  73  30  56  44
  41  53 198 141 155 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  54 269  63 141
 153 113 101  60  41 416 309 125  91 143  31  41 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 374 346 157  17  40 223]
CBFL per class weights: tensor([1.3522, 0.6612, 1.1635, 1.2216, 0.9229, 0.8828, 0.6644, 0.7277, 0.6594,
        1.2475, 0.8869, 0.6279, 1.0948, 1.4860, 0.8390, 1.9924, 0.7277, 0.6076,
        1.5082, 2.0897, 1.2475, 0.8118, 0.9486, 1.1425, 1.3693, 1.0948, 1.9477,
        1.0774, 0.8036, 1.3357, 1.6340, 1.4441, 1.1635, 2.3237, 1.4053, 1.6924,
        1.7910, 1.4647, 0.7006, 0.7984, 0.7662, 0.7138, 0.8911, 1.0860, 0.8525,
        0.7192, 0.7959, 0.6133, 0.7437, 0.6138, 0.7933, 0.6932, 0.8010, 1.4647,
        0.7642, 0.7489, 0.6995, 0.7791, 0.6224, 0.6099, 0.7088, 1.3870, 0.6902,
        0.6942, 0.8325, 0.9229, 0.9833, 0.7602, 1.4441, 0.6483, 1.2894, 0.7984,
        0.7704, 0.8911, 0.9486, 1.3357, 1.7910, 0.6142, 0.6332, 0.8456, 1.0092,
        0.7933, 2.2595, 1.7910, 0.6344, 0.7885, 0.8325, 0.8090, 1.1857, 1.1324,
        0.6845, 0.7861, 0.7354, 0.6678, 0.8063, 0.6776, 0.7984, 0.6776, 1.2475,
        0.6318, 0.6073, 0.6932, 0.6210, 0.6132, 0.6892, 0.7403, 0.9541, 0.8036,
        1.6625, 1.0530, 0.7489, 0.6810, 0.6249, 0.6197, 0.7602, 0.6399, 1.1226,
        0.6177, 1.2610, 0.8560, 0.6193, 0.6241, 0.7622, 3.8512, 1.8272, 0.6768],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 177 248  66 114 329  80  52 127  37 177 536
  51  34  66 136 101  75  58  80  37  83 139  60  46  54  73  30  56  45
  41  53 198 141 155 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  54 269  63 141
 153 113 101  60  41 415 309 125  91 143  31  41 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 346 157  17  40 223]
CBFL per class weights: tensor([1.3531, 0.6623, 1.1643, 1.2224, 0.9235, 0.8833, 0.6648, 0.7282, 0.6598,
        1.2483, 0.8874, 0.6283, 1.0955, 1.4870, 0.8395, 1.9490, 0.7282, 0.6080,
        1.5092, 2.0911, 1.2483, 0.8123, 0.9492, 1.1432, 1.3702, 1.0955, 1.9490,
        1.0698, 0.8041, 1.3366, 1.6350, 1.4451, 1.1643, 2.3252, 1.4063, 1.6636,
        1.7922, 1.4656, 0.7011, 0.7989, 0.7667, 0.7143, 0.8916, 1.0867, 0.8531,
        0.7196, 0.7964, 0.6137, 0.7442, 0.6142, 0.7939, 0.6936, 0.8015, 1.4656,
        0.7647, 0.7494, 0.7000, 0.7796, 0.6228, 0.6103, 0.7093, 1.3879, 0.6906,
        0.6947, 0.8331, 0.9235, 0.9840, 0.7607, 1.4451, 0.6487, 1.2903, 0.7989,
        0.7709, 0.8916, 0.9492, 1.3366, 1.7922, 0.6147, 0.6336, 0.8462, 1.0099,
        0.7939, 2.2610, 1.7922, 0.6349, 0.7890, 0.8331, 0.8095, 1.1865, 1.1332,
        0.6850, 0.7866, 0.7359, 0.6682, 0.8068, 0.6781, 0.7989, 0.6781, 1.2483,
        0.6322, 0.6077, 0.6936, 0.6214, 0.6136, 0.6897, 0.7408, 0.9547, 0.8041,
        1.6636, 1.0537, 0.7494, 0.6814, 0.6254, 0.6201, 0.7607, 0.6403, 1.1234,
        0.6182, 1.2618, 0.8566, 0.6198, 0.6245, 0.7627, 3.8537, 1.8284, 0.6773],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 177 248  66 114 329  80  52 127  37 177 536
  51  34  66 136 101  75  58  80  37  83 139  60  46  54  73  30  56  45
  41  53 198 141 154 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  54 269  63 141
 153 113 101  60  41 415 309 125  91 143  31  42 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 346 157  17  40 223]
CBFL per class weights: tensor([1.3534, 0.6624, 1.1646, 1.2228, 0.9237, 0.8836, 0.6650, 0.7284, 0.6600,
        1.2486, 0.8877, 0.6284, 1.0958, 1.4874, 0.8397, 1.9495, 0.7284, 0.6082,
        1.5096, 2.0916, 1.2486, 0.8125, 0.9495, 1.1435, 1.3705, 1.0958, 1.9495,
        1.0701, 0.8044, 1.3369, 1.6354, 1.4455, 1.1646, 2.3258, 1.4066, 1.6640,
        1.7926, 1.4660, 0.7013, 0.7991, 0.7690, 0.7145, 0.8919, 1.0870, 0.8533,
        0.7198, 0.7966, 0.6139, 0.7444, 0.6143, 0.7941, 0.6938, 0.8017, 1.4660,
        0.7649, 0.7496, 0.7002, 0.7798, 0.6230, 0.6105, 0.7095, 1.3882, 0.6908,
        0.6948, 0.8333, 0.9237, 0.9842, 0.7609, 1.4455, 0.6489, 1.2906, 0.7991,
        0.7711, 0.8919, 0.9495, 1.3369, 1.7926, 0.6149, 0.6338, 0.8464, 1.0102,
        0.7941, 2.2615, 1.7582, 0.6350, 0.7892, 0.8333, 0.8098, 1.1868, 1.1335,
        0.6852, 0.7868, 0.7361, 0.6684, 0.8070, 0.6783, 0.7991, 0.6783, 1.2486,
        0.6323, 0.6079, 0.6938, 0.6216, 0.6137, 0.6898, 0.7410, 0.9549, 0.8044,
        1.6640, 1.0540, 0.7496, 0.6816, 0.6255, 0.6203, 0.7609, 0.6405, 1.1237,
        0.6183, 1.2622, 0.8568, 0.6200, 0.6247, 0.7629, 3.8547, 1.8289, 0.6774],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 177 248  66 114 329  80  52 127  37 177 535
  51  34  66 136 101  75  58  80  37  83 139  60  46  54  73  30  56  45
  41  53 198 141 154 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  56 269  63 141
 153 113 101  60  41 415 309 125  91 143  31  42 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 346 157  17  40 223]
CBFL per class weights: tensor([1.3538, 0.6626, 1.1649, 1.2231, 0.9240, 0.8838, 0.6652, 0.7286, 0.6602,
        1.2490, 0.8879, 0.6286, 1.0961, 1.4878, 0.8400, 1.9501, 0.7286, 0.6084,
        1.5100, 2.0922, 1.2490, 0.8128, 0.9498, 1.1439, 1.3709, 1.0961, 1.9501,
        1.0704, 0.8046, 1.3373, 1.6360, 1.4459, 1.1649, 2.3265, 1.4070, 1.6646,
        1.7932, 1.4665, 0.7015, 0.7994, 0.7692, 0.7147, 0.8922, 1.0873, 0.8535,
        0.7200, 0.7968, 0.6141, 0.7446, 0.6145, 0.7943, 0.6940, 0.8020, 1.4665,
        0.7651, 0.7499, 0.7004, 0.7801, 0.6232, 0.6106, 0.7097, 1.3887, 0.6910,
        0.6950, 0.8336, 0.9240, 0.9845, 0.7611, 1.4070, 0.6491, 1.2910, 0.7994,
        0.7713, 0.8922, 0.9498, 1.3373, 1.7932, 0.6151, 0.6340, 0.8466, 1.0105,
        0.7943, 2.2622, 1.7587, 0.6352, 0.7894, 0.8336, 0.8100, 1.1872, 1.1338,
        0.6854, 0.7870, 0.7363, 0.6686, 0.8073, 0.6785, 0.7994, 0.6785, 1.2490,
        0.6325, 0.6081, 0.6940, 0.6218, 0.6139, 0.6900, 0.7412, 0.9552, 0.8046,
        1.6646, 1.0543, 0.7499, 0.6818, 0.6257, 0.6205, 0.7611, 0.6407, 1.1240,
        0.6185, 1.2625, 0.8571, 0.6202, 0.6249, 0.7631, 3.8559, 1.8294, 0.6776],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 177 248  66 114 329  80  52 127  37 177 535
  51  34  66 136 101  75  58  80  37  83 139  60  46  54  73  30  56  45
  41  53 198 141 154 187 113  81 123 183 142 426 167 421 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  56 269  63 141
 153 113 101  60  41 415 309 125  91 143  31  42 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 346 157  17  40 223]
CBFL per class weights: tensor([1.3538, 0.6626, 1.1649, 1.2231, 0.9240, 0.8838, 0.6652, 0.7286, 0.6602,
        1.2490, 0.8879, 0.6286, 1.0961, 1.4878, 0.8400, 1.9501, 0.7286, 0.6084,
        1.5100, 2.0922, 1.2490, 0.8128, 0.9498, 1.1439, 1.3709, 1.0961, 1.9501,
        1.0704, 0.8046, 1.3373, 1.6360, 1.4459, 1.1649, 2.3265, 1.4070, 1.6646,
        1.7932, 1.4665, 0.7015, 0.7994, 0.7692, 0.7147, 0.8922, 1.0873, 0.8535,
        0.7200, 0.7968, 0.6141, 0.7446, 0.6145, 0.7943, 0.6940, 0.8020, 1.4665,
        0.7651, 0.7499, 0.7004, 0.7801, 0.6232, 0.6106, 0.7097, 1.3887, 0.6910,
        0.6950, 0.8336, 0.9240, 0.9845, 0.7611, 1.4070, 0.6491, 1.2910, 0.7994,
        0.7713, 0.8922, 0.9498, 1.3373, 1.7932, 0.6151, 0.6340, 0.8466, 1.0105,
        0.7943, 2.2622, 1.7587, 0.6352, 0.7894, 0.8336, 0.8100, 1.1872, 1.1338,
        0.6854, 0.7870, 0.7363, 0.6686, 0.8073, 0.6785, 0.7994, 0.6785, 1.2490,
        0.6325, 0.6081, 0.6940, 0.6218, 0.6139, 0.6900, 0.7412, 0.9552, 0.8046,
        1.6646, 1.0543, 0.7499, 0.6818, 0.6257, 0.6205, 0.7611, 0.6407, 1.1240,
        0.6185, 1.2625, 0.8571, 0.6202, 0.6249, 0.7631, 3.8559, 1.8294, 0.6776],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 535
  51  35  66 136 101  75  58  80  37  83 139  60  46  54  73  30  56  45
  41  53 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  57 269  63 141
 153 113 101  60  41 415 309 125  91 143  31  42 305 145 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3549, 0.6632, 1.1659, 1.2241, 0.9248, 0.8846, 0.6658, 0.7307, 0.6607,
        1.2500, 0.8887, 0.6291, 1.0970, 1.4890, 0.8407, 1.9516, 0.7292, 0.6089,
        1.5113, 2.0438, 1.2500, 0.8134, 0.9505, 1.1448, 1.3721, 1.0970, 1.9516,
        1.0713, 0.8053, 1.3384, 1.6373, 1.4471, 1.1659, 2.3284, 1.4082, 1.6659,
        1.7947, 1.4677, 0.7021, 0.8000, 0.7699, 0.7153, 0.8929, 1.0882, 0.8542,
        0.7206, 0.7975, 0.6146, 0.7452, 0.6151, 0.7950, 0.6946, 0.8026, 1.4677,
        0.7657, 0.7505, 0.7009, 0.7807, 0.6237, 0.6111, 0.7103, 1.3898, 0.6916,
        0.6956, 0.8342, 0.9248, 0.9853, 0.7617, 1.3898, 0.6496, 1.2920, 0.8000,
        0.7720, 0.8929, 0.9505, 1.3384, 1.7947, 0.6156, 0.6345, 0.8473, 1.0113,
        0.7950, 2.2641, 1.7601, 0.6357, 0.7901, 0.8342, 0.8107, 1.1881, 1.1347,
        0.6859, 0.7877, 0.7369, 0.6692, 0.8079, 0.6790, 0.8000, 0.6790, 1.2500,
        0.6331, 0.6086, 0.6946, 0.6223, 0.6144, 0.6906, 0.7418, 0.9560, 0.8053,
        1.6659, 1.0551, 0.7505, 0.6824, 0.6262, 0.6210, 0.7617, 0.6412, 1.1249,
        0.6190, 1.2636, 0.8578, 0.6207, 0.6256, 0.7637, 3.8590, 1.7947, 0.6782],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 535
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  53
 156 164 199 149 355 477 191  57 208 204 129 106  95 158  57 269  63 141
 153 113 101  60  41 415 309 126  91 143  31  42 305 146 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3549, 0.6632, 1.1659, 1.2241, 0.9248, 0.8846, 0.6658, 0.7307, 0.6607,
        1.2500, 0.8887, 0.6291, 1.0970, 1.4890, 0.8407, 1.9517, 0.7292, 0.6089,
        1.5113, 2.0438, 1.2500, 0.8134, 0.9505, 1.1448, 1.3721, 1.0970, 1.9517,
        1.0552, 0.8053, 1.3384, 1.6373, 1.4471, 1.1659, 2.3284, 1.4082, 1.6659,
        1.7947, 1.4890, 0.7021, 0.8000, 0.7699, 0.7153, 0.8929, 1.0882, 0.8542,
        0.7206, 0.7975, 0.6146, 0.7452, 0.6151, 0.7950, 0.6946, 0.8026, 1.4677,
        0.7657, 0.7505, 0.7010, 0.7807, 0.6237, 0.6111, 0.7103, 1.3898, 0.6916,
        0.6956, 0.8342, 0.9248, 0.9853, 0.7617, 1.3898, 0.6496, 1.2920, 0.8000,
        0.7720, 0.8929, 0.9505, 1.3384, 1.7947, 0.6156, 0.6345, 0.8440, 1.0113,
        0.7950, 2.2641, 1.7601, 0.6357, 0.7877, 0.8342, 0.8107, 1.1882, 1.1347,
        0.6859, 0.7877, 0.7369, 0.6692, 0.8079, 0.6790, 0.8000, 0.6790, 1.2500,
        0.6331, 0.6086, 0.6946, 0.6223, 0.6144, 0.6906, 0.7418, 0.9560, 0.8053,
        1.6659, 1.0552, 0.7505, 0.6824, 0.6262, 0.6210, 0.7617, 0.6412, 1.1249,
        0.6190, 1.2636, 0.8578, 0.6207, 0.6256, 0.7637, 3.8590, 1.7947, 0.6782],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 535
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  53
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  58 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  42 305 146 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 371 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3558, 0.6636, 1.1666, 1.2249, 0.9253, 0.8851, 0.6662, 0.7311, 0.6611,
        1.2508, 0.8892, 0.6295, 1.0977, 1.4899, 0.8412, 1.9528, 0.7296, 0.6093,
        1.5122, 2.0450, 1.2508, 0.8139, 0.9511, 1.1455, 1.3729, 1.0977, 1.9528,
        1.0558, 0.8057, 1.3392, 1.6383, 1.4480, 1.1666, 2.3298, 1.4091, 1.6669,
        1.7957, 1.4899, 0.7025, 0.8005, 0.7703, 0.7157, 0.8934, 1.0889, 0.8547,
        0.7211, 0.7980, 0.6150, 0.7456, 0.6155, 0.7954, 0.6950, 0.8031, 1.4685,
        0.7682, 0.7509, 0.7014, 0.7812, 0.6241, 0.6115, 0.7107, 1.3906, 0.6920,
        0.6960, 0.8347, 0.9253, 0.9859, 0.7622, 1.3729, 0.6500, 1.2928, 0.8005,
        0.7724, 0.8934, 0.9511, 1.3392, 1.7957, 0.6160, 0.6349, 0.8445, 1.0119,
        0.7954, 2.2051, 1.7612, 0.6361, 0.7882, 0.8347, 0.8112, 1.1889, 1.1354,
        0.6863, 0.7882, 0.7374, 0.6696, 0.8084, 0.6794, 0.8005, 0.6794, 1.2508,
        0.6334, 0.6089, 0.6950, 0.6227, 0.6148, 0.6910, 0.7423, 0.9566, 0.8057,
        1.6669, 1.0558, 0.7509, 0.6828, 0.6266, 0.6214, 0.7622, 0.6416, 1.1256,
        0.6194, 1.2643, 0.8583, 0.6211, 0.6260, 0.7642, 3.8614, 1.7957, 0.6786],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 535
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  53
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  58 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  42 305 146 129 137  70  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 372 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3556, 0.6635, 1.1665, 1.2248, 0.9253, 0.8850, 0.6661, 0.7311, 0.6611,
        1.2507, 0.8891, 0.6295, 1.0976, 1.4898, 0.8411, 1.9527, 0.7296, 0.6092,
        1.5121, 2.0448, 1.2507, 0.8139, 0.9510, 1.1454, 1.3728, 1.0976, 1.9527,
        1.0557, 0.8057, 1.3391, 1.6381, 1.4478, 1.1665, 2.3296, 1.4089, 1.6668,
        1.7956, 1.4898, 0.7024, 0.8004, 0.7703, 0.7157, 0.8933, 1.0888, 0.8547,
        0.7210, 0.7979, 0.6149, 0.7456, 0.6154, 0.7954, 0.6949, 0.8030, 1.4684,
        0.7682, 0.7509, 0.7013, 0.7811, 0.6240, 0.6115, 0.7106, 1.3905, 0.6919,
        0.6960, 0.8347, 0.9253, 0.9858, 0.7621, 1.3728, 0.6499, 1.2927, 0.8004,
        0.7724, 0.8933, 0.9510, 1.3391, 1.7956, 0.6159, 0.6348, 0.8444, 1.0118,
        0.7954, 2.2049, 1.7610, 0.6361, 0.7881, 0.8347, 0.8111, 1.2004, 1.1353,
        0.6863, 0.7881, 0.7373, 0.6695, 0.8084, 0.6794, 0.8004, 0.6794, 1.2507,
        0.6334, 0.6089, 0.6949, 0.6226, 0.6147, 0.6910, 0.7422, 0.9565, 0.8057,
        1.6668, 1.0557, 0.7509, 0.6827, 0.6265, 0.6212, 0.7621, 0.6415, 1.1255,
        0.6193, 1.2642, 0.8582, 0.6210, 0.6259, 0.7641, 3.8610, 1.7956, 0.6785],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 535
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  59 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  42 305 146 129 137  71  76
 214 146 172 235 138 222 141 222  66 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 372 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3557, 0.6636, 1.1665, 1.2248, 0.9253, 0.8851, 0.6661, 0.7311, 0.6611,
        1.2507, 0.8892, 0.6295, 1.0977, 1.4899, 0.8412, 1.9528, 0.7296, 0.6093,
        1.5121, 2.0450, 1.2507, 0.8139, 0.9511, 1.1455, 1.3729, 1.0977, 1.9528,
        1.0558, 0.8057, 1.3392, 1.6382, 1.4479, 1.1665, 2.3298, 1.4090, 1.6669,
        1.7957, 1.4899, 0.7025, 0.8005, 0.7703, 0.7157, 0.8934, 1.0888, 0.8547,
        0.7210, 0.7979, 0.6149, 0.7456, 0.6155, 0.7954, 0.6950, 0.8031, 1.4899,
        0.7682, 0.7509, 0.7014, 0.7812, 0.6240, 0.6115, 0.7107, 1.3906, 0.6920,
        0.6960, 0.8347, 0.9253, 0.9859, 0.7622, 1.3557, 0.6500, 1.2928, 0.8005,
        0.7724, 0.8934, 0.9511, 1.3392, 1.7957, 0.6159, 0.6349, 0.8445, 1.0119,
        0.7954, 2.2051, 1.7611, 0.6361, 0.7881, 0.8347, 0.8111, 1.1888, 1.1354,
        0.6863, 0.7881, 0.7373, 0.6695, 0.8084, 0.6794, 0.8005, 0.6794, 1.2507,
        0.6334, 0.6089, 0.6950, 0.6226, 0.6148, 0.6910, 0.7422, 0.9566, 0.8057,
        1.6669, 1.0558, 0.7509, 0.6828, 0.6266, 0.6212, 0.7622, 0.6416, 1.1256,
        0.6194, 1.2643, 0.8583, 0.6211, 0.6260, 0.7642, 3.8612, 1.7957, 0.6786],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 167 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  43 305 146 129 137  71  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 372 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3564, 0.6639, 1.1671, 1.2254, 0.9257, 0.8855, 0.6665, 0.7315, 0.6614,
        1.2513, 0.8896, 0.6298, 1.0982, 1.4906, 0.8416, 1.9537, 0.7300, 0.6096,
        1.5129, 2.0459, 1.2513, 0.8143, 0.9515, 1.1460, 1.3735, 1.0982, 1.9537,
        1.0563, 0.8061, 1.3398, 1.6390, 1.4486, 1.1671, 2.3309, 1.4097, 1.6677,
        1.7965, 1.4906, 0.7028, 0.8009, 0.7707, 0.7161, 0.8938, 1.0894, 0.8551,
        0.7214, 0.7983, 0.6152, 0.7460, 0.6158, 0.7958, 0.6953, 0.8035, 1.4906,
        0.7686, 0.7513, 0.7017, 0.7815, 0.6243, 0.6118, 0.7110, 1.3913, 0.6923,
        0.6963, 0.8351, 0.9257, 0.9864, 0.7625, 1.3398, 0.6503, 1.2934, 0.8009,
        0.7728, 0.8938, 0.9515, 1.3398, 1.7965, 0.6162, 0.6352, 0.8449, 1.0124,
        0.7958, 2.2061, 1.7291, 0.6364, 0.7885, 0.8351, 0.8115, 1.1894, 1.1359,
        0.6866, 0.7885, 0.7377, 0.6699, 0.8088, 0.6797, 0.8035, 0.6797, 1.2382,
        0.6337, 0.6092, 0.6953, 0.6229, 0.6151, 0.6913, 0.7426, 0.9570, 0.8061,
        1.6677, 1.0563, 0.7513, 0.6831, 0.6269, 0.6215, 0.7625, 0.6419, 1.1261,
        0.6197, 1.2649, 0.8587, 0.6214, 0.6263, 0.7645, 3.8631, 1.7965, 0.6789],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  43 305 146 129 137  71  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 139
  45  85 164 218 342 372 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3564, 0.6639, 1.1671, 1.2254, 0.9258, 0.8855, 0.6665, 0.7315, 0.6614,
        1.2513, 0.8896, 0.6298, 1.0982, 1.4906, 0.8416, 1.9537, 0.7300, 0.6096,
        1.5129, 2.0460, 1.2513, 0.8143, 0.9515, 1.1460, 1.3735, 1.0982, 1.9537,
        1.0563, 0.8061, 1.3398, 1.6390, 1.4486, 1.1671, 2.3309, 1.4097, 1.6677,
        1.7966, 1.4906, 0.7028, 0.8009, 0.7707, 0.7161, 0.8938, 1.0894, 0.8551,
        0.7214, 0.7983, 0.6152, 0.7443, 0.6158, 0.7958, 0.6953, 0.8035, 1.4906,
        0.7686, 0.7513, 0.7017, 0.7816, 0.6243, 0.6118, 0.7110, 1.3913, 0.6923,
        0.6964, 0.8351, 0.9258, 0.9864, 0.7626, 1.3398, 0.6503, 1.2934, 0.8009,
        0.7728, 0.8938, 0.9515, 1.3398, 1.7966, 0.6162, 0.6352, 0.8449, 1.0124,
        0.7958, 2.2061, 1.7291, 0.6364, 0.7885, 0.8351, 0.8115, 1.1894, 1.1359,
        0.6867, 0.7885, 0.7377, 0.6699, 0.8088, 0.6797, 0.8035, 0.6797, 1.2382,
        0.6337, 0.6092, 0.6953, 0.6230, 0.6151, 0.6913, 0.7426, 0.9570, 0.8061,
        1.6677, 1.0563, 0.7513, 0.6831, 0.6269, 0.6215, 0.7626, 0.6419, 1.1261,
        0.6197, 1.2649, 0.8587, 0.6214, 0.6263, 0.7645, 3.8631, 1.7966, 0.6789],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  68 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  66 136 101  75  58  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  45 305 146 129 137  71  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 138
  45  85 164 218 342 372 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3570, 0.6642, 1.1677, 1.2260, 0.9262, 0.8859, 0.6668, 0.7318, 0.6617,
        1.2519, 0.8900, 0.6301, 1.0987, 1.4913, 0.8420, 1.9546, 0.7303, 0.6099,
        1.5136, 2.0469, 1.2519, 0.8147, 0.9520, 1.1466, 1.3742, 1.0987, 1.9546,
        1.0568, 0.8065, 1.3405, 1.6398, 1.4493, 1.1677, 2.3320, 1.4104, 1.6685,
        1.7974, 1.4913, 0.7031, 0.8013, 0.7710, 0.7164, 0.8942, 1.0899, 0.8555,
        0.7217, 0.7987, 0.6155, 0.7446, 0.6161, 0.7962, 0.6956, 0.8038, 1.4913,
        0.7690, 0.7516, 0.7020, 0.7819, 0.6246, 0.6121, 0.7113, 1.3919, 0.6926,
        0.6967, 0.8355, 0.9262, 0.9868, 0.7629, 1.3405, 0.6506, 1.2940, 0.8013,
        0.7731, 0.8942, 0.9520, 1.3405, 1.7974, 0.6165, 0.6355, 0.8453, 1.0128,
        0.7962, 2.2072, 1.6685, 0.6367, 0.7889, 0.8355, 0.8119, 1.1900, 1.1365,
        0.6870, 0.7889, 0.7380, 0.6702, 0.8092, 0.6801, 0.8038, 0.6801, 1.2388,
        0.6340, 0.6095, 0.6956, 0.6232, 0.6154, 0.6917, 0.7429, 0.9575, 0.8092,
        1.6685, 1.0568, 0.7516, 0.6834, 0.6272, 0.6218, 0.7629, 0.6422, 1.1267,
        0.6200, 1.2655, 0.8591, 0.6217, 0.6266, 0.7649, 3.8649, 1.7974, 0.6792],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  66 136 101  75  59  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  47 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 138
  45  85 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3575, 0.6645, 1.1681, 1.2393, 0.9266, 0.8863, 0.6670, 0.7321, 0.6620,
        1.2524, 0.8904, 0.6303, 1.0991, 1.4919, 0.8423, 1.9554, 0.7306, 0.6101,
        1.5142, 2.0477, 1.2524, 0.8150, 0.9524, 1.1470, 1.3575, 1.0991, 1.9554,
        1.0572, 0.8068, 1.3410, 1.6404, 1.4499, 1.1681, 2.3329, 1.4109, 1.6691,
        1.7981, 1.4919, 0.7034, 0.8016, 0.7713, 0.7167, 0.8946, 1.0903, 0.8559,
        0.7220, 0.7990, 0.6158, 0.7449, 0.6163, 0.7965, 0.6959, 0.8042, 1.4919,
        0.7693, 0.7519, 0.7023, 0.7822, 0.6249, 0.6123, 0.7116, 1.3925, 0.6929,
        0.6969, 0.8358, 0.9266, 0.9872, 0.7632, 1.3410, 0.6508, 1.2945, 0.8016,
        0.7734, 0.8946, 0.9524, 1.3410, 1.7981, 0.6168, 0.6357, 0.8456, 1.0132,
        0.7965, 2.2080, 1.6130, 0.6370, 0.7892, 0.8358, 0.8122, 1.2021, 1.1369,
        0.6872, 0.7892, 0.7383, 0.6704, 0.8095, 0.6803, 0.8042, 0.6803, 1.2393,
        0.6343, 0.6097, 0.6959, 0.6235, 0.6156, 0.6919, 0.7432, 0.9579, 0.8095,
        1.6691, 1.0572, 0.7519, 0.6837, 0.6274, 0.6219, 0.7632, 0.6424, 1.1271,
        0.6202, 1.2660, 0.8594, 0.6219, 0.6268, 0.7652, 3.8664, 1.7981, 0.6795],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  75  59  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  91 143  32  47 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 138
  45  85 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3577, 0.6645, 1.1682, 1.2394, 0.9266, 0.8863, 0.6671, 0.7322, 0.6621,
        1.2525, 0.8905, 0.6304, 1.0993, 1.4920, 0.8424, 1.9556, 0.7307, 0.6102,
        1.5143, 2.0479, 1.2394, 0.8151, 0.9525, 1.1471, 1.3577, 1.0993, 1.9556,
        1.0573, 0.8069, 1.3411, 1.6406, 1.4500, 1.1682, 2.3331, 1.4111, 1.6693,
        1.7983, 1.4920, 0.7035, 0.8016, 0.7714, 0.7167, 0.8947, 1.0904, 0.8560,
        0.7221, 0.7991, 0.6158, 0.7450, 0.6164, 0.7966, 0.6960, 0.8042, 1.4920,
        0.7693, 0.7520, 0.7024, 0.7823, 0.6249, 0.6124, 0.7117, 1.3926, 0.6930,
        0.6970, 0.8359, 0.9266, 0.9873, 0.7633, 1.3411, 0.6509, 1.2947, 0.8016,
        0.7735, 0.8947, 0.9525, 1.3411, 1.7983, 0.6168, 0.6358, 0.8457, 1.0133,
        0.7966, 2.2083, 1.6132, 0.6370, 0.7893, 0.8359, 0.8123, 1.2022, 1.1370,
        0.6873, 0.7893, 0.7384, 0.6705, 0.8096, 0.6804, 0.8042, 0.6804, 1.2394,
        0.6343, 0.6098, 0.6960, 0.6235, 0.6157, 0.6920, 0.7433, 0.9580, 0.8096,
        1.6693, 1.0573, 0.7520, 0.6838, 0.6275, 0.6220, 0.7633, 0.6425, 1.1272,
        0.6203, 1.2661, 0.8595, 0.6220, 0.6269, 0.7653, 3.8668, 1.7983, 0.6796],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  75  59  80  37  85 139  60  46  54  73  30  56  45
  41  52 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  90 143  32  47 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 314 547 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3577, 0.6645, 1.1682, 1.2394, 0.9267, 0.8863, 0.6671, 0.7322, 0.6621,
        1.2526, 0.8905, 0.6304, 1.0993, 1.4921, 0.8424, 1.9556, 0.7307, 0.6102,
        1.5143, 2.0479, 1.2394, 0.8151, 0.9525, 1.1472, 1.3577, 1.0993, 1.9556,
        1.0573, 0.8069, 1.3411, 1.6406, 1.4500, 1.1682, 2.3332, 1.4111, 1.6693,
        1.7983, 1.4921, 0.7035, 0.8017, 0.7714, 0.7168, 0.8947, 1.0904, 0.8560,
        0.7221, 0.7991, 0.6158, 0.7450, 0.6164, 0.7966, 0.6960, 0.8043, 1.4921,
        0.7693, 0.7520, 0.7024, 0.7823, 0.6250, 0.6124, 0.7117, 1.3926, 0.6930,
        0.6970, 0.8359, 0.9267, 0.9873, 0.7633, 1.3411, 0.6509, 1.2947, 0.8017,
        0.7735, 0.8947, 0.9525, 1.3411, 1.7983, 0.6168, 0.6358, 0.8457, 1.0202,
        0.7966, 2.2083, 1.6132, 0.6370, 0.7893, 0.8359, 0.8123, 1.2022, 1.1370,
        0.6873, 0.7893, 0.7384, 0.6705, 0.8096, 0.6804, 0.8043, 0.6804, 1.2394,
        0.6343, 0.6098, 0.6960, 0.6236, 0.6157, 0.6920, 0.7433, 0.9580, 0.8096,
        1.6693, 1.0495, 0.7520, 0.6838, 0.6275, 0.6220, 0.7633, 0.6425, 1.1272,
        0.6203, 1.2661, 0.8595, 0.6220, 0.6269, 0.7653, 3.8669, 1.7983, 0.6796],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  75  59  80  37  85 139  60  46  54  73  30  56  45
  41  51 198 141 154 187 113  81 123 183 142 426 168 420 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  60 269  63 141
 153 113 101  60  41 415 309 126  90 143  32  47 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 315 547 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3575, 0.6644, 1.1680, 1.2392, 0.9265, 0.8862, 0.6670, 0.7320, 0.6620,
        1.2523, 0.8903, 0.6303, 1.0991, 1.4918, 0.8422, 1.9553, 0.7305, 0.6101,
        1.5141, 2.0476, 1.2392, 0.8150, 0.9523, 1.1470, 1.3575, 1.0991, 1.9553,
        1.0571, 0.8068, 1.3409, 1.6403, 1.4498, 1.1680, 2.3327, 1.4108, 1.6690,
        1.7980, 1.5141, 0.7034, 0.8015, 0.7713, 0.7166, 0.8945, 1.0902, 0.8558,
        0.7220, 0.7990, 0.6157, 0.7449, 0.6163, 0.7964, 0.6959, 0.8041, 1.4918,
        0.7692, 0.7519, 0.7023, 0.7822, 0.6248, 0.6123, 0.7116, 1.3924, 0.6929,
        0.6969, 0.8358, 0.9265, 0.9872, 0.7632, 1.3409, 0.6508, 1.2944, 0.8015,
        0.7734, 0.8945, 0.9523, 1.3409, 1.7980, 0.6167, 0.6357, 0.8455, 1.0201,
        0.7964, 2.2079, 1.6129, 0.6369, 0.7891, 0.8358, 0.8122, 1.2020, 1.1368,
        0.6872, 0.7891, 0.7383, 0.6704, 0.8094, 0.6803, 0.8041, 0.6803, 1.2392,
        0.6340, 0.6097, 0.6959, 0.6234, 0.6156, 0.6919, 0.7432, 0.9578, 0.8094,
        1.6690, 1.0493, 0.7519, 0.6837, 0.6274, 0.6219, 0.7632, 0.6424, 1.1270,
        0.6202, 1.2659, 0.8594, 0.6219, 0.6268, 0.7651, 3.8662, 1.7980, 0.6795],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  75  59  80  37  85 139  60  46  54  73  30  57  45
  41  51 198 141 154 187 113  81 123 183 142 426 168 419 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  61 269  63 141
 153 113 101  60  40 415 309 126  90 143  32  47 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 315 547 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3574, 0.6644, 1.1680, 1.2392, 0.9265, 0.8862, 0.6670, 0.7320, 0.6619,
        1.2523, 0.8903, 0.6303, 1.0991, 1.4918, 0.8422, 1.9552, 0.7305, 0.6101,
        1.5141, 2.0475, 1.2392, 0.8149, 0.9523, 1.1469, 1.3574, 1.0991, 1.9552,
        1.0571, 0.8067, 1.3409, 1.6403, 1.4497, 1.1680, 2.3327, 1.3924, 1.6690,
        1.7980, 1.5141, 0.7034, 0.8015, 0.7713, 0.7166, 0.8945, 1.0902, 0.8558,
        0.7220, 0.7989, 0.6157, 0.7449, 0.6163, 0.7964, 0.6959, 0.8041, 1.4918,
        0.7692, 0.7518, 0.7022, 0.7822, 0.6248, 0.6123, 0.7116, 1.3924, 0.6929,
        0.6969, 0.8358, 0.9265, 0.9872, 0.7631, 1.3249, 0.6508, 1.2944, 0.8015,
        0.7734, 0.8945, 0.9523, 1.3409, 1.8343, 0.6167, 0.6357, 0.8455, 1.0200,
        0.7964, 2.2079, 1.6129, 0.6369, 0.7891, 0.8358, 0.8122, 1.2020, 1.1368,
        0.6872, 0.7891, 0.7383, 0.6704, 0.8094, 0.6803, 0.8041, 0.6803, 1.2392,
        0.6339, 0.6097, 0.6959, 0.6234, 0.6155, 0.6919, 0.7432, 0.9578, 0.8094,
        1.6690, 1.0493, 0.7518, 0.6836, 0.6274, 0.6218, 0.7631, 0.6424, 1.1270,
        0.6201, 1.2659, 0.8594, 0.6218, 0.6268, 0.7651, 3.8661, 1.7980, 0.6794],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  75  59  80  37  86 139  60  46  54  73  30  57  45
  41  51 198 141 154 187 113  81 123 183 142 426 168 418 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  62 269  63 141
 153 113 101  60  40 415 309 126  90 143  32  48 305 146 129 137  70  76
 214 146 172 235 138 222 140 222  67 315 547 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 385  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3580, 0.6647, 1.1685, 1.2396, 0.9268, 0.8865, 0.6672, 0.7323, 0.6622,
        1.2528, 0.8907, 0.6305, 1.0995, 1.4924, 0.8425, 1.9560, 0.7308, 0.6103,
        1.5147, 2.0483, 1.2396, 0.8153, 0.9527, 1.1474, 1.3580, 1.0995, 1.9560,
        1.0497, 0.8071, 1.3414, 1.6410, 1.4503, 1.1685, 2.3336, 1.3929, 1.6696,
        1.7987, 1.5147, 0.7036, 0.8018, 0.7716, 0.7169, 0.8949, 1.0907, 0.8561,
        0.7222, 0.7993, 0.6160, 0.7451, 0.6167, 0.7967, 0.6961, 0.8044, 1.4924,
        0.7695, 0.7521, 0.7025, 0.7825, 0.6251, 0.6125, 0.7118, 1.3929, 0.6931,
        0.6972, 0.8361, 0.9268, 0.9875, 0.7634, 1.3099, 0.6510, 1.2949, 0.8018,
        0.7737, 0.8949, 0.9527, 1.3414, 1.8350, 0.6170, 0.6359, 0.8459, 1.0205,
        0.7967, 2.2087, 1.5872, 0.6372, 0.7894, 0.8361, 0.8125, 1.2025, 1.1373,
        0.6875, 0.7894, 0.7386, 0.6706, 0.8097, 0.6805, 0.8044, 0.6805, 1.2396,
        0.6342, 0.6099, 0.6961, 0.6237, 0.6158, 0.6922, 0.7435, 0.9582, 0.8097,
        1.6696, 1.0497, 0.7521, 0.6839, 0.6276, 0.6221, 0.7634, 0.6426, 1.1274,
        0.6204, 1.2664, 0.8597, 0.6221, 0.6270, 0.7654, 3.8677, 1.7987, 0.6797],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  74  59  80  37  86 139  60  46  54  73  30  57  45
  41  51 198 141 154 187 113  81 123 183 142 426 168 417 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  63 269  63 141
 153 113 101  60  40 415 309 126  90 143  32  49 305 146 129 137  70  76
 214 146 173 235 138 222 140 222  67 315 547 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 384  65 122 373 345 157  17  41 223]
CBFL per class weights: tensor([1.3583, 0.6648, 1.1688, 1.2399, 0.9271, 0.8867, 0.6674, 0.7325, 0.6624,
        1.2531, 0.8909, 0.6307, 1.0998, 1.4927, 0.8428, 1.9565, 0.7310, 0.6104,
        1.5150, 2.0489, 1.2399, 0.8155, 0.9529, 1.1581, 1.3583, 1.0998, 1.9565,
        1.0500, 0.8073, 1.3417, 1.6414, 1.4507, 1.1688, 2.3342, 1.3933, 1.6701,
        1.7991, 1.5150, 0.7038, 0.8020, 0.7718, 0.7171, 0.8951, 1.0909, 0.8564,
        0.7224, 0.7995, 0.6161, 0.7453, 0.6169, 0.7969, 0.6963, 0.8046, 1.4927,
        0.7697, 0.7523, 0.7027, 0.7827, 0.6252, 0.6127, 0.7120, 1.3933, 0.6933,
        0.6973, 0.8363, 0.9271, 0.9878, 0.7636, 1.2952, 0.6512, 1.2952, 0.8020,
        0.7739, 0.8951, 0.9529, 1.3417, 1.8355, 0.6171, 0.6361, 0.8461, 1.0207,
        0.7969, 2.2093, 1.5624, 0.6373, 0.7896, 0.8363, 0.8127, 1.2028, 1.1376,
        0.6876, 0.7896, 0.7371, 0.6708, 0.8099, 0.6807, 0.8046, 0.6807, 1.2399,
        0.6343, 0.6101, 0.6963, 0.6238, 0.6159, 0.6923, 0.7436, 0.9584, 0.8099,
        1.6701, 1.0500, 0.7523, 0.6841, 0.6278, 0.6222, 0.7636, 0.6428, 1.1277,
        0.6207, 1.2667, 0.8599, 0.6222, 0.6272, 0.7656, 3.8686, 1.7991, 0.6799],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  74  59  80  37  86 139  60  46  54  73  30  57  45
  41  51 197 141 154 187 113  81 123 183 142 426 168 417 143 205 140  52
 155 164 199 149 355 477 191  57 208 204 129 106  95 158  63 269  63 141
 153 113 101  60  40 415 309 126  90 143  32  50 305 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 209 169 100 138
  45  86 164 218 342 373 158 289  77 384  65 122 373 345 157  17  42 223]
CBFL per class weights: tensor([1.3589, 0.6651, 1.1693, 1.2405, 0.9275, 0.8872, 0.6677, 0.7328, 0.6627,
        1.2537, 0.8913, 0.6310, 1.1003, 1.4934, 0.8431, 1.9574, 0.7313, 0.6107,
        1.5157, 2.0498, 1.2405, 0.8158, 0.9533, 1.1586, 1.3589, 1.1003, 1.9574,
        1.0505, 0.8076, 1.3423, 1.6421, 1.4513, 1.1693, 2.3353, 1.3939, 1.6708,
        1.7999, 1.5157, 0.7053, 0.8024, 0.7721, 0.7174, 0.8955, 1.0914, 0.8567,
        0.7227, 0.7998, 0.6164, 0.7457, 0.6172, 0.7973, 0.6966, 0.8050, 1.4934,
        0.7700, 0.7527, 0.7030, 0.7830, 0.6255, 0.6129, 0.7123, 1.3939, 0.6936,
        0.6977, 0.8367, 0.9275, 0.9882, 0.7640, 1.2958, 0.6515, 1.2958, 0.8024,
        0.7742, 0.8955, 0.9533, 1.3423, 1.8363, 0.6174, 0.6364, 0.8465, 1.0212,
        0.7973, 2.2103, 1.5389, 0.6376, 0.7900, 0.8367, 0.8131, 1.2033, 1.1381,
        0.6870, 0.7900, 0.7375, 0.6711, 0.8103, 0.6810, 0.8050, 0.6810, 1.2405,
        0.6346, 0.6104, 0.6966, 0.6241, 0.6162, 0.6926, 0.7440, 0.9588, 0.8103,
        1.6708, 1.0505, 0.7527, 0.6844, 0.6281, 0.6225, 0.7640, 0.6431, 1.1282,
        0.6210, 1.2673, 0.8603, 0.6225, 0.6274, 0.7660, 3.8704, 1.7653, 0.6802],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 177 534
  51  35  67 136 101  74  60  80  37  86 139  60  46  54  73  30  57  45
  41  51 197 141 154 187 113  81 123 183 142 426 168 417 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 106  94 158  63 269  63 141
 153 113 101  60  40 415 309 126  90 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 209 169 100 138
  45  86 164 218 342 374 158 289  77 384  65 122 373 345 157  17  42 223]
CBFL per class weights: tensor([1.3590, 0.6652, 1.1693, 1.2406, 0.9275, 0.8872, 0.6677, 0.7329, 0.6627,
        1.2537, 0.8913, 0.6310, 1.1003, 1.4935, 0.8432, 1.9575, 0.7314, 0.6107,
        1.5158, 2.0499, 1.2406, 0.8159, 0.9534, 1.1586, 1.3424, 1.1003, 1.9575,
        1.0505, 0.8077, 1.3424, 1.6422, 1.4514, 1.1693, 2.3353, 1.3939, 1.6709,
        1.8000, 1.5158, 0.7053, 0.8024, 0.7721, 0.7174, 0.8955, 1.0915, 0.8568,
        0.7228, 0.7998, 0.6164, 0.7457, 0.6172, 0.7973, 0.6967, 0.8050, 1.4935,
        0.7701, 0.7527, 0.7030, 0.7830, 0.6255, 0.6130, 0.7124, 1.4124, 0.6936,
        0.6977, 0.8367, 0.9275, 0.9946, 0.7640, 1.2959, 0.6515, 1.2959, 0.8024,
        0.7743, 0.8955, 0.9534, 1.3424, 1.8364, 0.6174, 0.6364, 0.8465, 1.0212,
        0.7973, 2.2103, 1.5158, 0.6376, 0.7900, 0.8367, 0.8131, 1.2154, 1.1381,
        0.6871, 0.7900, 0.7375, 0.6711, 0.8103, 0.6810, 0.8050, 0.6810, 1.2406,
        0.6347, 0.6104, 0.6967, 0.6241, 0.6162, 0.6927, 0.7440, 0.9589, 0.8103,
        1.6709, 1.0505, 0.7527, 0.6844, 0.6281, 0.6224, 0.7640, 0.6431, 1.1283,
        0.6210, 1.2673, 0.8603, 0.6225, 0.6275, 0.7660, 3.8705, 1.7654, 0.6802],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 176 534
  51  35  67 136 101  75  60  80  37  86 139  60  46  54  73  30  57  45
  41  51 197 141 154 187 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 106  94 158  64 269  63 141
 153 113 101  60  39 415 309 126  90 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 209 169 100 138
  45  86 164 218 342 374 158 289  77 384  65 122 374 345 157  17  42 223]
CBFL per class weights: tensor([1.3588, 0.6651, 1.1692, 1.2404, 0.9274, 0.8871, 0.6677, 0.7328, 0.6626,
        1.2536, 0.8912, 0.6309, 1.1002, 1.4933, 0.8431, 1.9572, 0.7328, 0.6107,
        1.5156, 2.0496, 1.2404, 0.8158, 0.9532, 1.1481, 1.3422, 1.1002, 1.9572,
        1.0504, 0.8076, 1.3422, 1.6420, 1.4512, 1.1692, 2.3351, 1.3938, 1.6707,
        1.7998, 1.5156, 0.7052, 0.8023, 0.7721, 0.7173, 0.8954, 1.0913, 0.8567,
        0.7227, 0.7998, 0.6163, 0.7456, 0.6173, 0.7972, 0.6966, 0.8049, 1.4933,
        0.7700, 0.7526, 0.7030, 0.7830, 0.6255, 0.6129, 0.7123, 1.4122, 0.6936,
        0.6976, 0.8366, 0.9274, 0.9944, 0.7639, 1.2812, 0.6514, 1.2957, 0.8023,
        0.7742, 0.8954, 0.9532, 1.3422, 1.8744, 0.6173, 0.6363, 0.8464, 1.0211,
        0.7972, 2.2101, 1.5156, 0.6376, 0.7899, 0.8366, 0.8130, 1.2152, 1.1380,
        0.6870, 0.7899, 0.7374, 0.6711, 0.8102, 0.6810, 0.8049, 0.6810, 1.2404,
        0.6346, 0.6103, 0.6966, 0.6241, 0.6162, 0.6926, 0.7439, 0.9588, 0.8102,
        1.6707, 1.0504, 0.7526, 0.6843, 0.6280, 0.6223, 0.7639, 0.6430, 1.1281,
        0.6209, 1.2672, 0.8602, 0.6223, 0.6274, 0.7659, 3.8701, 1.7652, 0.6801],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 176 534
  51  35  67 136 101  75  60  80  37  86 139  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 106  94 158  64 269  63 141
 153 113 101  60  39 415 309 127  90 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 209 169 100 138
  45  86 164 218 342 374 158 289  78 384  65 122 374 345 158  17  42 223]
CBFL per class weights: tensor([1.3589, 0.6651, 1.1693, 1.2405, 0.9275, 0.8872, 0.6677, 0.7328, 0.6627,
        1.2537, 0.8913, 0.6310, 1.1003, 1.4934, 0.8432, 1.9574, 0.7328, 0.6107,
        1.5157, 2.0498, 1.2405, 0.8158, 0.9533, 1.1482, 1.3424, 1.1003, 1.9574,
        1.0505, 0.8076, 1.3424, 1.6421, 1.4514, 1.1693, 2.3353, 1.3939, 1.6708,
        1.8000, 1.5157, 0.7064, 0.8024, 0.7721, 0.7187, 0.8955, 1.0914, 0.8568,
        0.7228, 0.7998, 0.6164, 0.7457, 0.6173, 0.7973, 0.6966, 0.8050, 1.4934,
        0.7700, 0.7527, 0.7030, 0.7830, 0.6255, 0.6130, 0.7124, 1.4124, 0.6936,
        0.6977, 0.8367, 0.9275, 0.9945, 0.7640, 1.2814, 0.6515, 1.2959, 0.8024,
        0.7742, 0.8955, 0.9533, 1.3424, 1.8746, 0.6174, 0.6364, 0.8432, 1.0212,
        0.7973, 2.2103, 1.5157, 0.6376, 0.7900, 0.8367, 0.8131, 1.2154, 1.1381,
        0.6870, 0.7900, 0.7375, 0.6711, 0.8103, 0.6810, 0.8050, 0.6810, 1.2405,
        0.6346, 0.6104, 0.6966, 0.6241, 0.6162, 0.6927, 0.7440, 0.9588, 0.8103,
        1.6708, 1.0505, 0.7527, 0.6844, 0.6281, 0.6224, 0.7640, 0.6431, 1.1187,
        0.6210, 1.2673, 0.8603, 0.6224, 0.6275, 0.7640, 3.8704, 1.7653, 0.6802],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 176 533
  51  35  67 136 101  75  60  80  37  86 139  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 106  94 158  65 269  63 141
 153 113 101  60  39 415 309 127  89 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 209 169 100 138
  45  86 164 218 342 374 158 289  78 384  65 122 374 345 159  17  43 223]
CBFL per class weights: tensor([1.3594, 0.6654, 1.1697, 1.2409, 0.9278, 0.8875, 0.6679, 0.7331, 0.6629,
        1.2541, 0.8916, 0.6312, 1.1006, 1.4939, 0.8434, 1.9581, 0.7331, 0.6110,
        1.5162, 2.0505, 1.2409, 0.8161, 0.9537, 1.1486, 1.3428, 1.1006, 1.9581,
        1.0508, 0.8079, 1.3428, 1.6427, 1.4518, 1.1697, 2.3361, 1.3944, 1.6714,
        1.8006, 1.5162, 0.7066, 0.8027, 0.7724, 0.7190, 0.8958, 1.0918, 0.8570,
        0.7230, 0.8001, 0.6166, 0.7459, 0.6175, 0.7976, 0.6969, 0.8053, 1.4939,
        0.7703, 0.7529, 0.7033, 0.7833, 0.6257, 0.6132, 0.7126, 1.4128, 0.6939,
        0.6979, 0.8370, 0.9278, 0.9949, 0.7642, 1.2677, 0.6517, 1.2963, 0.8027,
        0.7745, 0.8958, 0.9537, 1.3428, 1.8752, 0.6176, 0.6366, 0.8434, 1.0286,
        0.7976, 2.2110, 1.5162, 0.6378, 0.7903, 0.8370, 0.8133, 1.2158, 1.1385,
        0.6873, 0.7903, 0.7377, 0.6714, 0.8106, 0.6812, 0.8053, 0.6812, 1.2409,
        0.6349, 0.6106, 0.6969, 0.6243, 0.6164, 0.6929, 0.7442, 0.9592, 0.8106,
        1.6714, 1.0508, 0.7529, 0.6846, 0.6283, 0.6226, 0.7642, 0.6433, 1.1190,
        0.6212, 1.2677, 0.8606, 0.6226, 0.6277, 0.7623, 3.8717, 1.7329, 0.6804],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 176 533
  51  35  67 136 101  75  60  80  37  86 139  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 106  94 158  65 269  63 141
 153 113 101  60  39 415 309 127  89 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 428 210 169 100 138
  45  86 164 218 342 374 158 289  78 384  65 122 374 345 159  17  43 223]
CBFL per class weights: tensor([1.3594, 0.6654, 1.1697, 1.2410, 0.9278, 0.8875, 0.6680, 0.7331, 0.6629,
        1.2541, 0.8916, 0.6312, 1.1007, 1.4939, 0.8434, 1.9581, 0.7331, 0.6110,
        1.5163, 2.0505, 1.2410, 0.8161, 0.9537, 1.1486, 1.3428, 1.1007, 1.9581,
        1.0508, 0.8079, 1.3428, 1.6427, 1.4519, 1.1697, 2.3361, 1.3944, 1.6714,
        1.8006, 1.5163, 0.7066, 0.8027, 0.7724, 0.7190, 0.8958, 1.0918, 0.8570,
        0.7230, 0.8001, 0.6166, 0.7459, 0.6175, 0.7976, 0.6969, 0.8053, 1.4939,
        0.7703, 0.7529, 0.7033, 0.7833, 0.6257, 0.6132, 0.7126, 1.4128, 0.6939,
        0.6979, 0.8370, 0.9278, 0.9949, 0.7643, 1.2677, 0.6517, 1.2963, 0.8027,
        0.7745, 0.8958, 0.9537, 1.3428, 1.8752, 0.6176, 0.6366, 0.8434, 1.0286,
        0.7976, 2.2111, 1.5163, 0.6378, 0.7903, 0.8370, 0.8133, 1.2158, 1.1385,
        0.6873, 0.7903, 0.7377, 0.6714, 0.8106, 0.6813, 0.8053, 0.6813, 1.2410,
        0.6349, 0.6106, 0.6969, 0.6243, 0.6164, 0.6919, 0.7442, 0.9592, 0.8106,
        1.6714, 1.0508, 0.7529, 0.6846, 0.6283, 0.6226, 0.7643, 0.6433, 1.1191,
        0.6212, 1.2677, 0.8606, 0.6226, 0.6277, 0.7623, 3.8717, 1.7329, 0.6804],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 176 533
  51  35  67 136 101  75  61  80  37  86 140  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 415 309 127  89 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  86 164 218 342 374 158 289  78 384  65 122 374 345 159  17  43 223]
CBFL per class weights: tensor([1.3596, 0.6654, 1.1698, 1.2411, 0.9279, 0.8876, 0.6680, 0.7332, 0.6630,
        1.2543, 0.8917, 0.6313, 1.1008, 1.4941, 0.8435, 1.9583, 0.7332, 0.6110,
        1.5164, 2.0507, 1.2411, 0.8162, 0.9538, 1.1487, 1.3269, 1.1008, 1.9583,
        1.0510, 0.8054, 1.3430, 1.6429, 1.4520, 1.1698, 2.3363, 1.3945, 1.6716,
        1.8008, 1.5164, 0.7067, 0.8028, 0.7725, 0.7190, 0.8959, 1.0919, 0.8571,
        0.7231, 0.8002, 0.6167, 0.7460, 0.6176, 0.7977, 0.6970, 0.8054, 1.4941,
        0.7704, 0.7530, 0.7033, 0.7834, 0.6258, 0.6132, 0.7127, 1.4130, 0.6939,
        0.6980, 0.8371, 0.9329, 0.9950, 0.7643, 1.2679, 0.6518, 1.2964, 0.8028,
        0.7746, 0.8959, 0.9538, 1.3430, 1.8754, 0.6177, 0.6367, 0.8435, 1.0287,
        0.7977, 2.2113, 1.5164, 0.6379, 0.7904, 0.8371, 0.8134, 1.2159, 1.1386,
        0.6874, 0.7904, 0.7378, 0.6714, 0.8107, 0.6813, 0.8054, 0.6813, 1.2411,
        0.6349, 0.6107, 0.6970, 0.6244, 0.6166, 0.6920, 0.7443, 0.9593, 0.8107,
        1.6716, 1.0510, 0.7530, 0.6847, 0.6284, 0.6227, 0.7643, 0.6434, 1.1192,
        0.6212, 1.2679, 0.8607, 0.6227, 0.6277, 0.7624, 3.8722, 1.7331, 0.6805],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 415 309 127  89 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 164 218 342 374 158 289  78 384  65 122 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3596, 0.6655, 1.1699, 1.2411, 0.9280, 0.8876, 0.6681, 0.7332, 0.6630,
        1.2543, 0.8917, 0.6313, 1.1008, 1.4942, 0.8436, 1.9584, 0.7347, 0.6111,
        1.5165, 2.0508, 1.2411, 0.8163, 0.9538, 1.1488, 1.3115, 1.1008, 1.9584,
        1.0510, 0.8054, 1.3430, 1.6429, 1.4521, 1.1699, 2.3365, 1.3946, 1.6717,
        1.8009, 1.5165, 0.7068, 0.8028, 0.7725, 0.7191, 0.8960, 1.0920, 0.8572,
        0.7231, 0.8002, 0.6167, 0.7461, 0.6176, 0.7977, 0.6970, 0.8054, 1.4942,
        0.7704, 0.7531, 0.7034, 0.7834, 0.6258, 0.6133, 0.7127, 1.4131, 0.6940,
        0.6980, 0.8371, 0.9329, 0.9950, 0.7644, 1.2679, 0.6518, 1.2965, 0.8028,
        0.7746, 0.8960, 0.9538, 1.3430, 1.8755, 0.6177, 0.6367, 0.8436, 1.0288,
        0.7977, 2.2114, 1.5165, 0.6379, 0.7904, 0.8371, 0.8135, 1.2160, 1.1387,
        0.6874, 0.7904, 0.7379, 0.6715, 0.8107, 0.6814, 0.8054, 0.6814, 1.2411,
        0.6350, 0.6107, 0.6970, 0.6244, 0.6166, 0.6920, 0.7444, 0.9593, 0.8107,
        1.6717, 1.0588, 0.7531, 0.6847, 0.6284, 0.6227, 0.7644, 0.6434, 1.1192,
        0.6213, 1.2679, 0.8607, 0.6225, 0.6278, 0.7624, 3.8724, 1.7332, 0.6805],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 415 309 127  89 143  32  51 305 146 129 137  69  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 164 218 342 374 158 289  78 384  65 122 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3596, 0.6655, 1.1699, 1.2411, 0.9280, 0.8876, 0.6681, 0.7332, 0.6630,
        1.2543, 0.8917, 0.6313, 1.1008, 1.4942, 0.8436, 1.9584, 0.7347, 0.6111,
        1.5165, 2.0508, 1.2411, 0.8163, 0.9538, 1.1488, 1.3115, 1.1008, 1.9584,
        1.0510, 0.8054, 1.3430, 1.6429, 1.4521, 1.1699, 2.3365, 1.3946, 1.6717,
        1.8009, 1.5165, 0.7068, 0.8028, 0.7725, 0.7191, 0.8960, 1.0920, 0.8572,
        0.7231, 0.8002, 0.6167, 0.7461, 0.6176, 0.7977, 0.6970, 0.8054, 1.4942,
        0.7704, 0.7531, 0.7034, 0.7834, 0.6258, 0.6133, 0.7127, 1.4131, 0.6940,
        0.6980, 0.8371, 0.9329, 0.9950, 0.7644, 1.2679, 0.6518, 1.2965, 0.8028,
        0.7746, 0.8960, 0.9538, 1.3430, 1.8755, 0.6177, 0.6367, 0.8436, 1.0288,
        0.7977, 2.2114, 1.5165, 0.6379, 0.7904, 0.8371, 0.8135, 1.2160, 1.1387,
        0.6874, 0.7904, 0.7379, 0.6715, 0.8107, 0.6814, 0.8054, 0.6814, 1.2411,
        0.6350, 0.6107, 0.6970, 0.6244, 0.6166, 0.6920, 0.7444, 0.9593, 0.8107,
        1.6717, 1.0588, 0.7531, 0.6847, 0.6284, 0.6227, 0.7644, 0.6434, 1.1192,
        0.6213, 1.2679, 0.8607, 0.6225, 0.6278, 0.7624, 3.8724, 1.7332, 0.6805],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  30  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 127  89 143  32  51 305 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 164 218 342 374 158 289  78 384  65 122 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3597, 0.6655, 1.1700, 1.2413, 0.9281, 0.8877, 0.6681, 0.7333, 0.6631,
        1.2545, 0.8918, 0.6314, 1.1009, 1.4943, 0.8437, 1.9586, 0.7348, 0.6111,
        1.5166, 2.0510, 1.2413, 0.8163, 0.9539, 1.1489, 1.3116, 1.1009, 1.9586,
        1.0511, 0.8055, 1.3432, 1.6431, 1.4522, 1.1700, 2.3367, 1.3947, 1.6718,
        1.8010, 1.5166, 0.7068, 0.8029, 0.7726, 0.7191, 0.8961, 1.0921, 0.8573,
        0.7232, 0.8003, 0.6168, 0.7461, 0.6177, 0.7978, 0.6971, 0.8055, 1.4943,
        0.7705, 0.7531, 0.7034, 0.7835, 0.6259, 0.6133, 0.7128, 1.4132, 0.6940,
        0.6981, 0.8372, 0.9330, 0.9951, 0.7644, 1.2681, 0.6519, 1.2966, 0.8029,
        0.7747, 0.8961, 0.9539, 1.3432, 1.8757, 0.6179, 0.6368, 0.8437, 1.0289,
        0.7978, 2.2116, 1.5166, 0.6380, 0.7905, 0.8372, 0.8135, 1.2040, 1.1388,
        0.6875, 0.7905, 0.7379, 0.6715, 0.8108, 0.6814, 0.8055, 0.6814, 1.2413,
        0.6350, 0.6108, 0.6971, 0.6245, 0.6167, 0.6921, 0.7444, 0.9594, 0.8108,
        1.6718, 1.0589, 0.7531, 0.6848, 0.6284, 0.6228, 0.7644, 0.6435, 1.1193,
        0.6213, 1.2681, 0.8608, 0.6226, 0.6278, 0.7625, 3.8727, 1.7334, 0.6806],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 127  89 143  32  51 305 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 164 218 342 374 158 289  78 384  65 122 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3604, 0.6659, 1.1706, 1.2419, 0.9285, 0.8881, 0.6685, 0.7337, 0.6634,
        1.2551, 0.8923, 0.6317, 1.1015, 1.4951, 0.8441, 1.9596, 0.7352, 0.6114,
        1.5174, 2.0521, 1.2419, 0.8167, 0.9544, 1.1495, 1.3123, 1.1015, 1.9596,
        1.0516, 0.8059, 1.3438, 1.6439, 1.4530, 1.1706, 2.2733, 1.3955, 1.6727,
        1.8019, 1.5174, 0.7072, 0.8033, 0.7730, 0.7195, 0.8965, 1.0926, 0.8577,
        0.7236, 0.8007, 0.6171, 0.7465, 0.6180, 0.7982, 0.6974, 0.8059, 1.4951,
        0.7709, 0.7535, 0.7038, 0.7839, 0.6262, 0.6136, 0.7131, 1.4139, 0.6944,
        0.6984, 0.8376, 0.9335, 0.9956, 0.7648, 1.2687, 0.6522, 1.2973, 0.8033,
        0.7751, 0.8965, 0.9544, 1.3438, 1.8767, 0.6182, 0.6371, 0.8441, 1.0294,
        0.7982, 2.2128, 1.5174, 0.6383, 0.7909, 0.8376, 0.8140, 1.2047, 1.1394,
        0.6878, 0.7909, 0.7383, 0.6719, 0.8112, 0.6818, 0.8059, 0.6818, 1.2419,
        0.6353, 0.6111, 0.6974, 0.6248, 0.6170, 0.6925, 0.7448, 0.9599, 0.8112,
        1.6727, 1.0594, 0.7535, 0.6852, 0.6288, 0.6231, 0.7648, 0.6438, 1.1199,
        0.6217, 1.2687, 0.8613, 0.6229, 0.6281, 0.7629, 3.8747, 1.7343, 0.6810],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  51 196 141 154 186 113  81 123 183 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 164 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3604, 0.6659, 1.1706, 1.2419, 0.9285, 0.8881, 0.6685, 0.7337, 0.6634,
        1.2551, 0.8923, 0.6317, 1.1015, 1.4951, 0.8441, 1.9596, 0.7352, 0.6114,
        1.5174, 2.0521, 1.2419, 0.8167, 0.9544, 1.1495, 1.3123, 1.1015, 1.9596,
        1.0516, 0.8059, 1.3438, 1.6439, 1.4530, 1.1706, 2.2733, 1.3954, 1.6727,
        1.8019, 1.5174, 0.7072, 0.8033, 0.7730, 0.7195, 0.8965, 1.0926, 0.8577,
        0.7236, 0.8007, 0.6171, 0.7465, 0.6180, 0.7982, 0.6974, 0.8059, 1.4951,
        0.7709, 0.7535, 0.7038, 0.7839, 0.6262, 0.6136, 0.7131, 1.4139, 0.6944,
        0.6984, 0.8376, 0.9335, 0.9956, 0.7648, 1.2687, 0.6522, 1.2973, 0.8033,
        0.7751, 0.8965, 0.9544, 1.3438, 1.8767, 0.6182, 0.6371, 0.8408, 1.0294,
        0.7982, 2.2127, 1.5174, 0.6386, 0.7909, 0.8376, 0.8140, 1.2047, 1.1393,
        0.6878, 0.7909, 0.7383, 0.6719, 0.8112, 0.6818, 0.8059, 0.6818, 1.2419,
        0.6353, 0.6111, 0.6974, 0.6248, 0.6170, 0.6925, 0.7448, 0.9599, 0.8112,
        1.6727, 1.0594, 0.7535, 0.6852, 0.6288, 0.6231, 0.7648, 0.6438, 1.1199,
        0.6217, 1.2687, 0.8649, 0.6228, 0.6281, 0.7629, 3.8747, 1.7343, 0.6810],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  51 196 141 154 186 113  81 123 182 142 426 168 416 143 205 140  52
 155 164 199 149 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 165 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3604, 0.6659, 1.1706, 1.2419, 0.9285, 0.8881, 0.6685, 0.7337, 0.6634,
        1.2551, 0.8923, 0.6317, 1.1015, 1.4951, 0.8441, 1.9596, 0.7352, 0.6114,
        1.5174, 2.0521, 1.2419, 0.8167, 0.9544, 1.1495, 1.3123, 1.1015, 1.9596,
        1.0516, 0.8059, 1.3438, 1.6439, 1.4530, 1.1706, 2.2733, 1.3955, 1.6727,
        1.8019, 1.5174, 0.7072, 0.8033, 0.7730, 0.7195, 0.8965, 1.0926, 0.8577,
        0.7249, 0.8007, 0.6171, 0.7465, 0.6180, 0.7982, 0.6974, 0.8059, 1.4951,
        0.7709, 0.7535, 0.7038, 0.7839, 0.6262, 0.6136, 0.7131, 1.4139, 0.6944,
        0.6984, 0.8376, 0.9335, 0.9956, 0.7648, 1.2687, 0.6522, 1.2973, 0.8033,
        0.7751, 0.8965, 0.9544, 1.3438, 1.8767, 0.6182, 0.6371, 0.8408, 1.0294,
        0.7982, 2.2127, 1.5174, 0.6386, 0.7909, 0.8376, 0.8140, 1.2047, 1.1394,
        0.6878, 0.7909, 0.7383, 0.6719, 0.8112, 0.6818, 0.8059, 0.6818, 1.2419,
        0.6353, 0.6111, 0.6974, 0.6248, 0.6170, 0.6925, 0.7448, 0.9599, 0.8112,
        1.6727, 1.0594, 0.7517, 0.6852, 0.6288, 0.6231, 0.7648, 0.6438, 1.1199,
        0.6217, 1.2687, 0.8649, 0.6228, 0.6281, 0.7629, 3.8747, 1.7343, 0.6810],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  50 196 141 154 186 113  81 123 182 142 426 168 416 143 205 140  52
 155 164 199 150 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  85 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3602, 0.6658, 1.1704, 1.2417, 0.9284, 0.8880, 0.6684, 0.7335, 0.6633,
        1.2549, 0.8922, 0.6316, 1.1013, 1.4949, 0.8440, 1.9593, 0.7351, 0.6113,
        1.5172, 2.0518, 1.2417, 0.8166, 0.9543, 1.1493, 1.3121, 1.1013, 1.9593,
        1.0515, 0.8058, 1.3436, 1.6437, 1.4527, 1.1704, 2.2729, 1.3952, 1.6724,
        1.8017, 1.5404, 0.7071, 0.8032, 0.7729, 0.7194, 0.8964, 1.0925, 0.8576,
        0.7248, 0.8006, 0.6170, 0.7464, 0.6179, 0.7981, 0.6973, 0.8058, 1.4949,
        0.7708, 0.7534, 0.7037, 0.7815, 0.6261, 0.6135, 0.7130, 1.4137, 0.6943,
        0.6983, 0.8375, 0.9333, 0.9955, 0.7647, 1.2685, 0.6521, 1.2971, 0.8032,
        0.7750, 0.8964, 0.9543, 1.3436, 1.8764, 0.6181, 0.6370, 0.8407, 1.0292,
        0.7981, 2.2124, 1.5172, 0.6385, 0.7908, 0.8375, 0.8138, 1.2045, 1.1392,
        0.6877, 0.7908, 0.7382, 0.6718, 0.8111, 0.6817, 0.8058, 0.6817, 1.2417,
        0.6353, 0.6110, 0.6973, 0.6247, 0.6169, 0.6923, 0.7447, 0.9598, 0.8111,
        1.6724, 1.0593, 0.7498, 0.6851, 0.6287, 0.6230, 0.7647, 0.6437, 1.1197,
        0.6216, 1.2685, 0.8648, 0.6227, 0.6281, 0.7628, 3.8741, 1.7340, 0.6809],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  50 196 141 154 186 113  81 123 182 142 426 168 416 143 205 140  52
 155 164 199 150 355 477 191  56 208 204 129 105  94 158  65 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 146 129 137  70  76
 215 146 173 235 138 222 140 222  67 315 546 205 363 427 210 169 100 138
  45  86 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3603, 0.6658, 1.1705, 1.2418, 0.9284, 0.8881, 0.6684, 0.7336, 0.6634,
        1.2550, 0.8922, 0.6316, 1.1014, 1.4949, 0.8440, 1.9594, 0.7351, 0.6114,
        1.5173, 2.0519, 1.2418, 0.8167, 0.9543, 1.1494, 1.3122, 1.1014, 1.9594,
        1.0515, 0.8058, 1.3437, 1.6438, 1.4528, 1.1705, 2.2731, 1.3953, 1.6725,
        1.8018, 1.5405, 0.7071, 0.8032, 0.7729, 0.7194, 0.8964, 1.0925, 0.8576,
        0.7249, 0.8006, 0.6170, 0.7464, 0.6179, 0.7981, 0.6973, 0.8058, 1.4949,
        0.7708, 0.7534, 0.7037, 0.7816, 0.6262, 0.6136, 0.7131, 1.4138, 0.6943,
        0.6984, 0.8376, 0.9334, 0.9955, 0.7648, 1.2686, 0.6522, 1.2972, 0.8032,
        0.7750, 0.8964, 0.9543, 1.3437, 1.8765, 0.6181, 0.6370, 0.8408, 1.0293,
        0.7981, 2.2125, 1.5173, 0.6386, 0.7908, 0.8376, 0.8139, 1.2046, 1.1392,
        0.6877, 0.7908, 0.7382, 0.6718, 0.8111, 0.6817, 0.8058, 0.6817, 1.2418,
        0.6353, 0.6110, 0.6973, 0.6248, 0.6169, 0.6924, 0.7448, 0.9598, 0.8111,
        1.6725, 1.0515, 0.7499, 0.6851, 0.6287, 0.6230, 0.7648, 0.6438, 1.1198,
        0.6216, 1.2686, 0.8648, 0.6227, 0.6281, 0.7628, 3.8744, 1.7341, 0.6809],
       device='cuda:0')
S real T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.464451 Loss T 0.098905 Method MME

Pred num ex per class (pseudo labels + labelled target examples):  [ 59 244  73  67 106 115 240 176 248  66 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  45
  41  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 158  66 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 146 129 137  70  76
 215 146 173 235 138 222 141 222  67 315 546 205 363 427 210 169 100 138
  45  86 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3605, 0.6659, 1.1706, 1.2419, 0.9286, 0.8882, 0.6685, 0.7337, 0.6634,
        1.2551, 0.8923, 0.6317, 1.1015, 1.4951, 0.8441, 1.9596, 0.7352, 0.6114,
        1.5174, 2.0521, 1.2419, 0.8168, 0.9544, 1.1495, 1.3123, 1.1015, 1.9596,
        1.0517, 0.8059, 1.3439, 1.6440, 1.4530, 1.1706, 2.2733, 1.3955, 1.6727,
        1.8020, 1.5407, 0.7072, 0.8033, 0.7730, 0.7195, 0.8965, 1.0927, 0.8577,
        0.7250, 0.8007, 0.6171, 0.7465, 0.6181, 0.7982, 0.6974, 0.8059, 1.4951,
        0.7709, 0.7553, 0.7038, 0.7817, 0.6262, 0.6136, 0.7132, 1.4140, 0.6944,
        0.6985, 0.8377, 0.9335, 0.9957, 0.7649, 1.2551, 0.6522, 1.2973, 0.8033,
        0.7751, 0.8965, 0.9544, 1.3439, 1.8767, 0.6182, 0.6371, 0.8408, 1.0294,
        0.7982, 2.2128, 1.5174, 0.6386, 0.7909, 0.8377, 0.8140, 1.2047, 1.1394,
        0.6878, 0.7909, 0.7383, 0.6719, 0.8112, 0.6818, 0.8033, 0.6818, 1.2419,
        0.6354, 0.6111, 0.6974, 0.6248, 0.6170, 0.6925, 0.7448, 0.9599, 0.8112,
        1.6727, 1.0517, 0.7500, 0.6852, 0.6288, 0.6231, 0.7649, 0.6438, 1.1199,
        0.6217, 1.2687, 0.8649, 0.6228, 0.6282, 0.7629, 3.8748, 1.7343, 0.6810],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 533
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  66 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 147 129 137  70  76
 215 146 173 235 138 222 141 222  67 315 546 205 363 427 210 169 100 138
  45  86 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3610, 0.6668, 1.1711, 1.2424, 0.9289, 0.8885, 0.6687, 0.7340, 0.6637,
        1.2692, 0.8927, 0.6320, 1.1020, 1.4957, 0.8444, 1.9604, 0.7355, 0.6117,
        1.5180, 2.0529, 1.2424, 0.8171, 0.9548, 1.1500, 1.3128, 1.1020, 1.9604,
        1.0521, 0.8062, 1.3444, 1.6446, 1.4536, 1.1711, 2.2742, 1.3960, 1.6446,
        1.7680, 1.5413, 0.7075, 0.8036, 0.7733, 0.7198, 0.8969, 1.0931, 0.8581,
        0.7252, 0.8010, 0.6173, 0.7468, 0.6183, 0.7985, 0.6977, 0.8062, 1.4957,
        0.7712, 0.7556, 0.7041, 0.7820, 0.6265, 0.6139, 0.7134, 1.4145, 0.6947,
        0.6987, 0.8380, 0.9339, 0.9961, 0.7671, 1.2556, 0.6525, 1.2978, 0.8036,
        0.7754, 0.8969, 0.9548, 1.3444, 1.8775, 0.6184, 0.6374, 0.8412, 1.0298,
        0.7985, 2.2137, 1.5180, 0.6389, 0.7888, 0.8380, 0.8143, 1.2052, 1.1398,
        0.6881, 0.7912, 0.7386, 0.6722, 0.8116, 0.6821, 0.8036, 0.6821, 1.2424,
        0.6356, 0.6113, 0.6977, 0.6251, 0.6172, 0.6927, 0.7451, 0.9603, 0.8116,
        1.6734, 1.0521, 0.7503, 0.6854, 0.6290, 0.6233, 0.7652, 0.6441, 1.1204,
        0.6219, 1.2692, 0.8653, 0.6230, 0.6284, 0.7632, 3.8763, 1.7350, 0.6812],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  62  80  37  86 140  60  46  54  73  31  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  67 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 147 129 137  70  76
 215 146 173 235 138 222 141 222  67 315 546 205 363 427 210 169 100 138
  45  86 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3612, 0.6669, 1.1712, 1.2425, 0.9290, 0.8886, 0.6688, 0.7340, 0.6638,
        1.2694, 0.8928, 0.6320, 1.1021, 1.4959, 0.8445, 1.9606, 0.7356, 0.6118,
        1.5182, 2.0532, 1.2425, 0.8172, 0.9549, 1.1501, 1.3130, 1.1021, 1.9606,
        1.0522, 0.8063, 1.3445, 1.6448, 1.4537, 1.1712, 2.2745, 1.3962, 1.6448,
        1.7682, 1.5415, 0.7076, 0.8037, 0.7734, 0.7199, 0.8970, 1.0932, 0.8581,
        0.7253, 0.8011, 0.6174, 0.7469, 0.6184, 0.7986, 0.6978, 0.8063, 1.4959,
        0.7713, 0.7557, 0.7042, 0.7821, 0.6265, 0.6139, 0.7135, 1.4147, 0.6948,
        0.6988, 0.8381, 0.9340, 0.9962, 0.7672, 1.2425, 0.6526, 1.2980, 0.8037,
        0.7755, 0.8970, 0.9549, 1.3445, 1.8776, 0.6185, 0.6374, 0.8413, 1.0299,
        0.7986, 2.2139, 1.5182, 0.6390, 0.7889, 0.8381, 0.8144, 1.2053, 1.1399,
        0.6882, 0.7913, 0.7387, 0.6722, 0.8116, 0.6821, 0.8037, 0.6821, 1.2425,
        0.6357, 0.6114, 0.6978, 0.6251, 0.6173, 0.6928, 0.7452, 0.9604, 0.8116,
        1.6736, 1.0522, 0.7504, 0.6855, 0.6291, 0.6234, 0.7652, 0.6441, 1.1205,
        0.6220, 1.2694, 0.8653, 0.6231, 0.6285, 0.7633, 3.8767, 1.7352, 0.6813],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  86 140  60  46  54  73  31  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  67 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 147 129 137  70  76
 215 146 173 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  78 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3613, 0.6669, 1.1714, 1.2427, 0.9291, 0.8887, 0.6689, 0.7341, 0.6638,
        1.2695, 0.8929, 0.6321, 1.1022, 1.4960, 0.8446, 1.9608, 0.7357, 0.6119,
        1.5184, 2.0534, 1.2427, 0.8173, 0.9550, 1.1502, 1.2981, 1.1022, 1.9608,
        1.0523, 0.8064, 1.3447, 1.6450, 1.4539, 1.1714, 2.2747, 1.3963, 1.6450,
        1.7684, 1.5416, 0.7076, 0.8038, 0.7735, 0.7200, 0.8971, 1.0933, 0.8583,
        0.7254, 0.8012, 0.6175, 0.7470, 0.6185, 0.7987, 0.6979, 0.8064, 1.4960,
        0.7714, 0.7558, 0.7042, 0.7821, 0.6266, 0.6140, 0.7136, 1.4148, 0.6948,
        0.6989, 0.8382, 0.9341, 0.9963, 0.7673, 1.2427, 0.6526, 1.2981, 0.8038,
        0.7756, 0.8971, 0.9550, 1.3447, 1.8779, 0.6186, 0.6375, 0.8414, 1.0300,
        0.7987, 2.2142, 1.5184, 0.6390, 0.7890, 0.8382, 0.8145, 1.2054, 1.1401,
        0.6882, 0.7914, 0.7388, 0.6723, 0.8117, 0.6822, 0.8038, 0.6822, 1.2427,
        0.6358, 0.6115, 0.6979, 0.6252, 0.6175, 0.6929, 0.7453, 0.9605, 0.8117,
        1.6738, 1.0523, 0.7504, 0.6856, 0.6292, 0.6235, 0.7653, 0.6442, 1.1206,
        0.6221, 1.2695, 0.8654, 0.6232, 0.6285, 0.7634, 3.8772, 1.7354, 0.6814],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  86 141  60  46  54  73  31  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  67 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 147 129 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  79 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3614, 0.6670, 1.1715, 1.2428, 0.9292, 0.8888, 0.6689, 0.7342, 0.6639,
        1.2696, 0.8929, 0.6322, 1.1023, 1.4962, 0.8447, 1.9610, 0.7357, 0.6119,
        1.5185, 2.0536, 1.2428, 0.8173, 0.9551, 1.1503, 1.2982, 1.1023, 1.9610,
        1.0524, 0.8039, 1.3448, 1.6451, 1.4540, 1.1715, 2.2749, 1.3965, 1.6451,
        1.7686, 1.5418, 0.7077, 0.8039, 0.7735, 0.7200, 0.8972, 1.0934, 0.8583,
        0.7255, 0.8013, 0.6175, 0.7470, 0.6185, 0.7988, 0.6979, 0.8065, 1.4962,
        0.7715, 0.7559, 0.7043, 0.7822, 0.6267, 0.6141, 0.7137, 1.4149, 0.6949,
        0.6989, 0.8382, 0.9342, 0.9964, 0.7674, 1.2428, 0.6527, 1.2982, 0.8039,
        0.7757, 0.8972, 0.9551, 1.3448, 1.8780, 0.6186, 0.6376, 0.8414, 1.0301,
        0.7988, 2.2143, 1.5185, 0.6391, 0.7891, 0.8382, 0.8145, 1.2055, 1.1402,
        0.6883, 0.7914, 0.7404, 0.6724, 0.8118, 0.6823, 0.8039, 0.6823, 1.2428,
        0.6358, 0.6115, 0.6979, 0.6253, 0.6175, 0.6930, 0.7454, 0.9606, 0.8118,
        1.6739, 1.0524, 0.7505, 0.6856, 0.6292, 0.6235, 0.7654, 0.6443, 1.1114,
        0.6221, 1.2696, 0.8655, 0.6232, 0.6286, 0.7634, 3.8775, 1.7355, 0.6814],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  86 141  60  46  54  73  31  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 415 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  67 269  63 141
 153 113 101  60  39 414 309 128  89 143  32  51 304 147 129 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  79 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3614, 0.6670, 1.1715, 1.2428, 0.9292, 0.8888, 0.6689, 0.7342, 0.6639,
        1.2696, 0.8929, 0.6322, 1.1023, 1.4962, 0.8447, 1.9610, 0.7357, 0.6119,
        1.5185, 2.0536, 1.2428, 0.8173, 0.9551, 1.1503, 1.2982, 1.1023, 1.9610,
        1.0524, 0.8039, 1.3448, 1.6451, 1.4540, 1.1715, 2.2749, 1.3965, 1.6451,
        1.7686, 1.5418, 0.7077, 0.8039, 0.7735, 0.7200, 0.8972, 1.0934, 0.8583,
        0.7255, 0.8013, 0.6175, 0.7470, 0.6185, 0.7988, 0.6979, 0.8065, 1.4962,
        0.7715, 0.7559, 0.7043, 0.7822, 0.6267, 0.6141, 0.7137, 1.4149, 0.6949,
        0.6989, 0.8382, 0.9342, 0.9964, 0.7674, 1.2428, 0.6527, 1.2982, 0.8039,
        0.7757, 0.8972, 0.9551, 1.3448, 1.8780, 0.6186, 0.6376, 0.8414, 1.0301,
        0.7988, 2.2143, 1.5185, 0.6391, 0.7891, 0.8382, 0.8145, 1.2055, 1.1402,
        0.6883, 0.7914, 0.7404, 0.6724, 0.8118, 0.6823, 0.8039, 0.6823, 1.2428,
        0.6358, 0.6115, 0.6979, 0.6253, 0.6175, 0.6930, 0.7454, 0.9606, 0.8118,
        1.6739, 1.0524, 0.7505, 0.6856, 0.6292, 0.6235, 0.7654, 0.6443, 1.1114,
        0.6221, 1.2696, 0.8655, 0.6232, 0.6286, 0.7634, 3.8775, 1.7355, 0.6814],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 249  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  85 141  60  46  54  73  32  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 414 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  68 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 129 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3620, 0.6673, 1.1719, 1.2433, 0.9296, 0.8892, 0.6692, 0.7345, 0.6636,
        1.2702, 0.8933, 0.6324, 1.1028, 1.4968, 0.8451, 1.9618, 0.7360, 0.6122,
        1.5191, 2.0544, 1.2433, 0.8177, 0.9555, 1.1508, 1.2988, 1.1028, 1.9618,
        1.0606, 0.8042, 1.3454, 1.6458, 1.4546, 1.1719, 2.2153, 1.3970, 1.6458,
        1.7693, 1.5424, 0.7080, 0.8042, 0.7739, 0.7203, 0.8975, 1.0939, 0.8587,
        0.7258, 0.8016, 0.6178, 0.7474, 0.6189, 0.7991, 0.6982, 0.8068, 1.4968,
        0.7718, 0.7562, 0.7046, 0.7825, 0.6269, 0.6143, 0.7140, 1.4155, 0.6952,
        0.6992, 0.8386, 0.9346, 0.9968, 0.7677, 1.2305, 0.6530, 1.2988, 0.8042,
        0.7760, 0.8975, 0.9555, 1.3454, 1.8788, 0.6189, 0.6375, 0.8418, 1.0528,
        0.7991, 2.2153, 1.5191, 0.6394, 0.7894, 0.8386, 0.8149, 1.2060, 1.1407,
        0.6886, 0.7918, 0.7407, 0.6726, 0.8122, 0.6826, 0.8042, 0.6826, 1.2433,
        0.6361, 0.6118, 0.6982, 0.6255, 0.6178, 0.6932, 0.7457, 0.9610, 0.8122,
        1.6746, 1.0528, 0.7508, 0.6859, 0.6295, 0.6238, 0.7657, 0.6446, 1.1028,
        0.6224, 1.2702, 0.8659, 0.6235, 0.6289, 0.7638, 3.8791, 1.7363, 0.6817],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  85 141  60  46  54  73  32  57  46
  42  50 196 141 154 186 113  81 123 182 142 426 168 414 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  68 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3620, 0.6673, 1.1720, 1.2433, 0.9296, 0.8892, 0.6692, 0.7345, 0.6642,
        1.2702, 0.8933, 0.6324, 1.1028, 1.4968, 0.8451, 1.9619, 0.7360, 0.6122,
        1.5192, 2.0545, 1.2433, 0.8177, 0.9555, 1.1508, 1.2988, 1.1028, 1.9619,
        1.0607, 0.8042, 1.3454, 1.6459, 1.4547, 1.1720, 2.2153, 1.3971, 1.6459,
        1.7693, 1.5424, 0.7080, 0.8042, 0.7739, 0.7204, 0.8976, 1.0939, 0.8587,
        0.7258, 0.8016, 0.6178, 0.7474, 0.6189, 0.7991, 0.6982, 0.8068, 1.4968,
        0.7718, 0.7562, 0.7046, 0.7826, 0.6269, 0.6143, 0.7140, 1.4156, 0.6952,
        0.6993, 0.8386, 0.9346, 0.9968, 0.7677, 1.2305, 0.6530, 1.2988, 0.8042,
        0.7760, 0.8976, 0.9555, 1.3454, 1.8789, 0.6189, 0.6375, 0.8418, 1.0529,
        0.7991, 2.2153, 1.5192, 0.6394, 0.7894, 0.8355, 0.8149, 1.2061, 1.1407,
        0.6886, 0.7918, 0.7408, 0.6727, 0.8122, 0.6826, 0.8042, 0.6826, 1.2433,
        0.6361, 0.6118, 0.6982, 0.6255, 0.6178, 0.6933, 0.7457, 0.9610, 0.8122,
        1.6746, 1.0529, 0.7508, 0.6860, 0.6295, 0.6238, 0.7657, 0.6446, 1.1028,
        0.6224, 1.2702, 0.8659, 0.6235, 0.6289, 0.7638, 3.8792, 1.7363, 0.6817],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  80  37  85 141  60  47  54  73  32  57  47
  42  50 196 141 154 186 113  81 123 182 142 426 168 414 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  69 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 426 210 169 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3628, 0.6676, 1.1726, 1.2440, 0.9301, 0.8897, 0.6696, 0.7349, 0.6645,
        1.2709, 0.8938, 0.6328, 1.1034, 1.4976, 0.8455, 1.9629, 0.7364, 0.6125,
        1.5200, 2.0556, 1.2440, 0.8181, 0.9560, 1.1514, 1.2995, 1.1034, 1.9629,
        1.0612, 0.8046, 1.3461, 1.6192, 1.4554, 1.1726, 2.2165, 1.3978, 1.6192,
        1.7703, 1.5433, 0.7084, 0.8046, 0.7743, 0.7207, 0.8980, 1.0945, 0.8592,
        0.7262, 0.8021, 0.6181, 0.7478, 0.6192, 0.7996, 0.6986, 0.8073, 1.4976,
        0.7722, 0.7566, 0.7050, 0.7830, 0.6273, 0.6147, 0.7144, 1.4163, 0.6956,
        0.6996, 0.8391, 0.9351, 0.9973, 0.7681, 1.2188, 0.6533, 1.2995, 0.8046,
        0.7764, 0.8980, 0.9560, 1.3461, 1.8799, 0.6192, 0.6379, 0.8423, 1.0534,
        0.7996, 2.2165, 1.5200, 0.6397, 0.7899, 0.8359, 0.8153, 1.2067, 1.1413,
        0.6890, 0.7922, 0.7412, 0.6730, 0.8126, 0.6829, 0.8046, 0.6829, 1.2440,
        0.6364, 0.6121, 0.6986, 0.6259, 0.6181, 0.6936, 0.7461, 0.9615, 0.8126,
        1.6755, 1.0534, 0.7512, 0.6863, 0.6298, 0.6241, 0.7661, 0.6449, 1.1034,
        0.6227, 1.2709, 0.8664, 0.6238, 0.6292, 0.7642, 3.8813, 1.7372, 0.6821],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 175 532
  51  35  67 136 101  75  63  79  37  85 141  60  47  55  73  32  57  47
  42  50 196 141 154 186 113  81 123 182 142 426 168 413 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  70 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 427 210 169 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 376 345 159  17  43 223]
CBFL per class weights: tensor([1.3630, 0.6678, 1.1728, 1.2442, 0.9303, 0.8898, 0.6697, 0.7350, 0.6647,
        1.2711, 0.8940, 0.6329, 1.1036, 1.4979, 0.8457, 1.9633, 0.7366, 0.6126,
        1.5203, 2.0559, 1.2442, 0.8183, 0.9562, 1.1516, 1.2997, 1.1127, 1.9633,
        1.0614, 0.8048, 1.3464, 1.6195, 1.4358, 1.1728, 2.2169, 1.3981, 1.6195,
        1.7706, 1.5436, 0.7085, 0.8048, 0.7744, 0.7209, 0.8982, 1.0947, 0.8593,
        0.7263, 0.8022, 0.6182, 0.7479, 0.6195, 0.7997, 0.6987, 0.8074, 1.4979,
        0.7724, 0.7568, 0.7051, 0.7831, 0.6274, 0.6148, 0.7145, 1.4166, 0.6957,
        0.6998, 0.8392, 0.9352, 0.9975, 0.7683, 1.2069, 0.6535, 1.2997, 0.8048,
        0.7766, 0.8982, 0.9562, 1.3464, 1.8802, 0.6194, 0.6380, 0.8424, 1.0536,
        0.7997, 2.2169, 1.5203, 0.6398, 0.7900, 0.8361, 0.8155, 1.2069, 1.1415,
        0.6891, 0.7924, 0.7413, 0.6731, 0.8128, 0.6831, 0.8048, 0.6831, 1.2442,
        0.6365, 0.6122, 0.6987, 0.6260, 0.6182, 0.6938, 0.7462, 0.9617, 0.8128,
        1.6758, 1.0536, 0.7514, 0.6864, 0.6300, 0.6242, 0.7663, 0.6450, 1.1036,
        0.6228, 1.2711, 0.8665, 0.6240, 0.6293, 0.7643, 3.8820, 1.7375, 0.6822],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 115 240 176 248  65 114 329  80  52 127  37 176 532
  51  35  67 136 101  75  63  79  37  85 142  60  47  55  73  32  57  47
  42  50 196 141 154 186 113  81 123 182 142 426 168 413 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  70 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3630, 0.6678, 1.1728, 1.2443, 0.9303, 0.8898, 0.6697, 0.7351, 0.6647,
        1.2711, 0.8940, 0.6329, 1.1036, 1.4979, 0.8457, 1.9633, 0.7351, 0.6126,
        1.5203, 2.0560, 1.2443, 0.8183, 0.9562, 1.1517, 1.2998, 1.1127, 1.9633,
        1.0614, 0.8022, 1.3464, 1.6195, 1.4358, 1.1728, 2.2170, 1.3981, 1.6195,
        1.7706, 1.5436, 0.7085, 0.8048, 0.7745, 0.7209, 0.8982, 1.0947, 0.8593,
        0.7263, 0.8022, 0.6183, 0.7479, 0.6195, 0.7997, 0.6987, 0.8074, 1.4979,
        0.7724, 0.7568, 0.7051, 0.7831, 0.6274, 0.6148, 0.7145, 1.4166, 0.6957,
        0.6998, 0.8392, 0.9353, 0.9975, 0.7683, 1.2070, 0.6535, 1.2998, 0.8048,
        0.7766, 0.8982, 0.9562, 1.3464, 1.8802, 0.6194, 0.6380, 0.8424, 1.0536,
        0.7997, 2.2170, 1.5203, 0.6398, 0.7900, 0.8361, 0.8155, 1.2070, 1.1415,
        0.6891, 0.7924, 0.7413, 0.6731, 0.8128, 0.6831, 0.8048, 0.6831, 1.2443,
        0.6366, 0.6122, 0.6987, 0.6260, 0.6182, 0.6938, 0.7479, 0.9617, 0.8128,
        1.6759, 1.0536, 0.7514, 0.6865, 0.6300, 0.6243, 0.7663, 0.6450, 1.1036,
        0.6228, 1.2711, 0.8665, 0.6241, 0.6293, 0.7643, 3.8821, 1.7376, 0.6822],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 116 240 176 248  65 114 329  80  52 127  37 176 532
  51  35  67 136 101  75  63  79  37  85 142  60  47  55  73  32  57  47
  42  50 196 141 154 186 113  81 123 182 142 426 168 413 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  70 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 215 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 375 345 159  17  43 223]
CBFL per class weights: tensor([1.3631, 0.6678, 1.1729, 1.2443, 0.9303, 0.8858, 0.6698, 0.7351, 0.6647,
        1.2712, 0.8940, 0.6329, 1.1036, 1.4980, 0.8457, 1.9634, 0.7351, 0.6126,
        1.5203, 2.0560, 1.2443, 0.8183, 0.9562, 1.1517, 1.2998, 1.1127, 1.9634,
        1.0615, 0.8023, 1.3464, 1.6196, 1.4358, 1.1729, 2.2170, 1.3982, 1.6196,
        1.7707, 1.5436, 0.7086, 0.8048, 0.7745, 0.7209, 0.8982, 1.0948, 0.8594,
        0.7263, 0.8023, 0.6183, 0.7480, 0.6195, 0.7997, 0.6988, 0.8074, 1.4980,
        0.7724, 0.7568, 0.7052, 0.7832, 0.6274, 0.6148, 0.7145, 1.4167, 0.6957,
        0.6998, 0.8393, 0.9353, 0.9976, 0.7683, 1.2070, 0.6535, 1.2998, 0.8048,
        0.7766, 0.8982, 0.9562, 1.3464, 1.8803, 0.6194, 0.6380, 0.8425, 1.0537,
        0.7997, 2.2170, 1.5203, 0.6399, 0.7900, 0.8361, 0.8155, 1.2070, 1.1416,
        0.6891, 0.7924, 0.7413, 0.6732, 0.8128, 0.6831, 0.8048, 0.6831, 1.2443,
        0.6366, 0.6123, 0.6988, 0.6260, 0.6182, 0.6938, 0.7480, 0.9618, 0.8128,
        1.6759, 1.0537, 0.7514, 0.6865, 0.6300, 0.6243, 0.7663, 0.6451, 1.1036,
        0.6229, 1.2712, 0.8666, 0.6241, 0.6294, 0.7644, 3.8822, 1.7376, 0.6823],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 116 240 176 248  65 114 329  80  52 127  37 176 532
  51  35  67 136 101  75  63  79  37  85 142  60  47  56  73  32  57  47
  42  50 196 141 154 186 113  81 123 182 142 426 168 413 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 157  70 269  63 141
 153 113 101  60  39 414 310 128  86 143  32  51 304 147 130 137  70  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 375 345 160  17  43 223]
CBFL per class weights: tensor([1.3633, 0.6679, 1.1731, 1.2445, 0.9305, 0.8859, 0.6699, 0.7352, 0.6648,
        1.2714, 0.8942, 0.6330, 1.1038, 1.4982, 0.8459, 1.9637, 0.7352, 0.6127,
        1.5206, 2.0564, 1.2445, 0.8185, 0.9564, 1.1519, 1.3000, 1.1129, 1.9637,
        1.0617, 0.8024, 1.3467, 1.6198, 1.4169, 1.1731, 2.2174, 1.3984, 1.6198,
        1.7710, 1.5439, 0.7087, 0.8050, 0.7746, 0.7210, 0.8984, 1.0949, 0.8595,
        0.7265, 0.8024, 0.6184, 0.7481, 0.6196, 0.7999, 0.6989, 0.8076, 1.4982,
        0.7725, 0.7569, 0.7053, 0.7833, 0.6275, 0.6149, 0.7146, 1.4169, 0.6959,
        0.6999, 0.8394, 0.9354, 0.9977, 0.7684, 1.2072, 0.6536, 1.3000, 0.8050,
        0.7767, 0.8984, 0.9564, 1.3467, 1.8806, 0.6195, 0.6381, 0.8426, 1.0538,
        0.7999, 2.2174, 1.5206, 0.6400, 0.7902, 0.8362, 0.8157, 1.2072, 1.1417,
        0.6902, 0.7925, 0.7414, 0.6733, 0.8129, 0.6832, 0.8050, 0.6832, 1.2445,
        0.6367, 0.6124, 0.6989, 0.6261, 0.6183, 0.6939, 0.7481, 0.9619, 0.8129,
        1.6762, 1.0538, 0.7515, 0.6866, 0.6301, 0.6244, 0.7664, 0.6452, 1.1038,
        0.6230, 1.2714, 0.8667, 0.6242, 0.6295, 0.7625, 3.8828, 1.7379, 0.6824],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 243  73  67 106 116 240 176 248  65 114 329  80  53 127  37 176 532
  51  35  67 136 101  75  63  79  37  85 142  60  47  56  73  32  57  47
  43  50 196 141 154 187 113  81 123 182 142 426 168 413 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 156  70 269  63 141
 153 113 101  60  40 414 310 128  85 143  32  51 304 147 130 137  70  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 218 342 374 158 289  80 384  65 121 375 345 160  17  43 223]
CBFL per class weights: tensor([1.3642, 0.6684, 1.1738, 1.2453, 0.9311, 0.8865, 0.6703, 0.7357, 0.6653,
        1.2722, 0.8948, 0.6334, 1.1045, 1.4777, 0.8464, 1.9650, 0.7357, 0.6132,
        1.5216, 2.0578, 1.2453, 0.8190, 0.9570, 1.1527, 1.3009, 1.1137, 1.9650,
        1.0624, 0.8029, 1.3476, 1.6209, 1.4178, 1.1738, 2.2189, 1.3993, 1.6209,
        1.7391, 1.5449, 0.7091, 0.8055, 0.7751, 0.7202, 0.8990, 1.0957, 0.8601,
        0.7269, 0.8029, 0.6188, 0.7486, 0.6200, 0.8004, 0.6993, 0.8081, 1.4992,
        0.7730, 0.7574, 0.7057, 0.7838, 0.6280, 0.6153, 0.7151, 1.4178, 0.6963,
        0.7004, 0.8400, 0.9361, 0.9984, 0.7710, 1.2080, 0.6540, 1.3009, 0.8055,
        0.7772, 0.8990, 0.9570, 1.3476, 1.8434, 0.6199, 0.6386, 0.8432, 1.0624,
        0.8004, 2.2189, 1.5216, 0.6404, 0.7907, 0.8368, 0.8162, 1.2080, 1.1425,
        0.6906, 0.7931, 0.7419, 0.6737, 0.8135, 0.6837, 0.8055, 0.6837, 1.2453,
        0.6371, 0.6128, 0.6993, 0.6265, 0.6187, 0.6944, 0.7486, 0.9626, 0.8135,
        1.6773, 1.0546, 0.7520, 0.6871, 0.6305, 0.6248, 0.7670, 0.6456, 1.1045,
        0.6234, 1.2722, 0.8673, 0.6246, 0.6299, 0.7631, 3.8854, 1.7391, 0.6828],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  53 127  37 176 532
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  44  50 196 141 154 187 113  81 123 182 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 155  70 269  63 141
 153 113 101  60  40 415 311 128  85 143  32  51 304 147 130 137  70  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  43 223]
CBFL per class weights: tensor([1.3648, 0.6693, 1.1743, 1.2459, 0.9315, 0.8869, 0.6706, 0.7360, 0.6655,
        1.2728, 0.8951, 0.6337, 1.1050, 1.4783, 0.8468, 1.9658, 0.7360, 0.6134,
        1.5223, 2.0586, 1.2459, 0.8194, 0.9574, 1.1531, 1.3014, 1.1141, 1.9658,
        1.0550, 0.8033, 1.3481, 1.6216, 1.4184, 1.1743, 2.2198, 1.3999, 1.5952,
        1.7082, 1.5456, 0.7094, 0.8058, 0.7754, 0.7205, 0.8994, 1.0961, 0.8604,
        0.7273, 0.8033, 0.6190, 0.7489, 0.6204, 0.8007, 0.6996, 0.8085, 1.4999,
        0.7734, 0.7577, 0.7060, 0.7841, 0.6282, 0.6156, 0.7154, 1.4184, 0.6966,
        0.7007, 0.8403, 0.9365, 0.9988, 0.7734, 1.2085, 0.6543, 1.3014, 0.8058,
        0.7776, 0.8994, 0.9574, 1.3481, 1.8442, 0.6201, 0.6385, 0.8435, 1.0628,
        0.8007, 2.2198, 1.5223, 0.6407, 0.7910, 0.8372, 0.8166, 1.2085, 1.1430,
        0.6909, 0.7934, 0.7423, 0.6740, 0.8138, 0.6839, 0.8058, 0.6839, 1.2459,
        0.6374, 0.6130, 0.6996, 0.6268, 0.6190, 0.6947, 0.7489, 0.9630, 0.8138,
        1.6780, 1.0550, 0.7524, 0.6882, 0.6308, 0.6251, 0.7673, 0.6459, 1.1141,
        0.6236, 1.2728, 0.8677, 0.6249, 0.6302, 0.7634, 3.8871, 1.7398, 0.6831],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  53 127  37 176 532
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  47  50 196 141 154 187 113  81 123 182 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 152  71 269  63 141
 153 113 101  60  40 415 311 128  85 143  32  51 304 147 130 137  70  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  43 223]
CBFL per class weights: tensor([1.3658, 0.6698, 1.1752, 1.2468, 0.9322, 0.8876, 0.6711, 0.7365, 0.6660,
        1.2737, 0.8958, 0.6342, 1.1058, 1.4794, 0.8474, 1.9673, 0.7365, 0.6139,
        1.5234, 2.0601, 1.2468, 0.8200, 0.9581, 1.1540, 1.3024, 1.1149, 1.9673,
        1.0558, 0.8039, 1.3491, 1.6228, 1.4195, 1.1752, 2.2214, 1.4009, 1.5963,
        1.6228, 1.5467, 0.7100, 0.8064, 0.7760, 0.7210, 0.9000, 1.0969, 0.8611,
        0.7278, 0.8039, 0.6195, 0.7494, 0.6208, 0.8013, 0.7001, 0.8090, 1.5010,
        0.7739, 0.7583, 0.7066, 0.7847, 0.6287, 0.6160, 0.7159, 1.4195, 0.6971,
        0.7012, 0.8409, 0.9372, 0.9995, 0.7803, 1.1977, 0.6548, 1.3024, 0.8064,
        0.7781, 0.9000, 0.9581, 1.3491, 1.8456, 0.6205, 0.6390, 0.8441, 1.0636,
        0.8013, 2.2214, 1.5234, 0.6411, 0.7916, 0.8378, 0.8172, 1.2094, 1.1438,
        0.6914, 0.7940, 0.7428, 0.6745, 0.8144, 0.6844, 0.8064, 0.6844, 1.2468,
        0.6378, 0.6135, 0.7001, 0.6273, 0.6194, 0.6952, 0.7494, 0.9637, 0.8144,
        1.6793, 1.0558, 0.7529, 0.6887, 0.6312, 0.6255, 0.7678, 0.6463, 1.1149,
        0.6241, 1.2737, 0.8683, 0.6254, 0.6306, 0.7639, 3.8899, 1.7411, 0.6836],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  53 127  37 176 532
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  47  50 196 141 154 187 113  81 123 182 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 152  71 270  63 141
 153 113 101  60  40 415 311 128  85 143  32  51 304 147 130 137  70  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  43 223]
CBFL per class weights: tensor([1.3658, 0.6698, 1.1752, 1.2468, 0.9322, 0.8876, 0.6711, 0.7365, 0.6660,
        1.2737, 0.8958, 0.6342, 1.1058, 1.4794, 0.8474, 1.9673, 0.7365, 0.6139,
        1.5234, 2.0601, 1.2468, 0.8200, 0.9581, 1.1540, 1.3024, 1.1149, 1.9673,
        1.0558, 0.8039, 1.3491, 1.6228, 1.4195, 1.1752, 2.2214, 1.4009, 1.5964,
        1.6228, 1.5467, 0.7100, 0.8064, 0.7760, 0.7210, 0.9000, 1.0969, 0.8611,
        0.7278, 0.8039, 0.6195, 0.7494, 0.6208, 0.8013, 0.7001, 0.8090, 1.5010,
        0.7739, 0.7583, 0.7066, 0.7847, 0.6287, 0.6160, 0.7159, 1.4195, 0.6971,
        0.7012, 0.8409, 0.9372, 0.9995, 0.7803, 1.1977, 0.6543, 1.3024, 0.8064,
        0.7781, 0.9000, 0.9581, 1.3491, 1.8456, 0.6205, 0.6390, 0.8441, 1.0636,
        0.8013, 2.2214, 1.5234, 0.6411, 0.7916, 0.8378, 0.8172, 1.2094, 1.1438,
        0.6914, 0.7940, 0.7428, 0.6745, 0.8144, 0.6845, 0.8064, 0.6845, 1.2468,
        0.6378, 0.6135, 0.7001, 0.6273, 0.6194, 0.6952, 0.7494, 0.9637, 0.8144,
        1.6793, 1.0558, 0.7529, 0.6887, 0.6312, 0.6255, 0.7678, 0.6463, 1.1149,
        0.6241, 1.2737, 0.8683, 0.6254, 0.6306, 0.7639, 3.8899, 1.7411, 0.6836],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  55 127  38 176 532
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  48  50 196 141 154 187 113  81 123 182 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 152  71 270  63 141
 153 113 101  60  40 414 311 128  85 143  32  51 304 147 130 137  69  76
 214 146 172 235 138 222 141 222  67 315 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  44 223]
CBFL per class weights: tensor([1.3672, 0.6705, 1.1764, 1.2481, 0.9331, 0.8885, 0.6718, 0.7373, 0.6667,
        1.2750, 0.8967, 0.6348, 1.1070, 1.4402, 0.8483, 1.9265, 0.7373, 0.6145,
        1.5249, 2.0623, 1.2481, 0.8208, 0.9591, 1.1552, 1.3037, 1.1161, 1.9693,
        1.0569, 0.8047, 1.3505, 1.6245, 1.4209, 1.1764, 2.2237, 1.4024, 1.5980,
        1.5980, 1.5483, 0.7107, 0.8073, 0.7768, 0.7218, 0.9010, 1.0981, 0.8620,
        0.7285, 0.8047, 0.6201, 0.7502, 0.6215, 0.8022, 0.7009, 0.8099, 1.5025,
        0.7747, 0.7591, 0.7073, 0.7855, 0.6293, 0.6167, 0.7167, 1.4209, 0.6978,
        0.7019, 0.8418, 0.9381, 1.0006, 0.7811, 1.1989, 0.6550, 1.3037, 0.8073,
        0.7789, 0.9010, 0.9591, 1.3505, 1.8475, 0.6213, 0.6397, 0.8450, 1.0647,
        0.8022, 2.2237, 1.5249, 0.6418, 0.7924, 0.8386, 0.8180, 1.2227, 1.1450,
        0.6921, 0.7948, 0.7436, 0.6752, 0.8152, 0.6852, 0.8073, 0.6852, 1.2481,
        0.6385, 0.6141, 0.7009, 0.6279, 0.6201, 0.6959, 0.7502, 0.9647, 0.8152,
        1.6810, 1.0569, 0.7537, 0.6894, 0.6319, 0.6262, 0.7686, 0.6470, 1.1161,
        0.6247, 1.2750, 0.8692, 0.6260, 0.6313, 0.7647, 3.8939, 1.7112, 0.6843],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  55 127  39 176 532
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  48  50 196 141 154 187 113  81 123 181 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 152  71 270  63 141
 153 113 101  60  40 414 311 128  85 143  32  51 304 147 130 137  69  76
 214 146 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  45 223]
CBFL per class weights: tensor([1.3679, 0.6708, 1.1771, 1.2487, 0.9337, 0.8890, 0.6721, 0.7377, 0.6671,
        1.2757, 0.8972, 0.6352, 1.1076, 1.4410, 0.8487, 1.8870, 0.7377, 0.6148,
        1.5258, 2.0634, 1.2487, 0.8212, 0.9597, 1.1558, 1.3044, 1.1167, 1.9704,
        1.0574, 0.8051, 1.3512, 1.6253, 1.4217, 1.1771, 2.2249, 1.4031, 1.5989,
        1.5989, 1.5491, 0.7111, 0.8077, 0.7772, 0.7222, 0.9014, 1.0987, 0.8624,
        0.7303, 0.8051, 0.6205, 0.7506, 0.6218, 0.8026, 0.7013, 0.8103, 1.5033,
        0.7751, 0.7595, 0.7077, 0.7860, 0.6297, 0.6170, 0.7171, 1.4217, 0.6982,
        0.7023, 0.8422, 0.9386, 1.0011, 0.7815, 1.1996, 0.6554, 1.3044, 0.8077,
        0.7794, 0.9014, 0.9597, 1.3512, 1.8485, 0.6216, 0.6400, 0.8455, 1.0653,
        0.8026, 2.2249, 1.5258, 0.6422, 0.7929, 0.8391, 0.8184, 1.2234, 1.1456,
        0.6925, 0.7952, 0.7440, 0.6756, 0.8157, 0.6855, 0.8077, 0.6855, 1.2487,
        0.6391, 0.6144, 0.7013, 0.6283, 0.6204, 0.6963, 0.7506, 0.9652, 0.8157,
        1.6819, 1.0574, 0.7541, 0.6898, 0.6322, 0.6265, 0.7691, 0.6474, 1.1167,
        0.6251, 1.2757, 0.8697, 0.6264, 0.6316, 0.7651, 3.8961, 1.6819, 0.6847],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  56 127  39 176 531
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  50  50 196 141 154 187 113  81 123 181 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 150  72 270  63 141
 153 113 101  60  40 414 311 128  85 143  32  51 304 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  47 223]
CBFL per class weights: tensor([1.3694, 0.6715, 1.1783, 1.2500, 0.9346, 0.8899, 0.6728, 0.7385, 0.6678,
        1.2770, 0.8981, 0.6358, 1.1087, 1.4232, 0.8496, 1.8890, 0.7385, 0.6155,
        1.5274, 2.0655, 1.2500, 0.8221, 0.9606, 1.1570, 1.3058, 1.1179, 1.9724,
        1.0585, 0.8060, 1.3526, 1.6270, 1.4232, 1.1783, 2.2272, 1.4046, 1.6005,
        1.5507, 1.5507, 0.7118, 0.8085, 0.7780, 0.7229, 0.9024, 1.0998, 0.8633,
        0.7311, 0.8060, 0.6211, 0.7514, 0.6224, 0.8034, 0.7020, 0.8112, 1.5049,
        0.7759, 0.7603, 0.7084, 0.7868, 0.6303, 0.6176, 0.7178, 1.4232, 0.6989,
        0.7030, 0.8431, 0.9396, 1.0022, 0.7868, 1.1894, 0.6560, 1.3058, 0.8085,
        0.7802, 0.9024, 0.9606, 1.3526, 1.8504, 0.6222, 0.6407, 0.8463, 1.0664,
        0.8034, 2.2272, 1.5274, 0.6428, 0.7937, 0.8400, 0.8193, 1.2247, 1.1468,
        0.6932, 0.7985, 0.7447, 0.6763, 0.8165, 0.6862, 0.8085, 0.6862, 1.2500,
        0.6398, 0.6151, 0.7020, 0.6289, 0.6210, 0.6970, 0.7514, 0.9662, 0.8165,
        1.6836, 1.0585, 0.7549, 0.6905, 0.6329, 0.6272, 0.7698, 0.6480, 1.1179,
        0.6257, 1.2770, 0.8706, 0.6270, 0.6323, 0.7659, 3.9001, 1.6270, 0.6854],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  56 127  39 176 531
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  50  50 196 141 154 187 113  81 123 181 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 150  72 270  63 141
 153 113 101  60  40 414 311 128  85 144  32  51 304 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  47 223]
CBFL per class weights: tensor([1.3694, 0.6715, 1.1783, 1.2501, 0.9346, 0.8899, 0.6729, 0.7385, 0.6678,
        1.2770, 0.8981, 0.6358, 1.1087, 1.4232, 0.8496, 1.8890, 0.7385, 0.6155,
        1.5274, 2.0656, 1.2501, 0.8221, 0.9607, 1.1570, 1.3058, 1.1179, 1.9725,
        1.0586, 0.8060, 1.3527, 1.6271, 1.4232, 1.1783, 2.2273, 1.4046, 1.6006,
        1.5508, 1.5508, 0.7118, 0.8086, 0.7781, 0.7229, 0.9024, 1.0998, 0.8633,
        0.7311, 0.8060, 0.6211, 0.7514, 0.6225, 0.8034, 0.7020, 0.8112, 1.5049,
        0.7760, 0.7603, 0.7084, 0.7868, 0.6303, 0.6177, 0.7178, 1.4232, 0.6990,
        0.7030, 0.8431, 0.9396, 1.0022, 0.7868, 1.1894, 0.6560, 1.3058, 0.8086,
        0.7802, 0.9024, 0.9607, 1.3527, 1.8504, 0.6223, 0.6407, 0.8464, 1.0664,
        0.8009, 2.2273, 1.5274, 0.6428, 0.7937, 0.8400, 0.8193, 1.2247, 1.1468,
        0.6932, 0.7985, 0.7448, 0.6763, 0.8166, 0.6863, 0.8086, 0.6863, 1.2501,
        0.6398, 0.6151, 0.7020, 0.6289, 0.6210, 0.6970, 0.7514, 0.9662, 0.8166,
        1.6837, 1.0586, 0.7549, 0.6905, 0.6329, 0.6272, 0.7699, 0.6480, 1.1179,
        0.6257, 1.2770, 0.8706, 0.6270, 0.6323, 0.7659, 3.9002, 1.6271, 0.6854],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  56 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  51  50 196 141 154 187 113  81 123 181 142 426 168 412 143 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  73 270  63 141
 153 113 101  60  40 414 311 128  85 144  32  51 304 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  47 223]
CBFL per class weights: tensor([1.3697, 0.6717, 1.1786, 1.2504, 0.9349, 0.8901, 0.6730, 0.7387, 0.6679,
        1.2774, 0.8984, 0.6360, 1.1090, 1.4236, 0.8498, 1.8895, 0.7387, 0.6157,
        1.5278, 2.0661, 1.2504, 0.8223, 0.9609, 1.1573, 1.3061, 1.1182, 1.9730,
        1.0588, 0.8062, 1.3530, 1.6275, 1.4236, 1.1786, 2.2279, 1.4050, 1.6010,
        1.5278, 1.5512, 0.7120, 0.8088, 0.7783, 0.7231, 0.9026, 1.1001, 0.8636,
        0.7313, 0.8062, 0.6213, 0.7516, 0.6226, 0.8036, 0.7022, 0.8114, 1.5053,
        0.7762, 0.7605, 0.7086, 0.7870, 0.6305, 0.6178, 0.7180, 1.4236, 0.6991,
        0.7032, 0.8434, 0.9399, 1.0024, 0.7893, 1.1786, 0.6562, 1.3061, 0.8088,
        0.7804, 0.9026, 0.9609, 1.3530, 1.8509, 0.6224, 0.6408, 0.8466, 1.0667,
        0.8011, 2.2279, 1.5278, 0.6430, 0.7939, 0.8402, 0.8195, 1.2250, 1.1471,
        0.6934, 0.7987, 0.7449, 0.6765, 0.8168, 0.6864, 0.8088, 0.6864, 1.2504,
        0.6400, 0.6153, 0.7022, 0.6291, 0.6212, 0.6972, 0.7516, 0.9665, 0.8168,
        1.6841, 1.0588, 0.7551, 0.6907, 0.6331, 0.6273, 0.7701, 0.6482, 1.1182,
        0.6259, 1.2774, 0.8708, 0.6272, 0.6324, 0.7661, 3.9012, 1.6275, 0.6856],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  56 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  32  57  48
  51  50 196 141 154 187 113  81 123 181 141 426 168 412 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  73 270  63 141
 153 113 101  60  40 414 311 128  85 144  32  52 304 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  47 223]
CBFL per class weights: tensor([1.3700, 0.6718, 1.1788, 1.2506, 0.9350, 0.8903, 0.6731, 0.7388, 0.6681,
        1.2776, 0.8985, 0.6361, 1.1092, 1.4238, 0.8500, 1.8898, 0.7388, 0.6158,
        1.5280, 2.0665, 1.2506, 0.8225, 0.9611, 1.1575, 1.3064, 1.1184, 1.9733,
        1.0590, 0.8063, 1.3533, 1.6278, 1.4238, 1.1788, 2.2283, 1.4052, 1.6012,
        1.5280, 1.5514, 0.7121, 0.8089, 0.7784, 0.7232, 0.9028, 1.1003, 0.8637,
        0.7314, 0.8089, 0.6214, 0.7517, 0.6227, 0.8013, 0.7023, 0.8115, 1.5056,
        0.7763, 0.7606, 0.7087, 0.7871, 0.6306, 0.6179, 0.7181, 1.4238, 0.6993,
        0.7033, 0.8435, 0.9400, 1.0026, 0.7894, 1.1788, 0.6563, 1.3064, 0.8089,
        0.7805, 0.9028, 0.9611, 1.3533, 1.8512, 0.6225, 0.6410, 0.8467, 1.0669,
        0.8013, 2.2283, 1.5056, 0.6431, 0.7940, 0.8403, 0.8197, 1.2252, 1.1473,
        0.6935, 0.7988, 0.7451, 0.6766, 0.8169, 0.6866, 0.8089, 0.6866, 1.2506,
        0.6401, 0.6154, 0.7023, 0.6292, 0.6213, 0.6973, 0.7517, 0.9666, 0.8169,
        1.6844, 1.0590, 0.7552, 0.6908, 0.6332, 0.6274, 0.7702, 0.6483, 1.1184,
        0.6260, 1.2776, 0.8710, 0.6273, 0.6325, 0.7663, 3.9019, 1.6278, 0.6857],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  57 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  51  50 196 141 154 187 113  81 123 181 141 426 168 412 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  73 270  63 141
 153 113 101  60  40 414 311 128  85 144  32  52 304 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 166 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3701, 0.6719, 1.1789, 1.2507, 0.9351, 0.8903, 0.6732, 0.7389, 0.6681,
        1.2777, 0.8986, 0.6362, 1.1093, 1.4053, 0.8501, 1.8900, 0.7389, 0.6159,
        1.5282, 2.0666, 1.2507, 0.8225, 0.9612, 1.1576, 1.3065, 1.1184, 1.9735,
        1.0591, 0.8064, 1.3534, 1.6279, 1.4239, 1.1789, 2.2894, 1.4053, 1.5759,
        1.5282, 1.5516, 0.7122, 0.8090, 0.7785, 0.7233, 0.9029, 1.1004, 0.8638,
        0.7315, 0.8090, 0.6214, 0.7518, 0.6228, 0.8014, 0.7023, 0.8116, 1.5057,
        0.7764, 0.7607, 0.7088, 0.7872, 0.6307, 0.6180, 0.7182, 1.4239, 0.6993,
        0.7034, 0.8436, 0.9401, 1.0027, 0.7895, 1.1789, 0.6564, 1.3065, 0.8090,
        0.7806, 0.9029, 0.9612, 1.3534, 1.8514, 0.6226, 0.6410, 0.8468, 1.0669,
        0.8014, 2.2284, 1.5057, 0.6432, 0.7941, 0.8404, 0.8197, 1.2253, 1.1474,
        0.6936, 0.7989, 0.7451, 0.6766, 0.8170, 0.6866, 0.8090, 0.6866, 1.2507,
        0.6401, 0.6154, 0.7023, 0.6292, 0.6214, 0.6974, 0.7518, 0.9667, 0.8170,
        1.6845, 1.0591, 0.7553, 0.6909, 0.6332, 0.6275, 0.7703, 0.6484, 1.1184,
        0.6261, 1.2777, 0.8710, 0.6273, 0.6326, 0.7663, 3.9022, 1.6014, 0.6858],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  57 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  51  50 196 141 154 187 113  81 123 181 141 426 168 412 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  73 270  63 141
 153 113 101  60  40 414 311 128  85 144  32  52 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 138
  45  86 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3701, 0.6719, 1.1789, 1.2507, 0.9351, 0.8904, 0.6732, 0.7389, 0.6681,
        1.2777, 0.8986, 0.6362, 1.1093, 1.4054, 0.8501, 1.8900, 0.7389, 0.6159,
        1.5282, 2.0666, 1.2507, 0.8225, 0.9612, 1.1576, 1.3065, 1.1185, 1.9735,
        1.0591, 0.8064, 1.3534, 1.6279, 1.4240, 1.1789, 2.2894, 1.4054, 1.5760,
        1.5282, 1.5516, 0.7122, 0.8090, 0.7785, 0.7233, 0.9029, 1.1004, 0.8638,
        0.7315, 0.8090, 0.6215, 0.7518, 0.6228, 0.8014, 0.7024, 0.8116, 1.5057,
        0.7764, 0.7607, 0.7088, 0.7872, 0.6307, 0.6180, 0.7182, 1.4240, 0.6993,
        0.7034, 0.8436, 0.9401, 1.0027, 0.7895, 1.1789, 0.6564, 1.3065, 0.8090,
        0.7806, 0.9029, 0.9612, 1.3534, 1.8514, 0.6226, 0.6410, 0.8468, 1.0669,
        0.8014, 2.2284, 1.5057, 0.6435, 0.7941, 0.8404, 0.8197, 1.2253, 1.1474,
        0.6936, 0.7989, 0.7451, 0.6766, 0.8170, 0.6866, 0.8090, 0.6866, 1.2507,
        0.6401, 0.6154, 0.7024, 0.6292, 0.6214, 0.6974, 0.7518, 0.9667, 0.8170,
        1.6846, 1.0591, 0.7535, 0.6909, 0.6332, 0.6275, 0.7703, 0.6484, 1.1185,
        0.6261, 1.2777, 0.8710, 0.6273, 0.6326, 0.7663, 3.9022, 1.6014, 0.6858],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  51  50 196 141 154 187 113  81 123 181 141 426 168 412 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  73 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3706, 0.6721, 1.1793, 1.2512, 0.9354, 0.8907, 0.6734, 0.7391, 0.6684,
        1.2782, 0.8989, 0.6364, 1.1097, 1.3879, 0.8504, 1.8906, 0.7391, 0.6161,
        1.5287, 2.0674, 1.2512, 0.8228, 0.9615, 1.1580, 1.3069, 1.1189, 1.9742,
        1.0595, 0.8067, 1.3539, 1.6285, 1.4245, 1.1793, 2.2902, 1.4058, 1.5765,
        1.5287, 1.5521, 0.7125, 0.8093, 0.7787, 0.7236, 0.9032, 1.1008, 0.8641,
        0.7318, 0.8093, 0.6217, 0.7521, 0.6230, 0.8016, 0.7026, 0.8119, 1.5062,
        0.7766, 0.7610, 0.7090, 0.7875, 0.6309, 0.6182, 0.7185, 1.4245, 0.6996,
        0.7036, 0.8439, 0.9404, 1.0031, 0.7897, 1.1793, 0.6566, 1.3069, 0.8093,
        0.7809, 0.9032, 0.9615, 1.3539, 1.8521, 0.6229, 0.6412, 0.8471, 1.0673,
        0.8016, 2.2292, 1.4846, 0.6437, 0.7944, 0.8407, 0.8200, 1.2258, 1.1478,
        0.6938, 0.7992, 0.7454, 0.6769, 0.8173, 0.6869, 0.8093, 0.6869, 1.2512,
        0.6404, 0.6156, 0.7026, 0.6295, 0.6216, 0.6976, 0.7521, 0.9671, 0.8200,
        1.6852, 1.0518, 0.7538, 0.6911, 0.6335, 0.6277, 0.7705, 0.6486, 1.1189,
        0.6263, 1.2782, 0.8713, 0.6276, 0.6328, 0.7666, 3.9036, 1.6020, 0.6860],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 530
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  51  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  74 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3707, 0.6722, 1.1794, 1.2513, 0.9355, 0.8907, 0.6735, 0.7392, 0.6684,
        1.2783, 0.8990, 0.6365, 1.1098, 1.3880, 0.8504, 1.8908, 0.7392, 0.6161,
        1.5288, 2.0675, 1.2513, 0.8229, 0.9616, 1.1581, 1.3071, 1.1189, 1.9743,
        1.0596, 0.8067, 1.3540, 1.6286, 1.4246, 1.1794, 2.2904, 1.4060, 1.5767,
        1.5288, 1.5523, 0.7125, 0.8093, 0.7788, 0.7236, 0.9033, 1.1009, 0.8642,
        0.7318, 0.8093, 0.6217, 0.7521, 0.6231, 0.8017, 0.7027, 0.8120, 1.5063,
        0.7767, 0.7610, 0.7091, 0.7875, 0.6309, 0.6183, 0.7185, 1.4246, 0.6996,
        0.7037, 0.8439, 0.9405, 1.0031, 0.7898, 1.1686, 0.6567, 1.3071, 0.8093,
        0.7809, 0.9033, 0.9616, 1.3540, 1.8522, 0.6229, 0.6413, 0.8472, 1.0674,
        0.8017, 2.2294, 1.4847, 0.6438, 0.7945, 0.8408, 0.8201, 1.2259, 1.1479,
        0.6939, 0.7993, 0.7455, 0.6769, 0.8173, 0.6869, 0.8093, 0.6869, 1.2513,
        0.6404, 0.6157, 0.7027, 0.6295, 0.6216, 0.6977, 0.7521, 0.9671, 0.8201,
        1.6853, 1.0519, 0.7539, 0.6912, 0.6335, 0.6278, 0.7706, 0.6487, 1.1189,
        0.6263, 1.2783, 0.8714, 0.6276, 0.6329, 0.7667, 3.9039, 1.6021, 0.6861],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 529
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  51  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  75 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3708, 0.6722, 1.1795, 1.2514, 0.9356, 0.8908, 0.6736, 0.7392, 0.6685,
        1.2784, 0.8991, 0.6365, 1.1099, 1.3881, 0.8505, 1.8910, 0.7392, 0.6162,
        1.5290, 2.0677, 1.2514, 0.8230, 0.9617, 1.1582, 1.3072, 1.1190, 1.9745,
        1.0597, 0.8068, 1.3541, 1.6288, 1.4247, 1.1795, 2.2906, 1.4061, 1.5768,
        1.5290, 1.5524, 0.7126, 0.8094, 0.7789, 0.7237, 0.9033, 1.1010, 0.8642,
        0.7319, 0.8094, 0.6218, 0.7522, 0.6232, 0.8018, 0.7027, 0.8120, 1.5065,
        0.7768, 0.7611, 0.7092, 0.7876, 0.6310, 0.6183, 0.7186, 1.4247, 0.6997,
        0.7038, 0.8440, 0.9406, 1.0032, 0.7899, 1.1582, 0.6567, 1.3072, 0.8094,
        0.7810, 0.9033, 0.9617, 1.3541, 1.8524, 0.6230, 0.6413, 0.8472, 1.0675,
        0.8018, 2.2296, 1.4848, 0.6438, 0.7945, 0.8408, 0.8202, 1.2260, 1.1480,
        0.6940, 0.7993, 0.7455, 0.6770, 0.8174, 0.6870, 0.8094, 0.6870, 1.2514,
        0.6405, 0.6157, 0.7027, 0.6296, 0.6217, 0.6977, 0.7522, 0.9672, 0.8202,
        1.6854, 1.0520, 0.7539, 0.6913, 0.6336, 0.6278, 0.7707, 0.6487, 1.1190,
        0.6264, 1.2784, 0.8715, 0.6277, 0.6329, 0.7667, 3.9042, 1.6022, 0.6861],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 529
  51  35  67 136 101  75  63  79  37  86 142  60  47  56  73  31  57  49
  52  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  75 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3711, 0.6724, 1.1797, 1.2516, 0.9358, 0.8910, 0.6737, 0.7394, 0.6686,
        1.2786, 0.8992, 0.6366, 1.1101, 1.3884, 0.8507, 1.8913, 0.7394, 0.6163,
        1.5292, 2.0681, 1.2516, 0.8231, 0.9618, 1.1584, 1.3074, 1.1192, 1.9749,
        1.0598, 0.8070, 1.3543, 1.6290, 1.4249, 1.1797, 2.2910, 1.4063, 1.5771,
        1.5067, 1.5527, 0.7127, 0.8095, 0.7790, 0.7238, 0.9035, 1.1012, 0.8644,
        0.7320, 0.8095, 0.6219, 0.7523, 0.6233, 0.8019, 0.7028, 0.8122, 1.5067,
        0.7769, 0.7612, 0.7093, 0.7877, 0.6311, 0.6184, 0.7187, 1.4249, 0.6998,
        0.7039, 0.8442, 0.9408, 1.0034, 0.7900, 1.1584, 0.6568, 1.3074, 0.8095,
        0.7811, 0.9035, 0.9618, 1.3543, 1.8527, 0.6231, 0.6415, 0.8474, 1.0677,
        0.8019, 2.2300, 1.4851, 0.6439, 0.7947, 0.8410, 0.8203, 1.2262, 1.1482,
        0.6941, 0.7995, 0.7457, 0.6771, 0.8175, 0.6871, 0.8095, 0.6871, 1.2516,
        0.6406, 0.6158, 0.7028, 0.6297, 0.6218, 0.6979, 0.7523, 0.9674, 0.8203,
        1.6857, 1.0522, 0.7541, 0.6914, 0.6337, 0.6279, 0.7708, 0.6488, 1.1192,
        0.6265, 1.2786, 0.8716, 0.6278, 0.6330, 0.7669, 3.9049, 1.6025, 0.6863],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 529
  51  35  67 136 101  75  64  79  37  86 142  60  47  56  73  31  57  49
  52  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  75 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3712, 0.6724, 1.1799, 1.2517, 0.9359, 0.8911, 0.6738, 0.7395, 0.6687,
        1.2788, 0.8993, 0.6367, 1.1102, 1.3885, 0.8508, 1.8915, 0.7395, 0.6164,
        1.5294, 2.0683, 1.2517, 0.8232, 0.9619, 1.1586, 1.2929, 1.1194, 1.9751,
        1.0600, 0.8071, 1.3545, 1.6292, 1.4251, 1.1799, 2.2913, 1.4065, 1.5773,
        1.5069, 1.5528, 0.7128, 0.8096, 0.7791, 0.7239, 0.9036, 1.1013, 0.8645,
        0.7321, 0.8096, 0.6220, 0.7524, 0.6234, 0.8020, 0.7029, 0.8123, 1.5069,
        0.7770, 0.7613, 0.7094, 0.7878, 0.6312, 0.6185, 0.7188, 1.4251, 0.6999,
        0.7040, 0.8443, 0.9409, 1.0035, 0.7901, 1.1586, 0.6569, 1.3076, 0.8096,
        0.7812, 0.9036, 0.9619, 1.3545, 1.8529, 0.6232, 0.6415, 0.8475, 1.0678,
        0.8020, 2.2303, 1.4853, 0.6440, 0.7948, 0.8411, 0.8204, 1.2263, 1.1484,
        0.6942, 0.7996, 0.7458, 0.6772, 0.8176, 0.6872, 0.8096, 0.6872, 1.2517,
        0.6407, 0.6159, 0.7029, 0.6298, 0.6219, 0.6979, 0.7524, 0.9675, 0.8204,
        1.6859, 1.0523, 0.7541, 0.6915, 0.6337, 0.6280, 0.7709, 0.6489, 1.1194,
        0.6266, 1.2788, 0.8717, 0.6279, 0.6331, 0.7670, 3.9054, 1.6027, 0.6863],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 240 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  64  79  37  86 142  60  47  56  73  31  57  49
  52  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 140  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  76 270  63 141
 153 113 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  48 223]
CBFL per class weights: tensor([1.3713, 0.6725, 1.1800, 1.2518, 0.9360, 0.8912, 0.6738, 0.7395, 0.6687,
        1.2789, 0.8994, 0.6367, 1.1103, 1.3887, 0.8508, 1.8917, 0.7395, 0.6165,
        1.5295, 2.0685, 1.2518, 0.8233, 0.9620, 1.1587, 1.2930, 1.1195, 1.9752,
        1.0601, 0.8071, 1.3546, 1.6294, 1.4252, 1.1800, 2.2915, 1.4066, 1.5774,
        1.5070, 1.5530, 0.7128, 0.8097, 0.7792, 0.7239, 0.9037, 1.1014, 0.8646,
        0.7321, 0.8097, 0.6220, 0.7525, 0.6234, 0.8021, 0.7030, 0.8123, 1.5070,
        0.7771, 0.7614, 0.7094, 0.7879, 0.6312, 0.6185, 0.7188, 1.4252, 0.6999,
        0.7040, 0.8443, 0.9410, 1.0036, 0.7902, 1.1485, 0.6570, 1.3077, 0.8097,
        0.7813, 0.9037, 0.9620, 1.3546, 1.8531, 0.6232, 0.6416, 0.8476, 1.0679,
        0.8021, 2.2304, 1.4854, 0.6441, 0.7948, 0.8412, 0.8205, 1.2264, 1.1485,
        0.6942, 0.7996, 0.7458, 0.6772, 0.8177, 0.6872, 0.8097, 0.6872, 1.2518,
        0.6407, 0.6160, 0.7030, 0.6298, 0.6219, 0.6980, 0.7525, 0.9676, 0.8205,
        1.6861, 1.0524, 0.7542, 0.6915, 0.6338, 0.6281, 0.7710, 0.6490, 1.1195,
        0.6266, 1.2789, 0.8718, 0.6279, 0.6332, 0.7670, 3.9057, 1.6028, 0.6864],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  65  79  37  86 142  60  47  56  73  31  57  49
  52  50 196 141 154 187 113  81 123 181 141 426 168 411 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  76 270  63 141
 153 114 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3718, 0.6727, 1.1804, 1.2523, 0.9363, 0.8915, 0.6747, 0.7398, 0.6690,
        1.2793, 0.8997, 0.6370, 1.1107, 1.3892, 0.8511, 1.8924, 0.7398, 0.6167,
        1.5301, 2.0692, 1.2523, 0.8236, 0.9624, 1.1591, 1.2793, 1.1199, 1.9760,
        1.0604, 0.8074, 1.3551, 1.6300, 1.4257, 1.1804, 2.2923, 1.4071, 1.5780,
        1.5076, 1.5535, 0.7131, 0.8100, 0.7794, 0.7242, 0.9040, 1.1018, 0.8649,
        0.7324, 0.8100, 0.6222, 0.7528, 0.6237, 0.8024, 0.7032, 0.8100, 1.5076,
        0.7773, 0.7616, 0.7097, 0.7882, 0.6315, 0.6188, 0.7191, 1.4257, 0.7002,
        0.7043, 0.8446, 0.9413, 1.0040, 0.7905, 1.1489, 0.6572, 1.3081, 0.8100,
        0.7816, 0.8997, 0.9624, 1.3551, 1.8537, 0.6235, 0.6418, 0.8479, 1.0683,
        0.8024, 2.2313, 1.4859, 0.6443, 0.7951, 0.8415, 0.8208, 1.2269, 1.1489,
        0.6945, 0.7999, 0.7461, 0.6775, 0.8180, 0.6875, 0.8100, 0.6875, 1.2523,
        0.6409, 0.6162, 0.7032, 0.6300, 0.6222, 0.6982, 0.7528, 0.9679, 0.8208,
        1.6867, 1.0528, 0.7545, 0.6918, 0.6340, 0.6283, 0.7712, 0.6492, 1.1199,
        0.6269, 1.2793, 0.8721, 0.6281, 0.6334, 0.7673, 3.9071, 1.5780, 0.6866],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  65  79  37  86 142  60  47  56  73  31  57  49
  52  50 196 141 154 187 113  81 123 181 141 426 168 410 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  77 270  63 141
 153 114 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3719, 0.6728, 1.1805, 1.2524, 0.9364, 0.8915, 0.6748, 0.7399, 0.6690,
        1.2794, 0.8998, 0.6370, 1.1108, 1.3893, 0.8512, 1.8925, 0.7399, 0.6167,
        1.5302, 2.0694, 1.2524, 0.8236, 0.9625, 1.1592, 1.2794, 1.1200, 1.9761,
        1.0605, 0.8075, 1.3552, 1.6301, 1.4259, 1.1805, 2.2925, 1.4072, 1.5781,
        1.5077, 1.5537, 0.7132, 0.8101, 0.7795, 0.7243, 0.9041, 1.1019, 0.8649,
        0.7325, 0.8101, 0.6223, 0.7528, 0.6238, 0.8024, 0.7033, 0.8101, 1.5077,
        0.7774, 0.7617, 0.7097, 0.7882, 0.6315, 0.6188, 0.7192, 1.4259, 0.7003,
        0.7043, 0.8447, 0.9414, 1.0040, 0.7905, 1.1390, 0.6573, 1.3082, 0.8101,
        0.7816, 0.8998, 0.9625, 1.3552, 1.8539, 0.6235, 0.6419, 0.8479, 1.0684,
        0.8024, 2.2314, 1.4861, 0.6443, 0.7952, 0.8415, 0.8208, 1.2270, 1.1490,
        0.6945, 0.8000, 0.7461, 0.6775, 0.8181, 0.6875, 0.8101, 0.6875, 1.2524,
        0.6410, 0.6162, 0.7033, 0.6301, 0.6222, 0.6983, 0.7528, 0.9680, 0.8208,
        1.6868, 1.0529, 0.7545, 0.6918, 0.6341, 0.6283, 0.7713, 0.6492, 1.1200,
        0.6269, 1.2794, 0.8722, 0.6282, 0.6334, 0.7674, 3.9074, 1.5781, 0.6867],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  66  79  37  86 142  60  47  56  73  31  57  50
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  78 270  63 141
 153 114 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 384  65 121 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3724, 0.6730, 1.1809, 1.2528, 0.9367, 0.8919, 0.6750, 0.7401, 0.6693,
        1.2799, 0.9002, 0.6373, 1.1112, 1.3898, 0.8515, 1.8932, 0.7401, 0.6170,
        1.5308, 2.0702, 1.2528, 0.8239, 0.9628, 1.1596, 1.2662, 1.1204, 1.9769,
        1.0609, 0.8078, 1.3557, 1.6307, 1.4264, 1.1809, 2.2933, 1.4078, 1.5542,
        1.5083, 1.5542, 0.7146, 0.8104, 0.7798, 0.7245, 0.9044, 1.1023, 0.8653,
        0.7327, 0.8104, 0.6225, 0.7531, 0.6240, 0.8027, 0.7036, 0.8104, 1.5083,
        0.7777, 0.7620, 0.7100, 0.7885, 0.6317, 0.6190, 0.7194, 1.4264, 0.7005,
        0.7046, 0.8450, 0.9417, 1.0044, 0.7908, 1.1298, 0.6575, 1.3087, 0.8104,
        0.7819, 0.9002, 0.9628, 1.3557, 1.8546, 0.6237, 0.6421, 0.8482, 1.0688,
        0.8027, 2.2323, 1.4866, 0.6446, 0.7955, 0.8418, 0.8211, 1.2274, 1.1494,
        0.6948, 0.8003, 0.7464, 0.6778, 0.8184, 0.6878, 0.8104, 0.6878, 1.2528,
        0.6412, 0.6165, 0.7036, 0.6303, 0.6224, 0.6986, 0.7531, 0.9684, 0.8211,
        1.6874, 1.0532, 0.7548, 0.6921, 0.6343, 0.6286, 0.7716, 0.6495, 1.1204,
        0.6271, 1.2799, 0.8725, 0.6284, 0.6337, 0.7677, 3.9089, 1.5787, 0.6870],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  66  79  37  86 142  60  47  56  73  31  57  50
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  78 270  63 141
 153 114 101  60  40 413 311 128  85 144  32  53 303 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 546 205 363 427 210 168 100 137
  45  87 167 217 342 374 158 289  79 385  65 121 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3724, 0.6730, 1.1809, 1.2528, 0.9367, 0.8919, 0.6750, 0.7401, 0.6693,
        1.2799, 0.9001, 0.6373, 1.1112, 1.3898, 0.8515, 1.8932, 0.7401, 0.6170,
        1.5308, 2.0702, 1.2528, 0.8239, 0.9628, 1.1596, 1.2662, 1.1204, 1.9768,
        1.0609, 0.8078, 1.3557, 1.6307, 1.4264, 1.1809, 2.2933, 1.4077, 1.5542,
        1.5083, 1.5542, 0.7146, 0.8104, 0.7798, 0.7245, 0.9044, 1.1023, 0.8653,
        0.7327, 0.8104, 0.6225, 0.7531, 0.6240, 0.8027, 0.7036, 0.8104, 1.5083,
        0.7777, 0.7620, 0.7100, 0.7885, 0.6317, 0.6190, 0.7194, 1.4264, 0.7005,
        0.7046, 0.8450, 0.9417, 1.0044, 0.7908, 1.1298, 0.6575, 1.3087, 0.8104,
        0.7819, 0.9001, 0.9628, 1.3557, 1.8546, 0.6237, 0.6421, 0.8482, 1.0688,
        0.8027, 2.2322, 1.4866, 0.6446, 0.7955, 0.8418, 0.8211, 1.2274, 1.1494,
        0.6948, 0.8003, 0.7464, 0.6778, 0.8184, 0.6878, 0.8104, 0.6878, 1.2528,
        0.6412, 0.6165, 0.7036, 0.6303, 0.6224, 0.6986, 0.7531, 0.9684, 0.8211,
        1.6874, 1.0532, 0.7548, 0.6921, 0.6343, 0.6286, 0.7716, 0.6495, 1.1204,
        0.6270, 1.2799, 0.8725, 0.6284, 0.6337, 0.7677, 3.9088, 1.5787, 0.6878],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  66  79  37  86 142  60  47  56  73  31  57  50
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  78 270  63 141
 153 114 101  60  40 413 311 128  85 144  31  53 301 147 130 137  69  76
 214 145 172 235 138 222 141 222  67 314 547 205 363 427 210 168 100 137
  45  87 168 217 342 374 158 289  79 385  66 121 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3719, 0.6728, 1.1805, 1.2524, 0.9364, 0.8915, 0.6748, 0.7399, 0.6690,
        1.2794, 0.8998, 0.6370, 1.1108, 1.3893, 0.8512, 1.8925, 0.7399, 0.6167,
        1.5302, 2.0694, 1.2524, 0.8236, 0.9625, 1.1592, 1.2657, 1.1200, 1.9761,
        1.0605, 0.8075, 1.3552, 1.6301, 1.4259, 1.1805, 2.2925, 1.4072, 1.5537,
        1.5077, 1.5537, 0.7143, 0.8101, 0.7795, 0.7243, 0.9041, 1.1019, 0.8649,
        0.7325, 0.8101, 0.6223, 0.7528, 0.6238, 0.8024, 0.7033, 0.8101, 1.5077,
        0.7774, 0.7617, 0.7097, 0.7882, 0.6315, 0.6188, 0.7192, 1.4259, 0.7003,
        0.7043, 0.8447, 0.9414, 1.0040, 0.7905, 1.1294, 0.6573, 1.3082, 0.8101,
        0.7816, 0.8998, 0.9625, 1.3552, 1.8539, 0.6235, 0.6419, 0.8479, 1.0684,
        0.8024, 2.2925, 1.4861, 0.6450, 0.7952, 0.8415, 0.8208, 1.2270, 1.1490,
        0.6945, 0.8000, 0.7461, 0.6775, 0.8181, 0.6875, 0.8101, 0.6875, 1.2524,
        0.6410, 0.6162, 0.7033, 0.6301, 0.6222, 0.6983, 0.7528, 0.9680, 0.8208,
        1.6868, 1.0529, 0.7528, 0.6918, 0.6341, 0.6283, 0.7713, 0.6492, 1.1200,
        0.6268, 1.2657, 0.8722, 0.6282, 0.6334, 0.7674, 3.9074, 1.5781, 0.6875],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  66  79  36  86 142  60  47  56  73  32  57  50
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 144 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  78 270  63 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 130 137  69  76
 214 145 172 235 138 222 141 223  67 314 547 205 363 427 210 168 100 137
  45  87 168 217 341 374 158 289  79 385  66 121 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3723, 0.6730, 1.1808, 1.2528, 0.9366, 0.8918, 0.6750, 0.7401, 0.6692,
        1.2798, 0.9001, 0.6372, 1.1111, 1.3897, 0.8515, 1.8931, 0.7401, 0.6169,
        1.5307, 2.0700, 1.2528, 0.8239, 0.9627, 1.1595, 1.2661, 1.1203, 2.0220,
        1.0608, 0.8077, 1.3556, 1.6306, 1.4263, 1.1808, 2.2321, 1.4076, 1.5541,
        1.5081, 1.5541, 0.7145, 0.8103, 0.7797, 0.7245, 0.9043, 1.1022, 0.8652,
        0.7327, 0.8103, 0.6225, 0.7530, 0.6240, 0.8027, 0.7035, 0.8103, 1.5081,
        0.7776, 0.7619, 0.7099, 0.7885, 0.6317, 0.6190, 0.7194, 1.4263, 0.7005,
        0.7045, 0.8450, 0.9416, 1.0043, 0.7907, 1.1297, 0.6575, 1.3086, 0.8103,
        0.7819, 0.9001, 0.9627, 1.3556, 1.8544, 0.6237, 0.6421, 0.8482, 1.0687,
        0.8027, 2.2931, 1.4657, 0.6452, 0.7954, 0.8418, 0.8211, 1.2273, 1.1493,
        0.6947, 0.8002, 0.7464, 0.6777, 0.8183, 0.6877, 0.8103, 0.6869, 1.2528,
        0.6412, 0.6164, 0.7035, 0.6303, 0.6224, 0.6985, 0.7530, 0.9683, 0.8211,
        1.6873, 1.0532, 0.7530, 0.6920, 0.6345, 0.6285, 0.7715, 0.6494, 1.1203,
        0.6270, 1.2661, 0.8724, 0.6284, 0.6336, 0.7676, 3.9086, 1.5785, 0.6877],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  75  66  79  36  86 142  60  47  56  73  32  57  51
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 143 205 141  52
 155 163 199 150 355 477 191  56 208 204 129 105  94 149  78 270  63 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 130 137  69  76
 214 145 172 235 138 222 141 223  67 314 547 205 363 427 210 168 100 137
  45  87 168 217 341 374 158 289  79 385  66 122 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3726, 0.6731, 1.1811, 1.2530, 0.9368, 0.8920, 0.6751, 0.7402, 0.6693,
        1.2800, 0.9003, 0.6373, 1.1113, 1.3899, 0.8516, 1.8934, 0.7402, 0.6170,
        1.5310, 2.0704, 1.2530, 0.8240, 0.9629, 1.1597, 1.2663, 1.1205, 2.0224,
        1.0610, 0.8079, 1.3558, 1.6309, 1.4266, 1.1811, 2.2325, 1.4079, 1.5310,
        1.5084, 1.5544, 0.7147, 0.8105, 0.7799, 0.7246, 0.9045, 1.1024, 0.8654,
        0.7328, 0.8105, 0.6226, 0.7532, 0.6241, 0.8053, 0.7036, 0.8105, 1.5084,
        0.7778, 0.7621, 0.7101, 0.7886, 0.6318, 0.6191, 0.7195, 1.4266, 0.7006,
        0.7047, 0.8451, 0.9418, 1.0045, 0.7909, 1.1299, 0.6576, 1.3089, 0.8105,
        0.7820, 0.9003, 0.9629, 1.3558, 1.8548, 0.6238, 0.6422, 0.8483, 1.0689,
        0.8028, 2.2936, 1.4659, 0.6453, 0.7956, 0.8419, 0.8212, 1.2276, 1.1495,
        0.6949, 0.8004, 0.7465, 0.6779, 0.8185, 0.6879, 0.8105, 0.6870, 1.2530,
        0.6413, 0.6165, 0.7036, 0.6304, 0.6225, 0.6986, 0.7532, 0.9685, 0.8212,
        1.6876, 1.0534, 0.7532, 0.6922, 0.6346, 0.6286, 0.7717, 0.6496, 1.1205,
        0.6271, 1.2663, 0.8690, 0.6285, 0.6338, 0.7677, 3.9093, 1.5788, 0.6879],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  74  66  79  36  86 142  60  47  56  73  32  57  51
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 143 205 141  52
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  78 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 130 137  69  76
 214 145 172 235 138 222 141 223  67 314 547 205 363 427 210 168 100 137
  45  87 168 217 341 374 157 289  80 385  66 122 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3727, 0.6732, 1.1812, 1.2531, 0.9369, 0.8921, 0.6752, 0.7403, 0.6694,
        1.2802, 0.9003, 0.6374, 1.1114, 1.3901, 0.8517, 1.8936, 0.7403, 0.6171,
        1.5311, 2.0706, 1.2531, 0.8241, 0.9630, 1.1704, 1.2664, 1.1206, 2.0226,
        1.0611, 0.8079, 1.3560, 1.6310, 1.4267, 1.1812, 2.2327, 1.4081, 1.5311,
        1.5086, 1.5546, 0.7147, 0.8105, 0.7800, 0.7247, 0.9046, 1.1025, 0.8655,
        0.7329, 0.8105, 0.6227, 0.7533, 0.6242, 0.8054, 0.7037, 0.8105, 1.5086,
        0.7779, 0.7622, 0.7102, 0.7887, 0.6319, 0.6192, 0.7183, 1.4267, 0.7007,
        0.7047, 0.8452, 0.9419, 1.0046, 0.7910, 1.1300, 0.6576, 1.2944, 0.8105,
        0.7821, 0.9003, 0.9630, 1.3560, 1.8550, 0.6239, 0.6422, 0.8484, 1.0690,
        0.8029, 2.2938, 1.4661, 0.6454, 0.7956, 0.8420, 0.8213, 1.2277, 1.1496,
        0.6949, 0.8004, 0.7466, 0.6779, 0.8186, 0.6879, 0.8105, 0.6871, 1.2531,
        0.6414, 0.6166, 0.7037, 0.6305, 0.6226, 0.6987, 0.7533, 0.9686, 0.8213,
        1.6878, 1.0535, 0.7533, 0.6922, 0.6347, 0.6287, 0.7738, 0.6496, 1.1114,
        0.6271, 1.2664, 0.8690, 0.6286, 0.6338, 0.7678, 3.9097, 1.5790, 0.6879],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  73  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  74  66  79  36  86 142  60  47  56  73  32  57  51
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 143 205 141  52
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  78 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 130 137  69  76
 214 145 172 235 138 222 141 223  67 314 547 205 363 427 210 168 100 137
  45  87 168 217 341 374 157 289  80 385  66 122 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3727, 0.6732, 1.1812, 1.2531, 0.9369, 0.8921, 0.6752, 0.7403, 0.6694,
        1.2802, 0.9003, 0.6374, 1.1114, 1.3901, 0.8517, 1.8936, 0.7403, 0.6171,
        1.5311, 2.0706, 1.2531, 0.8241, 0.9630, 1.1704, 1.2664, 1.1206, 2.0226,
        1.0611, 0.8079, 1.3560, 1.6310, 1.4267, 1.1812, 2.2327, 1.4081, 1.5311,
        1.5086, 1.5546, 0.7147, 0.8105, 0.7800, 0.7247, 0.9046, 1.1025, 0.8655,
        0.7329, 0.8105, 0.6227, 0.7533, 0.6242, 0.8054, 0.7037, 0.8105, 1.5086,
        0.7779, 0.7622, 0.7102, 0.7887, 0.6319, 0.6192, 0.7183, 1.4267, 0.7007,
        0.7047, 0.8452, 0.9419, 1.0046, 0.7910, 1.1300, 0.6576, 1.2944, 0.8105,
        0.7821, 0.9003, 0.9630, 1.3560, 1.8550, 0.6239, 0.6422, 0.8484, 1.0690,
        0.8029, 2.2938, 1.4661, 0.6454, 0.7956, 0.8420, 0.8213, 1.2277, 1.1496,
        0.6949, 0.8004, 0.7466, 0.6779, 0.8186, 0.6879, 0.8105, 0.6871, 1.2531,
        0.6414, 0.6166, 0.7037, 0.6305, 0.6226, 0.6987, 0.7533, 0.9686, 0.8213,
        1.6878, 1.0535, 0.7533, 0.6922, 0.6347, 0.6287, 0.7738, 0.6496, 1.1114,
        0.6271, 1.2664, 0.8690, 0.6286, 0.6338, 0.7678, 3.9097, 1.5790, 0.6879],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 242  72  67 106 116 239 176 248  65 114 329  80  58 127  39 176 528
  51  35  67 136 101  74  67  79  36  86 142  60  47  56  73  32  57  51
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 143 205 141  52
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  79 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 130 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 385  66 122 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3729, 0.6733, 1.1924, 1.2533, 0.9370, 0.8922, 0.6752, 0.7404, 0.6695,
        1.2803, 0.9004, 0.6375, 1.1116, 1.3902, 0.8518, 1.8938, 0.7404, 0.6172,
        1.5313, 2.0708, 1.2533, 0.8242, 0.9631, 1.1705, 1.2533, 1.1207, 2.0229,
        1.0613, 0.8080, 1.3561, 1.6312, 1.4268, 1.1813, 2.2330, 1.4082, 1.5313,
        1.5087, 1.5547, 0.7148, 0.8106, 0.7800, 0.7248, 0.9047, 1.1026, 0.8655,
        0.7330, 0.8106, 0.6227, 0.7533, 0.6242, 0.8055, 0.7038, 0.8106, 1.5087,
        0.7779, 0.7622, 0.7102, 0.7888, 0.6319, 0.6192, 0.7184, 1.4268, 0.7007,
        0.7048, 0.8453, 0.9420, 1.0047, 0.7911, 1.1207, 0.6577, 1.2945, 0.8106,
        0.7822, 0.9004, 0.9631, 1.3561, 1.8552, 0.6239, 0.6423, 0.8485, 1.0691,
        0.8030, 2.2941, 1.4662, 0.6454, 0.7957, 0.8421, 0.8214, 1.2278, 1.1498,
        0.6950, 0.8005, 0.7467, 0.6780, 0.8186, 0.6880, 0.8080, 0.6872, 1.2533,
        0.6414, 0.6166, 0.7038, 0.6305, 0.6226, 0.6998, 0.7533, 0.9687, 0.8214,
        1.6880, 1.0536, 0.7533, 0.6923, 0.6347, 0.6288, 0.7738, 0.6497, 1.1116,
        0.6272, 1.2666, 0.8691, 0.6286, 0.6339, 0.7679, 3.9101, 1.5792, 0.6880],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 241  72  67 106 116 238 176 248  65 114 329  80  58 127  39 176 526
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  52
  52  50 195 141 154 187 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  80 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 385  66 122 375 345 160  17  49 222]
CBFL per class weights: tensor([1.3740, 0.6745, 1.1934, 1.2543, 0.9378, 0.8929, 0.6765, 0.7410, 0.6700,
        1.2814, 0.9012, 0.6380, 1.1125, 1.3914, 0.8525, 1.8954, 0.7410, 0.6178,
        1.5326, 2.0246, 1.2543, 0.8249, 0.9639, 1.1715, 1.2543, 1.1125, 2.0246,
        1.0621, 0.8087, 1.3573, 1.6326, 1.4280, 1.1823, 2.2349, 1.4094, 1.5100,
        1.5100, 1.5560, 0.7154, 0.8113, 0.7807, 0.7254, 0.9055, 1.1036, 0.8663,
        0.7336, 0.8113, 0.6232, 0.7540, 0.6248, 0.8062, 0.7044, 0.8113, 1.4883,
        0.7786, 0.7629, 0.7108, 0.7895, 0.6325, 0.6198, 0.7190, 1.4280, 0.7013,
        0.7054, 0.8460, 0.9428, 1.0056, 0.7917, 1.1125, 0.6583, 1.2956, 0.8113,
        0.7828, 0.9012, 0.9639, 1.3573, 1.8567, 0.6245, 0.6429, 0.8492, 1.0700,
        0.8037, 2.2960, 1.4675, 0.6460, 0.7964, 0.8460, 0.8221, 1.2289, 1.1507,
        0.6956, 0.8012, 0.7473, 0.6786, 0.8193, 0.6886, 0.8087, 0.6878, 1.2543,
        0.6420, 0.6172, 0.7044, 0.6311, 0.6232, 0.7003, 0.7540, 0.9695, 0.8221,
        1.6894, 1.0545, 0.7540, 0.6929, 0.6353, 0.6293, 0.7745, 0.6502, 1.1125,
        0.6277, 1.2676, 0.8699, 0.6291, 0.6344, 0.7686, 3.9134, 1.5805, 0.6886],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 238 176 248  66 114 329  80  58 127  39 176 526
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 141 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  80 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  66 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3744, 0.6753, 1.1938, 1.2546, 0.9381, 0.8932, 0.6767, 0.7412, 0.6702,
        1.2680, 0.9014, 0.6382, 1.1128, 1.3918, 0.8527, 1.8959, 0.7412, 0.6179,
        1.5330, 2.0251, 1.2546, 0.8251, 0.9642, 1.1718, 1.2546, 1.1128, 2.0251,
        1.0624, 0.8089, 1.3576, 1.6330, 1.4284, 1.1826, 2.2355, 1.4098, 1.4887,
        1.5104, 1.5565, 0.7156, 0.8115, 0.7809, 0.7269, 0.9057, 1.1039, 0.8665,
        0.7338, 0.8115, 0.6234, 0.7542, 0.6249, 0.8064, 0.7046, 0.8115, 1.4887,
        0.7788, 0.7631, 0.7110, 0.7897, 0.6326, 0.6199, 0.7192, 1.4284, 0.7015,
        0.7056, 0.8462, 0.9431, 1.0059, 0.7919, 1.1128, 0.6584, 1.2959, 0.8115,
        0.7831, 0.9014, 0.9642, 1.3576, 1.8572, 0.6246, 0.6430, 0.8495, 1.0703,
        0.8039, 2.2966, 1.4679, 0.6462, 0.7966, 0.8462, 0.8223, 1.2292, 1.1510,
        0.6958, 0.8014, 0.7475, 0.6788, 0.8195, 0.6888, 0.8089, 0.6879, 1.2546,
        0.6422, 0.6173, 0.7046, 0.6312, 0.6233, 0.7005, 0.7542, 0.9698, 0.8223,
        1.6899, 1.0548, 0.7542, 0.6931, 0.6354, 0.6295, 0.7747, 0.6504, 1.1128,
        0.6280, 1.2680, 0.8701, 0.6293, 0.6346, 0.7688, 3.9145, 1.5809, 0.6879],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 238 176 248  66 114 329  80  59 127  39 176 526
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 141 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  80 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3747, 0.6755, 1.1940, 1.2550, 0.9383, 0.8934, 0.6768, 0.7414, 0.6704,
        1.2683, 0.9017, 0.6383, 1.1131, 1.3747, 0.8530, 1.8964, 0.7414, 0.6181,
        1.5334, 2.0256, 1.2550, 0.8253, 0.9644, 1.1721, 1.2550, 1.1131, 2.0256,
        1.0627, 0.8091, 1.3580, 1.6334, 1.4288, 1.1829, 2.2360, 1.4101, 1.4891,
        1.5108, 1.5568, 0.7158, 0.8117, 0.7811, 0.7271, 0.9059, 1.1041, 0.8667,
        0.7340, 0.8117, 0.6236, 0.7544, 0.6251, 0.8066, 0.7047, 0.8117, 1.4891,
        0.7790, 0.7633, 0.7112, 0.7899, 0.6328, 0.6201, 0.7194, 1.4288, 0.7017,
        0.7058, 0.8464, 0.9433, 1.0061, 0.7921, 1.1131, 0.6586, 1.2962, 0.8117,
        0.7832, 0.9017, 0.9644, 1.3580, 1.8577, 0.6248, 0.6432, 0.8497, 1.0706,
        0.8041, 2.2972, 1.4682, 0.6463, 0.7968, 0.8464, 0.8225, 1.2295, 1.1513,
        0.6959, 0.8016, 0.7477, 0.6789, 0.8197, 0.6889, 0.8091, 0.6881, 1.2550,
        0.6423, 0.6175, 0.7047, 0.6314, 0.6235, 0.7007, 0.7544, 0.9700, 0.8225,
        1.6903, 1.0550, 0.7544, 0.6932, 0.6356, 0.6296, 0.7749, 0.6506, 1.1131,
        0.6282, 1.2550, 0.8703, 0.6295, 0.6347, 0.7689, 3.9154, 1.5813, 0.6881],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 238 176 248  66 114 329  80  59 127  39 176 526
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 141 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  80 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3747, 0.6755, 1.1940, 1.2550, 0.9383, 0.8934, 0.6768, 0.7414, 0.6704,
        1.2683, 0.9017, 0.6383, 1.1131, 1.3747, 0.8530, 1.8964, 0.7414, 0.6181,
        1.5334, 2.0256, 1.2550, 0.8253, 0.9644, 1.1721, 1.2550, 1.1131, 2.0256,
        1.0627, 0.8091, 1.3580, 1.6334, 1.4288, 1.1829, 2.2360, 1.4101, 1.4891,
        1.5108, 1.5568, 0.7158, 0.8117, 0.7811, 0.7271, 0.9059, 1.1041, 0.8667,
        0.7340, 0.8117, 0.6236, 0.7544, 0.6251, 0.8066, 0.7047, 0.8117, 1.4891,
        0.7790, 0.7633, 0.7112, 0.7899, 0.6328, 0.6201, 0.7194, 1.4288, 0.7017,
        0.7058, 0.8464, 0.9433, 1.0061, 0.7921, 1.1131, 0.6586, 1.2962, 0.8117,
        0.7832, 0.9017, 0.9644, 1.3580, 1.8577, 0.6248, 0.6432, 0.8497, 1.0706,
        0.8041, 2.2972, 1.4682, 0.6463, 0.7968, 0.8464, 0.8225, 1.2295, 1.1513,
        0.6959, 0.8016, 0.7477, 0.6789, 0.8197, 0.6889, 0.8091, 0.6881, 1.2550,
        0.6423, 0.6175, 0.7047, 0.6314, 0.6235, 0.7007, 0.7544, 0.9700, 0.8225,
        1.6903, 1.0550, 0.7544, 0.6932, 0.6356, 0.6296, 0.7749, 0.6506, 1.1131,
        0.6282, 1.2550, 0.8703, 0.6295, 0.6347, 0.7689, 3.9154, 1.5813, 0.6881],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 238 176 248  66 114 329  80  59 127  39 176 525
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 141 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  81 270  64 141
 153 114 101  60  40 413 311 128  85 144  31  54 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3748, 0.6755, 1.1941, 1.2550, 0.9384, 0.8934, 0.6769, 0.7414, 0.6704,
        1.2684, 0.9017, 0.6384, 1.1131, 1.3748, 0.8530, 1.8965, 0.7414, 0.6181,
        1.5335, 2.0257, 1.2550, 0.8254, 0.9645, 1.1722, 1.2550, 1.1131, 2.0257,
        1.0628, 0.8092, 1.3581, 1.6335, 1.4289, 1.1830, 2.2362, 1.4102, 1.4892,
        1.5109, 1.5570, 0.7158, 0.8118, 0.7812, 0.7271, 0.9060, 1.1042, 0.8668,
        0.7340, 0.8118, 0.6236, 0.7544, 0.6251, 0.8066, 0.7048, 0.8118, 1.4892,
        0.7791, 0.7633, 0.7112, 0.7899, 0.6328, 0.6201, 0.7195, 1.4289, 0.7017,
        0.7058, 0.8465, 0.9434, 1.0062, 0.7922, 1.1042, 0.6587, 1.2963, 0.8118,
        0.7833, 0.9017, 0.9645, 1.3581, 1.8578, 0.6248, 0.6432, 0.8497, 1.0706,
        0.8041, 2.2973, 1.4683, 0.6464, 0.7969, 0.8465, 0.8226, 1.2296, 1.1514,
        0.6960, 0.8017, 0.7477, 0.6790, 0.8198, 0.6890, 0.8092, 0.6882, 1.2550,
        0.6424, 0.6175, 0.7048, 0.6314, 0.6235, 0.7008, 0.7544, 0.9701, 0.8226,
        1.6904, 1.0551, 0.7544, 0.6933, 0.6356, 0.6297, 0.7749, 0.6506, 1.1131,
        0.6282, 1.2550, 0.8704, 0.6295, 0.6348, 0.7690, 3.9157, 1.5814, 0.6882],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  59 128  40 176 525
  51  36  67 136 101  74  67  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 141 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 477 192  56 208 204 129 105  94 149  81 270  64 141
 153 114 101  60  40 412 311 128  85 144  31  55 301 147 129 137  69  76
 214 145 172 235 138 222 142 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3755, 0.6759, 1.1947, 1.2557, 0.9388, 0.8939, 0.6779, 0.7418, 0.6708,
        1.2690, 0.9022, 0.6387, 1.1137, 1.3755, 0.8501, 1.8587, 0.7418, 0.6184,
        1.5342, 2.0267, 1.2557, 0.8258, 0.9650, 1.1727, 1.2557, 1.1137, 2.0267,
        1.0633, 0.8096, 1.3587, 1.6343, 1.4296, 1.1836, 2.2373, 1.4109, 1.4899,
        1.5116, 1.5577, 0.7162, 0.8122, 0.7815, 0.7275, 0.9064, 1.1047, 0.8672,
        0.7344, 0.8122, 0.6239, 0.7548, 0.6254, 0.8070, 0.7051, 0.8122, 1.4899,
        0.7794, 0.7637, 0.7116, 0.7903, 0.6332, 0.6204, 0.7198, 1.4296, 0.7021,
        0.7062, 0.8469, 0.9438, 1.0067, 0.7926, 1.1047, 0.6590, 1.2970, 0.8122,
        0.7837, 0.9022, 0.9650, 1.3587, 1.8587, 0.6252, 0.6435, 0.8501, 1.0712,
        0.8045, 2.2985, 1.4489, 0.6467, 0.7972, 0.8469, 0.8230, 1.2302, 1.1520,
        0.6963, 0.8021, 0.7481, 0.6793, 0.8202, 0.6893, 0.8096, 0.6885, 1.2557,
        0.6427, 0.6178, 0.7051, 0.6317, 0.6238, 0.7011, 0.7548, 0.9705, 0.8230,
        1.6912, 1.0556, 0.7548, 0.6936, 0.6359, 0.6300, 0.7753, 0.6509, 1.1137,
        0.6285, 1.2557, 0.8708, 0.6298, 0.6351, 0.7694, 3.9176, 1.5822, 0.6885],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  60 128  41 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 140 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 163 199 150 355 476 192  56 208 204 129 105  94 149  82 270  64 141
 153 114 101  60  40 412 311 128  85 144  31  56 301 147 129 137  69  76
 214 145 172 235 137 222 141 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3765, 0.6763, 1.1955, 1.2565, 0.9395, 0.8945, 0.6784, 0.7423, 0.6712,
        1.2699, 0.9028, 0.6391, 1.1145, 1.3597, 0.8507, 1.8232, 0.7423, 0.6189,
        1.5353, 2.0281, 1.2565, 0.8264, 0.9656, 1.1735, 1.2436, 1.1145, 2.0281,
        1.0640, 0.8101, 1.3597, 1.6355, 1.4306, 1.1844, 2.2388, 1.4119, 1.4910,
        1.5127, 1.5588, 0.7167, 0.8154, 0.7821, 0.7280, 0.9071, 1.1055, 0.8678,
        0.7349, 0.8127, 0.6243, 0.7553, 0.6259, 0.8076, 0.7056, 0.8127, 1.4910,
        0.7800, 0.7642, 0.7121, 0.7908, 0.6336, 0.6209, 0.7203, 1.4306, 0.7026,
        0.7067, 0.8475, 0.9445, 1.0074, 0.7931, 1.0968, 0.6594, 1.2979, 0.8127,
        0.7842, 0.9028, 0.9656, 1.3597, 1.8600, 0.6257, 0.6440, 0.8507, 1.0719,
        0.8051, 2.3000, 1.4306, 0.6471, 0.7978, 0.8475, 0.8235, 1.2310, 1.1528,
        0.6968, 0.8026, 0.7486, 0.6798, 0.8235, 0.6898, 0.8127, 0.6890, 1.2565,
        0.6431, 0.6182, 0.7056, 0.6322, 0.6243, 0.7016, 0.7553, 0.9712, 0.8235,
        1.6924, 1.0563, 0.7553, 0.6941, 0.6364, 0.6304, 0.7759, 0.6514, 1.1145,
        0.6290, 1.2565, 0.8714, 0.6303, 0.6355, 0.7699, 3.9203, 1.5833, 0.6890],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  61 128  41 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 140 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 105  94 149  82 270  64 141
 153 114 101  60  40 412 311 128  84 144  31  56 301 147 129 137  69  76
 214 145 172 235 137 222 141 223  67 314 547 205 363 427 209 168 100 137
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3766, 0.6764, 1.1956, 1.2566, 0.9395, 0.8946, 0.6784, 0.7424, 0.6713,
        1.2700, 0.9029, 0.6392, 1.1145, 1.3435, 0.8508, 1.8233, 0.7424, 0.6190,
        1.5354, 2.0283, 1.2566, 0.8264, 0.9657, 1.1736, 1.2437, 1.1145, 2.0283,
        1.0641, 0.8102, 1.3598, 1.6356, 1.4307, 1.1845, 2.2390, 1.4120, 1.4911,
        1.5128, 1.5589, 0.7167, 0.8154, 0.7821, 0.7280, 0.9071, 1.1056, 0.8679,
        0.7349, 0.8128, 0.6244, 0.7554, 0.6259, 0.8077, 0.7057, 0.8128, 1.4911,
        0.7800, 0.7624, 0.7121, 0.7909, 0.6336, 0.6210, 0.7204, 1.4307, 0.7026,
        0.7067, 0.8476, 0.9446, 1.0074, 0.7932, 1.0969, 0.6595, 1.2980, 0.8128,
        0.7843, 0.9029, 0.9657, 1.3598, 1.8601, 0.6257, 0.6440, 0.8508, 1.0801,
        0.8051, 2.3002, 1.4307, 0.6472, 0.7979, 0.8476, 0.8236, 1.2311, 1.1529,
        0.6969, 0.8027, 0.7487, 0.6798, 0.8236, 0.6899, 0.8128, 0.6890, 1.2566,
        0.6432, 0.6183, 0.7057, 0.6322, 0.6243, 0.7016, 0.7554, 0.9713, 0.8236,
        1.6925, 1.0564, 0.7554, 0.6942, 0.6364, 0.6305, 0.7759, 0.6514, 1.1145,
        0.6290, 1.2566, 0.8715, 0.6303, 0.6356, 0.7700, 3.9206, 1.5834, 0.6890],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  61 128  41 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  73  32  57  53
  52  50 195 140 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 105  93 149  82 270  64 141
 153 114 101  60  40 412 311 128  84 144  31  56 301 147 129 137  69  76
 214 145 172 235 137 222 141 223  67 314 547 205 363 427 209 168 100 138
  45  87 168 217 341 374 157 289  80 384  67 122 375 345 160  17  49 223]
CBFL per class weights: tensor([1.3765, 0.6764, 1.1956, 1.2566, 0.9395, 0.8945, 0.6784, 0.7423, 0.6713,
        1.2699, 0.9028, 0.6392, 1.1145, 1.3435, 0.8508, 1.8232, 0.7423, 0.6189,
        1.5353, 2.0282, 1.2566, 0.8264, 0.9657, 1.1736, 1.2436, 1.1145, 2.0282,
        1.0641, 0.8102, 1.3597, 1.6355, 1.4306, 1.1844, 2.2389, 1.4119, 1.4910,
        1.5128, 1.5589, 0.7167, 0.8154, 0.7821, 0.7280, 0.9071, 1.1056, 0.8678,
        0.7349, 0.8128, 0.6244, 0.7553, 0.6259, 0.8076, 0.7057, 0.8128, 1.4910,
        0.7800, 0.7624, 0.7121, 0.7909, 0.6336, 0.6209, 0.7203, 1.4306, 0.7026,
        0.7067, 0.8475, 0.9445, 1.0139, 0.7932, 1.0968, 0.6595, 1.2979, 0.8128,
        0.7843, 0.9028, 0.9657, 1.3597, 1.8601, 0.6257, 0.6440, 0.8508, 1.0800,
        0.8051, 2.3001, 1.4306, 0.6472, 0.7978, 0.8475, 0.8236, 1.2311, 1.1528,
        0.6969, 0.8027, 0.7486, 0.6798, 0.8236, 0.6898, 0.8128, 0.6890, 1.2566,
        0.6431, 0.6183, 0.7057, 0.6322, 0.6243, 0.7016, 0.7553, 0.9713, 0.8208,
        1.6925, 1.0564, 0.7553, 0.6941, 0.6364, 0.6304, 0.7759, 0.6514, 1.1145,
        0.6290, 1.2566, 0.8714, 0.6303, 0.6356, 0.7699, 3.9205, 1.5834, 0.6890],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  41 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  74  32  57  53
  52  50 195 140 154 186 113  81 123 181 141 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 105  93 149  82 270  64 141
 153 114 101  60  40 412 311 128  84 144  31  56 301 147 129 137  68  76
 214 145 172 235 137 222 141 223  67 314 547 205 363 427 209 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  17  50 223]
CBFL per class weights: tensor([1.3769, 0.6766, 1.1960, 1.2570, 0.9398, 0.8948, 0.6786, 0.7426, 0.6715,
        1.2703, 0.9031, 0.6394, 1.1148, 1.3282, 0.8510, 1.8238, 0.7426, 0.6191,
        1.5358, 2.0288, 1.2570, 0.8266, 0.9660, 1.1740, 1.2440, 1.1148, 2.0288,
        1.0644, 0.8104, 1.3601, 1.6360, 1.4311, 1.1740, 2.2396, 1.4124, 1.4915,
        1.5132, 1.5593, 0.7169, 0.8156, 0.7824, 0.7282, 0.9074, 1.1059, 0.8681,
        0.7351, 0.8130, 0.6246, 0.7556, 0.6261, 0.8079, 0.7059, 0.8130, 1.4915,
        0.7802, 0.7626, 0.7123, 0.7911, 0.6338, 0.6211, 0.7205, 1.4311, 0.7028,
        0.7069, 0.8478, 0.9448, 1.0142, 0.7934, 1.0972, 0.6597, 1.2983, 0.8130,
        0.7845, 0.9031, 0.9660, 1.3601, 1.8606, 0.6259, 0.6442, 0.8510, 1.0804,
        0.8054, 2.3008, 1.4311, 0.6474, 0.7981, 0.8478, 0.8238, 1.2440, 1.1532,
        0.6971, 0.8029, 0.7489, 0.6800, 0.8238, 0.6900, 0.8130, 0.6892, 1.2570,
        0.6433, 0.6185, 0.7059, 0.6324, 0.6245, 0.7018, 0.7556, 0.9715, 0.8211,
        1.6930, 1.0567, 0.7556, 0.6952, 0.6366, 0.6306, 0.7761, 0.6516, 1.1148,
        0.6292, 1.2570, 0.8717, 0.6305, 0.6358, 0.7702, 3.9217, 1.5593, 0.6892],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  74  32  57  53
  52  50 195 140 154 186 113  81 123 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 105  93 149  83 270  64 141
 153 114 102  60  40 411 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 172 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  17  50 223]
CBFL per class weights: tensor([1.3776, 0.6769, 1.1966, 1.2576, 0.9403, 0.8953, 0.6790, 0.7429, 0.6718,
        1.2710, 0.9036, 0.6397, 1.1154, 1.3289, 0.8515, 1.7896, 0.7429, 0.6194,
        1.5366, 2.0299, 1.2576, 0.8271, 0.9665, 1.1745, 1.2446, 1.1154, 2.0299,
        1.0649, 0.8108, 1.3608, 1.6369, 1.4318, 1.1745, 2.2407, 1.4131, 1.4922,
        1.5140, 1.5601, 0.7173, 0.8161, 0.7827, 0.7286, 0.9078, 1.1064, 0.8685,
        0.7355, 0.8161, 0.6249, 0.7559, 0.6264, 0.8083, 0.7062, 0.8134, 1.4922,
        0.7806, 0.7630, 0.7127, 0.7915, 0.6341, 0.6214, 0.7209, 1.4318, 0.7032,
        0.7073, 0.8482, 0.9453, 1.0147, 0.7938, 1.0892, 0.6600, 1.2990, 0.8134,
        0.7849, 0.9036, 0.9610, 1.3608, 1.8616, 0.6263, 0.6445, 0.8515, 1.0809,
        0.8058, 2.3020, 1.4131, 0.6477, 0.7985, 0.8482, 0.8242, 1.2446, 1.1537,
        0.6974, 0.8033, 0.7492, 0.6804, 0.8242, 0.6904, 0.8134, 0.6896, 1.2576,
        0.6437, 0.6188, 0.7062, 0.6327, 0.6248, 0.7032, 0.7559, 0.9720, 0.8215,
        1.6938, 1.0572, 0.7559, 0.6956, 0.6369, 0.6309, 0.7765, 0.6519, 1.1154,
        0.6295, 1.2576, 0.8721, 0.6308, 0.6361, 0.7706, 3.9237, 1.5601, 0.6896],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  74  32  57  53
  52  49 195 140 154 186 113  81 123 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  83 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  50 223]
CBFL per class weights: tensor([1.3796, 0.6779, 1.1983, 1.2594, 0.9416, 0.8965, 0.6799, 0.7440, 0.6728,
        1.2728, 0.9049, 0.6406, 1.1170, 1.3308, 0.8527, 1.7922, 0.7440, 0.6203,
        1.5388, 2.0328, 1.2594, 0.8283, 0.9678, 1.1762, 1.2464, 1.1170, 2.0328,
        1.0665, 0.8120, 1.3628, 1.6392, 1.4338, 1.1762, 2.2439, 1.4151, 1.4944,
        1.5162, 1.5869, 0.7183, 0.8172, 0.7839, 0.7297, 0.9091, 1.1080, 0.8698,
        0.7366, 0.8172, 0.6258, 0.7570, 0.6273, 0.8094, 0.7072, 0.8146, 1.4944,
        0.7818, 0.7641, 0.7137, 0.7927, 0.6350, 0.6223, 0.7220, 1.4338, 0.7042,
        0.7083, 0.8494, 0.9416, 1.0162, 0.7949, 1.0908, 0.6614, 1.3008, 0.8146,
        0.7860, 0.9049, 0.9624, 1.3628, 1.8643, 0.6273, 0.6455, 0.8527, 1.0825,
        0.8069, 2.3053, 1.4151, 0.6486, 0.7996, 0.8494, 0.8254, 1.2464, 1.1554,
        0.6984, 0.8045, 0.7487, 0.6813, 0.8254, 0.6914, 0.8146, 0.6906, 1.2594,
        0.6446, 0.6197, 0.7072, 0.6336, 0.6257, 0.7042, 0.7570, 0.9734, 0.8227,
        1.6963, 1.0588, 0.7570, 0.6966, 0.6378, 0.6319, 0.7776, 0.6529, 1.1170,
        0.6304, 1.2594, 0.8734, 0.6317, 0.6370, 0.7717, 3.7292, 1.5624, 0.6906],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 524
  51  36  67 136 101  74  68  80  36  86 142  60  47  56  74  32  57  53
  52  49 195 140 154 186 113  81 123 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  83 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  50 223]
CBFL per class weights: tensor([1.3796, 0.6779, 1.1983, 1.2594, 0.9416, 0.8965, 0.6799, 0.7440, 0.6728,
        1.2728, 0.9049, 0.6406, 1.1170, 1.3308, 0.8527, 1.7922, 0.7440, 0.6203,
        1.5388, 2.0328, 1.2594, 0.8283, 0.9678, 1.1762, 1.2464, 1.1170, 2.0328,
        1.0665, 0.8120, 1.3628, 1.6392, 1.4338, 1.1762, 2.2439, 1.4151, 1.4944,
        1.5162, 1.5869, 0.7183, 0.8172, 0.7839, 0.7297, 0.9091, 1.1080, 0.8698,
        0.7366, 0.8172, 0.6258, 0.7570, 0.6273, 0.8094, 0.7072, 0.8146, 1.4944,
        0.7818, 0.7641, 0.7137, 0.7927, 0.6350, 0.6223, 0.7220, 1.4338, 0.7042,
        0.7083, 0.8494, 0.9416, 1.0162, 0.7949, 1.0908, 0.6614, 1.3008, 0.8146,
        0.7860, 0.9049, 0.9624, 1.3628, 1.8643, 0.6273, 0.6455, 0.8527, 1.0825,
        0.8069, 2.3053, 1.4151, 0.6486, 0.7996, 0.8494, 0.8254, 1.2464, 1.1554,
        0.6984, 0.8045, 0.7487, 0.6813, 0.8254, 0.6914, 0.8146, 0.6906, 1.2594,
        0.6446, 0.6197, 0.7072, 0.6336, 0.6257, 0.7042, 0.7570, 0.9734, 0.8227,
        1.6963, 1.0588, 0.7570, 0.6966, 0.6378, 0.6319, 0.7776, 0.6529, 1.1170,
        0.6304, 1.2594, 0.8734, 0.6317, 0.6370, 0.7717, 3.7292, 1.5624, 0.6906],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 524
  51  36  67 136 101  74  69  80  36  86 142  60  47  56  74  32  57  54
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  83 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  51 223]
CBFL per class weights: tensor([1.3802, 0.6782, 1.1988, 1.2599, 0.9420, 0.8969, 0.6802, 0.7443, 0.6731,
        1.2733, 0.9052, 0.6409, 1.1175, 1.3313, 0.8530, 1.7930, 0.7443, 0.6206,
        1.5395, 2.0336, 1.2599, 0.8286, 0.9683, 1.1767, 1.2344, 1.1175, 2.0336,
        1.0669, 0.8123, 1.3634, 1.6399, 1.4345, 1.1767, 2.2449, 1.4157, 1.4741,
        1.5168, 1.5876, 0.7186, 0.8176, 0.7842, 0.7300, 0.9095, 1.1085, 0.8738,
        0.7369, 0.8176, 0.6260, 0.7574, 0.6276, 0.8098, 0.7075, 0.8149, 1.4950,
        0.7821, 0.7645, 0.7140, 0.7930, 0.6353, 0.6226, 0.7223, 1.4345, 0.7045,
        0.7086, 0.8498, 0.9420, 1.0166, 0.7953, 1.0912, 0.6617, 1.3014, 0.8149,
        0.7864, 0.9052, 0.9628, 1.3634, 1.8651, 0.6276, 0.6457, 0.8530, 1.0829,
        0.8073, 2.3063, 1.4157, 0.6489, 0.8000, 0.8498, 0.8258, 1.2470, 1.1559,
        0.6987, 0.8048, 0.7490, 0.6816, 0.8258, 0.6917, 0.8149, 0.6908, 1.2599,
        0.6449, 0.6199, 0.7075, 0.6339, 0.6260, 0.7045, 0.7574, 0.9738, 0.8230,
        1.6970, 1.0592, 0.7574, 0.6969, 0.6381, 0.6321, 0.7780, 0.6532, 1.1175,
        0.6307, 1.2599, 0.8738, 0.6320, 0.6373, 0.7720, 3.7308, 1.5395, 0.6908],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 524
  51  36  67 136 101  74  69  80  36  86 142  60  47  56  75  32  57  54
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  83 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  51 223]
CBFL per class weights: tensor([1.3803, 0.6782, 1.1989, 1.2600, 0.9421, 0.8970, 0.6803, 0.7444, 0.6731,
        1.2734, 0.9053, 0.6409, 1.1176, 1.3315, 0.8531, 1.7931, 0.7444, 0.6206,
        1.5396, 2.0338, 1.2600, 0.8287, 0.9683, 1.1768, 1.2345, 1.1176, 2.0338,
        1.0670, 0.8124, 1.3635, 1.6401, 1.4346, 1.1663, 2.2451, 1.4158, 1.4742,
        1.5169, 1.5877, 0.7187, 0.8177, 0.7843, 0.7300, 0.9096, 1.1086, 0.8738,
        0.7370, 0.8177, 0.6261, 0.7574, 0.6276, 0.8099, 0.7076, 0.8150, 1.4951,
        0.7822, 0.7645, 0.7141, 0.7931, 0.6354, 0.6226, 0.7223, 1.4346, 0.7045,
        0.7086, 0.8499, 0.9421, 1.0167, 0.7954, 1.0913, 0.6618, 1.3015, 0.8150,
        0.7864, 0.9053, 0.9629, 1.3635, 1.8652, 0.6276, 0.6458, 0.8531, 1.0830,
        0.8073, 2.3065, 1.4158, 0.6489, 0.8000, 0.8499, 0.8259, 1.2471, 1.1560,
        0.6988, 0.8049, 0.7491, 0.6817, 0.8259, 0.6917, 0.8150, 0.6909, 1.2600,
        0.6449, 0.6200, 0.7076, 0.6339, 0.6260, 0.7045, 0.7574, 0.9739, 0.8231,
        1.6971, 1.0593, 0.7574, 0.6969, 0.6382, 0.6322, 0.7780, 0.6532, 1.1176,
        0.6307, 1.2600, 0.8738, 0.6320, 0.6373, 0.7721, 3.7311, 1.5396, 0.6909],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 523
  51  36  67 136 101  74  69  80  36  86 142  60  47  56  75  32  57  54
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  84 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  76
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  51 223]
CBFL per class weights: tensor([1.3804, 0.6783, 1.1990, 1.2601, 0.9422, 0.8971, 0.6803, 0.7444, 0.6732,
        1.2735, 0.9054, 0.6410, 1.1177, 1.3315, 0.8532, 1.7932, 0.7444, 0.6207,
        1.5397, 2.0340, 1.2601, 0.8287, 0.9684, 1.1769, 1.2346, 1.1177, 2.0340,
        1.0671, 0.8125, 1.3636, 1.6402, 1.4347, 1.1663, 2.2452, 1.4159, 1.4743,
        1.5170, 1.5878, 0.7187, 0.8177, 0.7843, 0.7301, 0.9097, 1.1087, 0.8739,
        0.7370, 0.8177, 0.6261, 0.7575, 0.6277, 0.8099, 0.7076, 0.8151, 1.4952,
        0.7822, 0.7646, 0.7141, 0.7931, 0.6354, 0.6227, 0.7224, 1.4347, 0.7046,
        0.7087, 0.8499, 0.9422, 1.0168, 0.7954, 1.0831, 0.6618, 1.3016, 0.8151,
        0.7865, 0.9054, 0.9629, 1.3636, 1.8653, 0.6277, 0.6458, 0.8532, 1.0831,
        0.8074, 2.3066, 1.4159, 0.6490, 0.8001, 0.8499, 0.8259, 1.2471, 1.1561,
        0.6988, 0.8049, 0.7491, 0.6817, 0.8259, 0.6918, 0.8151, 0.6909, 1.2601,
        0.6450, 0.6200, 0.7076, 0.6340, 0.6260, 0.7046, 0.7575, 0.9740, 0.8231,
        1.6972, 1.0594, 0.7575, 0.6970, 0.6382, 0.6322, 0.7781, 0.6533, 1.1177,
        0.6308, 1.2601, 0.8739, 0.6321, 0.6374, 0.7721, 3.7313, 1.5397, 0.6909],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 237 176 248  66 114 329  80  62 128  42 176 523
  51  36  67 136 101  74  69  80  36  87 142  60  47  56  75  32  57  54
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  84 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  77
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 160  18  51 223]
CBFL per class weights: tensor([1.3806, 0.6784, 1.1991, 1.2603, 0.9423, 0.8972, 0.6804, 0.7445, 0.6732,
        1.2737, 0.9055, 0.6411, 1.1178, 1.3317, 0.8533, 1.7935, 0.7445, 0.6208,
        1.5399, 2.0342, 1.2603, 0.8288, 0.9685, 1.1771, 1.2347, 1.1178, 2.0342,
        1.0595, 0.8126, 1.3638, 1.6404, 1.4349, 1.1665, 2.2455, 1.4161, 1.4745,
        1.5172, 1.5881, 0.7188, 0.8178, 0.7844, 0.7302, 0.9098, 1.1088, 0.8740,
        0.7371, 0.8178, 0.6262, 0.7576, 0.6278, 0.8100, 0.7077, 0.8152, 1.4955,
        0.7823, 0.7647, 0.7142, 0.7932, 0.6355, 0.6228, 0.7225, 1.4349, 0.7047,
        0.7088, 0.8500, 0.9423, 1.0169, 0.7955, 1.0832, 0.6619, 1.3018, 0.8152,
        0.7866, 0.9055, 0.9631, 1.3638, 1.8656, 0.6278, 0.6459, 0.8533, 1.0832,
        0.8075, 2.3070, 1.4161, 0.6491, 0.8002, 0.8500, 0.8260, 1.2473, 1.1462,
        0.6989, 0.8050, 0.7492, 0.6818, 0.8260, 0.6919, 0.8152, 0.6910, 1.2603,
        0.6450, 0.6201, 0.7077, 0.6341, 0.6261, 0.7047, 0.7576, 0.9741, 0.8232,
        1.6975, 1.0595, 0.7576, 0.6971, 0.6383, 0.6323, 0.7782, 0.6534, 1.1178,
        0.6309, 1.2603, 0.8740, 0.6322, 0.6375, 0.7722, 3.7318, 1.5399, 0.6910],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 236 176 248  66 114 329  80  62 128  42 176 522
  51  36  67 136 101  74  69  80  36  87 142  60  47  56  75  32  57  54
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  84 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  77
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 161  18  52 223]
CBFL per class weights: tensor([1.3809, 0.6785, 1.1994, 1.2605, 0.9425, 0.8974, 0.6812, 0.7447, 0.6734,
        1.2739, 0.9057, 0.6412, 1.1180, 1.3320, 0.8535, 1.7938, 0.7447, 0.6210,
        1.5402, 2.0346, 1.2605, 0.8290, 0.9687, 1.1773, 1.2350, 1.1180, 2.0346,
        1.0597, 0.8127, 1.3640, 1.6407, 1.4351, 1.1667, 2.2460, 1.4164, 1.4748,
        1.5175, 1.5884, 0.7190, 0.8180, 0.7846, 0.7303, 0.9100, 1.1090, 0.8742,
        0.7372, 0.8180, 0.6263, 0.7577, 0.6279, 0.8102, 0.7079, 0.8153, 1.4957,
        0.7825, 0.7648, 0.7144, 0.7934, 0.6356, 0.6229, 0.7226, 1.4351, 0.7048,
        0.7089, 0.8502, 0.9425, 1.0171, 0.7957, 1.0834, 0.6620, 1.3020, 0.8153,
        0.7867, 0.9057, 0.9632, 1.3640, 1.8660, 0.6279, 0.6461, 0.8535, 1.0834,
        0.8077, 2.3074, 1.4164, 0.6492, 0.8003, 0.8502, 0.8262, 1.2476, 1.1465,
        0.6991, 0.8052, 0.7494, 0.6820, 0.8262, 0.6920, 0.8153, 0.6912, 1.2605,
        0.6452, 0.6202, 0.7079, 0.6342, 0.6263, 0.7048, 0.7577, 0.9743, 0.8234,
        1.6978, 1.0597, 0.7577, 0.6972, 0.6384, 0.6324, 0.7783, 0.6535, 1.1180,
        0.6310, 1.2605, 0.8742, 0.6323, 0.6376, 0.7704, 3.7325, 1.5175, 0.6912],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 236 175 248  66 114 329  80  62 128  42 176 522
  51  36  67 136 101  74  69  80  36  87 142  60  47  56  75  32  57  55
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  84 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  77
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 161  18  53 223]
CBFL per class weights: tensor([1.3813, 0.6787, 1.1998, 1.2609, 0.9428, 0.8976, 0.6815, 0.7465, 0.6736,
        1.2743, 0.9060, 0.6414, 1.1184, 1.3324, 0.8537, 1.7944, 0.7449, 0.6212,
        1.5407, 2.0353, 1.2609, 0.8293, 0.9690, 1.1777, 1.2354, 1.1184, 2.0353,
        1.0601, 0.8130, 1.3645, 1.6412, 1.4356, 1.1671, 2.2467, 1.4169, 1.4551,
        1.5180, 1.5889, 0.7192, 0.8182, 0.7848, 0.7305, 0.9103, 1.1094, 0.8745,
        0.7375, 0.8182, 0.6265, 0.7580, 0.6281, 0.8104, 0.7081, 0.8156, 1.4962,
        0.7827, 0.7651, 0.7146, 0.7936, 0.6358, 0.6231, 0.7228, 1.4356, 0.7050,
        0.7092, 0.8505, 0.9428, 1.0174, 0.7959, 1.0838, 0.6622, 1.3024, 0.8156,
        0.7870, 0.9060, 0.9636, 1.3645, 1.8666, 0.6281, 0.6463, 0.8537, 1.0838,
        0.8079, 2.3081, 1.4169, 0.6494, 0.8006, 0.8505, 0.8264, 1.2480, 1.1468,
        0.6993, 0.8054, 0.7496, 0.6822, 0.8264, 0.6922, 0.8156, 0.6914, 1.2609,
        0.6454, 0.6204, 0.7081, 0.6344, 0.6265, 0.7050, 0.7580, 0.9746, 0.8237,
        1.6983, 1.0601, 0.7580, 0.6974, 0.6386, 0.6326, 0.7786, 0.6537, 1.1184,
        0.6312, 1.2609, 0.8745, 0.6325, 0.6378, 0.7707, 3.7337, 1.4962, 0.6914],
       device='cuda:0')
Pred num ex per class (pseudo labels + labelled target examples):  [ 59 240  72  67 106 116 236 175 248  66 114 328  80  62 128  42 176 522
  51  36  67 136 101  74  69  80  36  87 142  60  47  56  75  32  57  55
  52  49 195 140 154 186 113  81 122 181 140 426 168 410 143 205 141  53
 155 164 199 150 355 476 192  56 208 204 129 106  93 149  84 269  64 141
 153 114 102  60  40 410 311 128  84 144  31  57 301 147 129 137  68  77
 214 145 173 235 137 222 141 223  67 314 547 205 363 427 208 168 100 138
  45  87 168 216 341 374 157 289  80 384  67 122 375 345 161  18  54 223]
CBFL per class weights: tensor([1.3815, 0.6788, 1.2000, 1.2612, 0.9429, 0.8978, 0.6816, 0.7466, 0.6737,
        1.2746, 0.9061, 0.6417, 1.1186, 1.3326, 0.8539, 1.7947, 0.7450, 0.6213,
        1.5409, 2.0356, 1.2612, 0.8294, 0.9692, 1.1779, 1.2356, 1.1186, 2.0356,
        1.0602, 0.8131, 1.3647, 1.6415, 1.4358, 1.1673, 2.2471, 1.4171, 1.4553,
        1.5183, 1.5891, 0.7193, 0.8184, 0.7850, 0.7307, 0.9104, 1.1096, 0.8746,
        0.7376, 0.8184, 0.6266, 0.7581, 0.6282, 0.8106, 0.7082, 0.8157, 1.4965,
        0.7829, 0.7652, 0.7147, 0.7938, 0.6359, 0.6232, 0.7230, 1.4358, 0.7052,
        0.7093, 0.8506, 0.9429, 1.0176, 0.7961, 1.0840, 0.6623, 1.3027, 0.8157,
        0.7871, 0.9061, 0.9637, 1.3647, 1.8669, 0.6282, 0.6464, 0.8539, 1.0840,
        0.8081, 2.3085, 1.4171, 0.6495, 0.8007, 0.8506, 0.8266, 1.2482, 1.1470,
        0.6994, 0.8056, 0.7498, 0.6823, 0.8266, 0.6923, 0.8157, 0.6915, 1.2612,
        0.6455, 0.6205, 0.7082, 0.6345, 0.6266, 0.7052, 0.7581, 0.9748, 0.8238,
        1.6986, 1.0602, 0.7581, 0.6976, 0.6387, 0.6327, 0.7787, 0.6538, 1.1186,
        0.6313, 1.2612, 0.8746, 0.6326, 0.6379, 0.7708, 3.7344, 1.4755, 0.6915],
       device='cuda:0')
