Dataset multi Source clipart Target sketch Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  18703
Unlabelled Target Dataset Size:  23826
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  23826 Source:  18703
Unlabeled Target Data Batches: 496
S clipart T sketch Train Ep: 0 lr0.01 	 Loss Classification: 5.043921 Loss T 0.470805 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9689, Accuracy: 17/1134 F1 (1.4991%)


Test set: Average loss: 4.9168, Accuracy: 262/23808 F1 (1.1005%)


Val set: Average loss: 4.9187, Accuracy: 4/360 F1 (1.1111%)

Patience Reset, Counter is: 0
best acc test 1.100470  acc val 1.111111 acc labeled target 1.499118
saving model...
S clipart T sketch Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.960928 Loss T 0.298569 Method MME

S clipart T sketch Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.568446 Loss T 0.218004 Method MME

S clipart T sketch Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 0.934756 Loss T 0.178742 Method MME

S clipart T sketch Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.434211 Loss T 0.191072 Method MME

S clipart T sketch Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.053222 Loss T 0.178485 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6619, Accuracy: 459/1134 F1 (40.4762%)


Test set: Average loss: 2.4610, Accuracy: 11071/23808 F1 (46.5012%)


Val set: Average loss: 2.4457, Accuracy: 174/360 F1 (48.3333%)

Patience Reset, Counter is: 0
best acc test 46.501176  acc val 48.333333 acc labeled target 40.476190
saving model...
S clipart T sketch Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.638027 Loss T 0.153068 Method MME

S clipart T sketch Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.647538 Loss T 0.158939 Method MME

S clipart T sketch Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.040665 Loss T 0.163214 Method MME

S clipart T sketch Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.732883 Loss T 0.146911 Method MME

S clipart T sketch Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.678900 Loss T 0.132449 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4715, Accuracy: 550/1134 F1 (48.5009%)


Test set: Average loss: 2.2350, Accuracy: 12850/23808 F1 (53.9735%)


Val set: Average loss: 2.2004, Accuracy: 184/360 F1 (51.1111%)

Patience Reset, Counter is: 0
best acc test 53.973454  acc val 51.111111 acc labeled target 48.500882
saving model...
S clipart T sketch Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.021616 Loss T 0.122283 Method MME

S clipart T sketch Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.937660 Loss T 0.096170 Method MME

S clipart T sketch Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.495005 Loss T 0.107274 Method MME

S clipart T sketch Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.921592 Loss T 0.107790 Method MME

S clipart T sketch Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.243801 Loss T 0.103880 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5951, Accuracy: 530/1134 F1 (46.7372%)


Test set: Average loss: 2.3559, Accuracy: 12520/23808 F1 (52.5874%)


Val set: Average loss: 2.2274, Accuracy: 183/360 F1 (50.8333%)

Patience getting saturated, current counter is:  0
best acc test 53.973454  acc val 50.833333 acc labeled target 46.737213
saving model...
S clipart T sketch Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.642087 Loss T 0.111238 Method MME

S clipart T sketch Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 0.627836 Loss T 0.091281 Method MME

S clipart T sketch Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.302081 Loss T 0.113148 Method MME

S clipart T sketch Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.720367 Loss T 0.125433 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.11111111 1.         0.11111111 0.44444445 0.         0.
 0.         0.5555556  1.         1.         0.33333334 1.
 0.6666667  0.         0.7777778  0.5555556  0.8888889  1.
 0.5555556  0.         0.6666667  0.8888889  0.44444445 0.8888889
 0.33333334 0.         0.         0.         0.         0.33333334
 0.5555556  0.44444445 0.         0.33333334 0.8888889  0.11111111
 0.6666667  0.         0.11111111 0.5555556  0.7777778  0.33333334
 0.33333334 0.5555556  0.6666667  0.22222222 1.         0.33333334
 0.33333334 0.8888889  0.44444445 0.33333334 0.8888889  0.33333334
 0.11111111 0.6666667  0.5555556  0.5555556  0.7777778  0.6666667
 0.5555556  0.33333334 0.8888889  0.11111111 0.7777778  0.6666667
 0.33333334 0.         0.         0.         0.22222222 0.33333334
 1.         0.5555556  0.33333334 0.         0.         0.11111111
 0.8888889  0.         0.         0.6666667  0.         0.
 0.         0.         0.7777778  0.6666667  0.         0.11111111
 0.         0.7777778  0.6666667  0.8888889  1.         0.6666667
 0.5555556  1.         0.44444445 0.33333334 0.8888889  0.6666667
 0.5555556  0.7777778  0.8888889  0.         0.33333334 0.5555556
 0.5555556  0.44444445 0.5555556  0.8888889  0.8888889  0.
 0.6666667  0.8888889  0.44444445 0.6666667  0.33333334 1.
 0.22222222 0.6666667  0.6666667  0.6666667  0.22222222 0.7777778 ]
Top k classes which perform poorly are:  [113, 27, 26, 25, 68, 67, 32, 75, 19, 76, 79, 80, 28, 82, 83, 37, 84, 85, 88, 6, 5, 4, 105, 90, 13, 69, 35, 38, 63, 54, 0, 77, 89, 2, 45, 124, 120, 70, 71, 66, 74, 99, 61, 53, 106, 51, 48, 47, 29, 24, 42, 41, 10, 118, 33, 22, 116, 109, 31, 3, 50, 98, 18, 73, 102, 96, 7, 15, 108, 110, 107, 39, 60, 43, 57, 30, 56, 65, 92, 123, 44, 87, 122, 121, 81, 12, 117, 101, 59, 20, 114, 36, 55, 95, 103, 125, 14, 91, 86, 64, 58, 40, 93, 16, 115, 21, 23, 112, 111, 34, 49, 52, 104, 78, 100, 62, 94, 72, 17, 97, 119, 11, 9, 8, 1, 46]
Per cls weights according to the accuracy are:  tensor([1.4474, 1.1839, 1.4474, 1.3206, 1.5000, 1.5000, 1.5000, 1.2869, 1.1839,
        1.1839, 1.3583, 1.1839, 1.2567, 1.5000, 1.2297, 1.2869, 1.2056, 1.1839,
        1.2869, 1.5000, 1.2567, 1.2056, 1.3206, 1.2056, 1.3583, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3583, 1.2869, 1.3206, 1.5000, 1.3583, 1.2056, 1.4474,
        1.2567, 1.5000, 1.4474, 1.2869, 1.2297, 1.3583, 1.3583, 1.2869, 1.2567,
        1.4004, 1.1839, 1.3583, 1.3583, 1.2056, 1.3206, 1.3583, 1.2056, 1.3583,
        1.4474, 1.2567, 1.2869, 1.2869, 1.2297, 1.2567, 1.2869, 1.3583, 1.2056,
        1.4474, 1.2297, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.4004, 1.3583,
        1.1839, 1.2869, 1.3583, 1.5000, 1.5000, 1.4474, 1.2056, 1.5000, 1.5000,
        1.2567, 1.5000, 1.5000, 1.5000, 1.5000, 1.2297, 1.2567, 1.5000, 1.4474,
        1.5000, 1.2297, 1.2567, 1.2056, 1.1839, 1.2567, 1.2869, 1.1839, 1.3206,
        1.3583, 1.2056, 1.2567, 1.2869, 1.2297, 1.2056, 1.5000, 1.3583, 1.2869,
        1.2869, 1.3206, 1.2869, 1.2056, 1.2056, 1.5000, 1.2567, 1.2056, 1.3206,
        1.2567, 1.3583, 1.1839, 1.4004, 1.2567, 1.2567, 1.2567, 1.4004, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.5526, 0.8161, 0.5526, 0.6794, 0.5000, 0.5000, 0.5000, 0.7131, 0.8161,
        0.8161, 0.6417, 0.8161, 0.7433, 0.5000, 0.7703, 0.7131, 0.7944, 0.8161,
        0.7131, 0.5000, 0.7433, 0.7944, 0.6794, 0.7944, 0.6417, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6417, 0.7131, 0.6794, 0.5000, 0.6417, 0.7944, 0.5526,
        0.7433, 0.5000, 0.5526, 0.7131, 0.7703, 0.6417, 0.6417, 0.7131, 0.7433,
        0.5996, 0.8161, 0.6417, 0.6417, 0.7944, 0.6794, 0.6417, 0.7944, 0.6417,
        0.5526, 0.7433, 0.7131, 0.7131, 0.7703, 0.7433, 0.7131, 0.6417, 0.7944,
        0.5526, 0.7703, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.5996, 0.6417,
        0.8161, 0.7131, 0.6417, 0.5000, 0.5000, 0.5526, 0.7944, 0.5000, 0.5000,
        0.7433, 0.5000, 0.5000, 0.5000, 0.5000, 0.7703, 0.7433, 0.5000, 0.5526,
        0.5000, 0.7703, 0.7433, 0.7944, 0.8161, 0.7433, 0.7131, 0.8161, 0.6794,
        0.6417, 0.7944, 0.7433, 0.7131, 0.7703, 0.7944, 0.5000, 0.6417, 0.7131,
        0.7131, 0.6794, 0.7131, 0.7944, 0.7944, 0.5000, 0.7433, 0.7944, 0.6794,
        0.7433, 0.6417, 0.8161, 0.5996, 0.7433, 0.7433, 0.7433, 0.5996, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.288358 Loss T 0.092691 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7436, Accuracy: 543/1134 F1 (47.8836%)


Test set: Average loss: 2.4599, Accuracy: 12546/23808 F1 (52.6966%)


Val set: Average loss: 2.4194, Accuracy: 183/360 F1 (50.8333%)

Patience getting saturated, current counter is:  1
best acc test 53.973454  acc val 50.833333 acc labeled target 47.883598
saving model...
S clipart T sketch Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 0.504046 Loss T 0.110473 Method MME

S clipart T sketch Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.503390 Loss T 0.088725 Method MME

S clipart T sketch Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.753530 Loss T 0.089550 Method MME

S clipart T sketch Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.211072 Loss T 0.090194 Method MME

S clipart T sketch Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.790593 Loss T 0.103008 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4421, Accuracy: 577/1134 F1 (50.8818%)


Test set: Average loss: 2.2022, Accuracy: 13704/23808 F1 (57.5605%)


Val set: Average loss: 2.0877, Accuracy: 199/360 F1 (55.2778%)

Patience Reset, Counter is: 2
best acc test 57.560484  acc val 55.277778 acc labeled target 50.881834
saving model...
S clipart T sketch Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.273984 Loss T 0.102641 Method MME

S clipart T sketch Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.229639 Loss T 0.077822 Method MME

S clipart T sketch Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.374918 Loss T 0.104674 Method MME

S clipart T sketch Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.127311 Loss T 0.103783 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.44444445 1.         0.33333334 0.6666667  0.11111111 0.
 0.33333334 0.7777778  1.         0.         0.6666667  1.
 0.         0.         0.33333334 0.7777778  0.6666667  0.7777778
 0.44444445 0.         0.8888889  0.7777778  0.33333334 1.
 0.22222222 0.11111111 0.         0.44444445 0.         1.
 0.5555556  0.22222222 0.11111111 0.5555556  1.         0.
 0.6666667  0.         0.5555556  0.8888889  0.5555556  0.33333334
 0.6666667  0.5555556  0.7777778  0.6666667  1.         0.6666667
 0.33333334 0.8888889  0.5555556  0.33333334 1.         0.6666667
 0.5555556  0.44444445 1.         0.6666667  0.8888889  1.
 0.5555556  0.33333334 1.         0.22222222 0.5555556  0.5555556
 0.         0.11111111 0.         0.         0.22222222 0.33333334
 0.6666667  0.22222222 0.33333334 0.         0.         0.44444445
 0.6666667  0.11111111 0.         0.7777778  0.11111111 0.22222222
 0.         0.         1.         0.6666667  0.         0.33333334
 0.         0.8888889  1.         0.6666667  0.8888889  0.6666667
 0.44444445 1.         0.6666667  0.33333334 0.8888889  0.6666667
 0.5555556  0.7777778  0.8888889  0.         0.44444445 0.5555556
 0.5555556  0.6666667  0.33333334 0.8888889  0.6666667  0.5555556
 0.5555556  1.         0.44444445 0.6666667  0.11111111 1.
 0.7777778  0.7777778  0.6666667  0.5555556  0.         0.8888889 ]
Top k classes which perform poorly are:  [12, 80, 85, 124, 88, 28, 13, 68, 26, 19, 90, 66, 105, 35, 5, 37, 76, 75, 69, 9, 84, 82, 79, 32, 25, 118, 67, 4, 83, 70, 63, 31, 73, 24, 99, 71, 41, 74, 2, 22, 6, 89, 14, 61, 51, 110, 48, 55, 0, 116, 27, 18, 106, 96, 77, 65, 64, 107, 60, 50, 30, 38, 114, 40, 43, 108, 113, 33, 102, 54, 123, 95, 10, 3, 87, 16, 98, 117, 93, 122, 109, 45, 57, 53, 112, 47, 78, 101, 42, 36, 72, 15, 121, 44, 7, 17, 120, 103, 21, 81, 104, 111, 125, 39, 94, 91, 58, 20, 49, 100, 1, 8, 11, 119, 23, 29, 97, 115, 46, 52, 56, 59, 86, 92, 34, 62]
Per cls weights according to the accuracy are:  tensor([1.3206, 1.1839, 1.3583, 1.2567, 1.4474, 1.5000, 1.3583, 1.2297, 1.1839,
        1.5000, 1.2567, 1.1839, 1.5000, 1.5000, 1.3583, 1.2297, 1.2567, 1.2297,
        1.3206, 1.5000, 1.2056, 1.2297, 1.3583, 1.1839, 1.4004, 1.4474, 1.5000,
        1.3206, 1.5000, 1.1839, 1.2869, 1.4004, 1.4474, 1.2869, 1.1839, 1.5000,
        1.2567, 1.5000, 1.2869, 1.2056, 1.2869, 1.3583, 1.2567, 1.2869, 1.2297,
        1.2567, 1.1839, 1.2567, 1.3583, 1.2056, 1.2869, 1.3583, 1.1839, 1.2567,
        1.2869, 1.3206, 1.1839, 1.2567, 1.2056, 1.1839, 1.2869, 1.3583, 1.1839,
        1.4004, 1.2869, 1.2869, 1.5000, 1.4474, 1.5000, 1.5000, 1.4004, 1.3583,
        1.2567, 1.4004, 1.3583, 1.5000, 1.5000, 1.3206, 1.2567, 1.4474, 1.5000,
        1.2297, 1.4474, 1.4004, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.5000, 1.2056, 1.1839, 1.2567, 1.2056, 1.2567, 1.3206, 1.1839, 1.2567,
        1.3583, 1.2056, 1.2567, 1.2869, 1.2297, 1.2056, 1.5000, 1.3206, 1.2869,
        1.2869, 1.2567, 1.3583, 1.2056, 1.2567, 1.2869, 1.2869, 1.1839, 1.3206,
        1.2567, 1.4474, 1.1839, 1.2297, 1.2297, 1.2567, 1.2869, 1.5000, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.6794, 0.8161, 0.6417, 0.7433, 0.5526, 0.5000, 0.6417, 0.7703, 0.8161,
        0.5000, 0.7433, 0.8161, 0.5000, 0.5000, 0.6417, 0.7703, 0.7433, 0.7703,
        0.6794, 0.5000, 0.7944, 0.7703, 0.6417, 0.8161, 0.5996, 0.5526, 0.5000,
        0.6794, 0.5000, 0.8161, 0.7131, 0.5996, 0.5526, 0.7131, 0.8161, 0.5000,
        0.7433, 0.5000, 0.7131, 0.7944, 0.7131, 0.6417, 0.7433, 0.7131, 0.7703,
        0.7433, 0.8161, 0.7433, 0.6417, 0.7944, 0.7131, 0.6417, 0.8161, 0.7433,
        0.7131, 0.6794, 0.8161, 0.7433, 0.7944, 0.8161, 0.7131, 0.6417, 0.8161,
        0.5996, 0.7131, 0.7131, 0.5000, 0.5526, 0.5000, 0.5000, 0.5996, 0.6417,
        0.7433, 0.5996, 0.6417, 0.5000, 0.5000, 0.6794, 0.7433, 0.5526, 0.5000,
        0.7703, 0.5526, 0.5996, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.5000, 0.7944, 0.8161, 0.7433, 0.7944, 0.7433, 0.6794, 0.8161, 0.7433,
        0.6417, 0.7944, 0.7433, 0.7131, 0.7703, 0.7944, 0.5000, 0.6794, 0.7131,
        0.7131, 0.7433, 0.6417, 0.7944, 0.7433, 0.7131, 0.7131, 0.8161, 0.6794,
        0.7433, 0.5526, 0.8161, 0.7703, 0.7703, 0.7433, 0.7131, 0.5000, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.252333 Loss T 0.082986 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7055, Accuracy: 562/1134 F1 (49.5591%)


Test set: Average loss: 2.4180, Accuracy: 13311/23808 F1 (55.9098%)


Val set: Average loss: 2.3358, Accuracy: 201/360 F1 (55.8333%)

Patience Reset, Counter is: 0
best acc test 55.909778  acc val 55.833333 acc labeled target 49.559083
saving model...
S clipart T sketch Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.359924 Loss T 0.074959 Method MME

S clipart T sketch Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.031165 Loss T 0.066152 Method MME

S clipart T sketch Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.322992 Loss T 0.071509 Method MME

S clipart T sketch Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.573789 Loss T 0.065915 Method MME

S clipart T sketch Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.562091 Loss T 0.095157 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5108, Accuracy: 616/1134 F1 (54.3210%)


Test set: Average loss: 2.3391, Accuracy: 13783/23808 F1 (57.8923%)


Val set: Average loss: 2.2500, Accuracy: 205/360 F1 (56.9444%)

Patience Reset, Counter is: 0
best acc test 57.892305  acc val 56.944444 acc labeled target 54.320988
saving model...
S clipart T sketch Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.388442 Loss T 0.072420 Method MME

S clipart T sketch Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.167943 Loss T 0.066948 Method MME

S clipart T sketch Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.396969 Loss T 0.039233 Method MME

S clipart T sketch Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.373299 Loss T 0.080135 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.11111111 0.6666667  0.         0.
 0.22222222 0.8888889  0.8888889  0.22222222 0.8888889  1.
 0.22222222 0.         0.33333334 1.         1.         0.7777778
 0.44444445 0.         0.8888889  0.8888889  0.33333334 1.
 0.33333334 0.11111111 0.22222222 0.44444445 0.         0.22222222
 0.5555556  0.5555556  0.22222222 0.6666667  1.         0.22222222
 0.6666667  0.         0.22222222 0.8888889  0.7777778  0.33333334
 0.22222222 0.5555556  0.7777778  0.11111111 1.         0.7777778
 0.33333334 1.         0.44444445 0.33333334 1.         0.44444445
 0.5555556  0.44444445 0.7777778  0.6666667  1.         0.8888889
 0.8888889  0.33333334 1.         0.22222222 0.8888889  0.8888889
 0.6666667  0.11111111 0.         0.         0.33333334 0.5555556
 0.6666667  0.44444445 0.33333334 0.         0.         0.8888889
 0.8888889  0.         0.         0.8888889  0.         0.
 0.         0.         1.         0.6666667  0.         0.22222222
 0.11111111 0.8888889  0.6666667  0.6666667  0.8888889  0.6666667
 0.44444445 1.         0.6666667  0.33333334 1.         0.6666667
 0.6666667  1.         0.8888889  0.         0.44444445 0.5555556
 0.7777778  0.5555556  0.7777778  0.6666667  0.8888889  0.8888889
 0.5555556  1.         0.5555556  0.6666667  0.         1.
 0.7777778  0.8888889  0.7777778  0.6666667  0.33333334 0.7777778 ]
Top k classes which perform poorly are:  [19, 84, 75, 85, 83, 13, 82, 118, 76, 105, 88, 28, 5, 4, 68, 80, 79, 69, 37, 25, 67, 90, 2, 45, 29, 35, 89, 32, 38, 9, 26, 63, 42, 12, 6, 41, 99, 51, 74, 24, 48, 22, 70, 61, 124, 14, 55, 106, 53, 50, 96, 27, 18, 73, 43, 107, 54, 31, 71, 30, 114, 116, 109, 98, 72, 95, 87, 93, 101, 123, 3, 117, 33, 66, 36, 111, 102, 57, 92, 44, 122, 120, 17, 56, 108, 47, 110, 40, 125, 113, 121, 104, 94, 112, 0, 39, 91, 10, 59, 21, 8, 64, 60, 7, 77, 78, 81, 65, 20, 1, 119, 11, 15, 16, 115, 86, 34, 46, 49, 52, 58, 103, 100, 97, 23, 62]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.4474, 1.2567, 1.5000, 1.5000, 1.4004, 1.2056, 1.2056,
        1.4004, 1.2056, 1.1839, 1.4004, 1.5000, 1.3583, 1.1839, 1.1839, 1.2297,
        1.3206, 1.5000, 1.2056, 1.2056, 1.3583, 1.1839, 1.3583, 1.4474, 1.4004,
        1.3206, 1.5000, 1.4004, 1.2869, 1.2869, 1.4004, 1.2567, 1.1839, 1.4004,
        1.2567, 1.5000, 1.4004, 1.2056, 1.2297, 1.3583, 1.4004, 1.2869, 1.2297,
        1.4474, 1.1839, 1.2297, 1.3583, 1.1839, 1.3206, 1.3583, 1.1839, 1.3206,
        1.2869, 1.3206, 1.2297, 1.2567, 1.1839, 1.2056, 1.2056, 1.3583, 1.1839,
        1.4004, 1.2056, 1.2056, 1.2567, 1.4474, 1.5000, 1.5000, 1.3583, 1.2869,
        1.2567, 1.3206, 1.3583, 1.5000, 1.5000, 1.2056, 1.2056, 1.5000, 1.5000,
        1.2056, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.4004,
        1.4474, 1.2056, 1.2567, 1.2567, 1.2056, 1.2567, 1.3206, 1.1839, 1.2567,
        1.3583, 1.1839, 1.2567, 1.2567, 1.1839, 1.2056, 1.5000, 1.3206, 1.2869,
        1.2297, 1.2869, 1.2297, 1.2567, 1.2056, 1.2056, 1.2869, 1.1839, 1.2869,
        1.2567, 1.5000, 1.1839, 1.2297, 1.2056, 1.2297, 1.2567, 1.3583, 1.2297])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.5526, 0.7433, 0.5000, 0.5000, 0.5996, 0.7944, 0.7944,
        0.5996, 0.7944, 0.8161, 0.5996, 0.5000, 0.6417, 0.8161, 0.8161, 0.7703,
        0.6794, 0.5000, 0.7944, 0.7944, 0.6417, 0.8161, 0.6417, 0.5526, 0.5996,
        0.6794, 0.5000, 0.5996, 0.7131, 0.7131, 0.5996, 0.7433, 0.8161, 0.5996,
        0.7433, 0.5000, 0.5996, 0.7944, 0.7703, 0.6417, 0.5996, 0.7131, 0.7703,
        0.5526, 0.8161, 0.7703, 0.6417, 0.8161, 0.6794, 0.6417, 0.8161, 0.6794,
        0.7131, 0.6794, 0.7703, 0.7433, 0.8161, 0.7944, 0.7944, 0.6417, 0.8161,
        0.5996, 0.7944, 0.7944, 0.7433, 0.5526, 0.5000, 0.5000, 0.6417, 0.7131,
        0.7433, 0.6794, 0.6417, 0.5000, 0.5000, 0.7944, 0.7944, 0.5000, 0.5000,
        0.7944, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.5996,
        0.5526, 0.7944, 0.7433, 0.7433, 0.7944, 0.7433, 0.6794, 0.8161, 0.7433,
        0.6417, 0.8161, 0.7433, 0.7433, 0.8161, 0.7944, 0.5000, 0.6794, 0.7131,
        0.7703, 0.7131, 0.7703, 0.7433, 0.7944, 0.7944, 0.7131, 0.8161, 0.7131,
        0.7433, 0.5000, 0.8161, 0.7703, 0.7944, 0.7703, 0.7433, 0.6417, 0.7703])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.094668 Loss T 0.089082 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6173, Accuracy: 611/1134 F1 (53.8801%)


Test set: Average loss: 2.4486, Accuracy: 13655/23808 F1 (57.3547%)


Val set: Average loss: 2.4164, Accuracy: 208/360 F1 (57.7778%)

Patience Reset, Counter is: 0
best acc test 57.354671  acc val 57.777778 acc labeled target 53.880071
saving model...
S clipart T sketch Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.066943 Loss T 0.078598 Method MME

S clipart T sketch Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.342339 Loss T 0.066829 Method MME

S clipart T sketch Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.323847 Loss T 0.062925 Method MME

S clipart T sketch Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.132721 Loss T 0.091201 Method MME

S clipart T sketch Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.548379 Loss T 0.056486 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5203, Accuracy: 638/1134 F1 (56.2610%)


Test set: Average loss: 2.3881, Accuracy: 14220/23808 F1 (59.7278%)


Val set: Average loss: 2.3922, Accuracy: 206/360 F1 (57.2222%)

Patience getting saturated, current counter is:  0
best acc test 57.354671  acc val 57.222222 acc labeled target 56.261023
saving model...
S clipart T sketch Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.352010 Loss T 0.080121 Method MME

S clipart T sketch Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.106045 Loss T 0.055755 Method MME

S clipart T sketch Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.136366 Loss T 0.071266 Method MME

S clipart T sketch Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.133236 Loss T 0.073563 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.         0.6666667  0.         0.
 0.         1.         1.         0.         1.         0.8888889
 0.         0.         0.33333334 1.         0.8888889  1.
 0.6666667  0.         0.7777778  1.         0.5555556  1.
 0.33333334 0.         0.         0.         0.         0.44444445
 0.5555556  0.22222222 0.22222222 0.5555556  1.         0.
 0.7777778  0.         0.6666667  0.5555556  0.6666667  0.33333334
 0.11111111 0.44444445 0.8888889  0.33333334 1.         0.44444445
 0.33333334 1.         0.44444445 0.22222222 0.8888889  0.7777778
 0.44444445 0.6666667  0.7777778  0.5555556  1.         1.
 0.8888889  0.33333334 0.8888889  0.33333334 1.         0.5555556
 0.8888889  0.         0.11111111 0.11111111 0.33333334 0.6666667
 1.         0.33333334 0.33333334 0.         0.         1.
 0.7777778  0.33333334 0.         1.         0.         0.22222222
 0.         0.         1.         0.6666667  0.         0.44444445
 0.22222222 1.         1.         1.         0.7777778  0.44444445
 0.5555556  1.         0.5555556  0.33333334 1.         0.6666667
 0.6666667  1.         1.         0.33333334 0.6666667  0.6666667
 1.         0.6666667  0.6666667  0.6666667  0.8888889  1.
 0.44444445 0.8888889  0.7777778  0.6666667  0.22222222 1.
 0.7777778  0.8888889  0.7777778  0.6666667  0.44444445 1.        ]
Top k classes which perform poorly are:  [75, 27, 28, 67, 76, 19, 80, 82, 35, 25, 12, 13, 9, 84, 85, 6, 5, 4, 2, 88, 37, 26, 69, 68, 42, 51, 32, 31, 118, 90, 83, 63, 41, 48, 24, 73, 45, 74, 79, 99, 61, 105, 14, 70, 50, 47, 54, 89, 29, 114, 95, 43, 124, 39, 96, 33, 30, 22, 98, 65, 57, 71, 87, 110, 102, 123, 55, 3, 106, 107, 109, 40, 38, 111, 101, 18, 117, 122, 120, 94, 20, 78, 36, 53, 56, 116, 115, 112, 121, 0, 62, 44, 52, 11, 66, 60, 16, 23, 113, 21, 17, 91, 119, 10, 8, 7, 1, 34, 15, 108, 86, 49, 58, 104, 103, 59, 100, 64, 97, 72, 77, 81, 93, 92, 46, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.5000, 1.1839, 1.1839,
        1.5000, 1.1839, 1.2056, 1.5000, 1.5000, 1.3583, 1.1839, 1.2056, 1.1839,
        1.2567, 1.5000, 1.2297, 1.1839, 1.2869, 1.1839, 1.3583, 1.5000, 1.5000,
        1.5000, 1.5000, 1.3206, 1.2869, 1.4004, 1.4004, 1.2869, 1.1839, 1.5000,
        1.2297, 1.5000, 1.2567, 1.2869, 1.2567, 1.3583, 1.4474, 1.3206, 1.2056,
        1.3583, 1.1839, 1.3206, 1.3583, 1.1839, 1.3206, 1.4004, 1.2056, 1.2297,
        1.3206, 1.2567, 1.2297, 1.2869, 1.1839, 1.1839, 1.2056, 1.3583, 1.2056,
        1.3583, 1.1839, 1.2869, 1.2056, 1.5000, 1.4474, 1.4474, 1.3583, 1.2567,
        1.1839, 1.3583, 1.3583, 1.5000, 1.5000, 1.1839, 1.2297, 1.3583, 1.5000,
        1.1839, 1.5000, 1.4004, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3206,
        1.4004, 1.1839, 1.1839, 1.1839, 1.2297, 1.3206, 1.2869, 1.1839, 1.2869,
        1.3583, 1.1839, 1.2567, 1.2567, 1.1839, 1.1839, 1.3583, 1.2567, 1.2567,
        1.1839, 1.2567, 1.2567, 1.2567, 1.2056, 1.1839, 1.3206, 1.2056, 1.2297,
        1.2567, 1.4004, 1.1839, 1.2297, 1.2056, 1.2297, 1.2567, 1.3206, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.5000, 0.8161, 0.8161,
        0.5000, 0.8161, 0.7944, 0.5000, 0.5000, 0.6417, 0.8161, 0.7944, 0.8161,
        0.7433, 0.5000, 0.7703, 0.8161, 0.7131, 0.8161, 0.6417, 0.5000, 0.5000,
        0.5000, 0.5000, 0.6794, 0.7131, 0.5996, 0.5996, 0.7131, 0.8161, 0.5000,
        0.7703, 0.5000, 0.7433, 0.7131, 0.7433, 0.6417, 0.5526, 0.6794, 0.7944,
        0.6417, 0.8161, 0.6794, 0.6417, 0.8161, 0.6794, 0.5996, 0.7944, 0.7703,
        0.6794, 0.7433, 0.7703, 0.7131, 0.8161, 0.8161, 0.7944, 0.6417, 0.7944,
        0.6417, 0.8161, 0.7131, 0.7944, 0.5000, 0.5526, 0.5526, 0.6417, 0.7433,
        0.8161, 0.6417, 0.6417, 0.5000, 0.5000, 0.8161, 0.7703, 0.6417, 0.5000,
        0.8161, 0.5000, 0.5996, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6794,
        0.5996, 0.8161, 0.8161, 0.8161, 0.7703, 0.6794, 0.7131, 0.8161, 0.7131,
        0.6417, 0.8161, 0.7433, 0.7433, 0.8161, 0.8161, 0.6417, 0.7433, 0.7433,
        0.8161, 0.7433, 0.7433, 0.7433, 0.7944, 0.8161, 0.6794, 0.7944, 0.7703,
        0.7433, 0.5996, 0.8161, 0.7703, 0.7944, 0.7703, 0.7433, 0.6794, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.228614 Loss T 0.086069 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7218, Accuracy: 614/1134 F1 (54.1446%)


Test set: Average loss: 2.4777, Accuracy: 13948/23808 F1 (58.5854%)


Val set: Average loss: 2.3983, Accuracy: 205/360 F1 (56.9444%)

Patience getting saturated, current counter is:  1
best acc test 57.354671  acc val 56.944444 acc labeled target 54.144621
saving model...
S clipart T sketch Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.170714 Loss T 0.062561 Method MME

S clipart T sketch Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.233693 Loss T 0.046978 Method MME

S clipart T sketch Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.203871 Loss T 0.045865 Method MME

S clipart T sketch Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.162410 Loss T 0.062908 Method MME

S clipart T sketch Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.364970 Loss T 0.058871 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.4111, Accuracy: 630/1134 F1 (55.5556%)


Test set: Average loss: 2.2838, Accuracy: 14632/23808 F1 (61.4583%)


Val set: Average loss: 2.2090, Accuracy: 208/360 F1 (57.7778%)

Patience Reset, Counter is: 2
best acc test 61.458333  acc val 57.777778 acc labeled target 55.555556
saving model...
S clipart T sketch Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.385285 Loss T 0.066070 Method MME

S clipart T sketch Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.208644 Loss T 0.057563 Method MME

S clipart T sketch Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.328070 Loss T 0.054214 Method MME

S clipart T sketch Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.177194 Loss T 0.062388 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  1.         0.         0.6666667  0.11111111 0.
 0.5555556  0.8888889  0.8888889  0.33333334 1.         0.8888889
 0.         0.         0.33333334 0.7777778  0.7777778  0.5555556
 0.5555556  0.22222222 1.         0.8888889  0.33333334 0.8888889
 0.44444445 0.11111111 0.22222222 0.         0.         0.6666667
 0.22222222 0.33333334 0.44444445 0.33333334 1.         0.
 0.6666667  0.         0.44444445 0.8888889  0.8888889  0.33333334
 0.5555556  0.44444445 0.8888889  0.5555556  1.         0.7777778
 0.22222222 1.         0.5555556  0.33333334 1.         1.
 1.         0.5555556  0.5555556  0.44444445 1.         0.8888889
 0.8888889  0.33333334 1.         0.44444445 1.         0.6666667
 0.33333334 0.         0.         0.         0.33333334 0.44444445
 0.7777778  0.22222222 0.33333334 0.         0.         1.
 0.8888889  0.         0.         0.8888889  0.         0.11111111
 0.         0.         1.         0.6666667  0.         0.33333334
 0.11111111 1.         0.6666667  0.6666667  1.         0.5555556
 0.6666667  0.8888889  0.6666667  0.33333334 0.8888889  0.5555556
 0.6666667  1.         1.         0.         0.5555556  0.6666667
 0.7777778  0.5555556  0.44444445 0.6666667  1.         1.
 0.6666667  1.         0.8888889  0.6666667  0.33333334 1.
 0.6666667  0.7777778  0.8888889  0.6666667  0.11111111 1.        ]
Top k classes which perform poorly are:  [105, 28, 35, 69, 37, 68, 75, 76, 67, 12, 79, 13, 88, 82, 5, 84, 2, 85, 80, 27, 25, 124, 90, 83, 4, 48, 30, 26, 73, 19, 66, 41, 9, 74, 61, 89, 70, 33, 118, 31, 99, 51, 22, 14, 57, 24, 110, 38, 32, 71, 63, 43, 55, 56, 106, 50, 6, 95, 45, 101, 17, 42, 18, 109, 117, 123, 3, 107, 102, 120, 29, 98, 114, 93, 92, 96, 36, 111, 65, 87, 15, 108, 121, 72, 47, 16, 97, 100, 0, 78, 7, 8, 122, 11, 21, 23, 39, 40, 44, 59, 60, 81, 116, 119, 115, 113, 112, 62, 103, 1, 10, 20, 34, 46, 49, 52, 53, 54, 58, 64, 77, 86, 91, 94, 104, 125]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.5000, 1.2567, 1.4474, 1.5000, 1.2869, 1.2056, 1.2056,
        1.3583, 1.1839, 1.2056, 1.5000, 1.5000, 1.3583, 1.2297, 1.2297, 1.2869,
        1.2869, 1.4004, 1.1839, 1.2056, 1.3583, 1.2056, 1.3206, 1.4474, 1.4004,
        1.5000, 1.5000, 1.2567, 1.4004, 1.3583, 1.3206, 1.3583, 1.1839, 1.5000,
        1.2567, 1.5000, 1.3206, 1.2056, 1.2056, 1.3583, 1.2869, 1.3206, 1.2056,
        1.2869, 1.1839, 1.2297, 1.4004, 1.1839, 1.2869, 1.3583, 1.1839, 1.1839,
        1.1839, 1.2869, 1.2869, 1.3206, 1.1839, 1.2056, 1.2056, 1.3583, 1.1839,
        1.3206, 1.1839, 1.2567, 1.3583, 1.5000, 1.5000, 1.5000, 1.3583, 1.3206,
        1.2297, 1.4004, 1.3583, 1.5000, 1.5000, 1.1839, 1.2056, 1.5000, 1.5000,
        1.2056, 1.5000, 1.4474, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.4474, 1.1839, 1.2567, 1.2567, 1.1839, 1.2869, 1.2567, 1.2056, 1.2567,
        1.3583, 1.2056, 1.2869, 1.2567, 1.1839, 1.1839, 1.5000, 1.2869, 1.2567,
        1.2297, 1.2869, 1.3206, 1.2567, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056,
        1.2567, 1.3583, 1.1839, 1.2567, 1.2297, 1.2056, 1.2567, 1.4474, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.5000, 0.7433, 0.5526, 0.5000, 0.7131, 0.7944, 0.7944,
        0.6417, 0.8161, 0.7944, 0.5000, 0.5000, 0.6417, 0.7703, 0.7703, 0.7131,
        0.7131, 0.5996, 0.8161, 0.7944, 0.6417, 0.7944, 0.6794, 0.5526, 0.5996,
        0.5000, 0.5000, 0.7433, 0.5996, 0.6417, 0.6794, 0.6417, 0.8161, 0.5000,
        0.7433, 0.5000, 0.6794, 0.7944, 0.7944, 0.6417, 0.7131, 0.6794, 0.7944,
        0.7131, 0.8161, 0.7703, 0.5996, 0.8161, 0.7131, 0.6417, 0.8161, 0.8161,
        0.8161, 0.7131, 0.7131, 0.6794, 0.8161, 0.7944, 0.7944, 0.6417, 0.8161,
        0.6794, 0.8161, 0.7433, 0.6417, 0.5000, 0.5000, 0.5000, 0.6417, 0.6794,
        0.7703, 0.5996, 0.6417, 0.5000, 0.5000, 0.8161, 0.7944, 0.5000, 0.5000,
        0.7944, 0.5000, 0.5526, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.5526, 0.8161, 0.7433, 0.7433, 0.8161, 0.7131, 0.7433, 0.7944, 0.7433,
        0.6417, 0.7944, 0.7131, 0.7433, 0.8161, 0.8161, 0.5000, 0.7131, 0.7433,
        0.7703, 0.7131, 0.6794, 0.7433, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944,
        0.7433, 0.6417, 0.8161, 0.7433, 0.7703, 0.7944, 0.7433, 0.5526, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.223251 Loss T 0.058290 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6345, Accuracy: 610/1134 F1 (53.7919%)


Test set: Average loss: 2.4880, Accuracy: 13989/23808 F1 (58.7576%)


Val set: Average loss: 2.4567, Accuracy: 206/360 F1 (57.2222%)

Patience getting saturated, current counter is:  0
best acc test 61.458333  acc val 57.222222 acc labeled target 53.791887
saving model...
S clipart T sketch Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.204966 Loss T 0.050208 Method MME

S clipart T sketch Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.050243 Loss T 0.035054 Method MME

S clipart T sketch Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.020849 Loss T 0.060044 Method MME

S clipart T sketch Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.318681 Loss T 0.068438 Method MME

S clipart T sketch Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.160886 Loss T 0.060506 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3993, Accuracy: 624/1134 F1 (55.0265%)


Test set: Average loss: 2.3036, Accuracy: 14731/23808 F1 (61.8742%)


Val set: Average loss: 2.1297, Accuracy: 217/360 F1 (60.2778%)

Patience Reset, Counter is: 1
best acc test 61.874160  acc val 60.277778 acc labeled target 55.026455
saving model...
S clipart T sketch Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.199830 Loss T 0.075094 Method MME

S clipart T sketch Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.037576 Loss T 0.049899 Method MME

S clipart T sketch Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.012591 Loss T 0.059984 Method MME

S clipart T sketch Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.106099 Loss T 0.062793 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.         0.5555556  0.11111111 0.
 0.11111111 1.         1.         0.33333334 0.8888889  1.
 0.         0.         0.33333334 0.8888889  0.6666667  0.8888889
 0.5555556  0.11111111 0.6666667  1.         0.33333334 1.
 0.44444445 0.11111111 0.         0.         0.         0.7777778
 0.5555556  0.22222222 0.33333334 0.33333334 1.         0.
 0.5555556  0.         0.6666667  0.8888889  0.6666667  0.33333334
 0.5555556  0.5555556  1.         0.44444445 1.         0.6666667
 0.33333334 1.         0.33333334 0.33333334 1.         1.
 0.8888889  0.33333334 0.6666667  0.5555556  0.8888889  1.
 1.         0.33333334 1.         0.33333334 1.         0.6666667
 0.6666667  0.         0.         0.         0.33333334 0.44444445
 0.5555556  0.22222222 0.22222222 0.         0.         0.8888889
 0.8888889  0.5555556  0.         0.8888889  0.         0.
 0.         0.         1.         0.6666667  0.         0.33333334
 0.22222222 0.8888889  0.6666667  0.8888889  0.7777778  0.6666667
 0.33333334 1.         0.7777778  0.33333334 1.         0.5555556
 0.6666667  0.7777778  1.         0.         0.5555556  0.6666667
 1.         0.6666667  0.6666667  0.5555556  1.         0.6666667
 0.5555556  1.         0.8888889  0.6666667  0.         1.
 0.8888889  0.5555556  0.7777778  0.5555556  0.5555556  1.        ]
Top k classes which perform poorly are:  [105, 27, 28, 68, 35, 37, 88, 26, 85, 83, 82, 80, 76, 75, 67, 84, 118, 69, 12, 2, 5, 13, 19, 25, 6, 4, 73, 90, 74, 31, 89, 41, 96, 50, 51, 48, 9, 63, 33, 32, 14, 99, 22, 70, 61, 55, 45, 24, 71, 124, 111, 72, 57, 123, 18, 79, 114, 42, 121, 101, 36, 106, 30, 3, 43, 102, 87, 107, 92, 95, 0, 65, 16, 20, 117, 38, 66, 40, 47, 113, 109, 56, 110, 103, 122, 98, 29, 94, 10, 120, 15, 17, 93, 39, 91, 58, 54, 77, 116, 78, 81, 108, 115, 112, 119, 62, 100, 1, 7, 8, 11, 21, 23, 34, 44, 46, 49, 52, 53, 59, 60, 64, 86, 97, 104, 125]
Per cls weights according to the accuracy are:  tensor([1.2567, 1.1839, 1.5000, 1.2869, 1.4474, 1.5000, 1.4474, 1.1839, 1.1839,
        1.3583, 1.2056, 1.1839, 1.5000, 1.5000, 1.3583, 1.2056, 1.2567, 1.2056,
        1.2869, 1.4474, 1.2567, 1.1839, 1.3583, 1.1839, 1.3206, 1.4474, 1.5000,
        1.5000, 1.5000, 1.2297, 1.2869, 1.4004, 1.3583, 1.3583, 1.1839, 1.5000,
        1.2869, 1.5000, 1.2567, 1.2056, 1.2567, 1.3583, 1.2869, 1.2869, 1.1839,
        1.3206, 1.1839, 1.2567, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.1839,
        1.2056, 1.3583, 1.2567, 1.2869, 1.2056, 1.1839, 1.1839, 1.3583, 1.1839,
        1.3583, 1.1839, 1.2567, 1.2567, 1.5000, 1.5000, 1.5000, 1.3583, 1.3206,
        1.2869, 1.4004, 1.4004, 1.5000, 1.5000, 1.2056, 1.2056, 1.2869, 1.5000,
        1.2056, 1.5000, 1.5000, 1.5000, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.4004, 1.2056, 1.2567, 1.2056, 1.2297, 1.2567, 1.3583, 1.1839, 1.2297,
        1.3583, 1.1839, 1.2869, 1.2567, 1.2297, 1.1839, 1.5000, 1.2869, 1.2567,
        1.1839, 1.2567, 1.2567, 1.2869, 1.1839, 1.2567, 1.2869, 1.1839, 1.2056,
        1.2567, 1.5000, 1.1839, 1.2056, 1.2869, 1.2297, 1.2869, 1.2869, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7433, 0.8161, 0.5000, 0.7131, 0.5526, 0.5000, 0.5526, 0.8161, 0.8161,
        0.6417, 0.7944, 0.8161, 0.5000, 0.5000, 0.6417, 0.7944, 0.7433, 0.7944,
        0.7131, 0.5526, 0.7433, 0.8161, 0.6417, 0.8161, 0.6794, 0.5526, 0.5000,
        0.5000, 0.5000, 0.7703, 0.7131, 0.5996, 0.6417, 0.6417, 0.8161, 0.5000,
        0.7131, 0.5000, 0.7433, 0.7944, 0.7433, 0.6417, 0.7131, 0.7131, 0.8161,
        0.6794, 0.8161, 0.7433, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.8161,
        0.7944, 0.6417, 0.7433, 0.7131, 0.7944, 0.8161, 0.8161, 0.6417, 0.8161,
        0.6417, 0.8161, 0.7433, 0.7433, 0.5000, 0.5000, 0.5000, 0.6417, 0.6794,
        0.7131, 0.5996, 0.5996, 0.5000, 0.5000, 0.7944, 0.7944, 0.7131, 0.5000,
        0.7944, 0.5000, 0.5000, 0.5000, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.5996, 0.7944, 0.7433, 0.7944, 0.7703, 0.7433, 0.6417, 0.8161, 0.7703,
        0.6417, 0.8161, 0.7131, 0.7433, 0.7703, 0.8161, 0.5000, 0.7131, 0.7433,
        0.8161, 0.7433, 0.7433, 0.7131, 0.8161, 0.7433, 0.7131, 0.8161, 0.7944,
        0.7433, 0.5000, 0.8161, 0.7944, 0.7131, 0.7703, 0.7131, 0.7131, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.060669 Loss T 0.045762 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6305, Accuracy: 622/1134 F1 (54.8501%)


Test set: Average loss: 2.4779, Accuracy: 14142/23808 F1 (59.4002%)


Val set: Average loss: 2.3299, Accuracy: 209/360 F1 (58.0556%)

Patience getting saturated, current counter is:  0
best acc test 61.874160  acc val 58.055556 acc labeled target 54.850088
saving model...
S clipart T sketch Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.281638 Loss T 0.063578 Method MME

S clipart T sketch Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.242172 Loss T 0.055066 Method MME

S clipart T sketch Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.025746 Loss T 0.054079 Method MME

S clipart T sketch Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.034687 Loss T 0.044421 Method MME

S clipart T sketch Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.195323 Loss T 0.029915 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.3686, Accuracy: 647/1134 F1 (57.0547%)


Test set: Average loss: 2.3461, Accuracy: 14824/23808 F1 (62.2648%)


Val set: Average loss: 2.2916, Accuracy: 214/360 F1 (59.4444%)

Patience getting saturated, current counter is:  1
best acc test 61.874160  acc val 59.444444 acc labeled target 57.054674
saving model...
S clipart T sketch Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.737885 Loss T 0.038507 Method MME

S clipart T sketch Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.037773 Loss T 0.041815 Method MME

S clipart T sketch Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.038511 Loss T 0.052750 Method MME

S clipart T sketch Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.022288 Loss T 0.044898 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  1.         0.         0.6666667  0.         0.
 0.6666667  1.         0.8888889  0.         1.         1.
 0.         0.33333334 0.44444445 0.6666667  0.8888889  1.
 0.44444445 0.         0.8888889  0.8888889  0.33333334 1.
 0.33333334 0.33333334 0.11111111 0.         0.         0.5555556
 0.44444445 0.22222222 0.22222222 0.33333334 0.8888889  0.
 0.7777778  0.         0.6666667  0.5555556  0.7777778  0.33333334
 0.33333334 0.33333334 0.8888889  0.44444445 1.         0.8888889
 0.33333334 1.         0.33333334 0.33333334 1.         1.
 1.         0.6666667  0.6666667  0.6666667  0.8888889  1.
 0.7777778  0.33333334 0.8888889  0.33333334 1.         0.7777778
 0.7777778  0.         0.         0.         0.5555556  0.5555556
 0.8888889  0.         0.33333334 0.         0.         1.
 0.8888889  0.8888889  0.         1.         0.         0.
 0.11111111 0.         1.         0.6666667  0.         0.33333334
 0.33333334 1.         0.6666667  1.         0.6666667  0.6666667
 0.33333334 1.         0.6666667  0.33333334 1.         0.6666667
 0.6666667  0.7777778  1.         0.         0.6666667  0.6666667
 1.         0.6666667  0.5555556  0.7777778  1.         1.
 0.6666667  1.         0.8888889  0.6666667  0.         0.8888889
 0.7777778  0.7777778  0.6666667  0.6666667  0.44444445 1.        ]
Top k classes which perform poorly are:  [35, 88, 69, 68, 75, 76, 19, 105, 73, 118, 27, 12, 67, 80, 9, 37, 82, 83, 5, 4, 2, 85, 28, 84, 26, 31, 32, 41, 42, 43, 51, 96, 63, 61, 48, 50, 99, 33, 89, 90, 13, 22, 24, 74, 25, 45, 30, 18, 14, 124, 70, 110, 71, 39, 29, 98, 94, 92, 95, 87, 107, 114, 57, 38, 122, 109, 117, 106, 15, 3, 123, 102, 101, 55, 56, 6, 121, 120, 60, 36, 111, 40, 103, 66, 65, 0, 116, 119, 62, 58, 47, 21, 20, 34, 16, 44, 8, 78, 79, 72, 10, 11, 7, 17, 115, 1, 113, 112, 23, 81, 46, 86, 49, 104, 52, 53, 54, 100, 59, 97, 64, 77, 93, 91, 108, 125]
Per cls weights according to the accuracy are:  tensor([1.2297, 1.1839, 1.5000, 1.2567, 1.5000, 1.5000, 1.2567, 1.1839, 1.2056,
        1.5000, 1.1839, 1.1839, 1.5000, 1.3583, 1.3206, 1.2567, 1.2056, 1.1839,
        1.3206, 1.5000, 1.2056, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.4474,
        1.5000, 1.5000, 1.2869, 1.3206, 1.4004, 1.4004, 1.3583, 1.2056, 1.5000,
        1.2297, 1.5000, 1.2567, 1.2869, 1.2297, 1.3583, 1.3583, 1.3583, 1.2056,
        1.3206, 1.1839, 1.2056, 1.3583, 1.1839, 1.3583, 1.3583, 1.1839, 1.1839,
        1.1839, 1.2567, 1.2567, 1.2567, 1.2056, 1.1839, 1.2297, 1.3583, 1.2056,
        1.3583, 1.1839, 1.2297, 1.2297, 1.5000, 1.5000, 1.5000, 1.2869, 1.2869,
        1.2056, 1.5000, 1.3583, 1.5000, 1.5000, 1.1839, 1.2056, 1.2056, 1.5000,
        1.1839, 1.5000, 1.5000, 1.4474, 1.5000, 1.1839, 1.2567, 1.5000, 1.3583,
        1.3583, 1.1839, 1.2567, 1.1839, 1.2567, 1.2567, 1.3583, 1.1839, 1.2567,
        1.3583, 1.1839, 1.2567, 1.2567, 1.2297, 1.1839, 1.5000, 1.2567, 1.2567,
        1.1839, 1.2567, 1.2869, 1.2297, 1.1839, 1.1839, 1.2567, 1.1839, 1.2056,
        1.2567, 1.5000, 1.2056, 1.2297, 1.2297, 1.2567, 1.2567, 1.3206, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7703, 0.8161, 0.5000, 0.7433, 0.5000, 0.5000, 0.7433, 0.8161, 0.7944,
        0.5000, 0.8161, 0.8161, 0.5000, 0.6417, 0.6794, 0.7433, 0.7944, 0.8161,
        0.6794, 0.5000, 0.7944, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.5526,
        0.5000, 0.5000, 0.7131, 0.6794, 0.5996, 0.5996, 0.6417, 0.7944, 0.5000,
        0.7703, 0.5000, 0.7433, 0.7131, 0.7703, 0.6417, 0.6417, 0.6417, 0.7944,
        0.6794, 0.8161, 0.7944, 0.6417, 0.8161, 0.6417, 0.6417, 0.8161, 0.8161,
        0.8161, 0.7433, 0.7433, 0.7433, 0.7944, 0.8161, 0.7703, 0.6417, 0.7944,
        0.6417, 0.8161, 0.7703, 0.7703, 0.5000, 0.5000, 0.5000, 0.7131, 0.7131,
        0.7944, 0.5000, 0.6417, 0.5000, 0.5000, 0.8161, 0.7944, 0.7944, 0.5000,
        0.8161, 0.5000, 0.5000, 0.5526, 0.5000, 0.8161, 0.7433, 0.5000, 0.6417,
        0.6417, 0.8161, 0.7433, 0.8161, 0.7433, 0.7433, 0.6417, 0.8161, 0.7433,
        0.6417, 0.8161, 0.7433, 0.7433, 0.7703, 0.8161, 0.5000, 0.7433, 0.7433,
        0.8161, 0.7433, 0.7131, 0.7703, 0.8161, 0.8161, 0.7433, 0.8161, 0.7944,
        0.7433, 0.5000, 0.7944, 0.7703, 0.7703, 0.7433, 0.7433, 0.6794, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.059424 Loss T 0.048097 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5375, Accuracy: 648/1134 F1 (57.1429%)


Test set: Average loss: 2.4524, Accuracy: 14587/23808 F1 (61.2693%)


Val set: Average loss: 2.2770, Accuracy: 217/360 F1 (60.2778%)

Patience Reset, Counter is: 2
best acc test 61.269321  acc val 60.277778 acc labeled target 57.142857
saving model...
S clipart T sketch Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.126525 Loss T 0.048607 Method MME

S clipart T sketch Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.253824 Loss T 0.054978 Method MME

S clipart T sketch Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.250480 Loss T 0.082172 Method MME

S clipart T sketch Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.051140 Loss T 0.052333 Method MME

S clipart T sketch Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.210675 Loss T 0.048690 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1747, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 2.0113, Accuracy: 15722/23808 F1 (66.0366%)


Val set: Average loss: 1.8218, Accuracy: 237/360 F1 (65.8333%)

Patience Reset, Counter is: 0
best acc test 66.036626  acc val 65.833333 acc labeled target 95.943563
saving model...
S clipart T sketch Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.249859 Loss T 0.063130 Method MME

S clipart T sketch Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.017102 Loss T 0.043744 Method MME

S clipart T sketch Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.033942 Loss T 0.049315 Method MME

S clipart T sketch Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.177818 Loss T 0.054774 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.7777778 1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.7777778
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 0.8888889 0.8888889 0.8888889 1.        1.
 0.8888889 1.        1.        1.        0.8888889 0.7777778 1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.7777778 1.        0.7777778
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [13, 33, 5, 88, 90, 105, 32, 104, 35, 39, 42, 99, 45, 96, 48, 37, 106, 95, 54, 55, 58, 63, 83, 67, 69, 80, 49, 28, 76, 19, 118, 25, 24, 23, 22, 18, 123, 9, 12, 115, 3, 119, 86, 89, 87, 120, 107, 84, 121, 82, 122, 81, 79, 78, 85, 91, 93, 116, 109, 110, 103, 77, 102, 111, 101, 117, 100, 112, 97, 113, 114, 94, 108, 92, 98, 0, 62, 74, 36, 34, 31, 30, 29, 27, 26, 21, 20, 17, 16, 15, 14, 11, 10, 8, 7, 6, 4, 2, 1, 38, 75, 40, 43, 73, 72, 71, 70, 68, 66, 65, 64, 124, 61, 60, 59, 57, 56, 53, 52, 51, 50, 47, 46, 44, 41, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.041060 Loss T 0.054739 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2688, Accuracy: 1064/1134 F1 (93.8272%)


Test set: Average loss: 2.2415, Accuracy: 15316/23808 F1 (64.3313%)


Val set: Average loss: 1.9353, Accuracy: 233/360 F1 (64.7222%)

Patience getting saturated, current counter is:  0
best acc test 66.036626  acc val 64.722222 acc labeled target 93.827160
saving model...
S clipart T sketch Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.081280 Loss T 0.066910 Method MME

S clipart T sketch Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.268953 Loss T 0.040331 Method MME

S clipart T sketch Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.074043 Loss T 0.040186 Method MME

S clipart T sketch Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.016891 Loss T 0.037340 Method MME

S clipart T sketch Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.143606 Loss T 0.047818 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1261, Accuracy: 1106/1134 F1 (97.5309%)


Test set: Average loss: 2.0332, Accuracy: 15819/23808 F1 (66.4441%)


Val set: Average loss: 1.7194, Accuracy: 245/360 F1 (68.0556%)

Patience Reset, Counter is: 1
best acc test 66.444052  acc val 68.055556 acc labeled target 97.530864
saving model...
S clipart T sketch Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.072523 Loss T 0.058258 Method MME

S clipart T sketch Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.164055 Loss T 0.056684 Method MME

S clipart T sketch Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.214411 Loss T 0.063689 Method MME

S clipart T sketch Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.060630 Loss T 0.044398 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.7777778
 1.        1.        1.        1.        1.        0.7777778 1.
 0.8888889 1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        0.8888889
 1.        0.7777778 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [50, 33, 27, 35, 42, 51, 25, 103, 48, 101, 100, 99, 69, 44, 38, 85, 84, 41, 14, 68, 80, 3, 8, 83, 6, 82, 92, 72, 91, 90, 73, 89, 75, 76, 77, 78, 88, 79, 87, 81, 74, 86, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 98, 97, 96, 95, 93, 71, 62, 67, 29, 28, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 7, 5, 4, 2, 1, 30, 31, 32, 34, 66, 65, 64, 63, 124, 61, 60, 59, 58, 57, 56, 70, 55, 53, 52, 49, 47, 46, 45, 43, 40, 39, 37, 36, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.186771 Loss T 0.038815 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2183, Accuracy: 1084/1134 F1 (95.5908%)


Test set: Average loss: 2.2268, Accuracy: 15588/23808 F1 (65.4738%)


Val set: Average loss: 1.9089, Accuracy: 234/360 F1 (65.0000%)

Patience getting saturated, current counter is:  0
best acc test 66.444052  acc val 65.000000 acc labeled target 95.590829
saving model...
S clipart T sketch Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.159052 Loss T 0.048014 Method MME

S clipart T sketch Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.050372 Loss T 0.050732 Method MME

S clipart T sketch Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.088534 Loss T 0.041140 Method MME

S clipart T sketch Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.167817 Loss T 0.027317 Method MME

S clipart T sketch Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.178071 Loss T 0.041814 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1318, Accuracy: 1098/1134 F1 (96.8254%)


Test set: Average loss: 2.1327, Accuracy: 15874/23808 F1 (66.6751%)


Val set: Average loss: 1.7988, Accuracy: 238/360 F1 (66.1111%)

Patience getting saturated, current counter is:  1
best acc test 66.444052  acc val 66.111111 acc labeled target 96.825397
saving model...
S clipart T sketch Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.049074 Loss T 0.032422 Method MME

S clipart T sketch Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.167713 Loss T 0.028896 Method MME

S clipart T sketch Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.022325 Loss T 0.046976 Method MME

S clipart T sketch Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.155621 Loss T 0.035300 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        1.        1.        0.8888889 1.        1.
 1.        0.7777778 1.        0.8888889 0.8888889 0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 1.        1.        1.        0.7777778 1.        1.
 1.        1.        1.        1.        0.8888889 0.7777778 1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889]
Top k classes which perform poorly are:  [96, 71, 88, 62, 40, 43, 47, 48, 54, 63, 67, 73, 74, 75, 76, 81, 84, 95, 98, 99, 102, 109, 115, 118, 121, 37, 31, 125, 6, 22, 9, 25, 23, 28, 7, 97, 8, 94, 93, 92, 91, 90, 89, 10, 87, 86, 85, 11, 83, 82, 12, 80, 100, 101, 103, 79, 123, 122, 1, 120, 119, 2, 117, 116, 3, 5, 114, 112, 111, 110, 4, 108, 107, 106, 105, 104, 113, 78, 13, 27, 51, 50, 49, 21, 46, 45, 44, 42, 41, 52, 24, 38, 36, 35, 34, 33, 32, 26, 30, 29, 39, 77, 53, 55, 14, 15, 16, 72, 17, 70, 69, 68, 18, 20, 66, 64, 19, 124, 61, 60, 59, 58, 57, 56, 65, 0]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.2056, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.7944, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.032160 Loss T 0.036019 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1927, Accuracy: 1080/1134 F1 (95.2381%)


Test set: Average loss: 2.2266, Accuracy: 15591/23808 F1 (65.4864%)


Val set: Average loss: 1.8988, Accuracy: 229/360 F1 (63.6111%)

Patience getting saturated, current counter is:  2
best acc test 66.444052  acc val 63.611111 acc labeled target 95.238095
saving model...
S clipart T sketch Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.020982 Loss T 0.046080 Method MME

S clipart T sketch Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.121237 Loss T 0.059917 Method MME

S clipart T sketch Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.010964 Loss T 0.051728 Method MME

S clipart T sketch Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.048175 Loss T 0.037503 Method MME

S clipart T sketch Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.077015 Loss T 0.040285 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1326, Accuracy: 1096/1134 F1 (96.6490%)


Test set: Average loss: 2.1275, Accuracy: 16008/23808 F1 (67.2379%)


Val set: Average loss: 1.9025, Accuracy: 242/360 F1 (67.2222%)

Patience getting saturated, current counter is:  3
best acc test 66.444052  acc val 67.222222 acc labeled target 96.649030
saving model...
S clipart T sketch Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.174090 Loss T 0.051097 Method MME

S clipart T sketch Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.168762 Loss T 0.027736 Method MME

S clipart T sketch Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.251573 Loss T 0.043402 Method MME

S clipart T sketch Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.181067 Loss T 0.032240 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.8888889 0.7777778 1.        1.        1.        1.        0.7777778
 0.8888889 0.8888889 1.        0.8888889 1.        0.8888889 0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        0.7777778 0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        0.8888889 0.8888889 0.8888889 1.       ]
Top k classes which perform poorly are:  [22, 79, 27, 44, 105, 56, 83, 28, 29, 31, 33, 34, 70, 99, 37, 98, 49, 94, 21, 57, 35, 18, 123, 122, 75, 118, 7, 107, 65, 76, 124, 80, 82, 115, 90, 85, 77, 86, 78, 84, 74, 73, 87, 88, 81, 89, 0, 92, 121, 120, 119, 117, 116, 114, 113, 112, 111, 110, 91, 109, 106, 104, 103, 102, 101, 100, 97, 96, 95, 93, 108, 72, 62, 69, 30, 26, 25, 24, 23, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 6, 5, 4, 3, 2, 1, 32, 71, 36, 39, 68, 67, 66, 64, 63, 61, 60, 59, 58, 55, 54, 53, 52, 51, 50, 48, 47, 46, 45, 43, 42, 41, 40, 38, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2297, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2297, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7703, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7703, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.163728 Loss T 0.037524 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1607, Accuracy: 1093/1134 F1 (96.3845%)


Test set: Average loss: 2.1730, Accuracy: 15750/23808 F1 (66.1542%)


Val set: Average loss: 1.7486, Accuracy: 240/360 F1 (66.6667%)

Patience getting saturated, current counter is:  4
best acc test 66.444052  acc val 66.666667 acc labeled target 96.384480
saving model...
S clipart T sketch Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.031139 Loss T 0.039596 Method MME

S clipart T sketch Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.024417 Loss T 0.049290 Method MME

S clipart T sketch Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.274069 Loss T 0.022289 Method MME

S clipart T sketch Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.173473 Loss T 0.035864 Method MME

S clipart T sketch Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.121816 Loss T 0.029751 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1339, Accuracy: 1100/1134 F1 (97.0018%)


Test set: Average loss: 2.0950, Accuracy: 16159/23808 F1 (67.8721%)


Val set: Average loss: 1.7697, Accuracy: 250/360 F1 (69.4444%)

Patience Reset, Counter is: 5
best acc test 67.872144  acc val 69.444444 acc labeled target 97.001764
saving model...
S clipart T sketch Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.012723 Loss T 0.044689 Method MME

S clipart T sketch Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.021727 Loss T 0.031531 Method MME

S clipart T sketch Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.175339 Loss T 0.046151 Method MME

S clipart T sketch Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.157880 Loss T 0.028008 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 0.7777778 1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 0.8888889 1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 0.7777778 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.7777778 0.8888889
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [80, 23, 7, 118, 110, 31, 100, 33, 24, 50, 57, 58, 111, 36, 90, 84, 13, 79, 78, 96, 9, 6, 39, 47, 41, 122, 42, 102, 30, 89, 0, 87, 86, 85, 91, 83, 82, 81, 77, 76, 75, 74, 73, 88, 92, 98, 94, 123, 121, 120, 119, 117, 116, 115, 114, 113, 112, 93, 109, 107, 106, 105, 104, 103, 101, 99, 72, 97, 95, 108, 71, 62, 69, 29, 28, 27, 26, 25, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 8, 5, 4, 3, 2, 1, 32, 34, 35, 37, 68, 67, 66, 65, 64, 63, 124, 61, 60, 59, 56, 70, 55, 53, 52, 51, 49, 48, 46, 45, 44, 43, 40, 38, 54, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2297,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7703,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.103114 Loss T 0.028790 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2016, Accuracy: 1087/1134 F1 (95.8554%)


Test set: Average loss: 2.2218, Accuracy: 15823/23808 F1 (66.4609%)


Val set: Average loss: 1.7961, Accuracy: 236/360 F1 (65.5556%)

Patience getting saturated, current counter is:  0
best acc test 67.872144  acc val 65.555556 acc labeled target 95.855379
saving model...
S clipart T sketch Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.228675 Loss T 0.031311 Method MME

S clipart T sketch Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.097258 Loss T 0.040602 Method MME

S clipart T sketch Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.038859 Loss T 0.034763 Method MME

S clipart T sketch Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.012287 Loss T 0.021955 Method MME

S clipart T sketch Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.010416 Loss T 0.036253 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1639, Accuracy: 1087/1134 F1 (95.8554%)


Test set: Average loss: 2.1842, Accuracy: 16150/23808 F1 (67.8343%)


Val set: Average loss: 1.8025, Accuracy: 243/360 F1 (67.5000%)

Patience getting saturated, current counter is:  1
best acc test 67.872144  acc val 67.500000 acc labeled target 95.855379
saving model...
S clipart T sketch Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.118883 Loss T 0.039740 Method MME

S clipart T sketch Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.072863 Loss T 0.032377 Method MME

S clipart T sketch Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.158272 Loss T 0.021408 Method MME

S clipart T sketch Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.229347 Loss T 0.041871 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        0.8888889 0.7777778
 1.        1.        0.7777778 1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.7777778 0.7777778
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.7777778
 1.        0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        0.8888889
 1.        1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.7777778 1.        1.        1.        0.8888889
 1.        1.        1.        0.7777778 1.        0.8888889 1.
 0.8888889 1.        1.        1.        1.        0.8888889 0.8888889]
Top k classes which perform poorly are:  [115, 27, 107, 6, 26, 55, 9, 42, 0, 60, 57, 38, 124, 36, 35, 54, 65, 74, 71, 33, 76, 80, 85, 90, 93, 95, 102, 111, 117, 119, 70, 32, 62, 30, 5, 11, 16, 24, 125, 39, 101, 100, 99, 98, 97, 96, 8, 94, 7, 10, 91, 29, 89, 88, 87, 86, 12, 84, 92, 83, 103, 105, 123, 122, 121, 120, 1, 118, 2, 116, 104, 3, 113, 112, 4, 110, 109, 108, 34, 106, 114, 25, 82, 13, 21, 56, 22, 23, 53, 52, 51, 50, 58, 49, 47, 46, 45, 44, 43, 37, 41, 40, 48, 81, 59, 61, 31, 78, 77, 14, 75, 15, 73, 72, 20, 28, 69, 68, 67, 66, 18, 64, 63, 19, 17, 79]
Per cls weights according to the accuracy are:  tensor([1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2297, 1.1839, 1.1839,
        1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2297,
        1.2297, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.2056,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.2297, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7703, 0.8161, 0.8161,
        0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7703,
        0.7703, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.7944,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.7703, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.117829 Loss T 0.046136 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2022, Accuracy: 1082/1134 F1 (95.4145%)


Test set: Average loss: 2.3039, Accuracy: 15756/23808 F1 (66.1794%)


Val set: Average loss: 1.8543, Accuracy: 239/360 F1 (66.3889%)

Patience getting saturated, current counter is:  2
best acc test 67.872144  acc val 66.388889 acc labeled target 95.414462
saving model...
S clipart T sketch Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.009427 Loss T 0.045987 Method MME

S clipart T sketch Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.182804 Loss T 0.035853 Method MME

S clipart T sketch Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.039429 Loss T 0.020017 Method MME

S clipart T sketch Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.020500 Loss T 0.035971 Method MME

S clipart T sketch Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.023602 Loss T 0.033187 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1197, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 2.2030, Accuracy: 16196/23808 F1 (68.0276%)


Val set: Average loss: 1.6841, Accuracy: 252/360 F1 (70.0000%)

Patience Reset, Counter is: 3
best acc test 68.027554  acc val 70.000000 acc labeled target 97.442681
saving model...
S clipart T sketch Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.013819 Loss T 0.035419 Method MME

S clipart T sketch Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.056595 Loss T 0.040549 Method MME

S clipart T sketch Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.169001 Loss T 0.039408 Method MME

S clipart T sketch Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.137806 Loss T 0.021050 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.7777778 0.8888889
 1.        1.        0.7777778 1.        1.        1.        1.
 0.8888889 1.        0.8888889 0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [30, 26, 55, 41, 88, 38, 37, 96, 35, 72, 99, 27, 53, 22, 108, 16, 92, 124, 67, 14, 112, 120, 75, 60, 6, 118, 111, 89, 73, 74, 87, 76, 79, 85, 84, 77, 83, 78, 82, 90, 81, 80, 86, 0, 97, 93, 123, 122, 121, 119, 117, 116, 115, 114, 113, 110, 91, 109, 106, 105, 104, 103, 102, 101, 100, 98, 95, 94, 107, 71, 62, 69, 31, 29, 28, 25, 24, 23, 21, 20, 19, 18, 17, 32, 15, 12, 11, 10, 9, 8, 7, 5, 4, 3, 2, 1, 13, 70, 33, 36, 68, 66, 65, 64, 63, 61, 59, 58, 57, 56, 54, 34, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 51, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297,
        1.2056, 1.1839, 1.1839, 1.2297, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703,
        0.7944, 0.8161, 0.8161, 0.7703, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.102321 Loss T 0.033161 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2261, Accuracy: 1080/1134 F1 (95.2381%)


Test set: Average loss: 2.3102, Accuracy: 15864/23808 F1 (66.6331%)


Val set: Average loss: 1.9406, Accuracy: 232/360 F1 (64.4444%)

Patience getting saturated, current counter is:  0
best acc test 68.027554  acc val 64.444444 acc labeled target 95.238095
saving model...
S clipart T sketch Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.177320 Loss T 0.022294 Method MME

S clipart T sketch Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.111753 Loss T 0.031280 Method MME

S clipart T sketch Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.009234 Loss T 0.042534 Method MME

S clipart T sketch Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.051852 Loss T 0.029311 Method MME

S clipart T sketch Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.015273 Loss T 0.035415 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1817, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 2.2103, Accuracy: 16176/23808 F1 (67.9436%)


Val set: Average loss: 1.8247, Accuracy: 244/360 F1 (67.7778%)

Patience getting saturated, current counter is:  1
best acc test 68.027554  acc val 67.777778 acc labeled target 95.943563
saving model...
S clipart T sketch Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.259111 Loss T 0.031741 Method MME

S clipart T sketch Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.030559 Loss T 0.027291 Method MME

S clipart T sketch Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.038765 Loss T 0.018352 Method MME

S clipart T sketch Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.035598 Loss T 0.032505 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.7777778 0.8888889 1.
 0.7777778 0.8888889 1.        1.        1.        0.7777778 0.8888889
 0.8888889 1.        0.6666667 0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        0.7777778 0.6666667 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [89, 37, 25, 28, 88, 33, 74, 26, 102, 29, 57, 34, 75, 50, 38, 54, 42, 43, 94, 51, 46, 35, 85, 58, 106, 122, 121, 68, 67, 114, 113, 13, 14, 11, 64, 110, 108, 83, 86, 84, 81, 80, 79, 82, 78, 77, 76, 87, 90, 0, 92, 123, 120, 119, 118, 117, 116, 115, 112, 111, 109, 107, 105, 104, 103, 101, 100, 99, 97, 96, 95, 93, 91, 98, 62, 72, 27, 24, 23, 22, 21, 20, 19, 18, 17, 16, 30, 15, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 12, 73, 31, 36, 71, 70, 69, 66, 65, 63, 124, 61, 60, 59, 32, 56, 53, 52, 49, 48, 47, 45, 44, 41, 40, 39, 55, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056,
        1.1839, 1.2297, 1.2056, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.2056,
        1.1839, 1.2567, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.2567,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839, 1.1839, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944,
        0.8161, 0.7703, 0.7944, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.7944,
        0.8161, 0.7433, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.7433,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161, 0.8161, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.029938 Loss T 0.015930 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2217, Accuracy: 1088/1134 F1 (95.9436%)


Test set: Average loss: 2.3284, Accuracy: 15795/23808 F1 (66.3432%)


Val set: Average loss: 1.9281, Accuracy: 236/360 F1 (65.5556%)

Patience getting saturated, current counter is:  2
best acc test 68.027554  acc val 65.555556 acc labeled target 95.943563
saving model...
S clipart T sketch Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.109486 Loss T 0.030258 Method MME

S clipart T sketch Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.205236 Loss T 0.034631 Method MME

S clipart T sketch Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.106972 Loss T 0.039030 Method MME

S clipart T sketch Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.022062 Loss T 0.045698 Method MME

S clipart T sketch Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.248581 Loss T 0.027777 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1261, Accuracy: 1103/1134 F1 (97.2663%)


Test set: Average loss: 2.2323, Accuracy: 16277/23808 F1 (68.3678%)


Val set: Average loss: 1.7403, Accuracy: 245/360 F1 (68.0556%)

Patience getting saturated, current counter is:  3
best acc test 68.027554  acc val 68.055556 acc labeled target 97.266314
saving model...
S clipart T sketch Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.043510 Loss T 0.029836 Method MME

S clipart T sketch Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.124238 Loss T 0.030728 Method MME

S clipart T sketch Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.025631 Loss T 0.031719 Method MME

S clipart T sketch Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.139700 Loss T 0.046855 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.7777778 0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        0.8888889 0.8888889
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 0.8888889 0.7777778 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [106, 32, 51, 35, 96, 33, 70, 37, 40, 41, 42, 49, 50, 52, 59, 78, 61, 124, 63, 65, 74, 97, 103, 71, 8, 14, 119, 114, 102, 115, 116, 84, 83, 82, 81, 80, 117, 118, 120, 121, 77, 122, 76, 75, 123, 73, 79, 85, 86, 87, 101, 100, 99, 98, 105, 107, 95, 108, 109, 104, 94, 93, 111, 92, 91, 112, 113, 90, 89, 88, 110, 0, 62, 69, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 13, 12, 11, 10, 9, 7, 6, 5, 4, 3, 2, 1, 26, 72, 27, 29, 68, 67, 66, 64, 60, 58, 57, 56, 55, 54, 53, 48, 47, 46, 45, 44, 43, 39, 38, 36, 34, 31, 30, 28, 125]
Per cls weights according to the accuracy are:  tensor([1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2297, 1.2056, 1.1839, 1.2056,
        1.1839, 1.2056, 1.1839, 1.1839, 1.2056, 1.2056, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.2297, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.2056, 1.1839,
        1.2056, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.2056, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.2297, 1.1839,
        1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839, 1.1839,
        1.1839, 1.1839, 1.2056, 1.1839, 1.1839, 1.1839, 1.1839, 1.2056, 1.1839])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7703, 0.7944, 0.8161, 0.7944,
        0.8161, 0.7944, 0.8161, 0.8161, 0.7944, 0.7944, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.7703, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.7944, 0.8161,
        0.7944, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.7944, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.7703, 0.8161,
        0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161, 0.8161,
        0.8161, 0.8161, 0.7944, 0.8161, 0.8161, 0.8161, 0.8161, 0.7944, 0.8161])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S clipart T sketch Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.015998 Loss T 0.038954 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.2488, Accuracy: 1081/1134 F1 (95.3263%)


Test set: Average loss: 2.2867, Accuracy: 15978/23808 F1 (67.1119%)


Val set: Average loss: 1.8865, Accuracy: 234/360 F1 (65.0000%)

Patience getting saturated, current counter is:  4
best acc test 68.027554  acc val 65.000000 acc labeled target 95.326279
saving model...
S clipart T sketch Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.008614 Loss T 0.020143 Method MME

S clipart T sketch Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.045675 Loss T 0.024521 Method MME

S clipart T sketch Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.048586 Loss T 0.029624 Method MME

S clipart T sketch Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.032512 Loss T 0.023032 Method MME

S clipart T sketch Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.033553 Loss T 0.029215 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1180, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 2.2669, Accuracy: 16249/23808 F1 (68.2502%)


Val set: Average loss: 1.7735, Accuracy: 244/360 F1 (67.7778%)

Patience getting saturated, current counter is:  5
