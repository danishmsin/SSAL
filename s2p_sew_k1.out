Dataset multi Source sketch Target painting Labeled num perclass 3 Network resnet34
126 classes in this dataset
Labelled Source Examples:  24582
Unlabelled Target Dataset Size:  31124
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  31124 Source:  24582
Unlabeled Target Data Batches: 648
S sketch T painting Train Ep: 0 lr0.01 	 Loss Classification: 4.953185 Loss T 0.469615 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 4.9636, Accuracy: 8/1134 F1 (0.7055%)


Test set: Average loss: 4.9457, Accuracy: 200/31104 F1 (0.6430%)


Val set: Average loss: 4.9685, Accuracy: 2/360 F1 (0.5556%)

Patience Reset, Counter is: 0
best acc test 0.643004  acc val 0.555556 acc labeled target 0.705467
saving model...
S sketch T painting Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.402580 Loss T 0.291100 Method MME

S sketch T painting Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 1.791935 Loss T 0.211025 Method MME

S sketch T painting Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 2.258849 Loss T 0.222348 Method MME

S sketch T painting Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.647187 Loss T 0.203144 Method MME

S sketch T painting Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.557210 Loss T 0.141980 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8249, Accuracy: 458/1134 F1 (40.3880%)


Test set: Average loss: 2.2113, Accuracy: 15859/31104 F1 (50.9870%)


Val set: Average loss: 2.4471, Accuracy: 163/360 F1 (45.2778%)

Patience Reset, Counter is: 0
best acc test 50.987011  acc val 45.277778 acc labeled target 40.388007
saving model...
S sketch T painting Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 2.173943 Loss T 0.161304 Method MME

S sketch T painting Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.264656 Loss T 0.149436 Method MME

S sketch T painting Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.384871 Loss T 0.127644 Method MME

S sketch T painting Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.535060 Loss T 0.154337 Method MME

S sketch T painting Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.314316 Loss T 0.133856 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5800, Accuracy: 519/1134 F1 (45.7672%)


Test set: Average loss: 1.9842, Accuracy: 17925/31104 F1 (57.6292%)


Val set: Average loss: 2.1703, Accuracy: 192/360 F1 (53.3333%)

Patience Reset, Counter is: 0
best acc test 57.629244  acc val 53.333333 acc labeled target 45.767196
saving model...
S sketch T painting Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.436069 Loss T 0.132944 Method MME

S sketch T painting Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.770712 Loss T 0.112268 Method MME

S sketch T painting Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.272705 Loss T 0.111556 Method MME

S sketch T painting Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.998205 Loss T 0.124326 Method MME

S sketch T painting Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 1.136452 Loss T 0.110763 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7448, Accuracy: 494/1134 F1 (43.5626%)


Test set: Average loss: 1.9770, Accuracy: 18269/31104 F1 (58.7352%)


Val set: Average loss: 2.4009, Accuracy: 186/360 F1 (51.6667%)

Patience getting saturated, current counter is:  0
best acc test 57.629244  acc val 51.666667 acc labeled target 43.562610
saving model...
S sketch T painting Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.752022 Loss T 0.138854 Method MME

S sketch T painting Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.016028 Loss T 0.115643 Method MME

S sketch T painting Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.314881 Loss T 0.115656 Method MME

S sketch T painting Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.403028 Loss T 0.115270 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.33333334 0.8888889  0.22222222 0.22222222 0.44444445 0.
 0.22222222 0.44444445 0.         0.33333334 0.6666667  0.6666667
 0.11111111 0.11111111 0.33333334 0.44444445 0.7777778  0.33333334
 0.33333334 0.22222222 0.6666667  0.22222222 0.44444445 0.33333334
 0.33333334 0.         0.22222222 0.         0.44444445 0.
 0.44444445 0.         0.22222222 0.         0.         0.
 0.         0.         0.6666667  0.7777778  0.6666667  0.33333334
 0.22222222 0.11111111 0.33333334 0.7777778  0.33333334 0.8888889
 0.33333334 0.6666667  0.         0.11111111 1.         0.7777778
 0.         0.         0.44444445 1.         0.22222222 1.
 0.6666667  0.44444445 0.         0.6666667  1.         0.33333334
 0.         0.33333334 0.5555556  0.5555556  0.33333334 0.8888889
 1.         0.8888889  0.         0.33333334 0.7777778  0.22222222
 0.22222222 0.7777778  0.         1.         0.22222222 0.
 0.6666667  0.33333334 0.         0.6666667  0.33333334 0.
 0.22222222 0.33333334 0.33333334 0.5555556  0.33333334 0.6666667
 0.22222222 0.8888889  0.5555556  1.         0.6666667  0.44444445
 0.6666667  0.7777778  0.8888889  0.5555556  0.6666667  0.
 0.         0.5555556  0.6666667  0.33333334 0.22222222 0.6666667
 0.33333334 1.         0.8888889  1.         0.22222222 1.
 0.6666667  1.         0.33333334 0.         0.8888889  1.        ]
Top k classes which perform poorly are:  [62, 54, 86, 29, 31, 33, 34, 25, 35, 37, 83, 80, 74, 66, 50, 36, 89, 27, 55, 5, 108, 107, 8, 123, 51, 13, 12, 43, 3, 77, 6, 42, 78, 82, 58, 2, 118, 96, 112, 32, 19, 26, 21, 90, 65, 91, 67, 114, 94, 75, 88, 85, 111, 122, 70, 92, 0, 23, 9, 18, 17, 41, 14, 48, 44, 46, 24, 22, 56, 30, 7, 101, 28, 15, 4, 61, 69, 68, 109, 98, 105, 93, 106, 113, 10, 95, 110, 100, 11, 102, 20, 49, 84, 38, 120, 87, 60, 40, 63, 45, 103, 16, 53, 39, 76, 79, 1, 124, 116, 71, 104, 73, 97, 47, 121, 119, 117, 57, 99, 81, 72, 52, 64, 59, 115, 125]
Per cls weights according to the accuracy are:  tensor([1.1433, 1.0822, 1.1601, 1.1601, 1.1282, 1.2000, 1.1601, 1.1282, 1.2000,
        1.1433, 1.1027, 1.1027, 1.1790, 1.1790, 1.1433, 1.1282, 1.0919, 1.1433,
        1.1433, 1.1601, 1.1027, 1.1601, 1.1282, 1.1433, 1.1433, 1.2000, 1.1601,
        1.2000, 1.1282, 1.2000, 1.1282, 1.2000, 1.1601, 1.2000, 1.2000, 1.2000,
        1.2000, 1.2000, 1.1027, 1.0919, 1.1027, 1.1433, 1.1601, 1.1790, 1.1433,
        1.0919, 1.1433, 1.0822, 1.1433, 1.1027, 1.2000, 1.1790, 1.0736, 1.0919,
        1.2000, 1.2000, 1.1282, 1.0736, 1.1601, 1.0736, 1.1027, 1.1282, 1.2000,
        1.1027, 1.0736, 1.1433, 1.2000, 1.1433, 1.1148, 1.1148, 1.1433, 1.0822,
        1.0736, 1.0822, 1.2000, 1.1433, 1.0919, 1.1601, 1.1601, 1.0919, 1.2000,
        1.0736, 1.1601, 1.2000, 1.1027, 1.1433, 1.2000, 1.1027, 1.1433, 1.2000,
        1.1601, 1.1433, 1.1433, 1.1148, 1.1433, 1.1027, 1.1601, 1.0822, 1.1148,
        1.0736, 1.1027, 1.1282, 1.1027, 1.0919, 1.0822, 1.1148, 1.1027, 1.2000,
        1.2000, 1.1148, 1.1027, 1.1433, 1.1601, 1.1027, 1.1433, 1.0736, 1.0822,
        1.0736, 1.1601, 1.0736, 1.1027, 1.0736, 1.1433, 1.2000, 1.0822, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.8567, 0.9178, 0.8399, 0.8399, 0.8718, 0.8000, 0.8399, 0.8718, 0.8000,
        0.8567, 0.8973, 0.8973, 0.8210, 0.8210, 0.8567, 0.8718, 0.9081, 0.8567,
        0.8567, 0.8399, 0.8973, 0.8399, 0.8718, 0.8567, 0.8567, 0.8000, 0.8399,
        0.8000, 0.8718, 0.8000, 0.8718, 0.8000, 0.8399, 0.8000, 0.8000, 0.8000,
        0.8000, 0.8000, 0.8973, 0.9081, 0.8973, 0.8567, 0.8399, 0.8210, 0.8567,
        0.9081, 0.8567, 0.9178, 0.8567, 0.8973, 0.8000, 0.8210, 0.9264, 0.9081,
        0.8000, 0.8000, 0.8718, 0.9264, 0.8399, 0.9264, 0.8973, 0.8718, 0.8000,
        0.8973, 0.9264, 0.8567, 0.8000, 0.8567, 0.8852, 0.8852, 0.8567, 0.9178,
        0.9264, 0.9178, 0.8000, 0.8567, 0.9081, 0.8399, 0.8399, 0.9081, 0.8000,
        0.9264, 0.8399, 0.8000, 0.8973, 0.8567, 0.8000, 0.8973, 0.8567, 0.8000,
        0.8399, 0.8567, 0.8567, 0.8852, 0.8567, 0.8973, 0.8399, 0.9178, 0.8852,
        0.9264, 0.8973, 0.8718, 0.8973, 0.9081, 0.9178, 0.8852, 0.8973, 0.8000,
        0.8000, 0.8852, 0.8973, 0.8567, 0.8399, 0.8973, 0.8567, 0.9264, 0.9178,
        0.9264, 0.8399, 0.9264, 0.8973, 0.9264, 0.8567, 0.8000, 0.9178, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.793355 Loss T 0.099216 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7653, Accuracy: 504/1134 F1 (44.4444%)


Test set: Average loss: 2.1178, Accuracy: 17861/31104 F1 (57.4235%)


Val set: Average loss: 2.3228, Accuracy: 196/360 F1 (54.4444%)

Patience Reset, Counter is: 1
best acc test 57.423483  acc val 54.444444 acc labeled target 44.444444
saving model...
S sketch T painting Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.311110 Loss T 0.099416 Method MME

S sketch T painting Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.480939 Loss T 0.108288 Method MME

S sketch T painting Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.487487 Loss T 0.081917 Method MME

S sketch T painting Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.896726 Loss T 0.083541 Method MME

S sketch T painting Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.466884 Loss T 0.094080 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6014, Accuracy: 554/1134 F1 (48.8536%)


Test set: Average loss: 1.9450, Accuracy: 19121/31104 F1 (61.4744%)


Val set: Average loss: 2.2520, Accuracy: 197/360 F1 (54.7222%)

Patience Reset, Counter is: 0
best acc test 61.474408  acc val 54.722222 acc labeled target 48.853616
saving model...
S sketch T painting Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 1.080419 Loss T 0.099664 Method MME

S sketch T painting Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.208251 Loss T 0.108310 Method MME

S sketch T painting Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 1.151058 Loss T 0.101537 Method MME

S sketch T painting Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.766447 Loss T 0.069423 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.5555556  0.5555556  0.33333334 0.44444445 0.
 0.11111111 0.22222222 0.         0.33333334 0.6666667  0.6666667
 0.         0.         0.33333334 0.6666667  0.44444445 0.7777778
 0.5555556  0.5555556  0.5555556  0.33333334 0.5555556  0.6666667
 0.44444445 0.33333334 0.         0.33333334 0.5555556  0.33333334
 0.6666667  0.         0.5555556  0.22222222 0.5555556  0.
 0.         0.         0.6666667  0.6666667  0.44444445 0.11111111
 0.         0.33333334 0.5555556  0.44444445 0.6666667  0.8888889
 0.5555556  0.6666667  0.11111111 0.11111111 0.7777778  0.6666667
 0.         0.         0.5555556  1.         0.44444445 0.8888889
 0.6666667  0.6666667  0.33333334 0.6666667  1.         0.5555556
 0.         0.33333334 0.5555556  0.44444445 0.33333334 0.6666667
 1.         0.8888889  0.33333334 0.33333334 0.8888889  0.33333334
 0.33333334 0.7777778  0.33333334 1.         0.11111111 0.
 1.         0.33333334 0.         0.5555556  0.33333334 0.
 0.33333334 0.22222222 0.6666667  1.         0.6666667  0.6666667
 0.         1.         0.44444445 0.7777778  0.8888889  0.5555556
 0.5555556  0.8888889  0.6666667  0.11111111 0.6666667  0.11111111
 0.22222222 0.6666667  0.5555556  0.33333334 0.5555556  0.6666667
 0.33333334 1.         0.7777778  1.         0.         1.
 0.33333334 1.         1.         0.33333334 1.         0.8888889 ]
Top k classes which perform poorly are:  [83, 35, 42, 13, 12, 26, 31, 96, 8, 54, 55, 5, 118, 89, 66, 86, 37, 36, 50, 51, 105, 82, 107, 41, 6, 91, 7, 33, 108, 75, 74, 85, 70, 77, 123, 114, 88, 3, 90, 120, 78, 80, 9, 111, 67, 62, 43, 25, 21, 27, 14, 29, 24, 45, 40, 69, 58, 4, 98, 16, 32, 1, 20, 112, 28, 110, 19, 68, 44, 2, 65, 87, 56, 22, 102, 101, 48, 34, 18, 95, 94, 106, 109, 92, 104, 113, 10, 11, 15, 23, 30, 38, 46, 39, 53, 60, 61, 63, 71, 49, 79, 17, 99, 116, 52, 125, 100, 47, 76, 73, 59, 103, 122, 121, 57, 119, 117, 115, 64, 72, 81, 84, 93, 97, 124, 0]
Per cls weights according to the accuracy are:  tensor([1.0736, 1.1148, 1.1148, 1.1433, 1.1282, 1.2000, 1.1790, 1.1601, 1.2000,
        1.1433, 1.1027, 1.1027, 1.2000, 1.2000, 1.1433, 1.1027, 1.1282, 1.0919,
        1.1148, 1.1148, 1.1148, 1.1433, 1.1148, 1.1027, 1.1282, 1.1433, 1.2000,
        1.1433, 1.1148, 1.1433, 1.1027, 1.2000, 1.1148, 1.1601, 1.1148, 1.2000,
        1.2000, 1.2000, 1.1027, 1.1027, 1.1282, 1.1790, 1.2000, 1.1433, 1.1148,
        1.1282, 1.1027, 1.0822, 1.1148, 1.1027, 1.1790, 1.1790, 1.0919, 1.1027,
        1.2000, 1.2000, 1.1148, 1.0736, 1.1282, 1.0822, 1.1027, 1.1027, 1.1433,
        1.1027, 1.0736, 1.1148, 1.2000, 1.1433, 1.1148, 1.1282, 1.1433, 1.1027,
        1.0736, 1.0822, 1.1433, 1.1433, 1.0822, 1.1433, 1.1433, 1.0919, 1.1433,
        1.0736, 1.1790, 1.2000, 1.0736, 1.1433, 1.2000, 1.1148, 1.1433, 1.2000,
        1.1433, 1.1601, 1.1027, 1.0736, 1.1027, 1.1027, 1.2000, 1.0736, 1.1282,
        1.0919, 1.0822, 1.1148, 1.1148, 1.0822, 1.1027, 1.1790, 1.1027, 1.1790,
        1.1601, 1.1027, 1.1148, 1.1433, 1.1148, 1.1027, 1.1433, 1.0736, 1.0919,
        1.0736, 1.2000, 1.0736, 1.1433, 1.0736, 1.0736, 1.1433, 1.0736, 1.0822])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9264, 0.8852, 0.8852, 0.8567, 0.8718, 0.8000, 0.8210, 0.8399, 0.8000,
        0.8567, 0.8973, 0.8973, 0.8000, 0.8000, 0.8567, 0.8973, 0.8718, 0.9081,
        0.8852, 0.8852, 0.8852, 0.8567, 0.8852, 0.8973, 0.8718, 0.8567, 0.8000,
        0.8567, 0.8852, 0.8567, 0.8973, 0.8000, 0.8852, 0.8399, 0.8852, 0.8000,
        0.8000, 0.8000, 0.8973, 0.8973, 0.8718, 0.8210, 0.8000, 0.8567, 0.8852,
        0.8718, 0.8973, 0.9178, 0.8852, 0.8973, 0.8210, 0.8210, 0.9081, 0.8973,
        0.8000, 0.8000, 0.8852, 0.9264, 0.8718, 0.9178, 0.8973, 0.8973, 0.8567,
        0.8973, 0.9264, 0.8852, 0.8000, 0.8567, 0.8852, 0.8718, 0.8567, 0.8973,
        0.9264, 0.9178, 0.8567, 0.8567, 0.9178, 0.8567, 0.8567, 0.9081, 0.8567,
        0.9264, 0.8210, 0.8000, 0.9264, 0.8567, 0.8000, 0.8852, 0.8567, 0.8000,
        0.8567, 0.8399, 0.8973, 0.9264, 0.8973, 0.8973, 0.8000, 0.9264, 0.8718,
        0.9081, 0.9178, 0.8852, 0.8852, 0.9178, 0.8973, 0.8210, 0.8973, 0.8210,
        0.8399, 0.8973, 0.8852, 0.8567, 0.8852, 0.8973, 0.8567, 0.9264, 0.9081,
        0.9264, 0.8000, 0.9264, 0.8567, 0.9264, 0.9264, 0.8567, 0.9264, 0.9178])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.653283 Loss T 0.060077 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8005, Accuracy: 522/1134 F1 (46.0317%)


Test set: Average loss: 2.0236, Accuracy: 18850/31104 F1 (60.6031%)


Val set: Average loss: 2.3127, Accuracy: 195/360 F1 (54.1667%)

Patience getting saturated, current counter is:  0
best acc test 61.474408  acc val 54.166667 acc labeled target 46.031746
saving model...
S sketch T painting Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.920471 Loss T 0.074155 Method MME

S sketch T painting Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.586158 Loss T 0.093283 Method MME

S sketch T painting Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.586701 Loss T 0.072337 Method MME

S sketch T painting Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.539797 Loss T 0.086245 Method MME

S sketch T painting Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.857175 Loss T 0.085613 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6476, Accuracy: 544/1134 F1 (47.9718%)


Test set: Average loss: 1.9050, Accuracy: 19905/31104 F1 (63.9950%)


Val set: Average loss: 2.2340, Accuracy: 200/360 F1 (55.5556%)

Patience Reset, Counter is: 1
best acc test 63.994985  acc val 55.555556 acc labeled target 47.971781
saving model...
S sketch T painting Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.744036 Loss T 0.101760 Method MME

S sketch T painting Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.554803 Loss T 0.069735 Method MME

S sketch T painting Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.535229 Loss T 0.104799 Method MME

S sketch T painting Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.791455 Loss T 0.083544 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.5555556  0.5555556  0.22222222 0.33333334 0.11111111
 0.22222222 0.22222222 0.22222222 0.44444445 0.7777778  0.6666667
 0.         0.         0.33333334 0.5555556  0.7777778  0.6666667
 0.7777778  0.33333334 0.5555556  0.33333334 0.6666667  0.22222222
 0.33333334 0.6666667  0.         0.         1.         0.33333334
 0.6666667  0.         0.22222222 0.33333334 0.         0.5555556
 0.         0.         0.6666667  1.         0.5555556  0.33333334
 0.         0.11111111 0.44444445 0.33333334 0.44444445 0.7777778
 0.33333334 0.6666667  0.         0.33333334 0.7777778  0.6666667
 0.         0.22222222 0.44444445 1.         0.33333334 0.7777778
 0.6666667  0.33333334 0.5555556  0.33333334 1.         0.33333334
 0.11111111 0.44444445 0.6666667  1.         0.33333334 0.6666667
 0.8888889  0.6666667  0.         0.33333334 0.8888889  0.11111111
 0.44444445 0.7777778  0.22222222 1.         0.         0.
 0.7777778  0.33333334 0.         0.6666667  0.22222222 0.11111111
 0.22222222 0.44444445 0.33333334 0.8888889  0.5555556  0.6666667
 0.33333334 0.8888889  0.33333334 0.7777778  0.8888889  0.44444445
 0.6666667  1.         0.6666667  0.44444445 0.6666667  0.33333334
 0.         0.6666667  0.5555556  0.33333334 0.11111111 0.6666667
 0.22222222 1.         0.7777778  1.         0.11111111 1.
 0.33333334 1.         1.         0.44444445 1.         1.        ]
Top k classes which perform poorly are:  [34, 82, 83, 37, 36, 31, 86, 50, 27, 26, 13, 12, 54, 74, 108, 42, 66, 118, 43, 89, 112, 77, 5, 7, 3, 114, 80, 32, 6, 8, 88, 23, 90, 55, 51, 61, 63, 48, 65, 45, 58, 75, 111, 70, 4, 98, 92, 41, 19, 21, 24, 96, 14, 29, 33, 85, 120, 107, 101, 9, 67, 44, 56, 91, 78, 123, 46, 105, 110, 94, 62, 1, 2, 15, 20, 40, 35, 71, 106, 102, 11, 95, 109, 17, 22, 113, 87, 25, 53, 38, 68, 73, 49, 60, 104, 30, 116, 99, 84, 59, 16, 79, 18, 47, 10, 52, 0, 100, 97, 93, 76, 72, 28, 122, 121, 39, 119, 57, 124, 103, 115, 64, 69, 81, 117, 125]
Per cls weights according to the accuracy are:  tensor([1.0822, 1.1148, 1.1148, 1.1601, 1.1433, 1.1790, 1.1601, 1.1601, 1.1601,
        1.1282, 1.0919, 1.1027, 1.2000, 1.2000, 1.1433, 1.1148, 1.0919, 1.1027,
        1.0919, 1.1433, 1.1148, 1.1433, 1.1027, 1.1601, 1.1433, 1.1027, 1.2000,
        1.2000, 1.0736, 1.1433, 1.1027, 1.2000, 1.1601, 1.1433, 1.2000, 1.1148,
        1.2000, 1.2000, 1.1027, 1.0736, 1.1148, 1.1433, 1.2000, 1.1790, 1.1282,
        1.1433, 1.1282, 1.0919, 1.1433, 1.1027, 1.2000, 1.1433, 1.0919, 1.1027,
        1.2000, 1.1601, 1.1282, 1.0736, 1.1433, 1.0919, 1.1027, 1.1433, 1.1148,
        1.1433, 1.0736, 1.1433, 1.1790, 1.1282, 1.1027, 1.0736, 1.1433, 1.1027,
        1.0822, 1.1027, 1.2000, 1.1433, 1.0822, 1.1790, 1.1282, 1.0919, 1.1601,
        1.0736, 1.2000, 1.2000, 1.0919, 1.1433, 1.2000, 1.1027, 1.1601, 1.1790,
        1.1601, 1.1282, 1.1433, 1.0822, 1.1148, 1.1027, 1.1433, 1.0822, 1.1433,
        1.0919, 1.0822, 1.1282, 1.1027, 1.0736, 1.1027, 1.1282, 1.1027, 1.1433,
        1.2000, 1.1027, 1.1148, 1.1433, 1.1790, 1.1027, 1.1601, 1.0736, 1.0919,
        1.0736, 1.1790, 1.0736, 1.1433, 1.0736, 1.0736, 1.1282, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9178, 0.8852, 0.8852, 0.8399, 0.8567, 0.8210, 0.8399, 0.8399, 0.8399,
        0.8718, 0.9081, 0.8973, 0.8000, 0.8000, 0.8567, 0.8852, 0.9081, 0.8973,
        0.9081, 0.8567, 0.8852, 0.8567, 0.8973, 0.8399, 0.8567, 0.8973, 0.8000,
        0.8000, 0.9264, 0.8567, 0.8973, 0.8000, 0.8399, 0.8567, 0.8000, 0.8852,
        0.8000, 0.8000, 0.8973, 0.9264, 0.8852, 0.8567, 0.8000, 0.8210, 0.8718,
        0.8567, 0.8718, 0.9081, 0.8567, 0.8973, 0.8000, 0.8567, 0.9081, 0.8973,
        0.8000, 0.8399, 0.8718, 0.9264, 0.8567, 0.9081, 0.8973, 0.8567, 0.8852,
        0.8567, 0.9264, 0.8567, 0.8210, 0.8718, 0.8973, 0.9264, 0.8567, 0.8973,
        0.9178, 0.8973, 0.8000, 0.8567, 0.9178, 0.8210, 0.8718, 0.9081, 0.8399,
        0.9264, 0.8000, 0.8000, 0.9081, 0.8567, 0.8000, 0.8973, 0.8399, 0.8210,
        0.8399, 0.8718, 0.8567, 0.9178, 0.8852, 0.8973, 0.8567, 0.9178, 0.8567,
        0.9081, 0.9178, 0.8718, 0.8973, 0.9264, 0.8973, 0.8718, 0.8973, 0.8567,
        0.8000, 0.8973, 0.8852, 0.8567, 0.8210, 0.8973, 0.8399, 0.9264, 0.9081,
        0.9264, 0.8210, 0.9264, 0.8567, 0.9264, 0.9264, 0.8718, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.575824 Loss T 0.077709 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8573, Accuracy: 540/1134 F1 (47.6190%)


Test set: Average loss: 2.0864, Accuracy: 19148/31104 F1 (61.5612%)


Val set: Average loss: 2.5010, Accuracy: 185/360 F1 (51.3889%)

Patience getting saturated, current counter is:  0
best acc test 63.994985  acc val 51.388889 acc labeled target 47.619048
saving model...
S sketch T painting Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.511753 Loss T 0.075009 Method MME

S sketch T painting Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.240484 Loss T 0.068683 Method MME

S sketch T painting Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.427070 Loss T 0.071940 Method MME

S sketch T painting Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.375638 Loss T 0.072850 Method MME

S sketch T painting Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.347719 Loss T 0.074781 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.6793, Accuracy: 572/1134 F1 (50.4409%)


Test set: Average loss: 1.9850, Accuracy: 20071/31104 F1 (64.5287%)


Val set: Average loss: 2.3058, Accuracy: 203/360 F1 (56.3889%)

Patience Reset, Counter is: 1
best acc test 64.528678  acc val 56.388889 acc labeled target 50.440917
saving model...
S sketch T painting Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.222206 Loss T 0.084251 Method MME

S sketch T painting Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 0.438969 Loss T 0.055534 Method MME

S sketch T painting Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.330993 Loss T 0.069938 Method MME

S sketch T painting Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.552308 Loss T 0.048886 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.7777778  0.33333334 0.         0.5555556  0.11111111
 0.22222222 0.         0.22222222 0.22222222 0.6666667  0.5555556
 0.22222222 0.11111111 0.33333334 0.33333334 0.5555556  0.6666667
 0.22222222 0.11111111 0.6666667  0.33333334 0.6666667  0.22222222
 0.6666667  0.6666667  0.         0.         1.         0.22222222
 0.7777778  0.         0.33333334 0.         0.33333334 0.
 0.         0.         0.6666667  0.6666667  0.6666667  0.22222222
 0.         0.22222222 0.5555556  1.         0.44444445 0.6666667
 0.22222222 0.6666667  0.22222222 0.33333334 0.8888889  0.6666667
 0.         0.44444445 0.6666667  0.8888889  0.33333334 1.
 0.6666667  0.33333334 0.44444445 0.11111111 1.         0.6666667
 0.11111111 0.8888889  0.6666667  0.44444445 0.5555556  0.7777778
 1.         0.8888889  0.44444445 0.33333334 0.8888889  0.33333334
 0.5555556  1.         0.33333334 1.         0.         0.
 0.8888889  0.22222222 0.         0.6666667  0.33333334 0.44444445
 0.33333334 0.33333334 0.44444445 0.8888889  0.6666667  0.5555556
 0.22222222 1.         0.44444445 0.7777778  0.8888889  0.33333334
 0.5555556  0.8888889  0.8888889  0.6666667  0.6666667  0.33333334
 0.         0.6666667  0.8888889  0.33333334 0.22222222 0.6666667
 0.22222222 1.         0.8888889  1.         0.         1.
 0.6666667  1.         1.         0.6666667  1.         1.        ]
Top k classes which perform poorly are:  [26, 83, 35, 27, 36, 86, 37, 82, 54, 31, 108, 42, 3, 118, 7, 33, 19, 66, 13, 5, 63, 114, 41, 112, 29, 43, 50, 23, 48, 96, 18, 6, 8, 85, 12, 9, 91, 90, 58, 75, 61, 80, 107, 77, 51, 111, 88, 101, 2, 14, 15, 21, 32, 34, 46, 98, 92, 89, 69, 74, 62, 55, 95, 102, 16, 4, 44, 78, 70, 11, 106, 40, 105, 87, 10, 120, 94, 49, 53, 38, 60, 22, 39, 113, 20, 123, 25, 68, 65, 109, 47, 24, 56, 17, 71, 30, 1, 99, 110, 104, 116, 103, 0, 93, 84, 76, 73, 67, 100, 52, 57, 97, 28, 122, 121, 45, 119, 59, 115, 124, 64, 72, 79, 81, 117, 125]
Per cls weights according to the accuracy are:  tensor([1.0822, 1.0919, 1.1433, 1.2000, 1.1148, 1.1790, 1.1601, 1.2000, 1.1601,
        1.1601, 1.1027, 1.1148, 1.1601, 1.1790, 1.1433, 1.1433, 1.1148, 1.1027,
        1.1601, 1.1790, 1.1027, 1.1433, 1.1027, 1.1601, 1.1027, 1.1027, 1.2000,
        1.2000, 1.0736, 1.1601, 1.0919, 1.2000, 1.1433, 1.2000, 1.1433, 1.2000,
        1.2000, 1.2000, 1.1027, 1.1027, 1.1027, 1.1601, 1.2000, 1.1601, 1.1148,
        1.0736, 1.1282, 1.1027, 1.1601, 1.1027, 1.1601, 1.1433, 1.0822, 1.1027,
        1.2000, 1.1282, 1.1027, 1.0822, 1.1433, 1.0736, 1.1027, 1.1433, 1.1282,
        1.1790, 1.0736, 1.1027, 1.1790, 1.0822, 1.1027, 1.1282, 1.1148, 1.0919,
        1.0736, 1.0822, 1.1282, 1.1433, 1.0822, 1.1433, 1.1148, 1.0736, 1.1433,
        1.0736, 1.2000, 1.2000, 1.0822, 1.1601, 1.2000, 1.1027, 1.1433, 1.1282,
        1.1433, 1.1433, 1.1282, 1.0822, 1.1027, 1.1148, 1.1601, 1.0736, 1.1282,
        1.0919, 1.0822, 1.1433, 1.1148, 1.0822, 1.0822, 1.1027, 1.1027, 1.1433,
        1.2000, 1.1027, 1.0822, 1.1433, 1.1601, 1.1027, 1.1601, 1.0736, 1.0822,
        1.0736, 1.2000, 1.0736, 1.1027, 1.0736, 1.0736, 1.1027, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9178, 0.9081, 0.8567, 0.8000, 0.8852, 0.8210, 0.8399, 0.8000, 0.8399,
        0.8399, 0.8973, 0.8852, 0.8399, 0.8210, 0.8567, 0.8567, 0.8852, 0.8973,
        0.8399, 0.8210, 0.8973, 0.8567, 0.8973, 0.8399, 0.8973, 0.8973, 0.8000,
        0.8000, 0.9264, 0.8399, 0.9081, 0.8000, 0.8567, 0.8000, 0.8567, 0.8000,
        0.8000, 0.8000, 0.8973, 0.8973, 0.8973, 0.8399, 0.8000, 0.8399, 0.8852,
        0.9264, 0.8718, 0.8973, 0.8399, 0.8973, 0.8399, 0.8567, 0.9178, 0.8973,
        0.8000, 0.8718, 0.8973, 0.9178, 0.8567, 0.9264, 0.8973, 0.8567, 0.8718,
        0.8210, 0.9264, 0.8973, 0.8210, 0.9178, 0.8973, 0.8718, 0.8852, 0.9081,
        0.9264, 0.9178, 0.8718, 0.8567, 0.9178, 0.8567, 0.8852, 0.9264, 0.8567,
        0.9264, 0.8000, 0.8000, 0.9178, 0.8399, 0.8000, 0.8973, 0.8567, 0.8718,
        0.8567, 0.8567, 0.8718, 0.9178, 0.8973, 0.8852, 0.8399, 0.9264, 0.8718,
        0.9081, 0.9178, 0.8567, 0.8852, 0.9178, 0.9178, 0.8973, 0.8973, 0.8567,
        0.8000, 0.8973, 0.9178, 0.8567, 0.8399, 0.8973, 0.8399, 0.9264, 0.9178,
        0.9264, 0.8000, 0.9264, 0.8973, 0.9264, 0.9264, 0.8973, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.423632 Loss T 0.069496 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8061, Accuracy: 534/1134 F1 (47.0899%)


Test set: Average loss: 2.0789, Accuracy: 19453/31104 F1 (62.5418%)


Val set: Average loss: 2.4249, Accuracy: 197/360 F1 (54.7222%)

Patience getting saturated, current counter is:  0
best acc test 64.528678  acc val 54.722222 acc labeled target 47.089947
saving model...
S sketch T painting Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.237167 Loss T 0.064236 Method MME

S sketch T painting Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.376660 Loss T 0.062051 Method MME

S sketch T painting Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.171728 Loss T 0.073624 Method MME

S sketch T painting Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.207010 Loss T 0.051976 Method MME

S sketch T painting Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.531723 Loss T 0.055396 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.5449, Accuracy: 607/1134 F1 (53.5273%)


Test set: Average loss: 1.9690, Accuracy: 20525/31104 F1 (65.9883%)


Val set: Average loss: 2.3019, Accuracy: 208/360 F1 (57.7778%)

Patience Reset, Counter is: 1
best acc test 65.988297  acc val 57.777778 acc labeled target 53.527337
saving model...
S sketch T painting Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 1.220129 Loss T 0.059358 Method MME

S sketch T painting Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.508111 Loss T 0.068801 Method MME

S sketch T painting Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.282166 Loss T 0.053863 Method MME

S sketch T painting Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.297885 Loss T 0.045950 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.7777778  0.33333334 0.22222222 0.44444445 0.22222222
 0.33333334 0.         0.22222222 0.44444445 0.6666667  0.6666667
 0.33333334 0.6666667  0.33333334 0.7777778  0.44444445 1.
 0.33333334 0.33333334 0.44444445 0.33333334 0.6666667  0.33333334
 0.6666667  0.6666667  0.         0.33333334 1.         0.5555556
 0.6666667  0.         0.33333334 0.22222222 0.11111111 0.11111111
 0.         0.         0.6666667  1.         0.6666667  0.22222222
 0.         0.11111111 0.33333334 0.8888889  0.6666667  0.6666667
 0.33333334 0.6666667  0.22222222 0.33333334 0.8888889  0.44444445
 0.11111111 0.6666667  0.5555556  1.         0.33333334 0.8888889
 0.6666667  0.5555556  0.6666667  0.11111111 1.         0.5555556
 0.         0.5555556  0.7777778  0.6666667  0.5555556  0.6666667
 0.8888889  1.         0.         0.44444445 1.         0.33333334
 0.6666667  1.         0.33333334 1.         0.         0.
 0.8888889  0.5555556  0.         0.5555556  0.22222222 0.11111111
 0.22222222 0.5555556  0.6666667  0.8888889  0.44444445 0.5555556
 0.22222222 0.8888889  0.5555556  1.         1.         0.44444445
 0.8888889  1.         0.8888889  0.22222222 0.6666667  0.5555556
 0.         0.8888889  0.7777778  0.5555556  0.33333334 0.6666667
 0.11111111 1.         0.7777778  1.         0.33333334 1.
 0.33333334 1.         1.         0.5555556  1.         1.        ]
Top k classes which perform poorly are:  [37, 66, 82, 83, 86, 42, 36, 31, 26, 74, 7, 108, 34, 54, 89, 63, 43, 35, 114, 50, 88, 90, 41, 33, 96, 8, 5, 3, 105, 120, 77, 2, 51, 12, 48, 14, 44, 112, 18, 118, 27, 32, 23, 21, 58, 19, 80, 6, 16, 20, 94, 75, 101, 53, 9, 4, 61, 67, 70, 65, 107, 56, 87, 91, 95, 29, 98, 123, 111, 85, 92, 113, 78, 106, 62, 55, 38, 30, 71, 10, 69, 11, 13, 60, 40, 22, 24, 25, 49, 47, 46, 116, 1, 15, 110, 68, 45, 97, 52, 109, 59, 102, 84, 104, 72, 93, 117, 122, 119, 115, 121, 0, 100, 99, 81, 79, 76, 73, 64, 124, 57, 39, 28, 17, 103, 125]
Per cls weights according to the accuracy are:  tensor([1.0736, 1.0919, 1.1433, 1.1601, 1.1282, 1.1601, 1.1433, 1.2000, 1.1601,
        1.1282, 1.1027, 1.1027, 1.1433, 1.1027, 1.1433, 1.0919, 1.1282, 1.0736,
        1.1433, 1.1433, 1.1282, 1.1433, 1.1027, 1.1433, 1.1027, 1.1027, 1.2000,
        1.1433, 1.0736, 1.1148, 1.1027, 1.2000, 1.1433, 1.1601, 1.1790, 1.1790,
        1.2000, 1.2000, 1.1027, 1.0736, 1.1027, 1.1601, 1.2000, 1.1790, 1.1433,
        1.0822, 1.1027, 1.1027, 1.1433, 1.1027, 1.1601, 1.1433, 1.0822, 1.1282,
        1.1790, 1.1027, 1.1148, 1.0736, 1.1433, 1.0822, 1.1027, 1.1148, 1.1027,
        1.1790, 1.0736, 1.1148, 1.2000, 1.1148, 1.0919, 1.1027, 1.1148, 1.1027,
        1.0822, 1.0736, 1.2000, 1.1282, 1.0736, 1.1433, 1.1027, 1.0736, 1.1433,
        1.0736, 1.2000, 1.2000, 1.0822, 1.1148, 1.2000, 1.1148, 1.1601, 1.1790,
        1.1601, 1.1148, 1.1027, 1.0822, 1.1282, 1.1148, 1.1601, 1.0822, 1.1148,
        1.0736, 1.0736, 1.1282, 1.0822, 1.0736, 1.0822, 1.1601, 1.1027, 1.1148,
        1.2000, 1.0822, 1.0919, 1.1148, 1.1433, 1.1027, 1.1790, 1.0736, 1.0919,
        1.0736, 1.1433, 1.0736, 1.1433, 1.0736, 1.0736, 1.1148, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9264, 0.9081, 0.8567, 0.8399, 0.8718, 0.8399, 0.8567, 0.8000, 0.8399,
        0.8718, 0.8973, 0.8973, 0.8567, 0.8973, 0.8567, 0.9081, 0.8718, 0.9264,
        0.8567, 0.8567, 0.8718, 0.8567, 0.8973, 0.8567, 0.8973, 0.8973, 0.8000,
        0.8567, 0.9264, 0.8852, 0.8973, 0.8000, 0.8567, 0.8399, 0.8210, 0.8210,
        0.8000, 0.8000, 0.8973, 0.9264, 0.8973, 0.8399, 0.8000, 0.8210, 0.8567,
        0.9178, 0.8973, 0.8973, 0.8567, 0.8973, 0.8399, 0.8567, 0.9178, 0.8718,
        0.8210, 0.8973, 0.8852, 0.9264, 0.8567, 0.9178, 0.8973, 0.8852, 0.8973,
        0.8210, 0.9264, 0.8852, 0.8000, 0.8852, 0.9081, 0.8973, 0.8852, 0.8973,
        0.9178, 0.9264, 0.8000, 0.8718, 0.9264, 0.8567, 0.8973, 0.9264, 0.8567,
        0.9264, 0.8000, 0.8000, 0.9178, 0.8852, 0.8000, 0.8852, 0.8399, 0.8210,
        0.8399, 0.8852, 0.8973, 0.9178, 0.8718, 0.8852, 0.8399, 0.9178, 0.8852,
        0.9264, 0.9264, 0.8718, 0.9178, 0.9264, 0.9178, 0.8399, 0.8973, 0.8852,
        0.8000, 0.9178, 0.9081, 0.8852, 0.8567, 0.8973, 0.8210, 0.9264, 0.9081,
        0.9264, 0.8567, 0.9264, 0.8567, 0.9264, 0.9264, 0.8852, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.626771 Loss T 0.067457 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7543, Accuracy: 557/1134 F1 (49.1182%)


Test set: Average loss: 2.0670, Accuracy: 19790/31104 F1 (63.6253%)


Val set: Average loss: 2.4708, Accuracy: 197/360 F1 (54.7222%)

Patience getting saturated, current counter is:  0
best acc test 65.988297  acc val 54.722222 acc labeled target 49.118166
saving model...
S sketch T painting Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.345447 Loss T 0.048680 Method MME

S sketch T painting Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.334578 Loss T 0.059189 Method MME

S sketch T painting Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.755397 Loss T 0.053193 Method MME

S sketch T painting Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.719889 Loss T 0.062144 Method MME

S sketch T painting Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.404770 Loss T 0.057925 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7232, Accuracy: 589/1134 F1 (51.9400%)


Test set: Average loss: 2.0096, Accuracy: 20535/31104 F1 (66.0204%)


Val set: Average loss: 2.3173, Accuracy: 215/360 F1 (59.7222%)

Patience Reset, Counter is: 1
best acc test 66.020448  acc val 59.722222 acc labeled target 51.940035
saving model...
S sketch T painting Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.058355 Loss T 0.052165 Method MME

S sketch T painting Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.291851 Loss T 0.059278 Method MME

S sketch T painting Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.491707 Loss T 0.055240 Method MME

S sketch T painting Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.224188 Loss T 0.072445 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  0.6666667  0.33333334 0.33333334 0.6666667  0.
 0.11111111 0.33333334 0.         0.44444445 0.7777778  0.5555556
 0.         0.6666667  0.33333334 0.5555556  0.8888889  1.
 0.33333334 0.22222222 0.6666667  0.33333334 0.6666667  0.44444445
 0.44444445 0.5555556  0.         0.         1.         0.6666667
 0.44444445 0.         0.         0.11111111 0.         0.
 0.         0.         0.6666667  0.8888889  0.6666667  0.11111111
 0.         0.         0.5555556  0.5555556  0.5555556  0.6666667
 0.33333334 0.6666667  0.22222222 0.33333334 1.         0.6666667
 0.         0.5555556  0.7777778  1.         0.6666667  0.6666667
 0.6666667  0.5555556  0.6666667  0.11111111 1.         0.44444445
 0.22222222 0.7777778  0.8888889  0.7777778  0.44444445 0.6666667
 0.8888889  1.         0.33333334 0.33333334 1.         0.44444445
 0.5555556  0.8888889  0.33333334 1.         0.         0.
 0.8888889  0.5555556  0.         0.6666667  0.33333334 0.
 0.11111111 0.33333334 0.6666667  0.6666667  0.6666667  0.6666667
 0.22222222 1.         0.33333334 0.8888889  1.         0.11111111
 0.44444445 0.7777778  0.7777778  0.5555556  0.6666667  0.5555556
 0.         0.7777778  0.7777778  0.33333334 0.33333334 0.6666667
 0.33333334 1.         1.         1.         0.11111111 0.8888889
 0.7777778  1.         1.         0.6666667  1.         1.        ]
Top k classes which perform poorly are:  [35, 86, 34, 27, 26, 54, 36, 37, 83, 31, 12, 89, 42, 82, 5, 108, 8, 32, 43, 63, 6, 41, 101, 90, 33, 118, 19, 96, 66, 50, 80, 51, 112, 98, 114, 48, 75, 21, 88, 18, 14, 91, 7, 3, 2, 74, 111, 102, 65, 77, 70, 23, 9, 30, 24, 107, 11, 15, 61, 46, 45, 25, 55, 105, 85, 44, 78, 87, 92, 93, 62, 47, 40, 1, 4, 123, 13, 20, 22, 29, 38, 113, 71, 95, 49, 53, 58, 59, 60, 106, 94, 110, 120, 109, 103, 104, 0, 56, 67, 69, 10, 79, 16, 72, 39, 68, 119, 84, 99, 122, 121, 17, 117, 116, 115, 97, 52, 57, 124, 64, 73, 76, 100, 81, 28, 125]
Per cls weights according to the accuracy are:  tensor([1.0919, 1.1027, 1.1433, 1.1433, 1.1027, 1.2000, 1.1790, 1.1433, 1.2000,
        1.1282, 1.0919, 1.1148, 1.2000, 1.1027, 1.1433, 1.1148, 1.0822, 1.0736,
        1.1433, 1.1601, 1.1027, 1.1433, 1.1027, 1.1282, 1.1282, 1.1148, 1.2000,
        1.2000, 1.0736, 1.1027, 1.1282, 1.2000, 1.2000, 1.1790, 1.2000, 1.2000,
        1.2000, 1.2000, 1.1027, 1.0822, 1.1027, 1.1790, 1.2000, 1.2000, 1.1148,
        1.1148, 1.1148, 1.1027, 1.1433, 1.1027, 1.1601, 1.1433, 1.0736, 1.1027,
        1.2000, 1.1148, 1.0919, 1.0736, 1.1027, 1.1027, 1.1027, 1.1148, 1.1027,
        1.1790, 1.0736, 1.1282, 1.1601, 1.0919, 1.0822, 1.0919, 1.1282, 1.1027,
        1.0822, 1.0736, 1.1433, 1.1433, 1.0736, 1.1282, 1.1148, 1.0822, 1.1433,
        1.0736, 1.2000, 1.2000, 1.0822, 1.1148, 1.2000, 1.1027, 1.1433, 1.2000,
        1.1790, 1.1433, 1.1027, 1.1027, 1.1027, 1.1027, 1.1601, 1.0736, 1.1433,
        1.0822, 1.0736, 1.1790, 1.1282, 1.0919, 1.0919, 1.1148, 1.1027, 1.1148,
        1.2000, 1.0919, 1.0919, 1.1433, 1.1433, 1.1027, 1.1433, 1.0736, 1.0736,
        1.0736, 1.1790, 1.0822, 1.0919, 1.0736, 1.0736, 1.1027, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9081, 0.8973, 0.8567, 0.8567, 0.8973, 0.8000, 0.8210, 0.8567, 0.8000,
        0.8718, 0.9081, 0.8852, 0.8000, 0.8973, 0.8567, 0.8852, 0.9178, 0.9264,
        0.8567, 0.8399, 0.8973, 0.8567, 0.8973, 0.8718, 0.8718, 0.8852, 0.8000,
        0.8000, 0.9264, 0.8973, 0.8718, 0.8000, 0.8000, 0.8210, 0.8000, 0.8000,
        0.8000, 0.8000, 0.8973, 0.9178, 0.8973, 0.8210, 0.8000, 0.8000, 0.8852,
        0.8852, 0.8852, 0.8973, 0.8567, 0.8973, 0.8399, 0.8567, 0.9264, 0.8973,
        0.8000, 0.8852, 0.9081, 0.9264, 0.8973, 0.8973, 0.8973, 0.8852, 0.8973,
        0.8210, 0.9264, 0.8718, 0.8399, 0.9081, 0.9178, 0.9081, 0.8718, 0.8973,
        0.9178, 0.9264, 0.8567, 0.8567, 0.9264, 0.8718, 0.8852, 0.9178, 0.8567,
        0.9264, 0.8000, 0.8000, 0.9178, 0.8852, 0.8000, 0.8973, 0.8567, 0.8000,
        0.8210, 0.8567, 0.8973, 0.8973, 0.8973, 0.8973, 0.8399, 0.9264, 0.8567,
        0.9178, 0.9264, 0.8210, 0.8718, 0.9081, 0.9081, 0.8852, 0.8973, 0.8852,
        0.8000, 0.9081, 0.9081, 0.8567, 0.8567, 0.8973, 0.8567, 0.9264, 0.9264,
        0.9264, 0.8210, 0.9178, 0.9081, 0.9264, 0.9264, 0.8973, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.208784 Loss T 0.067773 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8682, Accuracy: 560/1134 F1 (49.3827%)


Test set: Average loss: 2.1509, Accuracy: 20079/31104 F1 (64.5544%)


Val set: Average loss: 2.4435, Accuracy: 201/360 F1 (55.8333%)

Patience getting saturated, current counter is:  0
best acc test 66.020448  acc val 55.833333 acc labeled target 49.382716
saving model...
S sketch T painting Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.486673 Loss T 0.054610 Method MME

S sketch T painting Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.188734 Loss T 0.057826 Method MME

S sketch T painting Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.351791 Loss T 0.054250 Method MME

S sketch T painting Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.144950 Loss T 0.058317 Method MME

S sketch T painting Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.265487 Loss T 0.060518 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.8602, Accuracy: 572/1134 F1 (50.4409%)


Test set: Average loss: 2.0858, Accuracy: 20520/31104 F1 (65.9722%)


Val set: Average loss: 2.2737, Accuracy: 219/360 F1 (60.8333%)

Patience Reset, Counter is: 1
best acc test 65.972222  acc val 60.833333 acc labeled target 50.440917
saving model...
S sketch T painting Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.172113 Loss T 0.051438 Method MME

S sketch T painting Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.205535 Loss T 0.058691 Method MME

S sketch T painting Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.095596 Loss T 0.047910 Method MME

S sketch T painting Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.384093 Loss T 0.042115 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.7777778  0.33333334 0.33333334 0.33333334 0.
 0.22222222 0.         0.         0.44444445 0.5555556  0.5555556
 0.         0.44444445 0.33333334 0.6666667  0.6666667  0.7777778
 0.22222222 0.33333334 0.33333334 0.33333334 0.6666667  0.33333334
 0.5555556  0.44444445 0.11111111 0.         0.8888889  0.22222222
 0.44444445 0.         0.33333334 0.         0.         0.
 0.         0.         0.6666667  0.8888889  0.6666667  0.22222222
 0.         0.         0.22222222 0.6666667  0.5555556  0.5555556
 0.33333334 0.6666667  0.33333334 0.33333334 1.         0.7777778
 0.         0.6666667  0.7777778  1.         0.5555556  0.7777778
 0.6666667  0.33333334 0.5555556  0.33333334 1.         0.33333334
 0.         0.5555556  1.         1.         0.44444445 0.8888889
 0.8888889  0.7777778  0.22222222 0.5555556  0.8888889  0.11111111
 0.33333334 0.8888889  0.33333334 1.         0.11111111 0.
 0.7777778  0.33333334 0.         0.6666667  0.33333334 0.44444445
 0.22222222 0.5555556  0.6666667  0.8888889  0.5555556  0.6666667
 0.11111111 1.         0.5555556  0.7777778  0.7777778  0.33333334
 0.8888889  0.8888889  0.7777778  0.5555556  0.6666667  0.44444445
 0.11111111 0.8888889  0.7777778  0.33333334 0.44444445 0.6666667
 0.33333334 1.         0.8888889  0.6666667  0.11111111 1.
 0.6666667  0.8888889  1.         0.44444445 1.         1.        ]
Top k classes which perform poorly are:  [86, 31, 66, 33, 42, 54, 12, 83, 43, 34, 8, 7, 5, 27, 35, 36, 37, 26, 82, 108, 77, 96, 118, 18, 90, 44, 74, 6, 41, 29, 51, 80, 50, 78, 111, 114, 61, 63, 85, 48, 32, 65, 101, 2, 3, 23, 21, 20, 19, 4, 14, 88, 70, 112, 9, 30, 13, 107, 89, 25, 123, 94, 91, 67, 98, 75, 62, 10, 11, 58, 24, 105, 47, 46, 117, 106, 95, 15, 16, 92, 22, 38, 87, 40, 55, 49, 120, 60, 113, 45, 1, 100, 99, 59, 56, 84, 53, 17, 110, 73, 104, 109, 121, 116, 0, 102, 28, 93, 79, 76, 72, 71, 39, 103, 122, 52, 119, 57, 115, 64, 68, 69, 81, 97, 124, 125]
Per cls weights according to the accuracy are:  tensor([1.0822, 1.0919, 1.1433, 1.1433, 1.1433, 1.2000, 1.1601, 1.2000, 1.2000,
        1.1282, 1.1148, 1.1148, 1.2000, 1.1282, 1.1433, 1.1027, 1.1027, 1.0919,
        1.1601, 1.1433, 1.1433, 1.1433, 1.1027, 1.1433, 1.1148, 1.1282, 1.1790,
        1.2000, 1.0822, 1.1601, 1.1282, 1.2000, 1.1433, 1.2000, 1.2000, 1.2000,
        1.2000, 1.2000, 1.1027, 1.0822, 1.1027, 1.1601, 1.2000, 1.2000, 1.1601,
        1.1027, 1.1148, 1.1148, 1.1433, 1.1027, 1.1433, 1.1433, 1.0736, 1.0919,
        1.2000, 1.1027, 1.0919, 1.0736, 1.1148, 1.0919, 1.1027, 1.1433, 1.1148,
        1.1433, 1.0736, 1.1433, 1.2000, 1.1148, 1.0736, 1.0736, 1.1282, 1.0822,
        1.0822, 1.0919, 1.1601, 1.1148, 1.0822, 1.1790, 1.1433, 1.0822, 1.1433,
        1.0736, 1.1790, 1.2000, 1.0919, 1.1433, 1.2000, 1.1027, 1.1433, 1.1282,
        1.1601, 1.1148, 1.1027, 1.0822, 1.1148, 1.1027, 1.1790, 1.0736, 1.1148,
        1.0919, 1.0919, 1.1433, 1.0822, 1.0822, 1.0919, 1.1148, 1.1027, 1.1282,
        1.1790, 1.0822, 1.0919, 1.1433, 1.1282, 1.1027, 1.1433, 1.0736, 1.0822,
        1.1027, 1.1790, 1.0736, 1.1027, 1.0822, 1.0736, 1.1282, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9178, 0.9081, 0.8567, 0.8567, 0.8567, 0.8000, 0.8399, 0.8000, 0.8000,
        0.8718, 0.8852, 0.8852, 0.8000, 0.8718, 0.8567, 0.8973, 0.8973, 0.9081,
        0.8399, 0.8567, 0.8567, 0.8567, 0.8973, 0.8567, 0.8852, 0.8718, 0.8210,
        0.8000, 0.9178, 0.8399, 0.8718, 0.8000, 0.8567, 0.8000, 0.8000, 0.8000,
        0.8000, 0.8000, 0.8973, 0.9178, 0.8973, 0.8399, 0.8000, 0.8000, 0.8399,
        0.8973, 0.8852, 0.8852, 0.8567, 0.8973, 0.8567, 0.8567, 0.9264, 0.9081,
        0.8000, 0.8973, 0.9081, 0.9264, 0.8852, 0.9081, 0.8973, 0.8567, 0.8852,
        0.8567, 0.9264, 0.8567, 0.8000, 0.8852, 0.9264, 0.9264, 0.8718, 0.9178,
        0.9178, 0.9081, 0.8399, 0.8852, 0.9178, 0.8210, 0.8567, 0.9178, 0.8567,
        0.9264, 0.8210, 0.8000, 0.9081, 0.8567, 0.8000, 0.8973, 0.8567, 0.8718,
        0.8399, 0.8852, 0.8973, 0.9178, 0.8852, 0.8973, 0.8210, 0.9264, 0.8852,
        0.9081, 0.9081, 0.8567, 0.9178, 0.9178, 0.9081, 0.8852, 0.8973, 0.8718,
        0.8210, 0.9178, 0.9081, 0.8567, 0.8718, 0.8973, 0.8567, 0.9264, 0.9178,
        0.8973, 0.8210, 0.9264, 0.8973, 0.9178, 0.9264, 0.8718, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.544514 Loss T 0.058557 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 2.7989, Accuracy: 590/1134 F1 (52.0282%)


Test set: Average loss: 2.1216, Accuracy: 20342/31104 F1 (65.3999%)


Val set: Average loss: 2.4629, Accuracy: 202/360 F1 (56.1111%)

Patience getting saturated, current counter is:  0
best acc test 65.972222  acc val 56.111111 acc labeled target 52.028219
saving model...
S sketch T painting Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.510032 Loss T 0.072557 Method MME

S sketch T painting Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.227765 Loss T 0.049263 Method MME

S sketch T painting Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.457675 Loss T 0.040859 Method MME

S sketch T painting Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.281786 Loss T 0.065964 Method MME

S sketch T painting Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.156470 Loss T 0.042209 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1596, Accuracy: 1090/1134 F1 (96.1199%)


Test set: Average loss: 1.8032, Accuracy: 21516/31104 F1 (69.1744%)


Val set: Average loss: 2.0325, Accuracy: 223/360 F1 (61.9444%)

Patience Reset, Counter is: 1
best acc test 69.174383  acc val 61.944444 acc labeled target 96.119929
saving model...
S sketch T painting Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.516785 Loss T 0.045272 Method MME

S sketch T painting Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.160709 Loss T 0.050362 Method MME

S sketch T painting Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.146206 Loss T 0.059541 Method MME

S sketch T painting Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.481165 Loss T 0.052987 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 0.7777778 1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        0.8888889 0.8888889 1.
 0.7777778 1.        1.        0.7777778 1.        1.        0.7777778
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.7777778 1.
 1.        0.8888889 0.7777778 1.        0.8888889 0.8888889 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [23, 54, 35, 58, 38, 8, 82, 41, 4, 50, 95, 51, 43, 100, 33, 32, 30, 29, 94, 57, 96, 46, 73, 108, 77, 3, 116, 63, 14, 15, 91, 61, 109, 60, 113, 88, 90, 76, 78, 79, 80, 86, 89, 85, 87, 84, 81, 83, 0, 93, 123, 122, 121, 120, 119, 118, 117, 115, 114, 112, 92, 111, 107, 106, 105, 104, 103, 102, 101, 75, 98, 97, 110, 99, 62, 72, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 31, 17, 13, 12, 11, 10, 9, 7, 6, 5, 2, 1, 16, 74, 34, 37, 71, 70, 69, 68, 67, 66, 65, 64, 124, 59, 36, 56, 53, 52, 49, 48, 47, 45, 44, 42, 40, 39, 55, 125]
Per cls weights according to the accuracy are:  tensor([1.0736, 1.0736, 1.0736, 1.0822, 1.0919, 1.0736, 1.0736, 1.0736, 1.0919,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0822, 1.0822, 1.0736, 1.0919,
        1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0919, 1.0736, 1.0822, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0736,
        1.0919, 1.0736, 1.0736, 1.0822, 1.0919, 1.0736, 1.0822, 1.0822, 1.0736,
        1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0919, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0822, 1.0822, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0822, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0822,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9264, 0.9264, 0.9264, 0.9178, 0.9081, 0.9264, 0.9264, 0.9264, 0.9081,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9178, 0.9178, 0.9264, 0.9081,
        0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9081, 0.9264, 0.9178, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9264,
        0.9081, 0.9264, 0.9264, 0.9178, 0.9081, 0.9264, 0.9178, 0.9178, 0.9264,
        0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9081, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9178, 0.9178, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9178, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9178,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.243847 Loss T 0.051493 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1851, Accuracy: 1083/1134 F1 (95.5026%)


Test set: Average loss: 1.9439, Accuracy: 21027/31104 F1 (67.6022%)


Val set: Average loss: 2.1580, Accuracy: 222/360 F1 (61.6667%)

Patience getting saturated, current counter is:  0
best acc test 69.174383  acc val 61.666667 acc labeled target 95.502646
saving model...
S sketch T painting Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.125825 Loss T 0.046023 Method MME

S sketch T painting Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.192024 Loss T 0.044718 Method MME

S sketch T painting Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.038940 Loss T 0.071412 Method MME

S sketch T painting Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.138803 Loss T 0.055618 Method MME

S sketch T painting Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.357966 Loss T 0.049208 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1046, Accuracy: 1105/1134 F1 (97.4427%)


Test set: Average loss: 1.8899, Accuracy: 21729/31104 F1 (69.8592%)


Val set: Average loss: 1.9849, Accuracy: 243/360 F1 (67.5000%)

Patience Reset, Counter is: 1
best acc test 69.859182  acc val 67.500000 acc labeled target 97.442681
saving model...
S sketch T painting Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.459893 Loss T 0.045799 Method MME

S sketch T painting Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.173115 Loss T 0.055303 Method MME

S sketch T painting Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.268821 Loss T 0.035582 Method MME

S sketch T painting Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.085320 Loss T 0.053832 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        0.8888889 0.8888889 1.
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.8888889 1.        1.        0.7777778 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [43, 54, 108, 95, 36, 34, 89, 88, 86, 26, 25, 103, 82, 105, 50, 91, 51, 92, 111, 13, 79, 65, 77, 76, 74, 3, 90, 70, 71, 72, 81, 73, 85, 80, 75, 83, 78, 87, 84, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 110, 109, 107, 106, 104, 102, 101, 100, 99, 98, 97, 96, 69, 93, 68, 62, 66, 29, 28, 27, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 30, 67, 31, 33, 64, 63, 124, 61, 60, 59, 58, 57, 56, 55, 53, 52, 49, 48, 47, 46, 45, 44, 42, 41, 40, 39, 38, 37, 35, 32, 125]
Per cls weights according to the accuracy are:  tensor([1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736,
        1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0919, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0736,
        1.0919, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0822, 1.0736, 1.0822, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0822,
        1.0736, 1.0822, 1.0822, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736, 1.0736,
        1.0919, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264,
        0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9081, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9264,
        0.9081, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9178, 0.9264, 0.9178, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9178,
        0.9264, 0.9178, 0.9178, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264, 0.9264,
        0.9081, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.103556 Loss T 0.042837 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1926, Accuracy: 1086/1134 F1 (95.7672%)


Test set: Average loss: 1.9937, Accuracy: 21140/31104 F1 (67.9655%)


Val set: Average loss: 2.1761, Accuracy: 227/360 F1 (63.0556%)

Patience getting saturated, current counter is:  0
best acc test 69.859182  acc val 63.055556 acc labeled target 95.767196
saving model...
S sketch T painting Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.205403 Loss T 0.038220 Method MME

S sketch T painting Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.169121 Loss T 0.035956 Method MME

S sketch T painting Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.085620 Loss T 0.062996 Method MME

S sketch T painting Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.040480 Loss T 0.019244 Method MME

S sketch T painting Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.081709 Loss T 0.053022 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1391, Accuracy: 1097/1134 F1 (96.7372%)


Test set: Average loss: 1.9023, Accuracy: 21839/31104 F1 (70.2128%)


Val set: Average loss: 2.0968, Accuracy: 234/360 F1 (65.0000%)

Patience getting saturated, current counter is:  1
best acc test 69.859182  acc val 65.000000 acc labeled target 96.737213
saving model...
S sketch T painting Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.381663 Loss T 0.042445 Method MME

S sketch T painting Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.071871 Loss T 0.045232 Method MME

S sketch T painting Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.181793 Loss T 0.043604 Method MME

S sketch T painting Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.193687 Loss T 0.040988 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        0.6666667 1.        0.8888889
 1.        0.7777778 1.        1.        0.7777778 1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        0.7777778 1.        1.        1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 0.8888889
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 0.8888889 1.        0.8888889 1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [61, 25, 86, 29, 32, 118, 36, 62, 104, 27, 103, 42, 91, 90, 83, 59, 75, 93, 106, 99, 19, 5, 110, 9, 112, 14, 114, 3, 109, 85, 84, 121, 82, 81, 80, 77, 78, 87, 76, 122, 123, 74, 73, 72, 71, 79, 88, 119, 120, 108, 107, 105, 111, 113, 102, 101, 115, 89, 100, 98, 116, 97, 96, 95, 94, 117, 92, 70, 69, 0, 67, 33, 31, 30, 28, 26, 24, 23, 22, 21, 20, 18, 34, 17, 15, 13, 12, 11, 10, 8, 7, 6, 4, 2, 1, 16, 35, 37, 38, 66, 65, 64, 63, 124, 60, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 68, 125]
Per cls weights according to the accuracy are:  tensor([1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736,
        1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.1027, 1.0736,
        1.0822, 1.0736, 1.0919, 1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0736,
        1.0919, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.1027, 1.0822,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0736,
        1.0822, 1.0822, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0822, 1.0736,
        1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0919, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264,
        0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.8973, 0.9264,
        0.9178, 0.9264, 0.9081, 0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9264,
        0.9081, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.8973, 0.9178,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9264,
        0.9178, 0.9178, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9178, 0.9264,
        0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9081, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.036033 Loss T 0.043084 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1810, Accuracy: 1085/1134 F1 (95.6790%)


Test set: Average loss: 1.9622, Accuracy: 21386/31104 F1 (68.7564%)


Val set: Average loss: 2.2602, Accuracy: 220/360 F1 (61.1111%)

Patience getting saturated, current counter is:  2
best acc test 69.859182  acc val 61.111111 acc labeled target 95.679012
saving model...
S sketch T painting Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.083474 Loss T 0.049823 Method MME

S sketch T painting Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.152596 Loss T 0.034791 Method MME

S sketch T painting Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.086049 Loss T 0.064589 Method MME

S sketch T painting Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.050777 Loss T 0.030838 Method MME

S sketch T painting Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.275300 Loss T 0.043278 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1542, Accuracy: 1093/1134 F1 (96.3845%)


Test set: Average loss: 1.9461, Accuracy: 21879/31104 F1 (70.3414%)


Val set: Average loss: 1.9460, Accuracy: 236/360 F1 (65.5556%)

Patience getting saturated, current counter is:  3
best acc test 69.859182  acc val 65.555556 acc labeled target 96.384480
saving model...
S sketch T painting Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.111792 Loss T 0.046429 Method MME

S sketch T painting Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.177178 Loss T 0.017195 Method MME

S sketch T painting Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.067531 Loss T 0.043926 Method MME

S sketch T painting Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.224801 Loss T 0.046224 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889 1.        1.        1.        1.        0.7777778 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        0.8888889
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        0.8888889 1.        1.
 1.        0.8888889 1.        0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 0.7777778 1.        1.        0.8888889 1.        0.8888889 0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.8888889 0.8888889 1.        0.8888889 1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [77, 5, 0, 34, 97, 71, 37, 94, 41, 42, 43, 92, 91, 46, 50, 52, 86, 54, 55, 84, 83, 82, 60, 80, 66, 69, 70, 32, 31, 96, 112, 123, 114, 116, 24, 23, 22, 108, 19, 85, 115, 117, 118, 81, 99, 113, 78, 120, 121, 76, 75, 122, 119, 79, 87, 100, 101, 102, 98, 103, 104, 95, 93, 105, 106, 107, 109, 90, 89, 88, 110, 111, 74, 62, 72, 27, 26, 25, 21, 20, 18, 17, 16, 15, 14, 28, 13, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 12, 29, 30, 33, 68, 67, 65, 64, 63, 124, 61, 59, 58, 57, 56, 53, 51, 49, 48, 47, 45, 44, 40, 39, 38, 36, 35, 73, 125]
Per cls weights according to the accuracy are:  tensor([1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0822, 1.0822, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0736, 1.0822, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0822, 1.0822, 1.0736,
        1.0736, 1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736,
        1.0822, 1.0822, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736, 1.0822, 1.0822, 1.0822,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0919, 1.0736, 1.0736, 1.0822,
        1.0736, 1.0822, 1.0822, 1.0822, 1.0736, 1.0822, 1.0736, 1.0736, 1.0736,
        1.0736, 1.0822, 1.0822, 1.0736, 1.0822, 1.0736, 1.0822, 1.0822, 1.0736,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736,
        1.0822, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0822, 1.0736, 1.0822,
        1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0736, 1.0822, 1.0736, 1.0736])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Per cls weights according to the accuracy are:  tensor([0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9178, 0.9178, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9264, 0.9178, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9178, 0.9178, 0.9264,
        0.9264, 0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264,
        0.9178, 0.9178, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264, 0.9178, 0.9178, 0.9178,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9081, 0.9264, 0.9264, 0.9178,
        0.9264, 0.9178, 0.9178, 0.9178, 0.9264, 0.9178, 0.9264, 0.9264, 0.9264,
        0.9264, 0.9178, 0.9178, 0.9264, 0.9178, 0.9264, 0.9178, 0.9178, 0.9264,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264,
        0.9178, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9178, 0.9264, 0.9178,
        0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9264, 0.9178, 0.9264, 0.9264])
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S sketch T painting Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.049666 Loss T 0.044376 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.1858, Accuracy: 1081/1134 F1 (95.3263%)


Test set: Average loss: 1.9785, Accuracy: 21439/31104 F1 (68.9268%)


Val set: Average loss: 2.3026, Accuracy: 222/360 F1 (61.6667%)

Patience getting saturated, current counter is:  4
best acc test 69.859182  acc val 61.666667 acc labeled target 95.326279
saving model...
S sketch T painting Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.123800 Loss T 0.026638 Method MME

S sketch T painting Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.321263 Loss T 0.025186 Method MME

S sketch T painting Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.135219 Loss T 0.027263 Method MME

S sketch T painting Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.033820 Loss T 0.030146 Method MME

S sketch T painting Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.042027 Loss T 0.049428 Method MME

24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
24
tensor(1134.)

Labeled Target set: Average loss: 0.0930, Accuracy: 1108/1134 F1 (97.7072%)


Test set: Average loss: 1.8740, Accuracy: 22094/31104 F1 (71.0327%)


Val set: Average loss: 2.1364, Accuracy: 240/360 F1 (66.6667%)

Patience getting saturated, current counter is:  5
