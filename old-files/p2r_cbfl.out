Dataset multi Source painting Target real Labeled num perclass 3 Network resnet34
126 classes in this dataset
Unlabelled Target Dataset Size:  69980
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  69980 Source:  31502
Unlabeled Target Data Size: 1457
S painting T real Train Ep: 0 lr0.01 	 Loss Classification: 4.981334 Loss T 0.470722 Method MME

S painting T real Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 2.053492 Loss T 0.269516 Method MME

S painting T real Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 2.079221 Loss T 0.195687 Method MME

S painting T real Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 2.607080 Loss T 0.193292 Method MME

S painting T real Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 1.449074 Loss T 0.173228 Method MME

S painting T real Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 1.406410 Loss T 0.163866 Method MME


Labeled Target set: Average loss: 1.9815, Accuracy: 606/1080 F1 (56.1111%)


Test set: Average loss: 1.6431, Accuracy: 43095/69960 F1 (61.5995%)


Val set: Average loss: 1.7960, Accuracy: 214/360 F1 (59.4444%)

best acc test 61.599485  acc val 59.444444 acc labeled target 56.111111
saving model...
S painting T real Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 1.070155 Loss T 0.143299 Method MME

S painting T real Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 1.269010 Loss T 0.140091 Method MME

S painting T real Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.234066 Loss T 0.102950 Method MME

S painting T real Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 1.432914 Loss T 0.100749 Method MME

S painting T real Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 1.616262 Loss T 0.131703 Method MME


Labeled Target set: Average loss: 1.7924, Accuracy: 616/1080 F1 (57.0370%)


Test set: Average loss: 1.4684, Accuracy: 45886/69960 F1 (65.5889%)


Val set: Average loss: 1.5730, Accuracy: 231/360 F1 (64.1667%)

best acc test 65.588908  acc val 64.166667 acc labeled target 57.037037
saving model...
S painting T real Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 1.570498 Loss T 0.126390 Method MME

S painting T real Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.841509 Loss T 0.105968 Method MME

S painting T real Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 1.703897 Loss T 0.109441 Method MME

S painting T real Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.591026 Loss T 0.120930 Method MME

S painting T real Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.607985 Loss T 0.129130 Method MME


Labeled Target set: Average loss: 1.8997, Accuracy: 626/1080 F1 (57.9630%)


Test set: Average loss: 1.4139, Accuracy: 47505/69960 F1 (67.9031%)


Val set: Average loss: 1.5248, Accuracy: 229/360 F1 (63.6111%)

best acc test 65.588908  acc val 63.611111 acc labeled target 57.962963
saving model...
S painting T real Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 1.426234 Loss T 0.082676 Method MME

S painting T real Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.360543 Loss T 0.111162 Method MME

S painting T real Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 1.058289 Loss T 0.094556 Method MME

S painting T real Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.973121 Loss T 0.083608 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.6666667  1.         0.11111111 0.6666667  0.
 0.6666667  0.         0.6666667  0.5        0.8888889  0.6666667
 0.         0.         0.6666667  0.6666667  0.22222222 1.
 0.11111111 0.6666667  0.11111111 0.6666667  1.         0.33333334
 0.         0.7777778  0.5555556  0.6666667  0.8888889  0.8888889
 1.         0.         0.44444445 0.22222222 0.44444445 1.
 0.         0.5555556  0.33333334 1.         0.6666667  1.
 0.         0.5555556  1.         0.7777778  0.8888889  0.7777778
 0.         0.8888889  0.         0.33333334 0.6666667  0.8888889
 0.         0.44444445 0.8888889  1.         0.7777778  0.5
 0.7777778  0.33333334 1.         0.         1.         1.
 0.         1.         0.8333333  1.         1.         0.44444445
 0.7777778  0.6666667  0.11111111 0.5555556  0.6666667  0.33333334
 0.         1.         0.         0.7777778  0.11111111 0.
 0.         1.         1.         0.33333334 0.         0.44444445
 0.         1.         0.6666667  0.8333333  0.8888889  0.7777778
 0.11111111 1.         0.11111111 0.6666667  0.8888889  0.6666667
 0.7777778  0.44444445 0.         0.6666667  0.7777778  0.8888889
 0.         0.5        0.6666667  0.33333334 1.         0.8888889
 0.33333334 1.         0.44444445 1.         0.         1.
 0.5555556  0.8888889  0.5555556  0.7777778  0.5555556  1.        ]
Top k classes which perform poorly are:  [104, 63, 66, 54, 50, 48, 42, 118, 36, 78, 80, 83, 24, 84, 108, 31, 7, 5, 13, 12, 90, 88, 3, 18, 98, 20, 74, 82, 96, 33, 16, 61, 114, 111, 51, 87, 77, 38, 23, 32, 55, 116, 103, 34, 89, 71, 9, 59, 109, 122, 26, 120, 75, 43, 37, 124, 73, 110, 105, 99, 76, 92, 101, 52, 40, 15, 19, 21, 27, 14, 8, 11, 4, 1, 6, 72, 102, 106, 60, 25, 81, 123, 95, 45, 47, 58, 93, 68, 94, 100, 10, 121, 28, 29, 46, 49, 53, 56, 113, 107, 119, 117, 112, 115, 0, 62, 91, 2, 17, 22, 30, 35, 39, 41, 44, 57, 64, 65, 67, 69, 70, 79, 85, 86, 97, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [124 175 128   8 262  10 191 112  24 369 179 200   3 127 128 174 405 459
  48 154   3 150 270 237  18 396 233 409 513  24 203  20  28  22  97  82
   3 144 175 109 448 547 235  48 489 243 326 547   8 220   8 174 258 131
  11   9 459 229  44 210 423   5 407   4 388 216  25 495 184 341 284 248
 135 347  14  29 914 261 203 323   4 182  13   6 382 227 204 261  21 154
   9 304 414 362 285 387  13 442  41 419 327   9 227 192 267 464 309 168
  15 338 220   4 437 298  14 373 169 496   3 443 147 204  40 312 127 534]
CBFL per class weights: tensor([0.3273, 0.2817, 0.3222, 3.0182, 0.2512, 2.4386, 0.2732, 0.3452, 1.0880,
        0.2390, 0.2794, 0.2692, 7.8507, 0.3234, 0.3222, 0.2823, 0.2372, 0.2355,
        0.6093, 0.2962, 7.8507, 0.2995, 0.2497, 0.2569, 1.4090, 0.2376, 0.2580,
        0.2371, 0.2345, 1.0880, 0.2680, 1.2805, 0.9506, 1.1754, 0.3744, 0.4154,
        7.8507, 0.3049, 0.2817, 0.3503, 0.2358, 0.2341, 0.2574, 0.6093, 0.2349,
        0.2554, 0.2423, 0.2341, 3.0182, 0.2619, 3.0182, 0.2823, 0.2520, 0.3186,
        2.2279, 2.6962, 0.2355, 0.2591, 0.6524, 0.2653, 0.2365, 4.7577, 0.2371,
        5.9175, 0.2380, 0.2632, 1.0495, 0.2348, 0.2767, 0.2410, 0.2474, 0.2542,
        0.3140, 0.2405, 1.7765, 0.9223, 0.2332, 0.2514, 0.2680, 0.2426, 5.9175,
        0.2778, 1.9038, 3.9845, 0.2383, 0.2597, 0.2676, 0.2514, 1.2255, 0.2962,
        2.6962, 0.2447, 0.2369, 0.2395, 0.2473, 0.2380, 1.9038, 0.2359, 0.6904,
        0.2367, 0.2422, 2.6962, 0.2597, 0.2728, 0.2503, 0.2354, 0.2441, 0.2860,
        1.6662, 0.2412, 0.2619, 5.9175, 0.2361, 0.2455, 1.7765, 0.2388, 0.2854,
        0.2348, 7.8507, 0.2359, 0.3021, 0.2676, 0.7044, 0.2438, 0.3234, 0.2343],
       device='cuda:0')
S painting T real Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.276379 Loss T 0.066281 Method MME


Labeled Target set: Average loss: 2.0368, Accuracy: 630/1080 F1 (58.3333%)


Test set: Average loss: 1.7180, Accuracy: 44038/69960 F1 (62.9474%)


Val set: Average loss: 1.9465, Accuracy: 221/360 F1 (61.3889%)

best acc test 65.588908  acc val 61.388889 acc labeled target 58.333333
saving model...
S painting T real Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.809254 Loss T 0.077996 Method MME

S painting T real Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 1.134741 Loss T 0.134130 Method MME

S painting T real Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 1.179729 Loss T 0.104001 Method MME

S painting T real Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 1.271719 Loss T 0.120240 Method MME

S painting T real Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 1.414818 Loss T 0.168082 Method MME


Labeled Target set: Average loss: 2.4523, Accuracy: 478/1080 F1 (44.2593%)


Test set: Average loss: 2.1131, Accuracy: 36535/69960 F1 (52.2227%)


Val set: Average loss: 2.2137, Accuracy: 176/360 F1 (48.8889%)

best acc test 65.588908  acc val 48.888889 acc labeled target 44.259259
saving model...
S painting T real Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 3.458275 Loss T 0.154110 Method MME

S painting T real Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 1.666345 Loss T 0.018377 Method MME

S painting T real Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 3.063505 Loss T 0.021016 Method MME

S painting T real Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 2.080420 Loss T 0.041208 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.         0.5555556  1.         0.         0.44444445
 0.         0.         0.         0.6666667  0.11111111 0.6666667
 0.         0.5        0.33333334 0.         0.22222222 1.
 0.16666667 0.22222222 0.         0.6666667  1.         0.33333334
 0.         0.33333334 0.6666667  0.5        0.33333334 0.7777778
 0.22222222 0.5555556  0.         0.33333334 0.33333334 0.8888889
 0.         0.5        0.33333334 1.         0.6666667  1.
 0.44444445 0.5555556  0.6666667  1.         0.         0.6666667
 0.44444445 1.         0.33333334 0.22222222 0.33333334 0.44444445
 0.22222222 1.         0.33333334 0.7777778  0.         1.
 0.7777778  0.         0.         0.         0.8888889  0.22222222
 0.         0.22222222 0.6666667  1.         0.44444445 0.22222222
 0.         0.33333334 0.6666667  1.         0.5555556  0.33333334
 0.         1.         0.11111111 0.6666667  0.5555556  0.
 0.         0.8888889  0.11111111 0.33333334 0.         0.6666667
 0.22222222 0.44444445 0.6666667  0.6666667  0.33333334 0.5
 0.11111111 0.6666667  0.33333334 0.7777778  0.33333334 0.6666667
 0.7777778  0.33333334 0.11111111 0.6666667  0.6666667  0.5
 0.44444445 0.44444445 0.7777778  0.16666667 1.         0.8888889
 0.         0.8888889  0.11111111 0.6666667  0.22222222 0.7777778
 0.         0.11111111 0.33333334 0.22222222 0.7777778  0.6666667 ]
Top k classes which perform poorly are:  [62, 32, 36, 114, 63, 72, 24, 61, 78, 58, 20, 46, 15, 120, 6, 1, 88, 4, 84, 7, 8, 66, 12, 83, 10, 86, 80, 96, 116, 121, 104, 18, 111, 54, 65, 51, 30, 71, 118, 19, 16, 90, 123, 67, 94, 52, 77, 98, 100, 56, 73, 87, 103, 14, 25, 28, 50, 33, 34, 38, 23, 122, 108, 109, 91, 42, 5, 70, 48, 53, 107, 37, 13, 27, 95, 2, 82, 43, 31, 76, 117, 92, 89, 97, 106, 105, 101, 93, 125, 81, 9, 74, 11, 68, 26, 40, 44, 47, 21, 110, 102, 119, 57, 99, 60, 124, 29, 85, 64, 35, 115, 113, 17, 22, 3, 41, 39, 45, 49, 55, 59, 69, 75, 79, 112, 0]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 123  150  121   58  252   56  185  102   24  321  177  183 4314  116
  133  161  337  396   48  139 1646  149  231  195   19  344  205  345
  433   33  189   29   26   25   89   78 3993  133  162  103  381  469
  213   55  430  227  277  501  204  201   84  155  219  124   39   29
  402  189   43  183  375  587  360   31  327  184   34  416  173  298
  243  217  122  316   57   43  790  247  187  279  272  168   39  109
  347  210  180  227   26  138   14  263  355  307  241  347   36  381
   41  368  291   27  219  178  242  423  275  152   32  295  207 1976
  352  271   19  319  160  429  111  396  132  188   56  283  125  445]
CBFL per class weights: tensor([0.8365, 0.7623, 0.8435, 1.3435, 0.6447, 1.3789, 0.7030, 0.9255, 2.7691,
        0.6180, 0.7140, 0.7056, 0.5935, 0.8622, 0.8050, 0.7403, 0.6143, 0.6048,
        1.5507, 0.7885, 0.5935, 0.7645, 0.6580, 0.6908, 3.4141, 0.6128, 0.6801,
        0.6126, 0.6012, 2.1025, 0.6979, 2.3474, 2.5809, 2.6712, 1.0039, 1.0922,
        0.5935, 0.8050, 0.7384, 0.9204, 0.6067, 0.5989, 0.6726, 1.3976, 0.6015,
        0.6610, 0.6326, 0.5974, 0.6811, 0.6842, 1.0410, 0.7518, 0.6674, 0.8331,
        1.8302, 2.3474, 0.6041, 0.6979, 1.6913, 0.7056, 0.6075, 0.5951, 0.6098,
        2.2170, 0.6165, 0.7043, 2.0504, 0.6027, 0.7200, 0.6247, 0.6500, 0.6690,
        0.8399, 0.6193, 1.3609, 1.6913, 0.5937, 0.6476, 0.7004, 0.6317, 0.6347,
        0.7280, 1.8302, 0.8916, 0.6122, 0.6753, 0.7097, 0.6610, 2.5809, 0.7911,
        4.5217, 0.6389, 0.6107, 0.6219, 0.6513, 0.6122, 1.9549, 0.6067, 1.7573,
        0.6086, 0.6272, 2.4972, 0.6674, 0.7126, 0.6506, 0.6021, 0.6334, 0.7580,
        2.1580, 0.6258, 0.6782, 0.5935, 0.6113, 0.6352, 3.4141, 0.6185, 0.7421,
        0.6016, 0.8828, 0.6048, 0.8079, 0.6992, 1.3789, 0.6301, 0.8297, 0.6003],
       device='cuda:0')
S painting T real Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 1.212461 Loss T 0.121623 Method MME


Labeled Target set: Average loss: 3.5275, Accuracy: 302/1080 F1 (27.9630%)


Test set: Average loss: 3.2613, Accuracy: 21762/69960 F1 (31.1063%)


Val set: Average loss: 3.4315, Accuracy: 106/360 F1 (29.4444%)

best acc test 65.588908  acc val 29.444444 acc labeled target 27.962963
saving model...
S painting T real Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.885642 Loss T 0.102637 Method MME

S painting T real Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.741490 Loss T 0.113706 Method MME

S painting T real Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.565161 Loss T 0.101654 Method MME

S painting T real Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 1.323844 Loss T 0.114161 Method MME

S painting T real Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.604472 Loss T 0.092772 Method MME


Labeled Target set: Average loss: 2.0304, Accuracy: 624/1080 F1 (57.7778%)


Test set: Average loss: 1.6501, Accuracy: 45503/69960 F1 (65.0415%)


Val set: Average loss: 1.7810, Accuracy: 233/360 F1 (64.7222%)

best acc test 65.041452  acc val 64.722222 acc labeled target 57.777778
saving model...
S painting T real Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 1.845880 Loss T 0.106764 Method MME

S painting T real Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 1.331108 Loss T 0.099762 Method MME

S painting T real Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.341376 Loss T 0.096570 Method MME

S painting T real Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.484756 Loss T 0.090173 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.33333334 0.6666667  1.         0.         0.7777778
 0.22222222 0.33333334 0.         0.6666667  0.6666667  0.6666667
 0.         0.33333334 0.6666667  0.11111111 0.5555556  1.
 0.         1.         0.         0.33333334 0.         0.5
 0.6666667  1.         0.33333334 0.6666667  0.6666667  1.
 0.5555556  0.5555556  1.         0.11111111 0.5555556  0.6666667
 0.         1.         0.33333334 1.         0.5        1.
 0.16666667 1.         0.8888889  1.         0.6666667  0.8333333
 0.         1.         0.6666667  0.6666667  0.44444445 0.33333334
 0.         0.7777778  0.6666667  0.7777778  0.6666667  0.6666667
 0.8888889  0.         1.         1.         1.         1.
 0.         0.5        1.         0.8888889  1.         0.
 0.44444445 0.44444445 0.6666667  0.8333333  0.11111111 0.33333334
 0.         1.         0.         1.         0.8888889  0.
 0.         1.         0.33333334 0.33333334 0.16666667 0.33333334
 0.11111111 1.         0.6666667  0.7777778  0.6666667  0.6666667
 0.44444445 0.6666667  0.6666667  0.7777778  0.6666667  0.6666667
 0.44444445 0.44444445 0.11111111 1.         0.6666667  0.44444445
 0.44444445 0.5555556  0.6666667  0.         1.         1.
 0.5        0.8888889  0.7777778  0.8888889  0.         1.
 0.22222222 0.7777778  0.6666667  0.22222222 0.7777778  1.        ]
Top k classes which perform poorly are:  [111, 83, 78, 84, 36, 118, 48, 22, 20, 18, 54, 12, 80, 4, 66, 61, 71, 8, 15, 33, 104, 90, 76, 88, 42, 120, 123, 6, 77, 38, 1, 86, 13, 89, 26, 7, 53, 87, 21, 73, 52, 108, 107, 72, 102, 96, 103, 40, 67, 114, 23, 16, 31, 30, 109, 34, 92, 94, 95, 97, 98, 100, 74, 106, 51, 46, 11, 10, 9, 24, 35, 14, 101, 50, 56, 28, 27, 58, 59, 2, 122, 110, 93, 116, 124, 5, 55, 57, 99, 121, 75, 47, 115, 117, 82, 44, 69, 60, 105, 113, 112, 119, 0, 62, 85, 3, 17, 19, 25, 29, 32, 37, 39, 41, 43, 45, 49, 63, 64, 65, 68, 70, 79, 81, 91, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 174  175  145   99  209   68  192  109  123  386  200  239 3304  172
  184  175  307  431  100  190 1293  186  212  194  451  369  219  363
  505   82  206  346  219   49  134  118 3030  176  193  155  411  533
  250  115  456  251  274  552  189  226  114  202  257  139  190   84
  469  248  167  210  398  584  405  151  352  250   79  329  208  336
  249  242  131  368  117  126  695  253  206  319  227  182   59  101
  401  259  178  265  292  153 2067  300  409  398  240  370  291  435
   78  442  279  110  273  200  280  481  288  160  703  316  249 1751
  404  310 1265  368  198  446   93  396  135  200   72  308  172  450]
CBFL per class weights: tensor([1.0135, 1.0114, 1.0913, 1.3282, 0.9539, 1.6908, 0.9793, 1.2577, 1.1799,
        0.8548, 0.9667, 0.9205, 0.8371, 1.0178, 0.9935, 1.0114, 0.8772, 0.8483,
        1.3205, 0.9827, 0.8372, 0.9898, 0.9500, 0.9760, 0.8462, 0.8582, 0.9413,
        0.8595, 0.8424, 1.4912, 0.9580, 0.8638, 0.9413, 2.1527, 1.1314, 1.2053,
        0.8371, 1.0093, 0.9777, 1.0605, 0.8508, 0.8411, 0.9110, 1.2218, 0.8458,
        0.9102, 0.8941, 0.8404, 0.9845, 0.9335, 1.2275, 0.9637, 0.9056, 1.1123,
        0.9827, 1.4684, 0.8447, 0.9126, 1.0293, 0.9526, 0.8528, 0.8395, 0.8517,
        1.0722, 0.8622, 0.9110, 1.5278, 0.8690, 0.9552, 0.8668, 0.9118, 0.9178,
        1.1437, 0.8584, 1.2107, 1.1657, 0.8379, 0.9086, 0.9580, 0.8725, 0.9324,
        0.9973, 1.8715, 1.3129, 0.8523, 0.9041, 1.0051, 0.8999, 0.8841, 1.0663,
        0.8371, 0.8803, 0.8511, 0.8528, 0.9196, 0.8580, 0.8846, 0.8479, 1.5406,
        0.8471, 0.8911, 1.2514, 0.8947, 0.9667, 0.8905, 0.8439, 0.8862, 1.0468,
        0.8379, 0.8736, 0.9118, 0.8371, 0.8518, 0.8760, 0.8372, 0.8584, 0.9697,
        0.8467, 1.3785, 0.8531, 1.1274, 0.9667, 1.6255, 0.8768, 1.0178, 0.8463],
       device='cuda:0')
S painting T real Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.644747 Loss T 0.092748 Method MME


Labeled Target set: Average loss: 2.1758, Accuracy: 613/1080 F1 (56.7593%)


Test set: Average loss: 1.9724, Accuracy: 41990/69960 F1 (60.0200%)


Val set: Average loss: 2.2343, Accuracy: 201/360 F1 (55.8333%)

best acc test 65.041452  acc val 55.833333 acc labeled target 56.759259
saving model...
S painting T real Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 1.086872 Loss T 0.085646 Method MME

S painting T real Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 1.814531 Loss T 0.086644 Method MME

S painting T real Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.893719 Loss T 0.081065 Method MME

S painting T real Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 0.931581 Loss T 0.069177 Method MME

S painting T real Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.753271 Loss T 0.079776 Method MME


Labeled Target set: Average loss: 1.6359, Accuracy: 686/1080 F1 (63.5185%)


Test set: Average loss: 1.3146, Accuracy: 49734/69960 F1 (71.0892%)


Val set: Average loss: 1.4433, Accuracy: 241/360 F1 (66.9444%)

best acc test 71.089194  acc val 66.944444 acc labeled target 63.518519
saving model...
S painting T real Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.902556 Loss T 0.070110 Method MME

S painting T real Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 1.185403 Loss T 0.068760 Method MME

S painting T real Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 1.236733 Loss T 0.078655 Method MME

S painting T real Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 1.046633 Loss T 0.063965 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.22222222 0.7777778  0.8888889  0.         1.
 0.8888889  0.8888889  0.6666667  0.5        0.6666667  0.6666667
 0.         0.5        0.6666667  0.         0.6666667  1.
 0.22222222 1.         0.         0.5555556  1.         0.33333334
 0.         1.         0.6666667  0.6666667  0.8888889  1.
 0.7777778  0.44444445 1.         0.6666667  0.33333334 0.6666667
 0.         1.         0.33333334 1.         0.6666667  1.
 0.44444445 0.6666667  1.         1.         0.7777778  0.8888889
 0.6666667  1.         0.6666667  0.6666667  0.33333334 0.7777778
 0.16666667 1.         0.6666667  1.         0.7777778  0.33333334
 1.         0.         1.         0.44444445 1.         0.5555556
 0.         1.         0.7777778  1.         0.8888889  0.5
 0.5555556  0.33333334 0.44444445 1.         0.6666667  0.44444445
 0.         1.         0.         1.         0.8888889  0.
 0.         1.         0.8888889  0.33333334 0.33333334 0.33333334
 0.22222222 1.         0.6666667  0.6666667  0.7777778  1.
 0.16666667 1.         0.6666667  0.7777778  0.5        0.5
 1.         0.22222222 0.33333334 0.7777778  0.5        0.6666667
 0.         0.6666667  0.6666667  0.         1.         1.
 0.33333334 1.         0.7777778  1.         0.         1.
 0.6666667  1.         0.6666667  1.         0.5555556  1.        ]
Top k classes which perform poorly are:  [66, 24, 78, 36, 20, 80, 83, 15, 84, 12, 118, 61, 108, 4, 111, 96, 54, 90, 18, 103, 1, 38, 73, 59, 52, 34, 114, 104, 87, 89, 88, 23, 63, 42, 74, 77, 31, 106, 100, 13, 101, 9, 71, 124, 65, 21, 72, 110, 107, 76, 92, 109, 56, 93, 48, 98, 51, 8, 10, 11, 14, 16, 122, 120, 27, 33, 35, 26, 50, 43, 40, 68, 116, 58, 53, 30, 2, 94, 99, 105, 46, 86, 6, 7, 3, 82, 28, 70, 47, 112, 102, 113, 121, 119, 123, 117, 115, 0, 62, 95, 5, 17, 19, 22, 25, 29, 32, 37, 39, 41, 44, 97, 45, 55, 57, 60, 64, 67, 69, 75, 79, 81, 85, 91, 49, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 240  214  202  171  206  293  230  214  254  431  264  296 2374  227
  237  209  431  484  165  274  964  247  283  280  387  440  284  460
  584  113  271  643  361  138  196  146 2229  267  231  240  475  588
  335  161  566  301  355  618  326  297  326  240  300  168  239  158
  530  346  262  293  473  475  524  257  413  341  100  428  241  375
  311  307  201  429  192  150  760  293  249  360  188  221  746   89
  482  305  290  306  307  196 1689  364  471  502  302  410  263  489
  115  520  357  179  330  282  343  546  323  216  549  363  284 1379
  473  368 1100  396  280  492  112  462  241  230  170  366  239  523]
CBFL per class weights: tensor([1.0109, 1.0416, 1.0595, 1.1214, 1.0532, 0.9714, 1.0216, 1.0416, 0.9980,
        0.9326, 0.9900, 0.9698, 0.9203, 1.0250, 1.0140, 1.0487, 0.9326, 0.9275,
        1.1369, 0.9829, 0.9204, 1.0042, 0.9772, 0.9790, 0.9396, 0.9315, 0.9766,
        0.9295, 0.9229, 1.3558, 0.9850, 0.9218, 0.9454, 1.2268, 1.0695, 1.1961,
        0.9203, 0.9878, 1.0205, 1.0109, 0.9282, 0.9228, 0.9532, 1.1479, 0.9235,
        0.9673, 0.9471, 0.9222, 0.9564, 0.9693, 0.9564, 1.0109, 0.9678, 1.1290,
        1.0119, 1.1567, 0.9248, 0.9497, 0.9916, 0.9714, 0.9283, 0.9282, 0.9251,
        0.9955, 0.9351, 0.9512, 1.4517, 0.9330, 1.0099, 0.9421, 0.9626, 0.9644,
        1.0611, 0.9328, 1.0767, 1.1821, 0.9208, 0.9714, 1.0024, 0.9457, 1.0842,
        1.0323, 0.9208, 1.5568, 0.9276, 0.9654, 0.9731, 0.9649, 0.9644, 1.0695,
        0.9203, 0.9447, 0.9285, 0.9263, 0.9668, 0.9355, 0.9908, 0.9271, 1.3432,
        0.9253, 0.9465, 1.1028, 0.9550, 0.9778, 0.9506, 0.9242, 0.9576, 1.0388,
        0.9240, 0.9449, 0.9766, 0.9203, 0.9283, 0.9437, 0.9203, 0.9379, 0.9790,
        0.9269, 1.3623, 0.9293, 1.0099, 1.0216, 1.1239, 0.9442, 1.0119, 0.9252],
       device='cuda:0')
S painting T real Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.821373 Loss T 0.095396 Method MME


Labeled Target set: Average loss: 2.1155, Accuracy: 643/1080 F1 (59.5370%)


Test set: Average loss: 1.7950, Accuracy: 44671/69960 F1 (63.8522%)


Val set: Average loss: 1.9998, Accuracy: 221/360 F1 (61.3889%)

best acc test 71.089194  acc val 61.388889 acc labeled target 59.537037
saving model...
S painting T real Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.636551 Loss T 0.078788 Method MME

S painting T real Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.367929 Loss T 0.068439 Method MME

S painting T real Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.491888 Loss T 0.083052 Method MME

S painting T real Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.767435 Loss T 0.091364 Method MME

S painting T real Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 1.035604 Loss T 0.086390 Method MME


Labeled Target set: Average loss: 1.6129, Accuracy: 704/1080 F1 (65.1852%)


Test set: Average loss: 1.2621, Accuracy: 50489/69960 F1 (72.1684%)


Val set: Average loss: 1.4036, Accuracy: 254/360 F1 (70.5556%)

best acc test 72.168382  acc val 70.555556 acc labeled target 65.185185
saving model...
S painting T real Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.374392 Loss T 0.062625 Method MME

S painting T real Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.469441 Loss T 0.065688 Method MME

S painting T real Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.938920 Loss T 0.077142 Method MME

S painting T real Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.409070 Loss T 0.062699 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.11111111 0.8888889  1.         0.11111111 1.
 0.44444445 0.5555556  0.6666667  0.7777778  0.7777778  0.6666667
 0.         0.22222222 0.6666667  0.33333334 0.5555556  1.
 0.11111111 0.7777778  0.11111111 0.44444445 1.         0.22222222
 0.22222222 0.7777778  0.6666667  0.6666667  0.6666667  1.
 0.5555556  0.5555556  1.         0.6666667  0.33333334 0.6666667
 0.         1.         0.33333334 1.         0.6666667  0.8888889
 0.44444445 0.8333333  0.8888889  1.         0.8888889  1.
 0.8888889  1.         0.6666667  0.5555556  0.33333334 0.7777778
 0.11111111 1.         0.6666667  1.         1.         0.6666667
 1.         0.         1.         0.7777778  1.         0.8888889
 0.         1.         0.7777778  0.7777778  1.         0.33333334
 0.5555556  0.33333334 0.8888889  1.         0.6666667  0.33333334
 0.         0.8888889  0.33333334 0.6666667  1.         0.
 0.         1.         1.         0.33333334 0.11111111 0.5555556
 1.         0.7777778  0.5        0.7777778  0.6666667  1.
 0.33333334 1.         1.         0.8888889  1.         0.6666667
 1.         0.16666667 0.22222222 0.8888889  0.6666667  0.7777778
 0.         0.6666667  0.8888889  0.         0.8888889  0.5
 0.6666667  1.         1.         1.         0.         1.
 0.5555556  0.7777778  0.5        0.22222222 0.6666667  1.        ]
Top k classes which perform poorly are:  [118, 84, 83, 66, 36, 78, 108, 111, 12, 61, 20, 18, 54, 88, 4, 1, 103, 13, 104, 23, 24, 123, 87, 38, 52, 96, 34, 71, 80, 73, 77, 15, 6, 21, 42, 122, 113, 92, 30, 7, 89, 51, 72, 16, 120, 31, 124, 59, 56, 106, 109, 33, 114, 101, 40, 35, 28, 27, 26, 81, 14, 11, 76, 8, 94, 50, 69, 68, 91, 63, 53, 93, 25, 19, 121, 10, 9, 107, 43, 48, 99, 105, 2, 41, 79, 46, 44, 112, 110, 65, 74, 115, 116, 117, 119, 100, 102, 0, 62, 97, 3, 5, 17, 22, 29, 32, 37, 39, 45, 47, 49, 98, 55, 58, 60, 64, 67, 70, 75, 82, 85, 86, 90, 95, 57, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 292  238  256  223  259  380  258  279  342  466  312  339 1783  262
  303  260  519  539  216  348  688  303  339  316  277  509  327  534
  640  147  330  785  457  191  257  173 1622  313  288  328  530  646
  411  200  665  335  442  669  535  331  496  268  341  214  214  205
  579  419  330  393  530  299  637  326  479  412  115  540  285  411
  372  356  300  490  263  177  844  357  279  390  159  252 1011   79
  524  349  416  340  305  255 1202  429  520  570  372  448  271  537
  171  589  461  202  390  364  391  591  363  286  459  422  316  983
  528  400  831  439  371  530  242  514  361  263  248  401  305  591]
CBFL per class weights: tensor([1.0014, 1.0436, 1.0265, 1.0610, 1.0240, 0.9694, 1.0248, 1.0093, 0.9796,
        0.9570, 0.9912, 0.9806, 0.9481, 1.0215, 0.9955, 1.0231, 0.9533, 0.9524,
        1.0702, 0.9777, 0.9491, 0.9955, 0.9806, 0.9895, 1.0106, 0.9539, 0.9850,
        0.9526, 0.9497, 1.2285, 0.9838, 0.9485, 0.9578, 1.1111, 1.0256, 1.1503,
        0.9481, 0.9908, 1.0037, 0.9846, 0.9528, 0.9496, 0.9636, 1.0948, 0.9493,
        0.9820, 0.9594, 0.9493, 0.9525, 0.9835, 0.9547, 1.0169, 0.9800, 1.0730,
        1.0730, 1.0866, 0.9510, 0.9624, 0.9838, 0.9668, 0.9528, 0.9976, 0.9497,
        0.9854, 0.9559, 0.9635, 1.3838, 0.9523, 1.0055, 0.9636, 0.9712, 0.9754,
        0.9970, 0.9551, 1.0207, 1.1407, 0.9483, 0.9751, 1.0093, 0.9673, 1.1886,
        1.0300, 0.9482, 1.7303, 0.9531, 0.9774, 0.9629, 0.9803, 0.9945, 1.0273,
        0.9481, 0.9610, 0.9533, 0.9512, 0.9712, 0.9588, 1.0147, 0.9525, 1.1553,
        0.9507, 0.9575, 1.0915, 0.9673, 0.9732, 0.9671, 0.9506, 0.9735, 1.0049,
        0.9576, 0.9620, 0.9895, 0.9482, 0.9529, 0.9655, 0.9484, 0.9598, 0.9715,
        0.9528, 1.0395, 0.9536, 0.9740, 1.0207, 1.0336, 0.9653, 0.9945, 0.9506],
       device='cuda:0')
S painting T real Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.534151 Loss T 0.067839 Method MME


Labeled Target set: Average loss: 1.8079, Accuracy: 682/1080 F1 (63.1481%)


Test set: Average loss: 1.4950, Accuracy: 47666/69960 F1 (68.1332%)


Val set: Average loss: 1.6495, Accuracy: 233/360 F1 (64.7222%)

best acc test 72.168382  acc val 64.722222 acc labeled target 63.148148
saving model...
S painting T real Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.127776 Loss T 0.083772 Method MME

S painting T real Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.371585 Loss T 0.082062 Method MME

S painting T real Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.388202 Loss T 0.091684 Method MME

S painting T real Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.590432 Loss T 0.063291 Method MME

S painting T real Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.875474 Loss T 0.070572 Method MME


Labeled Target set: Average loss: 1.5880, Accuracy: 722/1080 F1 (66.8519%)


Test set: Average loss: 1.2550, Accuracy: 51155/69960 F1 (73.1204%)


Val set: Average loss: 1.4804, Accuracy: 245/360 F1 (68.0556%)

best acc test 72.168382  acc val 68.055556 acc labeled target 66.851852
saving model...
S painting T real Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.212553 Loss T 0.069712 Method MME

S painting T real Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.433131 Loss T 0.057238 Method MME

S painting T real Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.369540 Loss T 0.084501 Method MME

S painting T real Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.555433 Loss T 0.050972 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.         0.6666667  0.6666667  1.         0.         1.
 0.8888889  1.         0.8888889  0.7777778  0.8888889  0.6666667
 0.         0.33333334 0.6666667  0.33333334 0.33333334 0.8888889
 0.6666667  1.         0.11111111 0.33333334 1.         0.33333334
 0.11111111 0.6666667  0.6666667  0.6666667  0.7777778  1.
 0.6666667  0.44444445 1.         0.33333334 0.33333334 0.6666667
 0.         0.7777778  0.         1.         0.6666667  0.8888889
 0.33333334 0.6666667  1.         0.8888889  0.7777778  1.
 0.7777778  1.         0.7777778  0.5        0.33333334 0.44444445
 0.11111111 1.         0.7777778  1.         0.5        0.8888889
 1.         0.         1.         0.8888889  1.         1.
 0.         1.         0.8888889  1.         1.         0.44444445
 0.5555556  0.44444445 0.6666667  0.8888889  0.6666667  0.44444445
 0.         1.         0.11111111 0.6666667  0.5555556  0.
 0.22222222 1.         1.         0.33333334 0.         0.5555556
 0.11111111 0.7777778  0.6666667  0.8888889  0.8888889  1.
 0.6666667  0.8888889  0.5555556  0.6666667  1.         0.6666667
 1.         0.33333334 0.33333334 1.         0.8888889  1.
 0.6666667  0.6666667  0.7777778  0.         1.         1.
 0.33333334 1.         0.6666667  1.         0.22222222 1.
 0.6666667  1.         0.5555556  0.6666667  0.8888889  1.        ]
Top k classes which perform poorly are:  [88, 66, 61, 4, 78, 36, 83, 12, 111, 38, 80, 24, 54, 90, 20, 84, 118, 42, 52, 34, 33, 23, 114, 15, 21, 87, 103, 16, 13, 104, 71, 53, 31, 77, 73, 51, 58, 122, 82, 98, 72, 89, 109, 108, 76, 74, 92, 81, 99, 14, 30, 101, 11, 35, 26, 25, 116, 96, 123, 40, 2, 43, 1, 18, 120, 27, 48, 91, 46, 28, 110, 37, 56, 50, 9, 97, 6, 10, 8, 106, 75, 68, 63, 124, 59, 93, 41, 45, 17, 94, 0, 105, 107, 112, 115, 117, 119, 121, 102, 113, 62, 95, 3, 5, 7, 19, 22, 29, 32, 39, 44, 47, 100, 49, 57, 60, 64, 65, 67, 69, 70, 79, 85, 86, 55, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 331  249  287  250  314  396  273  319  377  497  336  369 1478  287
  336  310  587  563  238  455  544  330  370  326  262  554  351  556
  666  155  357  902  507  203  284  186 1345  353  312  405  562  696
  467  226  691  361  487  701  585  338  553  284  347  250  287  218
  600  458  375  482  552  249  690  379  508  439  134  600  307  437
  406  391  363  527  320  184  908  399  297  403  141  270 1140  101
  538  381  461  349  309  272 1043  471  541  587  416  463  335  556
  190  620  508  248  422  404  421  614  378  350  400  448  339  807
  541  442  752  456  412  540  224  561  390  286  284  424  385  603]
CBFL per class weights: tensor([0.9948, 1.0447, 1.0159, 1.0437, 1.0018, 0.9774, 1.0251, 0.9996, 0.9813,
        0.9657, 0.9930, 0.9832, 0.9591, 1.0159, 0.9930, 1.0036, 0.9618, 0.9625,
        1.0557, 0.9691, 0.9632, 0.9952, 0.9830, 0.9968, 1.0334, 0.9628, 0.9881,
        0.9627, 0.9603, 1.2150, 0.9864, 0.9592, 0.9650, 1.1024, 1.0177, 1.1340,
        0.9591, 0.9876, 1.0027, 0.9758, 0.9625, 0.9600, 0.9680, 1.0695, 0.9600,
        0.9853, 0.9664, 0.9600, 0.9618, 0.9923, 0.9628, 1.0177, 0.9894, 1.0437,
        1.0159, 1.0799, 0.9614, 0.9688, 0.9818, 0.9667, 0.9629, 1.0447, 0.9601,
        0.9809, 0.9650, 0.9709, 1.2963, 0.9614, 1.0051, 0.9711, 0.9756, 0.9783,
        0.9848, 0.9639, 0.9992, 1.1382, 0.9592, 0.9768, 1.0102, 0.9761, 1.2660,
        1.0272, 0.9591, 1.5042, 0.9634, 0.9804, 0.9685, 0.9888, 1.0041, 1.0258,
        0.9591, 0.9676, 0.9633, 0.9618, 0.9740, 0.9683, 0.9934, 0.9627, 1.1259,
        0.9610, 0.9650, 1.0456, 0.9731, 0.9759, 0.9733, 0.9611, 0.9811, 0.9884,
        0.9767, 0.9699, 0.9920, 0.9594, 0.9633, 0.9705, 0.9596, 0.9690, 0.9746,
        0.9634, 1.0720, 0.9625, 0.9785, 1.0165, 1.0177, 0.9728, 0.9796, 0.9614],
       device='cuda:0')
S painting T real Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.344742 Loss T 0.086207 Method MME


Labeled Target set: Average loss: 1.6723, Accuracy: 689/1080 F1 (63.7963%)


Test set: Average loss: 1.4428, Accuracy: 48794/69960 F1 (69.7456%)


Val set: Average loss: 1.6409, Accuracy: 239/360 F1 (66.3889%)

best acc test 72.168382  acc val 66.388889 acc labeled target 63.796296
saving model...
S painting T real Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.655327 Loss T 0.046221 Method MME

S painting T real Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.353682 Loss T 0.075053 Method MME

S painting T real Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.291690 Loss T 0.077867 Method MME

S painting T real Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.564240 Loss T 0.078460 Method MME

S painting T real Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.328443 Loss T 0.054224 Method MME


Labeled Target set: Average loss: 0.0565, Accuracy: 1067/1080 F1 (98.7963%)


Test set: Average loss: 1.0035, Accuracy: 53869/69960 F1 (76.9997%)


Val set: Average loss: 1.1636, Accuracy: 272/360 F1 (75.5556%)

best acc test 76.999714  acc val 75.555556 acc labeled target 98.796296
saving model...
S painting T real Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 1.108830 Loss T 0.068006 Method MME

S painting T real Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.229018 Loss T 0.076666 Method MME

S painting T real Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.997956 Loss T 0.039372 Method MME

S painting T real Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.377834 Loss T 0.047686 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.7777778 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8333333
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [23, 62, 94, 84, 52, 53, 80, 45, 88, 61, 67, 87, 86, 89, 90, 91, 83, 82, 85, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 81, 92, 93, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 66, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 0, 63, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 28, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 29, 30, 31, 124, 60, 59, 58, 57, 56, 55, 54, 51, 50, 49, 48, 47, 46, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 344  306  311  268  410  386  274  346  404  518  348  394 1231  326
  358  406  619  579  295  524  612  351  391  344  267  590  363  580
  683  166  375  801  522  224  291  201 1146  378  327  453  573  719
  495  245  704  377  521  711  602  355  610  307  364  274  249  226
  635  484  436  548  572  218  709  431  530  471  159  594  328  441
  440  457  407  557  357  181  932  423  314  427  202  283 1006  168
  568  394  504  381  354  292  963  491  559  621  442  471  351  576
  199  641  534  288  439  433  450  638  396  401  465  467  351  682
  566  465  662  462  444  556  308  596  452  309  310  469  425  612]
CBFL per class weights: tensor([1.0011, 1.0164, 1.0140, 1.0398, 0.9855, 0.9900, 1.0354, 1.0004, 0.9865,
        0.9748, 0.9998, 0.9883, 0.9695, 1.0076, 0.9968, 0.9862, 0.9714, 0.9724,
        1.0222, 0.9745, 0.9716, 0.9988, 0.9889, 1.0011, 1.0406, 0.9721, 0.9954,
        0.9724, 0.9705, 1.1948, 0.9924, 0.9698, 0.9746, 1.0836, 1.0245, 1.1178,
        0.9695, 0.9917, 1.0072, 0.9798, 0.9726, 0.9702, 0.9762, 1.0598, 0.9703,
        0.9919, 0.9747, 0.9703, 0.9718, 0.9977, 0.9716, 1.0159, 0.9952, 1.0354,
        1.0560, 1.0810, 0.9711, 0.9770, 0.9818, 0.9735, 0.9726, 1.0915, 0.9703,
        0.9824, 0.9742, 0.9781, 1.2154, 0.9720, 1.0068, 0.9812, 0.9813, 0.9794,
        0.9860, 0.9731, 0.9971, 1.1572, 0.9696, 0.9835, 1.0126, 0.9830, 1.1161,
        1.0294, 0.9695, 1.1893, 0.9727, 0.9883, 0.9757, 0.9910, 0.9979, 1.0239,
        0.9696, 0.9765, 0.9730, 0.9714, 0.9810, 0.9781, 0.9988, 0.9725, 1.1212,
        0.9711, 0.9741, 1.0263, 0.9814, 0.9822, 0.9801, 0.9711, 0.9880, 0.9870,
        0.9786, 0.9785, 0.9988, 0.9705, 0.9728, 0.9786, 0.9708, 0.9789, 0.9808,
        0.9731, 1.0155, 0.9719, 0.9799, 1.0150, 1.0145, 0.9783, 0.9832, 0.9716],
       device='cuda:0')
S painting T real Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.251760 Loss T 0.070190 Method MME


Labeled Target set: Average loss: 0.1174, Accuracy: 1054/1080 F1 (97.5926%)


Test set: Average loss: 1.2606, Accuracy: 50937/69960 F1 (72.8087%)


Val set: Average loss: 1.4082, Accuracy: 253/360 F1 (70.2778%)

best acc test 76.999714  acc val 70.277778 acc labeled target 97.592593
saving model...
S painting T real Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.508418 Loss T 0.069259 Method MME

S painting T real Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.174429 Loss T 0.045457 Method MME

S painting T real Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.704669 Loss T 0.047722 Method MME

S painting T real Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.363168 Loss T 0.053346 Method MME

S painting T real Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.328699 Loss T 0.042148 Method MME


Labeled Target set: Average loss: 0.0417, Accuracy: 1073/1080 F1 (99.3519%)


Test set: Average loss: 1.0238, Accuracy: 54157/69960 F1 (77.4114%)


Val set: Average loss: 1.1211, Accuracy: 269/360 F1 (74.7222%)

best acc test 76.999714  acc val 74.722222 acc labeled target 99.351852
saving model...
S painting T real Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.693714 Loss T 0.048843 Method MME

S painting T real Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.739859 Loss T 0.047649 Method MME

S painting T real Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.222051 Loss T 0.076672 Method MME

S painting T real Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.417587 Loss T 0.062005 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [23, 45, 90, 38, 77, 18, 54, 83, 84, 85, 0, 87, 88, 89, 91, 86, 82, 81, 80, 79, 78, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 92, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 66, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 63, 28, 27, 26, 25, 24, 22, 21, 20, 19, 17, 16, 15, 29, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 46, 44, 43, 42, 41, 40, 39, 37, 36, 35, 34, 33, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 362  380  326  284  460  359  281  378  424  541  371  412 1015  346
  372  490  655  587  319  588  648  372  410  359  274  607  380  595
  694  179  385  747  528  245  304  206 1005  392  335  495  593  741
  525  279  720  388  549  717  626  364  643  321  371  294  209  234
  654  492  481  624  581  230  735  478  540  491  169  590  356  452
  465  522  451  582  389  187  975  429  329  447  301  292  860  215
  597  411  524  408  411  311  901  505  572  638  466  477  375  592
  228  671  554  319  467  459  478  656  400  450  541  486  371  612
  583  490  559  473  467  562  400  611  494  321  352  515  461  625]
CBFL per class weights: tensor([1.0016, 0.9972, 1.0135, 1.0349, 0.9849, 1.0024, 1.0368, 0.9976, 0.9892,
        0.9795, 0.9993, 0.9910, 0.9753, 1.0064, 0.9990, 0.9824, 0.9766, 0.9779,
        1.0165, 0.9779, 0.9767, 0.9990, 0.9914, 1.0024, 1.0416, 0.9775, 0.9972,
        0.9777, 0.9762, 1.1686, 0.9961, 0.9758, 0.9801, 1.0661, 1.0235, 1.1160,
        0.9753, 0.9946, 1.0101, 0.9821, 0.9778, 0.9758, 0.9803, 1.0381, 0.9760,
        0.9954, 0.9792, 0.9760, 0.9771, 1.0011, 0.9768, 1.0156, 0.9993, 1.0289,
        1.1113, 1.0779, 0.9766, 0.9823, 0.9831, 0.9771, 0.9781, 1.0826, 0.9759,
        0.9833, 0.9796, 0.9823, 1.1937, 0.9779, 1.0033, 0.9858, 0.9845, 0.9804,
        0.9859, 0.9781, 0.9952, 1.1510, 0.9753, 0.9885, 1.0124, 0.9863, 1.0250,
        1.0300, 0.9754, 1.1023, 0.9777, 0.9912, 0.9803, 0.9917, 0.9912, 1.0201,
        0.9754, 0.9814, 0.9784, 0.9769, 0.9844, 0.9834, 0.9983, 0.9778, 1.0850,
        0.9764, 0.9790, 1.0165, 0.9843, 0.9850, 0.9833, 0.9766, 0.9931, 0.9860,
        0.9795, 0.9827, 0.9993, 0.9774, 0.9781, 0.9824, 0.9788, 0.9837, 0.9843,
        0.9787, 0.9931, 0.9774, 0.9821, 1.0156, 1.0045, 0.9808, 0.9848, 0.9771],
       device='cuda:0')
S painting T real Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.403859 Loss T 0.051935 Method MME


Labeled Target set: Average loss: 0.0740, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.2840, Accuracy: 51269/69960 F1 (73.2833%)


Val set: Average loss: 1.4084, Accuracy: 262/360 F1 (72.7778%)

best acc test 76.999714  acc val 72.777778 acc labeled target 98.518519
saving model...
S painting T real Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.501539 Loss T 0.040103 Method MME

S painting T real Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.081243 Loss T 0.083475 Method MME

S painting T real Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.050566 Loss T 0.038897 Method MME

S painting T real Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.175205 Loss T 0.065749 Method MME

S painting T real Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.034199 Loss T 0.056529 Method MME


Labeled Target set: Average loss: 0.0457, Accuracy: 1067/1080 F1 (98.7963%)


Test set: Average loss: 1.0776, Accuracy: 53917/69960 F1 (77.0683%)


Val set: Average loss: 1.2236, Accuracy: 265/360 F1 (73.6111%)

best acc test 76.999714  acc val 73.611111 acc labeled target 98.796296
saving model...
S painting T real Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.146868 Loss T 0.040633 Method MME

S painting T real Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.302638 Loss T 0.037556 Method MME

S painting T real Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.417926 Loss T 0.048281 Method MME

S painting T real Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.139318 Loss T 0.066919 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8333333 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        0.8888889 0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8333333 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [93, 26, 30, 83, 106, 50, 110, 15, 13, 53, 54, 66, 63, 75, 90, 89, 88, 68, 87, 86, 85, 84, 69, 82, 81, 80, 70, 79, 71, 91, 72, 73, 77, 74, 76, 78, 0, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 67, 92, 95, 62, 64, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 31, 32, 33, 124, 61, 60, 59, 58, 57, 56, 55, 52, 51, 49, 48, 65, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 46, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [370 409 343 294 481 354 291 388 444 557 383 433 870 362 394 561 665 600
 342 630 578 380 425 382 271 627 394 609 717 183 392 842 527 278 307 213
 900 402 348 531 599 748 577 293 733 397 581 717 631 380 673 343 383 309
 179 236 659 504 498 681 588 240 741 492 559 497 170 589 380 460 484 557
 497 611 405 189 986 441 346 464 438 313 724 234 608 433 550 418 415 330
 839 521 581 654 472 486 397 595 246 692 554 349 482 478 495 662 407 484
 574 509 370 565 598 499 509 481 489 567 458 630 519 328 381 531 482 632]
CBFL per class weights: tensor([1.0021, 0.9941, 1.0099, 1.0315, 0.9856, 1.0065, 1.0332, 0.9980, 0.9892,
        0.9814, 0.9990, 0.9905, 0.9779, 1.0042, 0.9968, 0.9813, 0.9790, 0.9801,
        1.0103, 0.9795, 0.9807, 0.9997, 0.9916, 0.9993, 1.0465, 0.9796, 0.9968,
        0.9799, 0.9785, 1.1625, 0.9972, 0.9780, 0.9827, 1.0415, 1.0246, 1.1080,
        0.9779, 0.9953, 1.0083, 0.9825, 0.9802, 0.9783, 0.9807, 1.0321, 0.9784,
        0.9962, 0.9806, 0.9785, 0.9795, 0.9997, 0.9789, 1.0099, 0.9990, 1.0236,
        1.1716, 1.0784, 0.9791, 0.9840, 0.9844, 0.9788, 0.9804, 1.0740, 0.9783,
        0.9848, 0.9813, 0.9844, 1.1940, 0.9804, 0.9997, 0.9875, 0.9854, 0.9814,
        0.9844, 0.9799, 0.9948, 1.1498, 0.9778, 0.9895, 1.0089, 0.9871, 0.9899,
        1.0217, 0.9784, 1.0806, 0.9799, 0.9905, 0.9817, 0.9926, 0.9931, 1.0146,
        0.9780, 0.9830, 0.9806, 0.9791, 0.9864, 0.9852, 0.9962, 0.9802, 1.0679,
        0.9787, 0.9815, 1.0080, 0.9855, 0.9859, 0.9846, 0.9790, 0.9944, 0.9854,
        0.9808, 0.9837, 1.0021, 0.9811, 0.9802, 0.9843, 0.9837, 0.9856, 0.9850,
        0.9811, 0.9877, 0.9795, 0.9831, 1.0154, 0.9995, 0.9825, 0.9855, 0.9795],
       device='cuda:0')
S painting T real Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.574121 Loss T 0.054675 Method MME


Labeled Target set: Average loss: 0.0876, Accuracy: 1058/1080 F1 (97.9630%)


Test set: Average loss: 1.2618, Accuracy: 51661/69960 F1 (73.8436%)


Val set: Average loss: 1.5870, Accuracy: 251/360 F1 (69.7222%)

best acc test 76.999714  acc val 69.722222 acc labeled target 97.962963
saving model...
S painting T real Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.016878 Loss T 0.072071 Method MME

S painting T real Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.606520 Loss T 0.051245 Method MME

S painting T real Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.046227 Loss T 0.038602 Method MME

S painting T real Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.213447 Loss T 0.059919 Method MME

S painting T real Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.350036 Loss T 0.053157 Method MME


Labeled Target set: Average loss: 0.0376, Accuracy: 1073/1080 F1 (99.3519%)


Test set: Average loss: 1.0422, Accuracy: 54571/69960 F1 (78.0031%)


Val set: Average loss: 1.2144, Accuracy: 272/360 F1 (75.5556%)

best acc test 78.003145  acc val 75.555556 acc labeled target 99.351852
saving model...
S painting T real Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.187778 Loss T 0.033378 Method MME

S painting T real Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.387676 Loss T 0.040243 Method MME

S painting T real Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.427729 Loss T 0.054960 Method MME

S painting T real Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.253642 Loss T 0.038751 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8333333
 0.8333333 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8333333 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [10, 101, 83, 84, 66, 121, 81, 82, 85, 0, 86, 87, 88, 89, 90, 80, 79, 77, 91, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 65, 78, 92, 94, 64, 123, 122, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 100, 99, 98, 97, 96, 95, 93, 63, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 124, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 375  430  362  305  500  362  294  398  454  566  389  448  755  386
  410  614  690  610  358  657  540  399  437  402  269  637  416  616
  720  184  396  868  486  288  317  221  829  410  362  548  606  760
  592  306  742  397  608  723  630  383  704  339  396  323  168  243
  675  513  516  728  593  237  752  500  576  507  171  583  408  462
  492  584  528  617  418  197 1003  454  357  477  520  321  643  242
  623  449  566  428  419  337  789  536  593  668  480  489  413  604
  250  706  561  370  492  494  507  666  411  489  585  519  373  584
  601  514  471  488  502  572  497  632  532  337  401  545  492  634]
CBFL per class weights: tensor([1.0023, 0.9923, 1.0056, 1.0270, 0.9856, 1.0056, 1.0329, 0.9974, 0.9895,
        0.9825, 0.9992, 0.9901, 0.9796, 0.9998, 0.9953, 0.9812, 0.9801, 0.9813,
        1.0067, 0.9805, 0.9835, 0.9972, 0.9914, 0.9967, 1.0494, 0.9808, 0.9943,
        0.9811, 0.9798, 1.1620, 0.9978, 0.9793, 0.9866, 1.0365, 1.0214, 1.0983,
        0.9794, 0.9953, 1.0056, 0.9831, 0.9814, 0.9796, 0.9817, 1.0265, 0.9797,
        0.9976, 0.9813, 0.9798, 0.9809, 1.0004, 0.9800, 1.0127, 0.9978, 1.0188,
        1.2011, 1.0724, 0.9802, 0.9848, 0.9846, 0.9798, 0.9817, 1.0788, 0.9796,
        0.9856, 0.9821, 0.9852, 1.1931, 0.9819, 0.9956, 0.9886, 0.9862, 0.9819,
        0.9840, 0.9811, 0.9940, 1.1360, 0.9792, 0.9895, 1.0070, 0.9873, 0.9844,
        1.0196, 0.9807, 1.0734, 0.9810, 0.9900, 0.9825, 0.9926, 0.9939, 1.0134,
        0.9795, 0.9836, 0.9817, 0.9803, 0.9871, 0.9864, 0.9948, 0.9814, 1.0655,
        0.9799, 0.9826, 1.0035, 0.9862, 0.9860, 0.9852, 0.9803, 0.9951, 0.9864,
        0.9819, 0.9845, 1.0027, 0.9819, 0.9815, 0.9848, 0.9878, 0.9864, 0.9855,
        0.9823, 0.9858, 0.9808, 0.9838, 1.0134, 0.9968, 0.9832, 0.9862, 0.9808],
       device='cuda:0')
S painting T real Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.308047 Loss T 0.056570 Method MME


Labeled Target set: Average loss: 0.0602, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.2053, Accuracy: 52282/69960 F1 (74.7313%)


Val set: Average loss: 1.4434, Accuracy: 256/360 F1 (71.1111%)

best acc test 78.003145  acc val 71.111111 acc labeled target 98.518519
saving model...
S painting T real Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.362139 Loss T 0.035674 Method MME

S painting T real Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.120278 Loss T 0.054378 Method MME

S painting T real Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.282173 Loss T 0.037548 Method MME

S painting T real Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.268060 Loss T 0.045106 Method MME

S painting T real Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.317810 Loss T 0.059062 Method MME


Labeled Target set: Average loss: 0.0316, Accuracy: 1075/1080 F1 (99.5370%)


Test set: Average loss: 1.0464, Accuracy: 54637/69960 F1 (78.0975%)


Val set: Average loss: 1.2456, Accuracy: 266/360 F1 (73.8889%)

best acc test 78.003145  acc val 73.888889 acc labeled target 99.537037
saving model...
S painting T real Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.353700 Loss T 0.071252 Method MME

S painting T real Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.650980 Loss T 0.030659 Method MME

S painting T real Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.533002 Loss T 0.045626 Method MME

S painting T real Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.302670 Loss T 0.031768 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [13, 52, 117, 78, 73, 0, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 86, 80, 77, 92, 76, 75, 74, 72, 71, 70, 69, 68, 67, 66, 79, 93, 94, 95, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 65, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 30, 31, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 51, 50, 49, 48, 63, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 388  440  376  307  504  372  304  415  462  580  401  462  668  388
  420  680  713  612  374  708  503  408  455  423  261  652  428  634
  725  189  399  907  448  299  328  227  767  416  366  565  609  775
  601  313  749  403  614  730  633  388  724  348  418  328  156  253
  683  520  540  779  591  233  763  519  588  517  178  579  433  474
  501  608  543  624  436  212 1003  459  362  481  568  325  569  249
  632  453  574  442  424  353  770  546  601  677  494  491  421  616
  254  721  572  387  498  498  520  671  415  524  591  526  373  598
  616  516  433  492  505  579  531  628  535  336  430  561  504  635]
CBFL per class weights: tensor([1.0005, 0.9922, 1.0032, 1.0272, 0.9865, 1.0041, 1.0287, 0.9956, 0.9898,
        0.9831, 0.9980, 0.9898, 0.9814, 1.0005, 0.9948, 0.9813, 0.9810, 0.9823,
        1.0036, 0.9810, 0.9865, 0.9968, 0.9905, 0.9944, 1.0570, 0.9816, 0.9937,
        0.9819, 0.9809, 1.1527, 0.9983, 0.9804, 0.9912, 1.0313, 1.0179, 1.0918,
        0.9807, 0.9955, 1.0056, 0.9836, 0.9824, 0.9806, 0.9826, 1.0243, 0.9808,
        0.9976, 0.9823, 0.9809, 0.9819, 1.0005, 0.9809, 1.0108, 0.9952, 1.0179,
        1.2385, 1.0639, 0.9813, 0.9855, 0.9846, 0.9806, 0.9828, 1.0845, 0.9807,
        0.9856, 0.9829, 0.9857, 1.1770, 0.9832, 0.9930, 0.9887, 0.9867, 0.9824,
        0.9844, 0.9821, 0.9927, 1.1123, 0.9803, 0.9901, 1.0067, 0.9881, 0.9835,
        1.0191, 0.9835, 1.0677, 0.9820, 0.9907, 0.9833, 0.9919, 0.9943, 1.0093,
        0.9807, 0.9843, 0.9826, 0.9813, 0.9871, 0.9873, 0.9947, 0.9823, 1.0630,
        0.9809, 0.9834, 1.0007, 0.9869, 0.9869, 0.9855, 0.9814, 0.9956, 0.9853,
        0.9828, 0.9852, 1.0039, 0.9827, 0.9823, 0.9858, 0.9930, 0.9873, 0.9864,
        0.9832, 0.9850, 0.9820, 0.9848, 1.0149, 0.9934, 0.9837, 0.9865, 0.9819],
       device='cuda:0')
S painting T real Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.023685 Loss T 0.046107 Method MME


Labeled Target set: Average loss: 0.0498, Accuracy: 1069/1080 F1 (98.9815%)


Test set: Average loss: 1.2272, Accuracy: 52655/69960 F1 (75.2644%)


Val set: Average loss: 1.4048, Accuracy: 264/360 F1 (73.3333%)

best acc test 78.003145  acc val 73.333333 acc labeled target 98.981481
saving model...
S painting T real Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.064314 Loss T 0.049179 Method MME

S painting T real Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.173530 Loss T 0.035133 Method MME

S painting T real Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.291604 Loss T 0.056016 Method MME

S painting T real Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.175880 Loss T 0.045271 Method MME

S painting T real Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.345671 Loss T 0.046476 Method MME


Labeled Target set: Average loss: 0.0388, Accuracy: 1072/1080 F1 (99.2593%)


Test set: Average loss: 1.0287, Accuracy: 55086/69960 F1 (78.7393%)


Val set: Average loss: 1.2223, Accuracy: 266/360 F1 (73.8889%)

best acc test 78.003145  acc val 73.888889 acc labeled target 99.259259
saving model...
S painting T real Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.311333 Loss T 0.053218 Method MME

S painting T real Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.101993 Loss T 0.049336 Method MME

S painting T real Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.047385 Loss T 0.035305 Method MME

S painting T real Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.234841 Loss T 0.041720 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        0.8333333
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        0.8888889
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [6, 78, 76, 70, 57, 114, 12, 10, 0, 83, 84, 86, 82, 87, 88, 89, 90, 91, 85, 81, 77, 79, 92, 75, 74, 73, 72, 71, 69, 68, 67, 80, 93, 96, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 66, 94, 65, 62, 63, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 9, 8, 7, 5, 4, 3, 2, 1, 31, 64, 32, 34, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 386  455  377  307  531  381  305  430  467  592  407  472  595  390
  435  705  730  622  387  759  452  417  467  438  256  668  434  642
  732  191  399  959  414  301  339  227  699  418  371  571  608  784
  630  319  749  403  626  728  642  403  740  352  423  335  161  254
  687  523  552  797  596  239  773  530  589  524  178  577  447  485
  511  610  558  630  449  216 1016  472  369  482  635  335  506  255
  642  467  587  452  425  359  726  547  604  692  502  496  422  617
  259  729  583  411  503  506  531  671  423  556  615  540  372  620
  615  522  408  496  509  586  546  628  539  341  455  566  519  638]
CBFL per class weights: tensor([1.0017, 0.9913, 1.0037, 1.0280, 0.9858, 1.0028, 1.0290, 0.9942, 0.9901,
        0.9836, 0.9977, 0.9897, 0.9835, 1.0009, 0.9936, 0.9819, 0.9817, 0.9829,
        1.0015, 0.9815, 0.9916, 0.9961, 0.9901, 0.9932, 1.0621, 0.9822, 0.9937,
        0.9826, 0.9817, 1.1497, 0.9992, 0.9811, 0.9966, 1.0311, 1.0147, 1.0926,
        0.9819, 0.9960, 1.0052, 0.9842, 0.9832, 0.9814, 0.9828, 1.0225, 0.9816,
        0.9984, 0.9829, 0.9817, 0.9826, 0.9984, 0.9816, 1.0104, 0.9952, 1.0161,
        1.2237, 1.0639, 0.9820, 0.9862, 0.9849, 0.9814, 0.9835, 1.0787, 0.9815,
        0.9858, 0.9837, 0.9861, 1.1779, 0.9840, 0.9921, 0.9886, 0.9868, 0.9832,
        0.9847, 0.9828, 0.9919, 1.1074, 0.9811, 0.9897, 1.0057, 0.9888, 0.9827,
        1.0161, 0.9871, 1.0630, 0.9826, 0.9901, 0.9837, 0.9916, 0.9949, 1.0084,
        0.9817, 0.9851, 0.9833, 0.9820, 0.9874, 0.9878, 0.9954, 0.9830, 1.0595,
        0.9817, 0.9838, 0.9971, 0.9873, 0.9871, 0.9858, 0.9822, 0.9952, 0.9847,
        0.9831, 0.9854, 1.0049, 0.9830, 0.9831, 0.9862, 0.9976, 0.9878, 0.9870,
        0.9838, 0.9851, 0.9828, 0.9854, 1.0140, 0.9913, 0.9844, 0.9864, 0.9827],
       device='cuda:0')
S painting T real Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.452699 Loss T 0.040817 Method MME


Labeled Target set: Average loss: 0.0592, Accuracy: 1063/1080 F1 (98.4259%)


Test set: Average loss: 1.2227, Accuracy: 52270/69960 F1 (74.7141%)


Val set: Average loss: 1.2880, Accuracy: 252/360 F1 (70.0000%)

best acc test 78.003145  acc val 70.000000 acc labeled target 98.425926
saving model...
S painting T real Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.050978 Loss T 0.032424 Method MME

S painting T real Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.020278 Loss T 0.042019 Method MME

S painting T real Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.199593 Loss T 0.051918 Method MME

S painting T real Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.071423 Loss T 0.027678 Method MME

S painting T real Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.284734 Loss T 0.034925 Method MME


Labeled Target set: Average loss: 0.0254, Accuracy: 1073/1080 F1 (99.3519%)


Test set: Average loss: 1.0471, Accuracy: 54907/69960 F1 (78.4834%)


Val set: Average loss: 1.3266, Accuracy: 263/360 F1 (73.0556%)

best acc test 78.003145  acc val 73.055556 acc labeled target 99.351852
saving model...
S painting T real Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.214229 Loss T 0.054463 Method MME

S painting T real Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.151299 Loss T 0.041630 Method MME

S painting T real Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.131127 Loss T 0.046306 Method MME

S painting T real Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.232982 Loss T 0.034397 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        0.8333333
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [90, 15, 92, 87, 84, 12, 78, 91, 89, 88, 86, 85, 83, 82, 81, 80, 0, 93, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 94, 95, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 65, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 63, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 47, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 386  462  383  312  538  384  307  441  469  598  416  483  530  403
  446  730  748  624  397  787  442  427  477  444  254  682  433  647
  741  191  403  961  403  298  352  228  651  423  378  580  618  793
  654  327  755  402  629  735  647  405  743  357  426  339  157  257
  689  528  559  806  600  247  781  540  593  532  187  571  457  485
  512  614  580  634  452  222 1025  475  374  488  726  334  464  279
  654  480  592  461  417  372  701  553  609  687  507  500  426  623
  258  741  587  433  506  510  539  684  417  597  618  546  387  607
  616  523  381  495  516  586  584  625  541  340  494  571  522  639]
CBFL per class weights: tensor([1.0024, 0.9913, 1.0031, 1.0264, 0.9862, 1.0029, 1.0288, 0.9935, 0.9906,
        0.9842, 0.9970, 0.9894, 0.9865, 0.9991, 0.9930, 0.9824, 0.9823, 0.9836,
        1.0002, 0.9821, 0.9934, 0.9954, 0.9899, 0.9932, 1.0646, 0.9828, 0.9945,
        0.9832, 0.9823, 1.1505, 0.9991, 0.9818, 0.9991, 1.0334, 1.0111, 1.0922,
        0.9832, 0.9959, 1.0042, 0.9846, 0.9837, 0.9821, 0.9831, 1.0199, 0.9822,
        0.9993, 0.9835, 0.9823, 0.9832, 0.9988, 0.9823, 1.0097, 0.9955, 1.0154,
        1.2371, 1.0620, 0.9827, 0.9866, 0.9853, 0.9820, 0.9841, 1.0712, 0.9821,
        0.9861, 0.9843, 0.9864, 1.1586, 0.9849, 0.9918, 0.9893, 0.9875, 0.9838,
        0.9846, 0.9834, 0.9923, 1.0999, 0.9818, 0.9901, 1.0052, 0.9891, 0.9824,
        1.0172, 0.9911, 1.0450, 0.9831, 0.9897, 0.9843, 0.9914, 0.9968, 1.0057,
        0.9826, 0.9855, 0.9839, 0.9827, 0.9878, 0.9882, 0.9955, 0.9836, 1.0611,
        0.9823, 0.9844, 0.9945, 0.9878, 0.9876, 0.9861, 0.9828, 0.9968, 0.9842,
        0.9837, 0.9858, 1.0022, 0.9839, 0.9838, 0.9869, 1.0035, 0.9886, 0.9873,
        0.9845, 0.9845, 0.9836, 0.9860, 1.0150, 0.9886, 0.9849, 0.9869, 0.9833],
       device='cuda:0')
S painting T real Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.132595 Loss T 0.058806 Method MME


Labeled Target set: Average loss: 0.0652, Accuracy: 1065/1080 F1 (98.6111%)


Test set: Average loss: 1.1829, Accuracy: 53294/69960 F1 (76.1778%)


Val set: Average loss: 1.3110, Accuracy: 264/360 F1 (73.3333%)

best acc test 78.003145  acc val 73.333333 acc labeled target 98.611111
saving model...
S painting T real Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.426408 Loss T 0.039444 Method MME

S painting T real Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.007608 Loss T 0.041479 Method MME

S painting T real Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.334691 Loss T 0.043360 Method MME

S painting T real Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.102760 Loss T 0.044238 Method MME

S painting T real Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.085478 Loss T 0.043611 Method MME


Labeled Target set: Average loss: 0.0448, Accuracy: 1067/1080 F1 (98.7963%)


Test set: Average loss: 0.9950, Accuracy: 55545/69960 F1 (79.3954%)


Val set: Average loss: 1.0434, Accuracy: 280/360 F1 (77.7778%)

best acc test 79.395369  acc val 77.777778 acc labeled target 98.796296
saving model...
S painting T real Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.149155 Loss T 0.045481 Method MME

S painting T real Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.506846 Loss T 0.037916 Method MME

S painting T real Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.222143 Loss T 0.049990 Method MME

S painting T real Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.320505 Loss T 0.054084 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8333333 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.6666667 1.        1.       ]
Top k classes which perform poorly are:  [123, 42, 84, 33, 52, 73, 56, 106, 97, 57, 81, 87, 85, 88, 89, 90, 83, 82, 86, 0, 79, 91, 77, 76, 75, 74, 72, 71, 70, 69, 68, 67, 80, 78, 92, 93, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 105, 104, 103, 102, 101, 100, 99, 98, 96, 95, 94, 66, 65, 62, 63, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 27, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 28, 29, 30, 124, 61, 60, 59, 58, 55, 54, 53, 51, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 34, 32, 31, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 386  466  383  317  546  380  305  443  470  607  420  498  481  408
  456  753  757  626  407  808  418  429  485  460  256  702  431  643
  743  192  405  977  391  306  361  227  608  426  382  592  624  793
  668  343  764  403  634  735  648  401  745  358  423  350  161  259
  695  535  570  828  607  256  786  545  596  543  182  566  474  490
  524  622  608  640  459  226 1030  481  381  493  780  339  431  276
  665  490  610  470  414  383  667  561  615  692  510  502  433  620
  258  753  587  442  512  513  550  688  420  627  614  551  395  608
  618  529  366  499  527  585  594  628  552  341  512  566  532  642]
CBFL per class weights: tensor([1.0029, 0.9913, 1.0035, 1.0245, 0.9862, 1.0042, 1.0302, 0.9937, 0.9910,
        0.9844, 0.9968, 0.9888, 0.9900, 0.9987, 0.9923, 0.9827, 0.9826, 0.9840,
        0.9989, 0.9824, 0.9971, 0.9955, 0.9897, 0.9919, 1.0633, 0.9830, 0.9952,
        0.9837, 0.9827, 1.1490, 0.9992, 0.9822, 1.0018, 1.0297, 1.0090, 1.0939,
        0.9843, 0.9959, 1.0037, 0.9847, 0.9840, 0.9825, 0.9833, 1.0144, 0.9826,
        0.9996, 0.9838, 0.9828, 0.9836, 0.9999, 0.9827, 1.0098, 0.9963, 1.0122,
        1.2250, 1.0607, 0.9831, 0.9867, 0.9854, 0.9824, 0.9844, 1.0633, 0.9825,
        0.9863, 0.9846, 0.9864, 1.1700, 0.9855, 0.9906, 0.9893, 0.9873, 0.9841,
        0.9843, 0.9837, 0.9920, 1.0951, 0.9822, 0.9900, 1.0040, 0.9891, 0.9825,
        1.0158, 0.9952, 1.0475, 0.9834, 0.9893, 0.9843, 0.9910, 0.9977, 1.0035,
        0.9834, 0.9857, 0.9842, 0.9831, 0.9880, 0.9885, 0.9950, 0.9841, 1.0616,
        0.9827, 0.9849, 0.9939, 0.9879, 0.9878, 0.9861, 0.9831, 0.9968, 0.9840,
        0.9842, 0.9860, 1.0010, 0.9843, 0.9841, 0.9870, 1.0076, 0.9887, 0.9871,
        0.9849, 0.9847, 0.9839, 0.9860, 1.0151, 0.9879, 0.9855, 0.9869, 0.9837],
       device='cuda:0')
S painting T real Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.256157 Loss T 0.062411 Method MME


Labeled Target set: Average loss: 0.0723, Accuracy: 1066/1080 F1 (98.7037%)


Test set: Average loss: 1.2490, Accuracy: 52308/69960 F1 (74.7684%)


Val set: Average loss: 1.3302, Accuracy: 261/360 F1 (72.5000%)

best acc test 79.395369  acc val 72.500000 acc labeled target 98.703704
saving model...
S painting T real Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.035666 Loss T 0.036120 Method MME

S painting T real Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.327331 Loss T 0.034949 Method MME

S painting T real Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.623191 Loss T 0.039884 Method MME

S painting T real Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.269154 Loss T 0.041221 Method MME

S painting T real Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.141628 Loss T 0.049151 Method MME


Labeled Target set: Average loss: 0.0329, Accuracy: 1071/1080 F1 (99.1667%)


Test set: Average loss: 1.0425, Accuracy: 55389/69960 F1 (79.1724%)


Val set: Average loss: 1.1716, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.395369  acc val 75.833333 acc labeled target 99.166667
saving model...
S painting T real Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.194634 Loss T 0.030259 Method MME

S painting T real Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.033398 Loss T 0.059898 Method MME

S painting T real Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.077658 Loss T 0.028848 Method MME

S painting T real Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.153661 Loss T 0.049984 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8333333 1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8333333 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [99, 42, 90, 69, 26, 56, 13, 51, 41, 0, 84, 85, 87, 83, 88, 89, 86, 82, 80, 91, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 68, 81, 92, 94, 67, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 95, 109, 66, 62, 64, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 30, 31, 32, 63, 124, 61, 60, 59, 58, 57, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 40, 39, 38, 37, 36, 35, 34, 33, 65, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 391  471  388  316  555  399  305  452  476  612  419  508  430  400
  456  764  757  625  412  828  394  433  486  483  257  714  431  651
  752  193  408 1008  383  312  366  229  590  441  387  595  628  790
  683  347  764  404  647  737  651  398  754  363  426  355  160  262
  703  535  579  849  607  246  785  548  588  553  186  562  480  489
  531  634  616  641  473  227 1038  484  393  497  856  346  392  274
  666  490  626  472  406  382  647  559  619  697  518  502  425  629
  261  755  593  456  514  517  556  699  416  648  617  550  397  595
  625  529  354  500  526  586  615  625  567  349  526  577  532  647]
CBFL per class weights: tensor([1.0020, 0.9910, 1.0026, 1.0251, 0.9861, 1.0005, 1.0304, 0.9929, 0.9906,
        0.9844, 0.9971, 0.9883, 0.9956, 1.0003, 0.9925, 0.9828, 0.9828, 0.9842,
        0.9982, 0.9826, 1.0014, 0.9952, 0.9898, 0.9900, 1.0626, 0.9831, 0.9954,
        0.9837, 0.9828, 1.1472, 0.9989, 0.9824, 1.0037, 1.0270, 1.0078, 1.0916,
        0.9850, 0.9942, 1.0028, 0.9848, 0.9841, 0.9827, 0.9834, 1.0133, 0.9828,
        0.9996, 0.9838, 0.9829, 0.9837, 1.0007, 0.9828, 1.0086, 0.9961, 1.0109,
        1.2283, 1.0584, 0.9832, 0.9869, 0.9853, 0.9825, 0.9845, 1.0729, 0.9827,
        0.9863, 0.9850, 0.9861, 1.1615, 0.9858, 0.9903, 0.9896, 0.9871, 0.9840,
        0.9843, 0.9839, 0.9909, 1.0941, 0.9824, 0.9900, 1.0016, 0.9890, 0.9825,
        1.0136, 1.0018, 1.0491, 0.9836, 0.9895, 0.9842, 0.9910, 0.9992, 1.0039,
        0.9838, 0.9859, 0.9843, 0.9832, 0.9877, 0.9887, 0.9962, 0.9841, 1.0592,
        0.9828, 0.9849, 0.9925, 0.9880, 0.9878, 0.9860, 0.9832, 0.9976, 0.9838,
        0.9843, 0.9863, 1.0008, 0.9848, 0.9842, 0.9872, 1.0112, 0.9888, 0.9873,
        0.9851, 0.9844, 0.9842, 0.9856, 1.0127, 0.9873, 0.9853, 0.9870, 0.9838],
       device='cuda:0')
S painting T real Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.068091 Loss T 0.048627 Method MME


Labeled Target set: Average loss: 0.0694, Accuracy: 1060/1080 F1 (98.1481%)


Test set: Average loss: 1.2415, Accuracy: 52673/69960 F1 (75.2902%)


Val set: Average loss: 1.4318, Accuracy: 253/360 F1 (70.2778%)

best acc test 79.395369  acc val 70.277778 acc labeled target 98.148148
saving model...
S painting T real Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.088807 Loss T 0.050815 Method MME

S painting T real Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.613061 Loss T 0.033725 Method MME

S painting T real Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.093448 Loss T 0.024731 Method MME

S painting T real Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.118440 Loss T 0.039976 Method MME

S painting T real Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.263289 Loss T 0.036506 Method MME


Labeled Target set: Average loss: 0.0217, Accuracy: 1073/1080 F1 (99.3519%)


Test set: Average loss: 1.0175, Accuracy: 55525/69960 F1 (79.3668%)


Val set: Average loss: 1.1064, Accuracy: 275/360 F1 (76.3889%)

best acc test 79.395369  acc val 76.388889 acc labeled target 99.351852
saving model...
S painting T real Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.123456 Loss T 0.028423 Method MME

S painting T real Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.079536 Loss T 0.036492 Method MME

S painting T real Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.288962 Loss T 0.045717 Method MME

S painting T real Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.155401 Loss T 0.051833 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8333333 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [15, 77, 41, 71, 118, 80, 38, 88, 81, 89, 85, 84, 83, 90, 82, 87, 86, 0, 91, 78, 76, 75, 74, 73, 72, 70, 69, 68, 67, 66, 79, 92, 94, 65, 123, 122, 121, 120, 119, 117, 116, 115, 114, 113, 112, 111, 110, 93, 109, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 108, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 37, 36, 35, 34, 33, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 389  477  393  320  549  407  304  456  485  610  420  514  389  404
  468  771  753  622  421  850  382  439  488  495  248  715  435  652
  749  194  409 1032  380  317  371  232  567  447  389  595  628  792
  692  360  765  407  646  741  650  405  757  374  427  363  162  269
  704  541  585  856  608  249  784  555  589  553  201  560  489  491
  536  638  629  650  476  229 1053  482  399  497  863  356  372  273
  666  499  626  480  412  387  635  566  626  702  529  505  422  627
  270  755  597  476  521  528  555  704  429  667  636  569  404  574
  621  532  335  503  531  587  619  630  572  349  538  585  538  647]
CBFL per class weights: tensor([1.0030, 0.9911, 1.0022, 1.0240, 0.9869, 0.9996, 1.0315, 0.9931, 0.9905,
        0.9851, 0.9976, 0.9886, 1.0030, 1.0002, 0.9919, 0.9833, 0.9834, 0.9848,
        0.9974, 0.9831, 1.0045, 0.9950, 0.9902, 0.9897, 1.0715, 0.9837, 0.9955,
        0.9843, 0.9834, 1.1460, 0.9993, 0.9829, 1.0050, 1.0253, 1.0071, 1.0887,
        0.9862, 0.9940, 1.0030, 0.9854, 0.9847, 0.9833, 0.9838, 1.0100, 0.9834,
        0.9996, 0.9844, 0.9835, 0.9843, 1.0000, 0.9834, 1.0064, 0.9965, 1.0092,
        1.2230, 1.0535, 0.9837, 0.9872, 0.9857, 0.9831, 0.9851, 1.0706, 0.9833,
        0.9866, 0.9856, 0.9867, 1.1332, 0.9865, 0.9902, 0.9900, 0.9874, 0.9845,
        0.9847, 0.9843, 0.9912, 1.0922, 0.9829, 0.9907, 1.0011, 0.9896, 0.9831,
        1.0112, 1.0069, 1.0505, 0.9841, 0.9895, 0.9847, 0.9909, 0.9988, 1.0034,
        0.9846, 0.9862, 0.9847, 0.9838, 0.9878, 0.9891, 0.9973, 0.9847, 1.0527,
        0.9834, 0.9854, 0.9912, 0.9882, 0.9878, 0.9866, 0.9837, 0.9963, 0.9841,
        0.9846, 0.9861, 1.0002, 0.9860, 0.9848, 0.9876, 1.0180, 0.9892, 0.9877,
        0.9856, 0.9849, 0.9847, 0.9861, 1.0133, 0.9873, 0.9857, 0.9873, 0.9844],
       device='cuda:0')
S painting T real Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.240000 Loss T 0.039356 Method MME


Labeled Target set: Average loss: 0.0625, Accuracy: 1070/1080 F1 (99.0741%)


Test set: Average loss: 1.1918, Accuracy: 53125/69960 F1 (75.9362%)


Val set: Average loss: 1.2411, Accuracy: 267/360 F1 (74.1667%)

best acc test 79.395369  acc val 74.166667 acc labeled target 99.074074
saving model...
S painting T real Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.108920 Loss T 0.037956 Method MME

S painting T real Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.130991 Loss T 0.024103 Method MME

S painting T real Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.076183 Loss T 0.034710 Method MME

S painting T real Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.085659 Loss T 0.033698 Method MME

S painting T real Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.147631 Loss T 0.037581 Method MME


Labeled Target set: Average loss: 0.0242, Accuracy: 1072/1080 F1 (99.2593%)


Test set: Average loss: 1.0320, Accuracy: 55841/69960 F1 (79.8185%)


Val set: Average loss: 1.1427, Accuracy: 279/360 F1 (77.5000%)

best acc test 79.395369  acc val 77.500000 acc labeled target 99.259259
saving model...
S painting T real Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.073100 Loss T 0.042324 Method MME

S painting T real Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.036686 Loss T 0.026147 Method MME

S painting T real Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.006275 Loss T 0.058378 Method MME

S painting T real Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.009314 Loss T 0.032325 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8333333 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [54, 65, 42, 66, 12, 55, 117, 16, 73, 91, 90, 89, 88, 87, 86, 85, 67, 84, 83, 82, 81, 80, 79, 78, 68, 77, 76, 75, 69, 74, 70, 71, 72, 92, 0, 95, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 93, 94, 62, 63, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 29, 15, 13, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 30, 31, 32, 124, 61, 60, 59, 58, 57, 56, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 391  476  395  316  560  401  306  465  486  611  427  519  356  408
  479  776  757  622  422  862  370  442  490  497  250  727  433  658
  755  199  410 1043  374  317  366  232  560  448  395  606  629  797
  695  358  767  413  643  749  653  410  762  389  424  361  178  270
  702  545  583  871  608  253  786  558  585  551  198  563  502  492
  534  651  639  654  478  227 1057  487  408  499  863  352  353  270
  663  502  632  483  418  388  619  569  629  699  533  507  440  629
  269  764  598  486  528  538  559  705  436  691  644  565  409  597
  623  539  316  504  531  589  618  633  577  350  579  596  542  647]
CBFL per class weights: tensor([1.0030, 0.9916, 1.0022, 1.0261, 0.9868, 1.0010, 1.0309, 0.9925, 0.9908,
        0.9854, 0.9969, 0.9886, 1.0115, 0.9998, 0.9913, 0.9837, 0.9837, 0.9852,
        0.9976, 0.9834, 1.0077, 0.9950, 0.9905, 0.9900, 1.0700, 0.9839, 0.9961,
        0.9846, 0.9838, 1.1372, 0.9995, 0.9833, 1.0067, 1.0257, 1.0087, 1.0890,
        0.9868, 0.9943, 1.0022, 0.9855, 0.9850, 0.9836, 0.9842, 1.0109, 0.9837,
        0.9990, 0.9848, 0.9838, 0.9846, 0.9995, 0.9837, 1.0034, 0.9973, 1.0101,
        1.1806, 1.0531, 0.9841, 0.9874, 0.9861, 0.9834, 0.9854, 1.0672, 0.9836,
        0.9869, 0.9860, 0.9871, 1.1390, 0.9867, 0.9896, 0.9903, 0.9879, 0.9847,
        0.9849, 0.9846, 0.9914, 1.0951, 0.9833, 0.9907, 0.9998, 0.9898, 0.9834,
        1.0127, 1.0124, 1.0531, 0.9845, 0.9896, 0.9850, 0.9910, 0.9982, 1.0036,
        0.9852, 0.9865, 0.9850, 0.9841, 0.9879, 0.9893, 0.9952, 0.9850, 1.0538,
        0.9837, 0.9857, 0.9908, 0.9882, 0.9877, 0.9868, 0.9841, 0.9957, 0.9842,
        0.9848, 0.9866, 0.9997, 0.9857, 0.9851, 0.9876, 1.0261, 0.9895, 0.9880,
        0.9859, 0.9852, 0.9850, 0.9862, 1.0133, 0.9862, 0.9857, 0.9875, 0.9847],
       device='cuda:0')
S painting T real Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.136065 Loss T 0.032497 Method MME


Labeled Target set: Average loss: 0.0546, Accuracy: 1068/1080 F1 (98.8889%)


Test set: Average loss: 1.1847, Accuracy: 53372/69960 F1 (76.2893%)


Val set: Average loss: 1.3474, Accuracy: 259/360 F1 (71.9444%)

best acc test 79.395369  acc val 71.944444 acc labeled target 98.888889
saving model...
S painting T real Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.589256 Loss T 0.057129 Method MME

S painting T real Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.326925 Loss T 0.050014 Method MME

S painting T real Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.087138 Loss T 0.033892 Method MME

S painting T real Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.069577 Loss T 0.038134 Method MME

S painting T real Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.068117 Loss T 0.036290 Method MME


Labeled Target set: Average loss: 0.0230, Accuracy: 1075/1080 F1 (99.5370%)


Test set: Average loss: 1.0268, Accuracy: 55612/69960 F1 (79.4911%)


Val set: Average loss: 1.1738, Accuracy: 277/360 F1 (76.9444%)

best acc test 79.395369  acc val 76.944444 acc labeled target 99.537037
saving model...
S painting T real Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.059183 Loss T 0.038184 Method MME

S painting T real Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.227807 Loss T 0.024602 Method MME

S painting T real Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.061987 Loss T 0.050079 Method MME

S painting T real Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.230871 Loss T 0.041010 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8333333 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [98, 16, 57, 11, 87, 81, 82, 83, 84, 86, 80, 88, 89, 90, 91, 85, 79, 0, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 92, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 97, 96, 94, 64, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 15, 14, 13, 12, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 63, 31, 33, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 393  479  393  316  564  398  306  476  486  615  431  522  325  411
  478  797  764  627  431  862  360  450  496  505  255  736  432  663
  753  201  416 1074  358  315  367  233  551  452  404  609  632  806
  708  365  774  417  652  751  655  419  765  392  428  370  194  268
  700  548  585  901  608  261  797  557  590  556  198  551  508  489
  537  653  630  661  488  234 1064  486  412  496  856  354  330  274
  668  507  649  489  425  380  611  571  631  700  530  509  455  625
  269  766  600  484  536  537  557  712  433  711  647  565  412  608
  622  539  293  506  528  592  608  646  577  351  584  610  541  647]
CBFL per class weights: tensor([1.0029, 0.9916, 1.0029, 1.0265, 0.9870, 1.0020, 1.0312, 0.9919, 0.9911,
        0.9856, 0.9967, 0.9888, 1.0226, 0.9997, 0.9917, 0.9839, 0.9841, 0.9854,
        0.9967, 0.9838, 1.0107, 0.9944, 0.9904, 0.9898, 1.0658, 0.9842, 0.9966,
        0.9849, 0.9841, 1.1340, 0.9989, 0.9836, 1.0113, 1.0269, 1.0088, 1.0883,
        0.9875, 0.9942, 1.0009, 0.9858, 0.9853, 0.9839, 0.9844, 1.0094, 0.9840,
        0.9987, 0.9850, 0.9841, 0.9850, 0.9984, 0.9841, 1.0031, 0.9971, 1.0081,
        1.1468, 1.0550, 0.9845, 0.9876, 0.9864, 0.9837, 0.9858, 1.0606, 0.9839,
        0.9873, 0.9862, 0.9873, 1.1394, 0.9875, 0.9896, 0.9909, 0.9881, 0.9850,
        0.9854, 0.9849, 0.9909, 1.0871, 0.9836, 0.9911, 0.9995, 0.9904, 0.9838,
        1.0125, 1.0206, 1.0505, 0.9848, 0.9897, 0.9851, 0.9909, 0.9975, 1.0057,
        0.9857, 0.9868, 0.9853, 0.9845, 0.9884, 0.9895, 0.9939, 0.9854, 1.0542,
        0.9840, 0.9860, 0.9913, 0.9881, 0.9881, 0.9873, 0.9844, 0.9964, 0.9844,
        0.9851, 0.9870, 0.9995, 0.9858, 0.9855, 0.9880, 1.0382, 0.9897, 0.9885,
        0.9862, 0.9858, 0.9851, 0.9866, 1.0134, 0.9864, 0.9857, 0.9879, 0.9851],
       device='cuda:0')
S painting T real Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.083162 Loss T 0.038513 Method MME


Labeled Target set: Average loss: 0.0668, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.2105, Accuracy: 53365/69960 F1 (76.2793%)


Val set: Average loss: 1.3968, Accuracy: 267/360 F1 (74.1667%)

best acc test 79.395369  acc val 74.166667 acc labeled target 98.518519
saving model...
S painting T real Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.189573 Loss T 0.046373 Method MME

S painting T real Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.546514 Loss T 0.028155 Method MME

S painting T real Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.359214 Loss T 0.052540 Method MME

S painting T real Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.086737 Loss T 0.053238 Method MME

S painting T real Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.174773 Loss T 0.039370 Method MME


Labeled Target set: Average loss: 0.0302, Accuracy: 1071/1080 F1 (99.1667%)


Test set: Average loss: 1.0113, Accuracy: 55941/69960 F1 (79.9614%)


Val set: Average loss: 1.2112, Accuracy: 273/360 F1 (75.8333%)

best acc test 79.395369  acc val 75.833333 acc labeled target 99.166667
saving model...
S painting T real Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.100709 Loss T 0.048891 Method MME

S painting T real Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.151631 Loss T 0.033539 Method MME

S painting T real Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.199000 Loss T 0.031409 Method MME

S painting T real Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.026890 Loss T 0.051521 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.7777778 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [57, 94, 13, 12, 23, 93, 41, 27, 88, 89, 87, 90, 86, 91, 92, 85, 84, 83, 0, 81, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 82, 80, 96, 67, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 95, 66, 62, 64, 30, 29, 28, 26, 25, 24, 22, 21, 20, 19, 18, 17, 31, 16, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 15, 32, 33, 34, 63, 124, 61, 60, 59, 58, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 38, 37, 36, 35, 65, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 394  484  393  318  568  391  307  488  487  621  433  521  295  408
  481  816  772  632  440  905  358  450  501  515  253  742  434  663
  755  202  417 1075  364  316  356  233  525  449  406  614  630  807
  716  368  773  417  653  762  658  420  770  391  430  379  196  274
  699  551  586  908  611  259  796  562  598  557  204  547  513  492
  541  658  632  666  494  244 1076  486  410  497  849  357  322  274
  674  506  657  493  431  381  603  575  634  697  534  512  456  629
  265  770  603  493  540  539  563  707  432  716  640  575  413  592
  622  541  284  508  532  588  606  645  580  355  589  620  551  646]
CBFL per class weights: tensor([1.0028, 0.9914, 1.0030, 1.0257, 0.9870, 1.0034, 1.0308, 0.9911, 0.9911,
        0.9856, 0.9966, 0.9890, 1.0372, 1.0003, 0.9916, 0.9840, 0.9841, 0.9854,
        0.9957, 0.9838, 1.0114, 0.9945, 0.9902, 0.9893, 1.0677, 0.9843, 0.9964,
        0.9850, 0.9842, 1.1324, 0.9988, 0.9837, 1.0097, 1.0266, 1.0120, 1.0884,
        0.9888, 0.9946, 1.0006, 0.9858, 0.9855, 0.9840, 0.9845, 1.0087, 0.9841,
        0.9988, 0.9851, 0.9842, 0.9850, 0.9984, 0.9841, 1.0034, 0.9970, 1.0060,
        1.1432, 1.0506, 0.9846, 0.9876, 0.9864, 0.9838, 0.9858, 1.0624, 0.9840,
        0.9872, 0.9861, 0.9874, 1.1290, 0.9878, 0.9894, 0.9908, 0.9880, 0.9850,
        0.9854, 0.9849, 0.9906, 1.0764, 0.9837, 0.9912, 0.9999, 0.9904, 0.9839,
        1.0117, 1.0240, 1.0506, 0.9848, 0.9898, 0.9851, 0.9907, 0.9968, 1.0056,
        0.9860, 0.9868, 0.9854, 0.9846, 0.9883, 0.9895, 0.9939, 0.9855, 1.0574,
        0.9841, 0.9860, 0.9907, 0.9881, 0.9881, 0.9872, 0.9845, 0.9967, 0.9845,
        0.9853, 0.9868, 0.9995, 0.9863, 0.9856, 0.9880, 1.0438, 0.9897, 0.9884,
        0.9864, 0.9859, 0.9852, 0.9866, 1.0123, 0.9864, 0.9857, 0.9876, 0.9852],
       device='cuda:0')
S painting T real Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.087233 Loss T 0.029023 Method MME


Labeled Target set: Average loss: 0.0280, Accuracy: 1075/1080 F1 (99.5370%)


Test set: Average loss: 1.1575, Accuracy: 53880/69960 F1 (77.0154%)


Val set: Average loss: 1.3114, Accuracy: 264/360 F1 (73.3333%)

best acc test 79.395369  acc val 73.333333 acc labeled target 99.537037
saving model...
S painting T real Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.182370 Loss T 0.061160 Method MME

S painting T real Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.160575 Loss T 0.036932 Method MME

S painting T real Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.197030 Loss T 0.037611 Method MME

S painting T real Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.202452 Loss T 0.038267 Method MME

S painting T real Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.078829 Loss T 0.049884 Method MME


Labeled Target set: Average loss: 0.0173, Accuracy: 1077/1080 F1 (99.7222%)


Test set: Average loss: 1.0191, Accuracy: 55980/69960 F1 (80.0172%)


Val set: Average loss: 1.1797, Accuracy: 275/360 F1 (76.3889%)

best acc test 79.395369  acc val 76.388889 acc labeled target 99.722222
saving model...
S painting T real Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.098331 Loss T 0.038928 Method MME

S painting T real Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.025277 Loss T 0.025371 Method MME

S painting T real Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.444897 Loss T 0.037252 Method MME

S painting T real Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.242879 Loss T 0.042986 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [34, 51, 13, 0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 78, 92, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 65, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 393  484  391  319  576  384  304  489  486  623  435  529  265  403
  483  816  780  634  443  916  372  456  507  516  252  740  436  666
  764  203  419 1059  359  316  352  236  508  457  409  620  638  803
  709  371  779  414  662  762  661  423  776  393  430  378  195  276
  703  550  583  918  611  271  802  558  597  564  206  548  531  497
  539  662  654  669  491  254 1089  479  408  498  866  360  315  275
  681  507  666  498  444  384  589  576  636  700  537  513  458  630
  264  768  608  502  542  540  573  702  437  720  637  578  413  598
  624  542  269  507  534  587  618  645  581  353  597  621  559  647]
CBFL per class weights: tensor([1.0030, 0.9914, 1.0034, 1.0253, 0.9867, 1.0049, 1.0324, 0.9910, 0.9912,
        0.9856, 0.9963, 0.9886, 1.0574, 1.0012, 0.9915, 0.9840, 0.9841, 0.9854,
        0.9953, 0.9838, 1.0077, 0.9939, 0.9898, 0.9893, 1.0686, 0.9843, 0.9962,
        0.9849, 0.9842, 1.1307, 0.9985, 0.9838, 1.0111, 1.0266, 1.0132, 1.0850,
        0.9897, 0.9938, 1.0001, 0.9857, 0.9853, 0.9840, 0.9845, 1.0079, 0.9841,
        0.9993, 0.9850, 0.9842, 0.9850, 0.9979, 0.9841, 1.0030, 0.9970, 1.0063,
        1.1450, 1.0492, 0.9846, 0.9877, 0.9865, 0.9838, 0.9859, 1.0528, 0.9840,
        0.9873, 0.9862, 0.9871, 1.1257, 0.9877, 0.9885, 0.9904, 0.9881, 0.9850,
        0.9851, 0.9849, 0.9909, 1.0668, 0.9837, 0.9918, 1.0003, 0.9904, 0.9839,
        1.0109, 1.0270, 1.0499, 0.9848, 0.9898, 0.9849, 0.9904, 0.9952, 1.0049,
        0.9864, 0.9867, 0.9854, 0.9846, 0.9882, 0.9894, 0.9937, 0.9855, 1.0582,
        0.9842, 0.9859, 0.9901, 0.9880, 0.9881, 0.9868, 0.9846, 0.9961, 0.9844,
        0.9854, 0.9867, 0.9995, 0.9861, 0.9856, 0.9880, 1.0543, 0.9898, 0.9883,
        0.9864, 0.9857, 0.9852, 0.9866, 1.0129, 0.9862, 0.9856, 0.9873, 0.9852],
       device='cuda:0')
S painting T real Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.012048 Loss T 0.033070 Method MME


Labeled Target set: Average loss: 0.0294, Accuracy: 1075/1080 F1 (99.5370%)


Test set: Average loss: 1.1410, Accuracy: 54366/69960 F1 (77.7101%)


Val set: Average loss: 1.2901, Accuracy: 269/360 F1 (74.7222%)

best acc test 79.395369  acc val 74.722222 acc labeled target 99.537037
saving model...
S painting T real Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.122829 Loss T 0.038028 Method MME

S painting T real Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.093411 Loss T 0.038114 Method MME

S painting T real Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.049158 Loss T 0.039072 Method MME

S painting T real Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.075543 Loss T 0.040325 Method MME

S painting T real Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.085667 Loss T 0.023654 Method MME


Labeled Target set: Average loss: 0.0136, Accuracy: 1077/1080 F1 (99.7222%)


Test set: Average loss: 1.0417, Accuracy: 55954/69960 F1 (79.9800%)


Val set: Average loss: 1.1535, Accuracy: 277/360 F1 (76.9444%)

best acc test 79.395369  acc val 76.944444 acc labeled target 99.722222
saving model...
S painting T real Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.254132 Loss T 0.032861 Method MME

S painting T real Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.290986 Loss T 0.044224 Method MME

S painting T real Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.015526 Loss T 0.029336 Method MME

S painting T real Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.089457 Loss T 0.030786 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8333333 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [10, 23, 78, 0, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 79, 93, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 94, 95, 96, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 65, 64, 62, 124, 29, 28, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 31, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 63, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 47, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 393  486  388  325  585  380  304  484  488  632  435  537  246  410
  485  819  787  637  447  936  375  454  508  519  251  744  439  667
  764  204  419 1063  355  311  361  233  490  460  412  623  639  804
  712  371  776  418  679  759  665  423  775  400  430  385  188  275
  708  553  587  930  613  293  800  558  598  570  202  551  540  498
  538  672  662  673  496  255 1087  477  409  499  841  364  296  279
  682  516  672  507  454  386  576  577  636  706  538  510  457  633
  261  772  613  503  543  543  574  705  440  725  634  578  417  592
  627  543  259  509  536  585  630  647  580  357  606  627  559  647]
CBFL per class weights: tensor([1.0028, 0.9910, 1.0038, 1.0225, 0.9863, 1.0056, 1.0321, 0.9912, 0.9909,
        0.9852, 0.9961, 0.9880, 1.0742, 0.9997, 0.9911, 0.9838, 0.9839, 0.9851,
        0.9946, 0.9836, 1.0067, 0.9939, 0.9895, 0.9889, 1.0693, 0.9841, 0.9956,
        0.9847, 0.9840, 1.1288, 0.9983, 0.9835, 1.0121, 1.0287, 1.0104, 1.0882,
        0.9907, 0.9933, 0.9994, 0.9854, 0.9851, 0.9838, 0.9843, 1.0077, 0.9839,
        0.9985, 0.9846, 0.9840, 0.9847, 0.9977, 0.9839, 1.0015, 0.9968, 1.0045,
        1.1586, 1.0497, 0.9843, 0.9873, 0.9862, 0.9836, 0.9856, 1.0381, 0.9838,
        0.9871, 0.9859, 0.9867, 1.1322, 0.9874, 0.9879, 0.9902, 0.9879, 0.9847,
        0.9848, 0.9847, 0.9903, 1.0657, 0.9835, 0.9917, 0.9999, 0.9901, 0.9837,
        1.0095, 1.0364, 1.0469, 0.9846, 0.9890, 0.9847, 0.9896, 0.9939, 1.0043,
        0.9865, 0.9865, 0.9852, 0.9843, 0.9879, 0.9894, 0.9936, 0.9852, 1.0605,
        0.9839, 0.9856, 0.9898, 0.9877, 0.9877, 0.9866, 0.9843, 0.9955, 0.9842,
        0.9852, 0.9865, 0.9986, 0.9861, 0.9853, 0.9877, 1.0622, 0.9895, 0.9880,
        0.9863, 0.9853, 0.9850, 0.9864, 1.0115, 0.9857, 0.9853, 0.9871, 0.9850],
       device='cuda:0')
S painting T real Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.184587 Loss T 0.040038 Method MME


Labeled Target set: Average loss: 0.0516, Accuracy: 1067/1080 F1 (98.7963%)


Test set: Average loss: 1.2031, Accuracy: 53148/69960 F1 (75.9691%)


Val set: Average loss: 1.3705, Accuracy: 260/360 F1 (72.2222%)

best acc test 79.395369  acc val 72.222222 acc labeled target 98.796296
saving model...
S painting T real Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.162909 Loss T 0.027229 Method MME

S painting T real Train Ep: 22200 lr0.004160141438467499 	 Loss Classification: 0.194862 Loss T 0.042804 Method MME

S painting T real Train Ep: 22300 lr0.004150477924193236 	 Loss Classification: 0.061482 Loss T 0.027570 Method MME

S painting T real Train Ep: 22400 lr0.00414086662499961 	 Loss Classification: 0.019010 Loss T 0.046250 Method MME

S painting T real Train Ep: 22500 lr0.004131307098896385 	 Loss Classification: 0.074444 Loss T 0.046536 Method MME


Labeled Target set: Average loss: 0.0052, Accuracy: 1080/1080 F1 (100.0000%)


Test set: Average loss: 1.0471, Accuracy: 55915/69960 F1 (79.9242%)


Val set: Average loss: 1.1958, Accuracy: 276/360 F1 (76.6667%)

best acc test 79.395369  acc val 76.666667 acc labeled target 100.000000
saving model...
S painting T real Train Ep: 22600 lr0.0041217989089795196 	 Loss Classification: 0.036692 Loss T 0.046152 Method MME

S painting T real Train Ep: 22700 lr0.004112341623357265 	 Loss Classification: 0.090672 Loss T 0.039265 Method MME

S painting T real Train Ep: 22800 lr0.004102934815077543 	 Loss Classification: 0.042878 Loss T 0.042978 Method MME

S painting T real Train Ep: 22900 lr0.004093578062056604 	 Loss Classification: 0.055446 Loss T 0.022553 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
Top k classes which perform poorly are:  [0, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 92, 93, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 64, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 63, 62, 61, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 124, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 31, 47, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 395  489  390  331  575  392  304  484  491  635  439  535  230  421
  480  845  783  637  451  942  368  456  518  525  251  742  441  670
  766  204  420 1067  364  311  363  226  480  459  410  627  643  807
  716  384  785  418  675  763  667  425  779  407  429  388  192  276
  711  556  583  922  613  282  801  557  599  571  199  551  560  508
  540  684  666  673  502  251 1085  466  411  503  807  358  282  279
  683  526  678  505  496  389  575  577  636  704  540  514  468  632
  259  771  612  508  544  550  575  710  452  738  643  577  418  565
  625  542  249  508  538  588  629  651  590  354  614  625  562  646]
CBFL per class weights: tensor([1.0022, 0.9906, 1.0032, 1.0199, 0.9863, 1.0028, 1.0319, 0.9909, 0.9904,
        0.9850, 0.9954, 0.9878, 1.0915, 0.9978, 0.9912, 0.9835, 0.9837, 0.9849,
        0.9940, 0.9834, 1.0082, 0.9934, 0.9887, 0.9883, 1.0691, 0.9839, 0.9951,
        0.9845, 0.9837, 1.1285, 0.9979, 0.9833, 1.0093, 1.0284, 1.0096, 1.0964,
        0.9912, 0.9931, 0.9995, 0.9851, 0.9848, 0.9836, 0.9840, 1.0045, 0.9837,
        0.9982, 0.9844, 0.9837, 0.9845, 0.9972, 0.9837, 1.0000, 0.9967, 1.0036,
        1.1503, 1.0487, 0.9841, 0.9870, 0.9861, 0.9834, 0.9854, 1.0447, 0.9836,
        0.9869, 0.9857, 0.9865, 1.1372, 0.9872, 0.9868, 0.9893, 0.9876, 0.9843,
        0.9845, 0.9844, 0.9897, 1.0691, 0.9833, 0.9925, 0.9993, 0.9896, 0.9836,
        1.0110, 1.0447, 1.0467, 0.9843, 0.9883, 0.9844, 0.9895, 0.9901, 1.0034,
        0.9863, 0.9863, 0.9849, 0.9841, 0.9876, 0.9889, 0.9923, 0.9850, 1.0619,
        0.9837, 0.9854, 0.9893, 0.9875, 0.9872, 0.9863, 0.9841, 0.9939, 0.9839,
        0.9848, 0.9863, 0.9982, 0.9867, 0.9851, 0.9875, 1.0710, 0.9893, 0.9877,
        0.9860, 0.9851, 0.9847, 0.9859, 1.0121, 0.9853, 0.9851, 0.9868, 0.9848],
       device='cuda:0')
S painting T real Train Ep: 23000 lr0.00408427094700893 	 Loss Classification: 0.071919 Loss T 0.037028 Method MME


Labeled Target set: Average loss: 0.0506, Accuracy: 1068/1080 F1 (98.8889%)


Test set: Average loss: 1.1465, Accuracy: 53947/69960 F1 (77.1112%)


Val set: Average loss: 1.2315, Accuracy: 274/360 F1 (76.1111%)

best acc test 79.395369  acc val 76.111111 acc labeled target 98.888889
saving model...
S painting T real Train Ep: 23100 lr0.004075013057378346 	 Loss Classification: 0.008848 Loss T 0.034435 Method MME

S painting T real Train Ep: 23200 lr0.004065803985270331 	 Loss Classification: 0.043256 Loss T 0.030859 Method MME

S painting T real Train Ep: 23300 lr0.004056643327385506 	 Loss Classification: 0.023057 Loss T 0.056091 Method MME

S painting T real Train Ep: 23400 lr0.004047530684954247 	 Loss Classification: 0.132976 Loss T 0.043611 Method MME

S painting T real Train Ep: 23500 lr0.0040384656636724406 	 Loss Classification: 0.050013 Loss T 0.028748 Method MME


Labeled Target set: Average loss: 0.0151, Accuracy: 1077/1080 F1 (99.7222%)


Test set: Average loss: 0.9958, Accuracy: 56205/69960 F1 (80.3388%)


Val set: Average loss: 1.1025, Accuracy: 279/360 F1 (77.5000%)

best acc test 79.395369  acc val 77.500000 acc labeled target 99.722222
saving model...
S painting T real Train Ep: 23600 lr0.004029447873638333 	 Loss Classification: 0.015891 Loss T 0.019808 Method MME

S painting T real Train Ep: 23700 lr0.00402047692929045 	 Loss Classification: 0.036096 Loss T 0.024594 Method MME

S painting T real Train Ep: 23800 lr0.004011552449346588 	 Loss Classification: 0.188774 Loss T 0.030843 Method MME

S painting T real Train Ep: 23900 lr0.004002674056743821 	 Loss Classification: 0.204813 Loss T 0.041227 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [12, 10, 15, 0, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 86, 80, 78, 93, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 94, 96, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 95, 64, 62, 124, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 13, 11, 9, 8, 7, 6, 5, 4, 3, 2, 1, 31, 63, 32, 34, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 33, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 394  490  392  332  576  380  303  485  490  630  442  545  214  419
  481  859  792  638  449  942  357  459  519  539  250  745  440  679
  771  206  424 1079  359  308  362  226  476  459  412  625  647  813
  722  391  787  418  677  770  670  426  783  407  430  382  189  272
  709  557  584  927  608  297  800  554  603  573  204  545  572  509
  539  700  670  674  508  249 1090  465  416  503  800  359  275  276
  678  529  689  503  499  393  561  571  637  703  545  514  463  633
  255  772  615  513  545  550  570  718  466  740  650  579  419  570
  632  543  243  508  535  585  632  650  583  357  625  627  571  646]
CBFL per class weights: tensor([1.0022, 0.9903, 1.0026, 1.0193, 0.9861, 1.0051, 1.0322, 0.9906, 0.9903,
        0.9848, 0.9948, 0.9872, 1.1126, 0.9979, 0.9909, 0.9832, 0.9834, 0.9847,
        0.9940, 0.9831, 1.0110, 0.9929, 0.9884, 0.9874, 1.0698, 0.9836, 0.9950,
        0.9841, 0.9835, 1.1250, 0.9971, 0.9831, 1.0104, 1.0297, 1.0096, 1.0961,
        0.9913, 0.9929, 0.9990, 0.9849, 0.9845, 0.9833, 0.9838, 1.0028, 0.9834,
        0.9980, 0.9842, 0.9835, 0.9842, 0.9968, 0.9834, 0.9998, 0.9963, 1.0047,
        1.1561, 1.0514, 0.9839, 0.9867, 0.9858, 0.9831, 0.9852, 1.0354, 0.9834,
        0.9868, 0.9854, 0.9862, 1.1283, 0.9872, 0.9862, 0.9890, 0.9874, 0.9839,
        0.9842, 0.9842, 0.9891, 1.0707, 0.9831, 0.9923, 0.9983, 0.9894, 0.9834,
        1.0104, 1.0492, 1.0485, 0.9841, 0.9879, 0.9840, 0.9894, 0.9896, 1.0024,
        0.9866, 0.9862, 0.9847, 0.9839, 0.9872, 0.9887, 0.9925, 0.9848, 1.0652,
        0.9835, 0.9851, 0.9888, 0.9872, 0.9870, 0.9863, 0.9838, 0.9922, 0.9836,
        0.9845, 0.9860, 0.9979, 0.9863, 0.9848, 0.9873, 1.0767, 0.9891, 0.9876,
        0.9858, 0.9848, 0.9845, 0.9859, 1.0110, 0.9849, 0.9849, 0.9862, 0.9846],
       device='cuda:0')
S painting T real Train Ep: 24000 lr0.0039938413785795416 	 Loss Classification: 0.339423 Loss T 0.041182 Method MME


Labeled Target set: Average loss: 0.0404, Accuracy: 1072/1080 F1 (99.2593%)


Test set: Average loss: 1.1313, Accuracy: 54280/69960 F1 (77.5872%)


Val set: Average loss: 1.2137, Accuracy: 268/360 F1 (74.4444%)

best acc test 79.395369  acc val 74.444444 acc labeled target 99.259259
saving model...
S painting T real Train Ep: 24100 lr0.003985054046053481 	 Loss Classification: 0.018085 Loss T 0.043120 Method MME

S painting T real Train Ep: 24200 lr0.003976311694410721 	 Loss Classification: 0.152952 Loss T 0.027694 Method MME

S painting T real Train Ep: 24300 lr0.00396761396288564 	 Loss Classification: 0.017295 Loss T 0.036332 Method MME

S painting T real Train Ep: 24400 lr0.003958960494646819 	 Loss Classification: 0.275752 Loss T 0.030544 Method MME

S painting T real Train Ep: 24500 lr0.0039503509367428465 	 Loss Classification: 0.045011 Loss T 0.030835 Method MME


Labeled Target set: Average loss: 0.0177, Accuracy: 1074/1080 F1 (99.4444%)


Test set: Average loss: 1.0175, Accuracy: 56214/69960 F1 (80.3516%)


Val set: Average loss: 1.1877, Accuracy: 280/360 F1 (77.7778%)

best acc test 80.351630  acc val 77.777778 acc labeled target 99.444444
saving model...
S painting T real Train Ep: 24600 lr0.00394178494004904 	 Loss Classification: 0.029263 Loss T 0.051588 Method MME

S painting T real Train Ep: 24700 lr0.003933262159215038 	 Loss Classification: 0.272975 Loss T 0.033093 Method MME

S painting T real Train Ep: 24800 lr0.00392478225261327 	 Loss Classification: 0.292927 Loss T 0.042813 Method MME

S painting T real Train Ep: 24900 lr0.003916344882288264 	 Loss Classification: 0.030836 Loss T 0.048427 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8333333 1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8333333 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [88, 51, 15, 104, 57, 71, 81, 82, 83, 85, 80, 86, 87, 89, 90, 84, 79, 0, 91, 77, 76, 75, 74, 73, 72, 70, 69, 68, 67, 66, 78, 92, 94, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 103, 102, 101, 100, 99, 98, 97, 96, 95, 109, 64, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 56, 55, 54, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 395  489  396  334  575  378  304  488  492  630  445  544  201  416
  483  881  797  639  454  945  344  464  521  534  247  749  446  679
  773  206  425 1110  356  312  370  230  468  463  420  629  647  813
  722  394  791  421  673  766  669  429  784  405  436  386  187  268
  714  559  585  939  610  294  802  552  603  575  211  539  571  509
  537  691  665  676  506  248 1090  467  417  503  799  365  267  285
  678  529  690  506  490  396  555  569  639  704  541  517  470  631
  254  776  613  521  549  551  571  723  471  744  658  584  422  564
  632  541  237  512  537  586  634  649  580  361  644  628  569  647]
CBFL per class weights: tensor([1.0019, 0.9902, 1.0017, 1.0185, 0.9860, 1.0055, 1.0316, 0.9903, 0.9900,
        0.9847, 0.9943, 0.9871, 1.1333, 0.9982, 0.9907, 0.9831, 0.9833, 0.9846,
        0.9933, 0.9830, 1.0149, 0.9923, 0.9882, 0.9876, 1.0726, 0.9835, 0.9942,
        0.9840, 0.9834, 1.1248, 0.9969, 0.9830, 1.0112, 1.0276, 1.0074, 1.0911,
        0.9920, 0.9924, 0.9976, 0.9847, 0.9844, 0.9832, 0.9837, 1.0021, 0.9833,
        0.9975, 0.9841, 0.9834, 0.9841, 0.9963, 0.9833, 1.0000, 0.9954, 1.0037,
        1.1601, 1.0543, 0.9837, 0.9865, 0.9857, 0.9830, 0.9851, 1.0370, 0.9833,
        0.9868, 0.9853, 0.9860, 1.1169, 0.9873, 0.9861, 0.9889, 0.9874, 0.9839,
        0.9842, 0.9841, 0.9891, 1.0716, 0.9830, 0.9920, 0.9981, 0.9893, 0.9833,
        1.0087, 1.0551, 1.0424, 0.9840, 0.9878, 0.9839, 0.9891, 0.9902, 1.0017,
        0.9867, 0.9862, 0.9846, 0.9838, 0.9873, 0.9884, 0.9918, 0.9847, 1.0660,
        0.9834, 0.9850, 0.9882, 0.9869, 0.9868, 0.9861, 0.9836, 0.9917, 0.9835,
        0.9843, 0.9857, 0.9973, 0.9864, 0.9847, 0.9873, 1.0830, 0.9887, 0.9874,
        0.9857, 0.9846, 0.9844, 0.9859, 1.0098, 0.9845, 0.9847, 0.9862, 0.9844],
       device='cuda:0')
S painting T real Train Ep: 25000 lr0.003907949713906802 	 Loss Classification: 0.025546 Loss T 0.045404 Method MME


Labeled Target set: Average loss: 0.0474, Accuracy: 1066/1080 F1 (98.7037%)


Test set: Average loss: 1.1673, Accuracy: 53940/69960 F1 (77.1012%)


Val set: Average loss: 1.3353, Accuracy: 269/360 F1 (74.7222%)

best acc test 80.351630  acc val 74.722222 acc labeled target 98.703704
saving model...
S painting T real Train Ep: 25100 lr0.003899596416708869 	 Loss Classification: 0.052173 Loss T 0.038198 Method MME

S painting T real Train Ep: 25200 lr0.0038912846634594346 	 Loss Classification: 0.032343 Loss T 0.041550 Method MME

S painting T real Train Ep: 25300 lr0.0038830141304009892 	 Loss Classification: 0.187599 Loss T 0.037015 Method MME

S painting T real Train Ep: 25400 lr0.003874784497206876 	 Loss Classification: 0.035915 Loss T 0.033470 Method MME

S painting T real Train Ep: 25500 lr0.003866595446935362 	 Loss Classification: 0.268279 Loss T 0.028048 Method MME


Labeled Target set: Average loss: 0.0275, Accuracy: 1072/1080 F1 (99.2593%)


Test set: Average loss: 1.0386, Accuracy: 56212/69960 F1 (80.3488%)


Val set: Average loss: 1.1817, Accuracy: 276/360 F1 (76.6667%)

best acc test 80.351630  acc val 76.666667 acc labeled target 99.259259
saving model...
S painting T real Train Ep: 25600 lr0.003858446665984465 	 Loss Classification: 0.036292 Loss T 0.049653 Method MME

S painting T real Train Ep: 25700 lr0.0038503378440474917 	 Loss Classification: 0.041085 Loss T 0.037188 Method MME

S painting T real Train Ep: 25800 lr0.003842268674069313 	 Loss Classification: 0.211003 Loss T 0.036527 Method MME

S painting T real Train Ep: 25900 lr0.0038342388522033147 	 Loss Classification: 0.033566 Loss T 0.030359 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [66, 65, 77, 27, 51, 54, 114, 0, 83, 84, 85, 86, 87, 88, 89, 90, 91, 82, 81, 78, 79, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 80, 92, 94, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 93, 64, 62, 124, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 63, 30, 32, 61, 60, 59, 58, 57, 56, 55, 53, 52, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 397  485  397  334  575  380  305  483  494  634  452  543  182  412
  485  873  796  637  455  954  342  467  524  528  249  753  443  682
  777  205  426 1121  362  316  379  232  458  464  431  629  650  810
  730  396  786  426  669  767  672  428  790  404  437  386  188  282
  717  559  583  949  615  285  798  556  609  577  220  540  574  513
  539  689  666  676  503  246 1095  462  413  509  790  367  260  287
  688  537  694  515  520  402  539  573  640  703  539  519  470  631
  256  764  612  531  546  553  571  722  474  750  668  583  420  556
  637  540  229  512  535  588  637  651  584  359  654  629  564  647]
CBFL per class weights: tensor([1.0014, 0.9904, 1.0014, 1.0183, 0.9859, 1.0049, 1.0309, 0.9905, 0.9897,
        0.9845, 0.9934, 0.9870, 1.1708, 0.9987, 0.9904, 0.9830, 0.9832, 0.9845,
        0.9931, 0.9829, 1.0155, 0.9919, 0.9879, 0.9877, 1.0705, 0.9833, 0.9944,
        0.9839, 0.9832, 1.1263, 0.9966, 0.9828, 1.0094, 1.0257, 1.0051, 1.0886,
        0.9928, 0.9922, 0.9959, 0.9846, 0.9843, 0.9831, 0.9835, 1.0015, 0.9832,
        0.9966, 0.9840, 0.9833, 0.9840, 0.9963, 0.9832, 1.0001, 0.9951, 1.0036,
        1.1578, 1.0442, 0.9836, 0.9864, 0.9856, 0.9829, 0.9849, 1.0423, 0.9831,
        0.9865, 0.9850, 0.9858, 1.1038, 0.9872, 0.9859, 0.9885, 0.9872, 0.9838,
        0.9840, 0.9839, 0.9891, 1.0734, 0.9828, 0.9924, 0.9986, 0.9888, 0.9832,
        1.0080, 1.0606, 1.0410, 0.9838, 0.9873, 0.9837, 0.9884, 0.9881, 1.0004,
        0.9872, 0.9859, 0.9844, 0.9837, 0.9872, 0.9882, 0.9916, 0.9846, 1.0640,
        0.9833, 0.9849, 0.9876, 0.9869, 0.9866, 0.9860, 0.9835, 0.9913, 0.9833,
        0.9840, 0.9856, 0.9975, 0.9865, 0.9845, 0.9872, 1.0922, 0.9886, 0.9874,
        0.9855, 0.9845, 0.9842, 0.9856, 1.0102, 0.9842, 0.9846, 0.9862, 0.9843],
       device='cuda:0')
S painting T real Train Ep: 26000 lr0.0038262480777690546 	 Loss Classification: 0.146891 Loss T 0.044686 Method MME


Labeled Target set: Average loss: 0.0710, Accuracy: 1062/1080 F1 (98.3333%)


Test set: Average loss: 1.1644, Accuracy: 53904/69960 F1 (77.0497%)


Val set: Average loss: 1.3069, Accuracy: 265/360 F1 (73.6111%)

best acc test 80.351630  acc val 73.611111 acc labeled target 98.333333
saving model...
S painting T real Train Ep: 26100 lr0.0038182960532105875 	 Loss Classification: 0.031291 Loss T 0.043457 Method MME

S painting T real Train Ep: 26200 lr0.0038103824840554513 	 Loss Classification: 0.017484 Loss T 0.037853 Method MME

S painting T real Train Ep: 26300 lr0.0038025070788743048 	 Loss Classification: 0.011858 Loss T 0.029390 Method MME

S painting T real Train Ep: 26400 lr0.003794669549241204 	 Loss Classification: 0.026387 Loss T 0.036651 Method MME

S painting T real Train Ep: 26500 lr0.0037868696096944997 	 Loss Classification: 0.029283 Loss T 0.036337 Method MME


Labeled Target set: Average loss: 0.0138, Accuracy: 1076/1080 F1 (99.6296%)


Test set: Average loss: 1.0368, Accuracy: 56174/69960 F1 (80.2945%)


Val set: Average loss: 1.1520, Accuracy: 276/360 F1 (76.6667%)

best acc test 80.351630  acc val 76.666667 acc labeled target 99.629630
saving model...
S painting T real Train Ep: 26600 lr0.00377910697769836 	 Loss Classification: 0.105890 Loss T 0.035150 Method MME

S painting T real Train Ep: 26700 lr0.0037713813736048834 	 Loss Classification: 0.045919 Loss T 0.059637 Method MME

S painting T real Train Ep: 26800 lr0.0037636925206168117 	 Loss Classification: 0.210458 Loss T 0.034672 Method MME

S painting T real Train Ep: 26900 lr0.0037560401447508216 	 Loss Classification: 0.110102 Loss T 0.031119 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [16, 36, 27, 99, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 92, 0, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 80, 93, 95, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 94, 64, 62, 124, 29, 28, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 63, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 34, 32, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 398  487  394  334  568  378  304  476  496  632  454  543  171  409
  491  871  797  636  458  962  335  470  527  525  249  753  445  682
  782  205  425 1136  358  315  382  231  452  465  437  631  650  813
  726  393  791  430  672  768  678  431  792  406  439  391  184  286
  720  560  581  950  619  289  801  556  610  574  225  540  577  515
  543  689  661  679  504  243 1099  461  414  514  779  369  254  287
  687  539  696  516  526  402  538  572  639  703  546  520  464  631
  257  766  615  531  547  553  573  722  476  757  679  578  421  557
  640  542  226  514  536  588  645  656  581  356  655  630  573  648]
CBFL per class weights: tensor([1.0009, 0.9900, 1.0016, 1.0180, 0.9858, 1.0051, 1.0311, 0.9908, 0.9893,
        0.9843, 0.9929, 0.9868, 1.1972, 0.9989, 0.9897, 0.9827, 0.9829, 0.9842,
        0.9925, 0.9826, 1.0177, 0.9914, 0.9875, 0.9876, 1.0702, 0.9831, 0.9939,
        0.9836, 0.9829, 1.1260, 0.9965, 0.9826, 1.0102, 1.0258, 1.0041, 1.0894,
        0.9931, 0.9918, 0.9949, 0.9843, 0.9840, 0.9828, 0.9832, 1.0018, 0.9829,
        0.9958, 0.9837, 0.9830, 0.9836, 0.9956, 0.9829, 0.9994, 0.9946, 1.0022,
        1.1660, 1.0413, 0.9833, 0.9861, 0.9854, 0.9826, 0.9845, 1.0395, 0.9829,
        0.9862, 0.9847, 0.9856, 1.0969, 0.9869, 0.9855, 0.9881, 0.9868, 0.9835,
        0.9838, 0.9836, 0.9888, 1.0761, 0.9826, 0.9922, 0.9981, 0.9882, 0.9829,
        1.0072, 1.0655, 1.0407, 0.9835, 0.9869, 0.9834, 0.9881, 0.9875, 1.0001,
        0.9870, 0.9857, 0.9841, 0.9834, 0.9866, 0.9879, 0.9919, 0.9843, 1.0628,
        0.9830, 0.9846, 0.9873, 0.9866, 0.9863, 0.9857, 0.9832, 0.9908, 0.9830,
        0.9836, 0.9855, 0.9970, 0.9862, 0.9841, 0.9868, 1.0956, 0.9882, 0.9871,
        0.9852, 0.9841, 0.9839, 0.9854, 1.0108, 0.9839, 0.9843, 0.9857, 0.9840],
       device='cuda:0')
S painting T real Train Ep: 27000 lr0.003748423974801389 	 Loss Classification: 0.396074 Loss T 0.025165 Method MME


Labeled Target set: Average loss: 0.0367, Accuracy: 1072/1080 F1 (99.2593%)


Test set: Average loss: 1.1179, Accuracy: 54527/69960 F1 (77.9403%)


Val set: Average loss: 1.2189, Accuracy: 267/360 F1 (74.1667%)

best acc test 80.351630  acc val 74.166667 acc labeled target 99.259259
saving model...
S painting T real Train Ep: 27100 lr0.003740843742305213 	 Loss Classification: 0.267972 Loss T 0.016432 Method MME

S painting T real Train Ep: 27200 lr0.0037332991815061845 	 Loss Classification: 0.175217 Loss T 0.030252 Method MME

S painting T real Train Ep: 27300 lr0.003725790029320905 	 Loss Classification: 0.303040 Loss T 0.020814 Method MME

S painting T real Train Ep: 27400 lr0.0037183160253047272 	 Loss Classification: 0.307329 Loss T 0.036030 Method MME

S painting T real Train Ep: 27500 lr0.003710876911618321 	 Loss Classification: 0.056505 Loss T 0.034111 Method MME


Labeled Target set: Average loss: 0.0283, Accuracy: 1074/1080 F1 (99.4444%)


Test set: Average loss: 1.0187, Accuracy: 56311/69960 F1 (80.4903%)


Val set: Average loss: 1.1740, Accuracy: 278/360 F1 (77.2222%)

best acc test 80.351630  acc val 77.222222 acc labeled target 99.444444
saving model...
S painting T real Train Ep: 27600 lr0.0037034724329947483 	 Loss Classification: 0.160090 Loss T 0.038590 Method MME

S painting T real Train Ep: 27700 lr0.0036961023367070435 	 Loss Classification: 0.069039 Loss T 0.032567 Method MME

S painting T real Train Ep: 27800 lr0.003688766372536283 	 Loss Classification: 0.044782 Loss T 0.026361 Method MME

S painting T real Train Ep: 27900 lr0.0036814642927401444 	 Loss Classification: 0.086050 Loss T 0.035148 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 0.8888889 1.        1.       ]
Top k classes which perform poorly are:  [79, 123, 122, 66, 69, 54, 81, 82, 83, 84, 85, 0, 80, 88, 89, 90, 86, 87, 76, 77, 91, 75, 74, 73, 72, 71, 70, 68, 67, 65, 78, 92, 93, 94, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 64, 63, 62, 61, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 29, 30, 31, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 124, 46, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 45, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
Predicted Number of Examples per Class is (According to the pseudo labels + labelled target examples):  [ 400  491  402  332  583  371  296  474  497  636  454  544  164  419
  490  861  803  634  458  972  333  472  526  527  247  751  447  679
  784  205  426 1137  360  318  386  233  444  468  439  631  652  812
  728  399  786  425  679  766  674  429  795  403  437  399  183  286
  725  560  590  958  620  296  806  562  608  577  226  541  578  512
  546  691  661  682  506  245 1103  469  414  514  779  368  249  287
  687  541  705  519  522  406  534  577  639  707  543  519  462  629
  257  766  616  537  548  549  574  722  475  753  668  576  429  555
  639  546  221  517  538  589  649  660  576  356  663  631  576  645]
CBFL per class weights: tensor([1.0003, 0.9895, 1.0000, 1.0186, 0.9852, 1.0066, 1.0352, 0.9908, 0.9891,
        0.9840, 0.9927, 0.9865, 1.2164, 0.9972, 0.9896, 0.9826, 0.9827, 0.9841,
        0.9923, 0.9824, 1.0182, 0.9910, 0.9874, 0.9873, 1.0719, 0.9829, 0.9935,
        0.9835, 0.9828, 1.1258, 0.9962, 0.9824, 1.0095, 1.0243, 1.0031, 1.0869,
        0.9938, 0.9914, 0.9944, 0.9841, 0.9838, 0.9827, 0.9830, 1.0005, 0.9827,
        0.9963, 0.9835, 0.9828, 0.9835, 0.9957, 0.9827, 0.9998, 0.9947, 1.0005,
        1.1680, 1.0412, 0.9831, 0.9859, 0.9850, 0.9824, 0.9843, 1.0352, 0.9827,
        0.9859, 0.9846, 0.9854, 1.0954, 0.9867, 0.9853, 0.9881, 0.9865, 0.9833,
        0.9837, 0.9834, 0.9885, 1.0739, 0.9824, 0.9913, 0.9979, 0.9880, 0.9828,
        1.0073, 1.0700, 1.0405, 0.9834, 0.9867, 0.9832, 0.9877, 0.9876, 0.9993,
        0.9870, 0.9854, 0.9840, 0.9832, 0.9866, 0.9877, 0.9919, 0.9841, 1.0627,
        0.9828, 0.9844, 0.9869, 0.9864, 0.9863, 0.9855, 0.9831, 0.9908, 0.9829,
        0.9836, 0.9854, 0.9957, 0.9861, 0.9840, 0.9865, 1.1019, 0.9879, 0.9868,
        0.9850, 0.9838, 0.9837, 0.9854, 1.0106, 0.9836, 0.9841, 0.9854, 0.9839],
       device='cuda:0')
S painting T real Train Ep: 28000 lr0.003674195852021934 	 Loss Classification: 0.035140 Loss T 0.046928 Method MME


Labeled Target set: Average loss: 0.0367, Accuracy: 1069/1080 F1 (98.9815%)


Test set: Average loss: 1.1128, Accuracy: 54620/69960 F1 (78.0732%)


Val set: Average loss: 1.3361, Accuracy: 263/360 F1 (73.0556%)

best acc test 80.351630  acc val 73.055556 acc labeled target 98.981481
saving model...
S painting T real Train Ep: 28100 lr0.0036669608075000928 	 Loss Classification: 0.115327 Loss T 0.019424 Method MME

S painting T real Train Ep: 28200 lr0.00365975891867815 	 Loss Classification: 0.028969 Loss T 0.033237 Method MME

S painting T real Train Ep: 28300 lr0.003652589947415138 	 Loss Classification: 0.285153 Loss T 0.043284 Method MME

S painting T real Train Ep: 28400 lr0.0036454536578964408 	 Loss Classification: 0.025752 Loss T 0.023263 Method MME

S painting T real Train Ep: 28500 lr0.0036383498166050877 	 Loss Classification: 0.192380 Loss T 0.026205 Method MME


Labeled Target set: Average loss: 0.0148, Accuracy: 1075/1080 F1 (99.5370%)

Terminated
