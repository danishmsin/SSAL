Dataset multi Source real Target clipart Labeled num perclass 3 Network resnet34
126 classes in this dataset
Unlabelled Target Dataset Size:  18325
Labelled Target Dataset Size:  378
Misc. Labelled Target Dataset Size:  378
Bank keys - Target:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier']) Source:  dict_keys(['feat_vec', 'labels', 'names', 'domain_identifier'])
Num  - Target:  18325 Source:  70358
Unlabeled Target Data Size: 381
S real T clipart Train Ep: 0 lr0.01 	 Loss Classification: 4.963021 Loss T 0.471431 Method MME

S real T clipart Train Ep: 100 lr0.009925650290240803 	 Loss Classification: 1.316417 Loss T 0.306769 Method MME

S real T clipart Train Ep: 200 lr0.009852577760521605 	 Loss Classification: 0.935467 Loss T 0.228694 Method MME

S real T clipart Train Ep: 300 lr0.009780748269686728 	 Loss Classification: 0.427577 Loss T 0.235565 Method MME

S real T clipart Train Ep: 400 lr0.009710128909124701 	 Loss Classification: 0.753715 Loss T 0.198329 Method MME

S real T clipart Train Ep: 500 lr0.00964068794694323 	 Loss Classification: 0.549963 Loss T 0.179375 Method MME


Labeled Target set: Average loss: 2.4860, Accuracy: 487/1080 F1 (45.0926%)


Test set: Average loss: 2.2654, Accuracy: 8914/18312 F1 (48.6785%)


Val set: Average loss: 2.3118, Accuracy: 172/360 F1 (47.7778%)

best acc test 48.678462  acc val 47.777778 acc labeled target 45.092593
saving model...
S real T clipart Train Ep: 600 lr0.00957239477517603 	 Loss Classification: 0.824862 Loss T 0.155463 Method MME

S real T clipart Train Ep: 700 lr0.009505219859830012 	 Loss Classification: 0.681840 Loss T 0.150745 Method MME

S real T clipart Train Ep: 800 lr0.009439134693595126 	 Loss Classification: 1.165493 Loss T 0.137445 Method MME

S real T clipart Train Ep: 900 lr0.009374111751051751 	 Loss Classification: 0.638933 Loss T 0.121533 Method MME

S real T clipart Train Ep: 1000 lr0.009310124446222227 	 Loss Classification: 0.835434 Loss T 0.141926 Method MME


Labeled Target set: Average loss: 2.3537, Accuracy: 552/1080 F1 (51.1111%)


Test set: Average loss: 2.1189, Accuracy: 9961/18312 F1 (54.3960%)


Val set: Average loss: 2.2292, Accuracy: 191/360 F1 (53.0556%)

best acc test 54.396024  acc val 53.055556 acc labeled target 51.111111
saving model...
S real T clipart Train Ep: 1100 lr0.00924714709232377 	 Loss Classification: 0.350195 Loss T 0.127105 Method MME

S real T clipart Train Ep: 1200 lr0.009185154863590003 	 Loss Classification: 0.939995 Loss T 0.115264 Method MME

S real T clipart Train Ep: 1300 lr0.00912412375903735 	 Loss Classification: 0.564548 Loss T 0.125255 Method MME

S real T clipart Train Ep: 1400 lr0.009064030568061049 	 Loss Classification: 0.576422 Loss T 0.121957 Method MME

S real T clipart Train Ep: 1500 lr0.009004852837753237 	 Loss Classification: 0.520998 Loss T 0.127010 Method MME


Labeled Target set: Average loss: 2.3474, Accuracy: 562/1080 F1 (52.0370%)


Test set: Average loss: 2.0659, Accuracy: 10501/18312 F1 (57.3449%)


Val set: Average loss: 2.1811, Accuracy: 206/360 F1 (57.2222%)

best acc test 57.344910  acc val 57.222222 acc labeled target 52.037037
saving model...
S real T clipart Train Ep: 1600 lr0.008946568841842816 	 Loss Classification: 0.762463 Loss T 0.105328 Method MME

S real T clipart Train Ep: 1700 lr0.008889157551163433 	 Loss Classification: 1.344662 Loss T 0.108969 Method MME

S real T clipart Train Ep: 1800 lr0.008832598605562044 	 Loss Classification: 0.700725 Loss T 0.103288 Method MME

S real T clipart Train Ep: 1900 lr0.008776872287166303 	 Loss Classification: 0.730848 Loss T 0.112645 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.33333334 0.5        0.6666667  0.5555556  0.         0.33333334
 0.22222222 0.44444445 0.33333334 0.         0.5555556  0.22222222
 0.         0.6666667  1.         0.22222222 0.7777778  0.8888889
 0.         0.6666667  0.         0.6666667  0.8888889  0.6666667
 0.33333334 0.5555556  0.6666667  1.         0.11111111 0.5
 0.44444445 0.         0.8333333  0.8888889  0.22222222 1.
 1.         0.33333334 0.6666667  0.         1.         0.44444445
 0.5555556  0.22222222 0.11111111 0.5555556  0.6666667  0.6666667
 0.22222222 0.6666667  0.5        0.22222222 1.         0.6666667
 1.         1.         1.         0.5555556  0.         0.6666667
 0.7777778  0.8888889  1.         0.22222222 0.6666667  0.8888889
 0.11111111 1.         0.8888889  0.         0.6666667  0.33333334
 0.7777778  0.22222222 0.         0.11111111 0.6666667  1.
 0.         0.6666667  0.11111111 0.6666667  0.         0.33333334
 0.5555556  1.         0.6666667  1.         0.         0.
 0.33333334 0.6666667  0.         0.6666667  0.         0.8888889
 0.44444445 0.33333334 0.44444445 0.22222222 0.7777778  0.7777778
 0.         0.11111111 0.33333334 0.5        0.44444445 0.6666667
 0.33333334 0.6666667  0.33333334 0.8888889  0.5555556  1.
 0.8888889  0.6666667  0.5555556  1.         0.         0.44444445
 1.         0.7777778  0.8888889  1.         0.         0.5555556 ]
Top k classes which perform poorly are:  [124, 94, 39, 31, 88, 102, 82, 20, 92, 78, 12, 18, 74, 58, 118, 4, 69, 89, 9, 80, 75, 103, 66, 44, 28, 73, 34, 51, 63, 43, 48, 99, 11, 6, 15, 71, 83, 0, 90, 5, 8, 110, 37, 104, 24, 108, 97, 106, 41, 7, 96, 119, 98, 30, 105, 50, 29, 1, 84, 112, 116, 125, 25, 57, 45, 3, 10, 42, 47, 81, 46, 93, 79, 21, 23, 38, 91, 19, 86, 49, 76, 53, 109, 13, 115, 70, 2, 64, 59, 107, 26, 16, 121, 101, 100, 60, 72, 32, 111, 95, 17, 68, 22, 114, 65, 122, 61, 33, 117, 56, 55, 123, 120, 67, 14, 54, 52, 77, 85, 87, 40, 36, 35, 27, 113, 62]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 2000 lr0.008721959494934213 	 Loss Classification: 0.853610 Loss T 0.105583 Method MME


Labeled Target set: Average loss: 2.5747, Accuracy: 551/1080 F1 (51.0185%)


Test set: Average loss: 2.0914, Accuracy: 10537/18312 F1 (57.5415%)


Val set: Average loss: 2.3680, Accuracy: 202/360 F1 (56.1111%)

best acc test 57.344910  acc val 56.111111 acc labeled target 51.018519
saving model...
S real T clipart Train Ep: 2100 lr0.008667841720414475 	 Loss Classification: 1.061636 Loss T 0.093964 Method MME

S real T clipart Train Ep: 2200 lr0.008614501024650454 	 Loss Classification: 0.688159 Loss T 0.107417 Method MME

S real T clipart Train Ep: 2300 lr0.008561920016164943 	 Loss Classification: 0.583547 Loss T 0.093752 Method MME

S real T clipart Train Ep: 2400 lr0.008510081829966844 	 Loss Classification: 0.668163 Loss T 0.120227 Method MME

S real T clipart Train Ep: 2500 lr0.008458970107524513 	 Loss Classification: 0.535673 Loss T 0.103330 Method MME


Labeled Target set: Average loss: 2.0235, Accuracy: 626/1080 F1 (57.9630%)


Test set: Average loss: 1.9026, Accuracy: 11038/18312 F1 (60.2774%)


Val set: Average loss: 2.0949, Accuracy: 212/360 F1 (58.8889%)

best acc test 60.277414  acc val 58.888889 acc labeled target 57.962963
saving model...
S real T clipart Train Ep: 2600 lr0.008408568977653933 	 Loss Classification: 0.144726 Loss T 0.091450 Method MME

S real T clipart Train Ep: 2700 lr0.00835886303827305 	 Loss Classification: 0.356218 Loss T 0.099544 Method MME

S real T clipart Train Ep: 2800 lr0.008309837338976545 	 Loss Classification: 0.548219 Loss T 0.093807 Method MME

S real T clipart Train Ep: 2900 lr0.008261477364388068 	 Loss Classification: 0.398187 Loss T 0.071392 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8333333  0.6666667  0.6666667  0.5555556  0.33333334 0.11111111
 0.22222222 0.5555556  0.5555556  0.         0.6666667  0.22222222
 0.6666667  0.22222222 0.44444445 0.         1.         1.
 0.7777778  0.6666667  0.         1.         1.         0.6666667
 0.         0.5555556  0.6666667  0.6666667  0.33333334 0.33333334
 0.6666667  0.22222222 0.6666667  0.6666667  0.6666667  1.
 0.6666667  0.6666667  0.6666667  0.         1.         0.8888889
 0.5555556  0.7777778  0.         1.         0.5555556  0.6666667
 0.33333334 0.6666667  0.6666667  0.6666667  1.         0.8888889
 0.6666667  1.         1.         1.         0.         0.6666667
 0.7777778  0.8888889  0.8888889  0.44444445 0.44444445 0.8888889
 0.33333334 0.6666667  0.5555556  0.         0.5555556  0.5
 0.6666667  0.5        0.         0.44444445 0.33333334 1.
 0.         1.         0.11111111 1.         0.         0.
 1.         1.         0.33333334 1.         0.         0.5
 0.5555556  0.5        0.         0.7777778  0.5        1.
 0.6666667  0.6666667  0.6666667  0.6666667  1.         1.
 0.22222222 0.5        0.22222222 0.33333334 0.         1.
 0.22222222 0.5        0.33333334 1.         0.44444445 0.8888889
 1.         0.6666667  0.44444445 1.         0.         0.7777778
 1.         0.6666667  0.7777778  0.8888889  0.         0.6666667 ]
Top k classes which perform poorly are:  [92, 39, 124, 69, 44, 24, 118, 74, 58, 78, 15, 82, 20, 88, 83, 9, 106, 80, 5, 104, 102, 31, 11, 108, 13, 6, 4, 86, 28, 29, 105, 48, 66, 110, 76, 14, 75, 116, 64, 63, 112, 91, 71, 73, 94, 89, 103, 109, 68, 70, 90, 46, 25, 3, 7, 42, 8, 23, 19, 99, 121, 98, 50, 12, 51, 96, 2, 1, 97, 10, 72, 27, 49, 54, 47, 115, 59, 38, 26, 37, 34, 33, 32, 67, 30, 36, 125, 122, 60, 18, 43, 93, 119, 0, 62, 53, 113, 61, 41, 65, 123, 22, 117, 120, 17, 35, 40, 114, 16, 21, 111, 85, 87, 107, 55, 56, 57, 101, 100, 77, 79, 81, 84, 95, 45, 52]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 3000 lr0.008213769018249545 	 Loss Classification: 0.157563 Loss T 0.053117 Method MME


Labeled Target set: Average loss: 2.3407, Accuracy: 589/1080 F1 (54.5370%)


Test set: Average loss: 1.9264, Accuracy: 11316/18312 F1 (61.7955%)


Val set: Average loss: 2.2406, Accuracy: 215/360 F1 (59.7222%)

best acc test 61.795544  acc val 59.722222 acc labeled target 54.537037
saving model...
S real T clipart Train Ep: 3100 lr0.008166698608209509 	 Loss Classification: 0.358939 Loss T 0.071670 Method MME

S real T clipart Train Ep: 3200 lr0.008120252831274708 	 Loss Classification: 0.225923 Loss T 0.073865 Method MME

S real T clipart Train Ep: 3300 lr0.008074418759891278 	 Loss Classification: 0.593603 Loss T 0.085513 Method MME

S real T clipart Train Ep: 3400 lr0.008029183828623731 	 Loss Classification: 0.472132 Loss T 0.090071 Method MME

S real T clipart Train Ep: 3500 lr0.007984535821401871 	 Loss Classification: 0.690014 Loss T 0.077827 Method MME


Labeled Target set: Average loss: 1.8783, Accuracy: 678/1080 F1 (62.7778%)


Test set: Average loss: 1.6597, Accuracy: 12065/18312 F1 (65.8858%)


Val set: Average loss: 1.8054, Accuracy: 227/360 F1 (63.0556%)

best acc test 65.885758  acc val 63.055556 acc labeled target 62.777778
saving model...
S real T clipart Train Ep: 3600 lr0.007940462859307384 	 Loss Classification: 0.515992 Loss T 0.081568 Method MME

S real T clipart Train Ep: 3700 lr0.007896953388873518 	 Loss Classification: 0.898411 Loss T 0.064793 Method MME

S real T clipart Train Ep: 3800 lr0.007853996170872714 	 Loss Classification: 0.142733 Loss T 0.089667 Method MME

S real T clipart Train Ep: 3900 lr0.00781158026956848 	 Loss Classification: 0.337851 Loss T 0.050779 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.5555556  1.         0.6666667  0.5555556  0.         0.11111111
 0.22222222 1.         0.33333334 0.         0.8888889  0.22222222
 0.33333334 1.         1.         1.         1.         0.8888889
 0.8888889  0.5555556  0.         0.8333333  0.8888889  0.6666667
 0.44444445 0.6666667  0.6666667  0.8888889  0.44444445 0.5555556
 0.33333334 0.33333334 0.6666667  0.7777778  0.8888889  1.
 0.6666667  0.6666667  0.6666667  0.5555556  1.         1.
 0.         1.         0.         0.6666667  0.8888889  0.5
 0.33333334 0.6666667  0.8888889  1.         1.         1.
 1.         1.         1.         0.7777778  0.         0.6666667
 0.8888889  0.7777778  0.8888889  0.44444445 1.         0.8888889
 0.33333334 0.         0.5555556  0.         0.5555556  0.5
 0.6666667  0.         0.         0.6666667  0.5555556  0.8888889
 0.         0.8888889  0.22222222 1.         0.         0.33333334
 1.         1.         0.6666667  0.8888889  0.         0.33333334
 0.33333334 0.5555556  0.         1.         0.33333334 1.
 0.8888889  0.7777778  0.7777778  0.8888889  1.         0.6666667
 0.22222222 0.22222222 0.22222222 0.33333334 0.7777778  1.
 0.11111111 0.6666667  0.6666667  1.         0.5555556  1.
 0.8333333  0.8888889  0.6666667  1.         0.         0.8333333
 1.         0.6666667  0.7777778  1.         0.33333334 0.8888889 ]
Top k classes which perform poorly are:  [82, 42, 44, 118, 92, 58, 88, 67, 9, 73, 4, 74, 78, 69, 20, 108, 5, 102, 80, 104, 103, 11, 6, 31, 105, 90, 124, 83, 94, 30, 89, 66, 8, 48, 12, 28, 63, 24, 71, 47, 0, 68, 76, 19, 112, 39, 3, 29, 70, 91, 72, 59, 45, 49, 109, 23, 25, 26, 110, 32, 75, 121, 36, 37, 38, 2, 116, 101, 86, 122, 98, 61, 57, 97, 106, 33, 114, 119, 21, 96, 99, 115, 87, 62, 125, 22, 18, 17, 46, 50, 34, 10, 27, 60, 65, 77, 79, 7, 13, 14, 15, 16, 1, 113, 111, 123, 120, 117, 84, 35, 85, 64, 56, 55, 93, 54, 107, 95, 52, 51, 100, 43, 41, 81, 53, 40]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 4000 lr0.007769695042409123 	 Loss Classification: 0.579673 Loss T 0.073894 Method MME


Labeled Target set: Average loss: 2.4239, Accuracy: 588/1080 F1 (54.4444%)


Test set: Average loss: 2.0362, Accuracy: 11360/18312 F1 (62.0358%)


Val set: Average loss: 2.3276, Accuracy: 209/360 F1 (58.0556%)

best acc test 65.885758  acc val 58.055556 acc labeled target 54.444444
saving model...
S real T clipart Train Ep: 4100 lr0.007728330130142108 	 Loss Classification: 0.183400 Loss T 0.065013 Method MME

S real T clipart Train Ep: 4200 lr0.007687475447329114 	 Loss Classification: 0.629474 Loss T 0.090020 Method MME

S real T clipart Train Ep: 4300 lr0.0076471211732427845 	 Loss Classification: 0.274882 Loss T 0.067402 Method MME

S real T clipart Train Ep: 4400 lr0.007607257743127307 	 Loss Classification: 1.353294 Loss T 0.060625 Method MME

S real T clipart Train Ep: 4500 lr0.007567875839805858 	 Loss Classification: 0.657316 Loss T 0.075383 Method MME


Labeled Target set: Average loss: 1.8997, Accuracy: 675/1080 F1 (62.5000%)


Test set: Average loss: 1.6733, Accuracy: 12291/18312 F1 (67.1199%)


Val set: Average loss: 1.7979, Accuracy: 236/360 F1 (65.5556%)

best acc test 67.119921  acc val 65.555556 acc labeled target 62.500000
saving model...
S real T clipart Train Ep: 4600 lr0.007528966385618854 	 Loss Classification: 0.066962 Loss T 0.073612 Method MME

S real T clipart Train Ep: 4700 lr0.007490520534677821 	 Loss Classification: 1.072688 Loss T 0.065845 Method MME

S real T clipart Train Ep: 4800 lr0.007452529665420465 	 Loss Classification: 0.288627 Loss T 0.085978 Method MME

S real T clipart Train Ep: 4900 lr0.007414985373453289 	 Loss Classification: 0.422108 Loss T 0.073870 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.8888889  0.8333333  0.6666667  0.7777778  0.11111111 0.22222222
 0.33333334 0.6666667  0.5555556  0.11111111 0.6666667  0.6666667
 0.33333334 0.5555556  0.6666667  0.8333333  1.         0.8888889
 1.         0.6666667  0.         1.         1.         0.8888889
 0.33333334 0.         0.22222222 0.6666667  0.33333334 0.5
 0.33333334 0.         0.6666667  0.8888889  1.         1.
 0.5555556  0.6666667  0.6666667  0.11111111 1.         0.6666667
 0.5555556  0.6666667  0.         0.7777778  0.6666667  0.5
 0.33333334 0.6666667  0.7777778  1.         1.         1.
 1.         1.         1.         0.7777778  0.33333334 0.7777778
 0.6666667  0.8888889  1.         0.6666667  1.         1.
 0.33333334 1.         1.         0.         0.6666667  0.44444445
 0.6666667  0.33333334 0.33333334 0.5555556  0.44444445 1.
 0.         1.         0.         1.         0.         0.33333334
 1.         0.8333333  0.44444445 0.8888889  0.         0.33333334
 0.11111111 0.5555556  0.         1.         0.44444445 1.
 0.6666667  0.8888889  1.         0.7777778  1.         0.6666667
 0.22222222 0.         0.33333334 0.22222222 0.7777778  1.
 0.33333334 0.6666667  0.16666667 1.         0.5555556  1.
 1.         0.8888889  0.6666667  1.         0.         0.8888889
 1.         0.7777778  0.6666667  1.         0.33333334 0.6666667 ]
Top k classes which perform poorly are:  [103, 44, 118, 20, 92, 78, 80, 31, 25, 88, 82, 69, 4, 39, 90, 9, 110, 5, 26, 102, 105, 30, 28, 104, 66, 74, 108, 73, 124, 48, 58, 12, 89, 6, 83, 24, 94, 86, 71, 76, 29, 47, 112, 8, 42, 13, 75, 36, 91, 101, 60, 63, 96, 72, 70, 125, 43, 116, 122, 27, 32, 109, 37, 38, 19, 41, 11, 10, 7, 46, 49, 2, 14, 3, 121, 50, 106, 45, 99, 59, 57, 15, 85, 1, 97, 119, 115, 0, 23, 33, 61, 87, 17, 120, 18, 21, 117, 22, 40, 114, 16, 113, 123, 111, 34, 35, 84, 51, 52, 81, 79, 77, 68, 93, 67, 95, 65, 64, 98, 100, 56, 55, 54, 53, 107, 62]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 5000 lr0.007377879464668811 	 Loss Classification: 0.558123 Loss T 0.043493 Method MME


Labeled Target set: Average loss: 2.1732, Accuracy: 654/1080 F1 (60.5556%)


Test set: Average loss: 1.7829, Accuracy: 12157/18312 F1 (66.3882%)


Val set: Average loss: 2.0833, Accuracy: 220/360 F1 (61.1111%)

best acc test 67.119921  acc val 61.111111 acc labeled target 60.555556
saving model...
S real T clipart Train Ep: 5100 lr0.007341203948625087 	 Loss Classification: 0.225252 Loss T 0.061928 Method MME

S real T clipart Train Ep: 5200 lr0.007304951032175895 	 Loss Classification: 0.539690 Loss T 0.071811 Method MME

S real T clipart Train Ep: 5300 lr0.007269113113340497 	 Loss Classification: 0.315209 Loss T 0.066400 Method MME

S real T clipart Train Ep: 5400 lr0.007233682775402483 	 Loss Classification: 0.495607 Loss T 0.059125 Method MME

S real T clipart Train Ep: 5500 lr0.007198652781227704 	 Loss Classification: 0.593501 Loss T 0.065127 Method MME


Labeled Target set: Average loss: 1.7636, Accuracy: 691/1080 F1 (63.9815%)


Test set: Average loss: 1.5578, Accuracy: 12753/18312 F1 (69.6429%)


Val set: Average loss: 1.8254, Accuracy: 237/360 F1 (65.8333%)

best acc test 69.642857  acc val 65.833333 acc labeled target 63.981481
saving model...
S real T clipart Train Ep: 5600 lr0.007164016067791809 	 Loss Classification: 0.617415 Loss T 0.069792 Method MME

S real T clipart Train Ep: 5700 lr0.0071297657409083726 	 Loss Classification: 0.888843 Loss T 0.066110 Method MME

S real T clipart Train Ep: 5800 lr0.0070958950701490225 	 Loss Classification: 0.460898 Loss T 0.061041 Method MME

S real T clipart Train Ep: 5900 lr0.007062397483947426 	 Loss Classification: 0.263448 Loss T 0.081860 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.6666667  1.         0.6666667  0.6666667  0.         0.5555556
 0.33333334 0.6666667  0.5555556  0.         0.8888889  0.5555556
 0.44444445 0.5555556  0.6666667  0.6666667  1.         1.
 0.6666667  0.6666667  0.         1.         0.8888889  0.8888889
 0.5555556  0.33333334 0.5555556  0.6666667  0.33333334 0.5
 0.6666667  0.         0.5555556  0.7777778  0.8888889  1.
 0.7777778  0.6666667  0.6666667  0.         1.         1.
 0.5        0.6666667  0.22222222 0.6666667  1.         0.6666667
 0.33333334 0.6666667  0.7777778  1.         1.         1.
 0.8888889  1.         0.8888889  1.         0.5555556  1.
 1.         0.33333334 1.         0.6666667  1.         1.
 0.         0.8333333  1.         0.         0.6666667  0.5555556
 1.         0.7777778  0.         0.5        0.11111111 1.
 0.33333334 0.8888889  0.         1.         0.11111111 0.11111111
 1.         1.         0.6666667  0.6666667  0.         0.44444445
 0.22222222 0.5        0.         1.         0.33333334 0.8888889
 1.         1.         1.         0.5        1.         0.6666667
 0.5        0.44444445 0.33333334 0.33333334 0.44444445 1.
 0.33333334 0.5        0.6666667  1.         0.6666667  1.
 1.         0.8333333  1.         1.         0.         0.11111111
 1.         0.6666667  0.6666667  1.         0.         1.        ]
Top k classes which perform poorly are:  [39, 74, 88, 20, 80, 118, 69, 31, 9, 66, 4, 124, 92, 82, 119, 76, 83, 90, 44, 104, 48, 108, 61, 105, 28, 78, 25, 94, 6, 12, 103, 106, 89, 75, 42, 91, 102, 29, 109, 99, 5, 8, 26, 11, 71, 13, 32, 24, 58, 87, 86, 101, 63, 110, 70, 0, 45, 121, 27, 30, 112, 122, 37, 38, 15, 43, 18, 19, 14, 47, 49, 7, 3, 2, 50, 73, 36, 33, 115, 67, 10, 95, 56, 22, 23, 79, 34, 54, 117, 116, 107, 114, 113, 100, 123, 111, 120, 98, 62, 96, 1, 16, 17, 21, 35, 40, 41, 46, 51, 52, 53, 97, 55, 59, 60, 64, 65, 68, 72, 77, 81, 84, 85, 93, 57, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 6000 lr0.007029266564879363 	 Loss Classification: 0.923672 Loss T 0.057763 Method MME


Labeled Target set: Average loss: 2.0701, Accuracy: 639/1080 F1 (59.1667%)


Test set: Average loss: 1.7948, Accuracy: 12248/18312 F1 (66.8851%)


Val set: Average loss: 2.1665, Accuracy: 217/360 F1 (60.2778%)

best acc test 69.642857  acc val 60.277778 acc labeled target 59.166667
saving model...
S real T clipart Train Ep: 6100 lr0.006996496045111504 	 Loss Classification: 0.678980 Loss T 0.071621 Method MME

S real T clipart Train Ep: 6200 lr0.00696407980201184 	 Loss Classification: 0.447305 Loss T 0.061175 Method MME

S real T clipart Train Ep: 6300 lr0.006932011853915101 	 Loss Classification: 0.312836 Loss T 0.032324 Method MME

S real T clipart Train Ep: 6400 lr0.006900286356036734 	 Loss Classification: 0.473010 Loss T 0.063914 Method MME

S real T clipart Train Ep: 6500 lr0.006868897596529406 	 Loss Classification: 0.650150 Loss T 0.059222 Method MME


Labeled Target set: Average loss: 1.6824, Accuracy: 705/1080 F1 (65.2778%)


Test set: Average loss: 1.6256, Accuracy: 12724/18312 F1 (69.4845%)


Val set: Average loss: 2.0245, Accuracy: 235/360 F1 (65.2778%)

best acc test 69.642857  acc val 65.277778 acc labeled target 65.277778
saving model...
S real T clipart Train Ep: 6600 lr0.006837839992676177 	 Loss Classification: 0.697085 Loss T 0.034712 Method MME

S real T clipart Train Ep: 6700 lr0.006807108087214876 	 Loss Classification: 0.192924 Loss T 0.074137 Method MME

S real T clipart Train Ep: 6800 lr0.006776696544788352 	 Loss Classification: 0.604195 Loss T 0.041033 Method MME

S real T clipart Train Ep: 6900 lr0.006746600148515609 	 Loss Classification: 0.275995 Loss T 0.035382 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [0.7777778  1.         0.44444445 0.8888889  0.         0.22222222
 0.33333334 0.8888889  0.16666667 0.         1.         0.5555556
 0.33333334 0.6666667  1.         1.         1.         0.8888889
 1.         0.5555556  0.         0.6666667  0.8888889  0.8888889
 0.33333334 0.33333334 0.5555556  0.5        0.6666667  0.5555556
 0.6666667  0.33333334 0.8888889  1.         0.7777778  1.
 0.6666667  1.         0.6666667  0.11111111 1.         0.8333333
 0.5555556  0.6666667  0.22222222 1.         0.8888889  0.6666667
 0.33333334 0.7777778  1.         1.         1.         0.8888889
 0.8333333  1.         0.8888889  0.7777778  0.6666667  0.7777778
 0.8888889  0.44444445 1.         0.6666667  1.         1.
 0.11111111 1.         0.8888889  0.16666667 0.6666667  0.44444445
 0.7777778  0.44444445 0.11111111 0.44444445 0.         1.
 0.         1.         0.         0.8888889  0.         0.22222222
 0.7777778  1.         0.6666667  1.         0.         0.5555556
 0.44444445 0.6666667  0.         0.7777778  0.44444445 1.
 0.6666667  1.         1.         0.8888889  0.8888889  0.7777778
 0.33333334 0.33333334 0.44444445 0.33333334 0.7777778  0.8888889
 0.5        0.6666667  0.5555556  1.         0.6666667  1.
 1.         0.8888889  0.5        1.         0.         0.22222222
 1.         1.         0.5555556  1.         0.         1.        ]
Top k classes which perform poorly are:  [78, 80, 82, 4, 76, 88, 9, 20, 118, 124, 92, 66, 39, 74, 69, 8, 119, 44, 83, 5, 48, 105, 6, 103, 102, 31, 25, 12, 24, 73, 2, 104, 71, 94, 61, 75, 90, 27, 108, 116, 89, 122, 42, 19, 11, 110, 29, 26, 63, 58, 109, 86, 47, 43, 96, 38, 36, 70, 30, 28, 112, 21, 91, 13, 101, 72, 84, 93, 0, 49, 106, 59, 57, 34, 54, 41, 3, 7, 17, 22, 23, 32, 115, 68, 99, 81, 46, 100, 53, 56, 60, 107, 117, 111, 120, 121, 123, 113, 114, 62, 97, 1, 10, 14, 15, 16, 18, 33, 35, 37, 40, 45, 50, 51, 52, 55, 64, 65, 67, 77, 79, 85, 87, 95, 98, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 7000 lr0.006716813796678979 	 Loss Classification: 0.173715 Loss T 0.070873 Method MME


Labeled Target set: Average loss: 2.0545, Accuracy: 648/1080 F1 (60.0000%)


Test set: Average loss: 1.7519, Accuracy: 12507/18312 F1 (68.2995%)


Val set: Average loss: 2.1219, Accuracy: 231/360 F1 (64.1667%)

best acc test 69.642857  acc val 64.166667 acc labeled target 60.000000
saving model...
S real T clipart Train Ep: 7100 lr0.006687332499522798 	 Loss Classification: 0.278958 Loss T 0.065430 Method MME

S real T clipart Train Ep: 7200 lr0.006658151376159165 	 Loss Classification: 0.538161 Loss T 0.041695 Method MME

S real T clipart Train Ep: 7300 lr0.00662926565157663 	 Loss Classification: 0.364250 Loss T 0.052182 Method MME

S real T clipart Train Ep: 7400 lr0.006600670653747793 	 Loss Classification: 0.342875 Loss T 0.054364 Method MME

S real T clipart Train Ep: 7500 lr0.0065723618108320175 	 Loss Classification: 0.079389 Loss T 0.057388 Method MME


Labeled Target set: Average loss: 0.0610, Accuracy: 1058/1080 F1 (97.9630%)


Test set: Average loss: 1.3632, Accuracy: 13600/18312 F1 (74.2682%)


Val set: Average loss: 1.4552, Accuracy: 262/360 F1 (72.7778%)

best acc test 74.268239  acc val 72.777778 acc labeled target 97.962963
saving model...
S real T clipart Train Ep: 7600 lr0.006544334648469591 	 Loss Classification: 0.575235 Loss T 0.027150 Method MME

S real T clipart Train Ep: 7700 lr0.006516584787163857 	 Loss Classification: 0.258872 Loss T 0.048682 Method MME

S real T clipart Train Ep: 7800 lr0.006489107939747966 	 Loss Classification: 0.319864 Loss T 0.041597 Method MME

S real T clipart Train Ep: 7900 lr0.0064618999089330565 	 Loss Classification: 0.210757 Loss T 0.041543 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        0.8888889
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 47, 91, 67, 44, 82, 22, 48, 55, 12, 56, 92, 58, 65, 7, 63, 78, 90, 89, 88, 87, 86, 85, 84, 74, 83, 70, 75, 71, 72, 73, 81, 80, 76, 77, 79, 0, 69, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 94, 62, 66, 28, 27, 26, 25, 24, 23, 21, 20, 19, 18, 17, 16, 15, 14, 13, 11, 10, 9, 8, 6, 5, 4, 3, 2, 1, 29, 68, 30, 32, 64, 124, 61, 60, 59, 57, 54, 53, 52, 51, 50, 49, 46, 45, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 8000 lr0.006434956584934828 	 Loss Classification: 0.294232 Loss T 0.063063 Method MME


Labeled Target set: Average loss: 0.1322, Accuracy: 1043/1080 F1 (96.5741%)


Test set: Average loss: 1.6163, Accuracy: 13060/18312 F1 (71.3194%)


Val set: Average loss: 1.7662, Accuracy: 245/360 F1 (68.0556%)

best acc test 74.268239  acc val 68.055556 acc labeled target 96.574074
saving model...
S real T clipart Train Ep: 8100 lr0.006408273943175546 	 Loss Classification: 0.941868 Loss T 0.040440 Method MME

S real T clipart Train Ep: 8200 lr0.006381848042058713 	 Loss Classification: 0.425390 Loss T 0.063143 Method MME

S real T clipart Train Ep: 8300 lr0.0063556750208137005 	 Loss Classification: 0.375139 Loss T 0.044701 Method MME

S real T clipart Train Ep: 8400 lr0.006329751097407787 	 Loss Classification: 0.408452 Loss T 0.056170 Method MME

S real T clipart Train Ep: 8500 lr0.0063040725665231365 	 Loss Classification: 0.404612 Loss T 0.038813 Method MME


Labeled Target set: Average loss: 0.0855, Accuracy: 1051/1080 F1 (97.3148%)


Test set: Average loss: 1.4189, Accuracy: 13679/18312 F1 (74.6997%)


Val set: Average loss: 1.5435, Accuracy: 256/360 F1 (71.1111%)

best acc test 74.268239  acc val 71.111111 acc labeled target 97.314815
saving model...
S real T clipart Train Ep: 8600 lr0.006278635797596355 	 Loss Classification: 0.300320 Loss T 0.033215 Method MME

S real T clipart Train Ep: 8700 lr0.006253437232918371 	 Loss Classification: 0.390383 Loss T 0.051839 Method MME

S real T clipart Train Ep: 8800 lr0.0062284733857924735 	 Loss Classification: 0.519990 Loss T 0.043796 Method MME

S real T clipart Train Ep: 8900 lr0.006203740838748417 	 Loss Classification: 0.335813 Loss T 0.033970 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        0.8888889 0.8888889 1.        0.8888889 0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        0.8888889 1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        0.5555556 1.
 0.8888889 0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [103, 63, 47, 108, 88, 36, 43, 66, 44, 46, 29, 99, 105, 106, 17, 90, 76, 122, 13, 12, 72, 75, 69, 87, 70, 71, 86, 73, 74, 80, 85, 84, 77, 83, 82, 89, 81, 78, 79, 0, 95, 92, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 91, 111, 109, 107, 104, 102, 101, 100, 98, 97, 96, 94, 93, 110, 68, 62, 65, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 16, 15, 14, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 67, 31, 33, 64, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 45, 42, 41, 40, 39, 38, 37, 35, 34, 32, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 9000 lr0.006179236241810624 	 Loss Classification: 0.281836 Loss T 0.038792 Method MME


Labeled Target set: Average loss: 0.0961, Accuracy: 1051/1080 F1 (97.3148%)


Test set: Average loss: 1.5416, Accuracy: 13377/18312 F1 (73.0505%)


Val set: Average loss: 1.6642, Accuracy: 253/360 F1 (70.2778%)

best acc test 74.268239  acc val 70.277778 acc labeled target 97.314815
saving model...
S real T clipart Train Ep: 9100 lr0.006154956310818535 	 Loss Classification: 0.380996 Loss T 0.039388 Method MME

S real T clipart Train Ep: 9200 lr0.0061308978257973165 	 Loss Classification: 0.487997 Loss T 0.035998 Method MME

S real T clipart Train Ep: 9300 lr0.0061070576293771285 	 Loss Classification: 0.137742 Loss T 0.049293 Method MME

S real T clipart Train Ep: 9400 lr0.006083432625259276 	 Loss Classification: 0.593298 Loss T 0.020231 Method MME

S real T clipart Train Ep: 9500 lr0.006060019776727621 	 Loss Classification: 0.347107 Loss T 0.033636 Method MME


Labeled Target set: Average loss: 0.0679, Accuracy: 1058/1080 F1 (97.9630%)


Test set: Average loss: 1.4421, Accuracy: 13794/18312 F1 (75.3277%)


Val set: Average loss: 1.3987, Accuracy: 266/360 F1 (73.8889%)

best acc test 75.327654  acc val 73.888889 acc labeled target 97.962963
saving model...
S real T clipart Train Ep: 9600 lr0.00603681610520369 	 Loss Classification: 0.565891 Loss T 0.019780 Method MME

S real T clipart Train Ep: 9700 lr0.0060138186888439825 	 Loss Classification: 0.199420 Loss T 0.027557 Method MME

S real T clipart Train Ep: 9800 lr0.005991024661178045 	 Loss Classification: 0.219173 Loss T 0.035840 Method MME

S real T clipart Train Ep: 9900 lr0.0059684312097859115 	 Loss Classification: 0.505602 Loss T 0.047238 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8333333 0.8888889 1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        0.8888889 0.8888889 1.        1.        1.        1.
 0.5555556 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.5555556 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8333333 1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 91, 44, 116, 45, 52, 26, 75, 57, 118, 3, 89, 58, 85, 84, 86, 87, 88, 83, 82, 0, 80, 79, 90, 77, 76, 74, 73, 72, 71, 70, 69, 81, 78, 94, 93, 123, 122, 121, 120, 119, 117, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 68, 92, 67, 62, 65, 28, 27, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 2, 1, 14, 66, 30, 32, 64, 124, 61, 60, 59, 56, 55, 54, 53, 51, 50, 49, 31, 48, 46, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 47, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 10000 lr0.005946035575013605 	 Loss Classification: 0.347729 Loss T 0.029742 Method MME


Labeled Target set: Average loss: 0.0940, Accuracy: 1054/1080 F1 (97.5926%)


Test set: Average loss: 1.5208, Accuracy: 13547/18312 F1 (73.9788%)


Val set: Average loss: 1.7231, Accuracy: 249/360 F1 (69.1667%)

best acc test 75.327654  acc val 69.166667 acc labeled target 97.592593
saving model...
S real T clipart Train Ep: 10100 lr0.005923835048725393 	 Loss Classification: 0.240189 Loss T 0.038109 Method MME

S real T clipart Train Ep: 10200 lr0.005901826973091593 	 Loss Classification: 0.472487 Loss T 0.036522 Method MME

S real T clipart Train Ep: 10300 lr0.005880008739410735 	 Loss Classification: 0.191008 Loss T 0.041915 Method MME

S real T clipart Train Ep: 10400 lr0.005858377786964935 	 Loss Classification: 0.407255 Loss T 0.034343 Method MME

S real T clipart Train Ep: 10500 lr0.005836931601907399 	 Loss Classification: 0.257941 Loss T 0.023001 Method MME


Labeled Target set: Average loss: 0.0518, Accuracy: 1060/1080 F1 (98.1481%)


Test set: Average loss: 1.4611, Accuracy: 13800/18312 F1 (75.3604%)


Val set: Average loss: 1.5032, Accuracy: 263/360 F1 (73.0556%)

best acc test 75.327654  acc val 73.055556 acc labeled target 98.148148
saving model...
S real T clipart Train Ep: 10600 lr0.005815667716181004 	 Loss Classification: 0.931975 Loss T 0.031786 Method MME

S real T clipart Train Ep: 10700 lr0.005794583706466925 	 Loss Classification: 0.552017 Loss T 0.032354 Method MME

S real T clipart Train Ep: 10800 lr0.005773677193162352 	 Loss Classification: 0.432841 Loss T 0.029278 Method MME

S real T clipart Train Ep: 10900 lr0.005752945839386346 	 Loss Classification: 0.061778 Loss T 0.035507 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 1.        0.8333333 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        0.8888889 0.8888889]
Top k classes which perform poorly are:  [47, 63, 103, 106, 29, 85, 104, 73, 125, 91, 124, 117, 58, 56, 88, 87, 67, 86, 68, 84, 83, 82, 81, 71, 79, 70, 89, 78, 77, 76, 75, 74, 72, 80, 69, 93, 92, 123, 122, 121, 120, 119, 118, 116, 115, 114, 113, 112, 111, 90, 110, 108, 107, 105, 102, 101, 100, 99, 98, 97, 96, 95, 94, 109, 66, 0, 64, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 27, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 28, 30, 31, 61, 60, 59, 57, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 65, 62]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 11000 lr0.005732387350012933 	 Loss Classification: 0.376723 Loss T 0.021675 Method MME


Labeled Target set: Average loss: 0.0826, Accuracy: 1055/1080 F1 (97.6852%)


Test set: Average loss: 1.4891, Accuracy: 13717/18312 F1 (74.9072%)


Val set: Average loss: 1.6371, Accuracy: 258/360 F1 (71.6667%)

best acc test 75.327654  acc val 71.666667 acc labeled target 97.685185
saving model...
S real T clipart Train Ep: 11100 lr0.005711999470730565 	 Loss Classification: 0.564289 Loss T 0.032382 Method MME

S real T clipart Train Ep: 11200 lr0.005691779987127103 	 Loss Classification: 0.572114 Loss T 0.032953 Method MME

S real T clipart Train Ep: 11300 lr0.005671726723799515 	 Loss Classification: 0.240857 Loss T 0.022703 Method MME

S real T clipart Train Ep: 11400 lr0.005651837543487509 	 Loss Classification: 0.290688 Loss T 0.039636 Method MME

S real T clipart Train Ep: 11500 lr0.005632110346230358 	 Loss Classification: 0.182630 Loss T 0.045264 Method MME


Labeled Target set: Average loss: 0.0409, Accuracy: 1066/1080 F1 (98.7037%)


Test set: Average loss: 1.4920, Accuracy: 13968/18312 F1 (76.2778%)


Val set: Average loss: 1.5896, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.277851  acc val 73.888889 acc labeled target 98.703704
saving model...
S real T clipart Train Ep: 11600 lr0.005612543068546177 	 Loss Classification: 0.281332 Loss T 0.037326 Method MME

S real T clipart Train Ep: 11700 lr0.005593133682632953 	 Loss Classification: 0.407777 Loss T 0.028214 Method MME

S real T clipart Train Ep: 11800 lr0.005573880195590681 	 Loss Classification: 0.064336 Loss T 0.042239 Method MME

S real T clipart Train Ep: 11900 lr0.0055547806486639095 	 Loss Classification: 0.011503 Loss T 0.027975 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.8888889 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        0.8333333
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 91, 83, 36, 23, 81, 33, 63, 68, 69, 73, 92, 66, 67, 90, 89, 88, 87, 86, 85, 84, 82, 70, 71, 80, 79, 78, 77, 76, 75, 74, 72, 0, 93, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 94, 110, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 109, 65, 62, 124, 27, 26, 25, 24, 22, 21, 20, 19, 18, 17, 16, 15, 28, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 29, 30, 31, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 35, 34, 32, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 12000 lr0.005535833116504121 	 Loss Classification: 0.308725 Loss T 0.023961 Method MME


Labeled Target set: Average loss: 0.0768, Accuracy: 1057/1080 F1 (97.8704%)


Test set: Average loss: 1.5511, Accuracy: 13726/18312 F1 (74.9563%)


Val set: Average loss: 1.6202, Accuracy: 268/360 F1 (74.4444%)

best acc test 74.956313  acc val 74.444444 acc labeled target 97.870370
saving model...
S real T clipart Train Ep: 12100 lr0.00551703570645129 	 Loss Classification: 0.300708 Loss T 0.032826 Method MME

S real T clipart Train Ep: 12200 lr0.005498386557834078 	 Loss Classification: 0.100246 Loss T 0.026678 Method MME

S real T clipart Train Ep: 12300 lr0.00547988384128807 	 Loss Classification: 0.433427 Loss T 0.029363 Method MME

S real T clipart Train Ep: 12400 lr0.005461525758091539 	 Loss Classification: 0.281133 Loss T 0.029661 Method MME

S real T clipart Train Ep: 12500 lr0.005443310539518174 	 Loss Classification: 0.286825 Loss T 0.026874 Method MME


Labeled Target set: Average loss: 0.0451, Accuracy: 1063/1080 F1 (98.4259%)


Test set: Average loss: 1.5395, Accuracy: 13977/18312 F1 (76.3270%)


Val set: Average loss: 1.5931, Accuracy: 269/360 F1 (74.7222%)

best acc test 76.326999  acc val 74.722222 acc labeled target 98.425926
saving model...
S real T clipart Train Ep: 12600 lr0.005425236446206295 	 Loss Classification: 0.104808 Loss T 0.019784 Method MME

S real T clipart Train Ep: 12700 lr0.005407301767544059 	 Loss Classification: 0.162420 Loss T 0.023799 Method MME

S real T clipart Train Ep: 12800 lr0.005389504821070177 	 Loss Classification: 0.176770 Loss T 0.027462 Method MME

S real T clipart Train Ep: 12900 lr0.005371843951889677 	 Loss Classification: 0.270246 Loss T 0.039061 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8333333 1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.5       1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.5555556 1.
 0.8888889 1.        1.        0.8888889 1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 103, 63, 25, 108, 31, 5, 119, 112, 105, 81, 82, 84, 85, 86, 87, 88, 83, 80, 0, 89, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 79, 90, 95, 92, 123, 122, 121, 120, 118, 117, 116, 115, 114, 113, 111, 110, 109, 107, 106, 104, 102, 101, 100, 99, 98, 97, 96, 94, 93, 91, 65, 62, 124, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 15, 13, 12, 11, 10, 9, 8, 7, 6, 4, 3, 2, 1, 14, 30, 32, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 13000 lr0.0053543175321042955 	 Loss Classification: 0.172186 Loss T 0.036871 Method MME


Labeled Target set: Average loss: 0.0702, Accuracy: 1057/1080 F1 (97.8704%)


Test set: Average loss: 1.5120, Accuracy: 13793/18312 F1 (75.3222%)


Val set: Average loss: 1.6491, Accuracy: 260/360 F1 (72.2222%)

best acc test 76.326999  acc val 72.222222 acc labeled target 97.870370
saving model...
S real T clipart Train Ep: 13100 lr0.005336923960257046 	 Loss Classification: 0.397213 Loss T 0.030508 Method MME

S real T clipart Train Ep: 13200 lr0.0053196616607905645 	 Loss Classification: 0.186454 Loss T 0.033375 Method MME

S real T clipart Train Ep: 13300 lr0.0053025290835188275 	 Loss Classification: 0.384946 Loss T 0.019441 Method MME

S real T clipart Train Ep: 13400 lr0.005285524703111859 	 Loss Classification: 0.102933 Loss T 0.021871 Method MME

S real T clipart Train Ep: 13500 lr0.005268647018593052 	 Loss Classification: 0.543995 Loss T 0.027567 Method MME


Labeled Target set: Average loss: 0.0458, Accuracy: 1062/1080 F1 (98.3333%)


Test set: Average loss: 1.5023, Accuracy: 14121/18312 F1 (77.1134%)


Val set: Average loss: 1.5846, Accuracy: 268/360 F1 (74.4444%)

best acc test 76.326999  acc val 74.444444 acc labeled target 98.333333
saving model...
S real T clipart Train Ep: 13600 lr0.005251894552848747 	 Loss Classification: 0.043973 Loss T 0.018274 Method MME

S real T clipart Train Ep: 13700 lr0.005235265852149712 	 Loss Classification: 0.300436 Loss T 0.019684 Method MME

S real T clipart Train Ep: 13800 lr0.005218759485684187 	 Loss Classification: 0.152797 Loss T 0.024170 Method MME

S real T clipart Train Ep: 13900 lr0.005202374045102174 	 Loss Classification: 0.051307 Loss T 0.029901 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8333333 1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        0.8333333 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        0.8888889 1.        1.        1.
 0.8888889 0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [91, 63, 103, 71, 56, 95, 28, 41, 15, 112, 113, 108, 73, 88, 66, 67, 87, 86, 68, 69, 85, 84, 83, 82, 70, 81, 80, 79, 78, 89, 77, 72, 76, 75, 74, 0, 94, 92, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 111, 110, 109, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 93, 90, 65, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 29, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 30, 31, 32, 61, 60, 59, 58, 57, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 14000 lr0.005186108144070652 	 Loss Classification: 0.814787 Loss T 0.010418 Method MME


Labeled Target set: Average loss: 0.0767, Accuracy: 1056/1080 F1 (97.7778%)


Test set: Average loss: 1.5833, Accuracy: 13817/18312 F1 (75.4533%)


Val set: Average loss: 1.7465, Accuracy: 260/360 F1 (72.2222%)

best acc test 76.326999  acc val 72.222222 acc labeled target 97.777778
saving model...
S real T clipart Train Ep: 14100 lr0.005169960417839403 	 Loss Classification: 0.149543 Loss T 0.010781 Method MME

S real T clipart Train Ep: 14200 lr0.005153929522817161 	 Loss Classification: 0.040525 Loss T 0.035961 Method MME

S real T clipart Train Ep: 14300 lr0.005138014136157799 	 Loss Classification: 0.457575 Loss T 0.014657 Method MME

S real T clipart Train Ep: 14400 lr0.005122212955356274 	 Loss Classification: 0.243225 Loss T 0.015323 Method MME

S real T clipart Train Ep: 14500 lr0.005106524697854057 	 Loss Classification: 0.321021 Loss T 0.024879 Method MME


Labeled Target set: Average loss: 0.0321, Accuracy: 1067/1080 F1 (98.7963%)


Test set: Average loss: 1.5358, Accuracy: 14066/18312 F1 (76.8130%)


Val set: Average loss: 1.5608, Accuracy: 273/360 F1 (75.8333%)

best acc test 76.813019  acc val 75.833333 acc labeled target 98.796296
saving model...
S real T clipart Train Ep: 14600 lr0.005090948100653781 	 Loss Classification: 0.205083 Loss T 0.014079 Method MME

S real T clipart Train Ep: 14700 lr0.0050754819199428855 	 Loss Classification: 0.329546 Loss T 0.022840 Method MME

S real T clipart Train Ep: 14800 lr0.005060124930725974 	 Loss Classification: 0.151977 Loss T 0.015135 Method MME

S real T clipart Train Ep: 14900 lr0.00504487592646567 	 Loss Classification: 0.093992 Loss T 0.019402 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 47, 99, 18, 32, 66, 71, 92, 90, 89, 67, 88, 87, 86, 85, 84, 83, 70, 82, 81, 93, 69, 79, 78, 77, 76, 75, 74, 73, 72, 68, 80, 0, 95, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 98, 97, 96, 65, 94, 62, 124, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 29, 64, 30, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 31, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 15000 lr0.005029733718731741 	 Loss Classification: 0.185068 Loss T 0.019540 Method MME


Labeled Target set: Average loss: 0.0538, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.5748, Accuracy: 13841/18312 F1 (75.5843%)


Val set: Average loss: 1.5890, Accuracy: 267/360 F1 (74.1667%)

best acc test 76.813019  acc val 74.166667 acc labeled target 98.518519
saving model...
S real T clipart Train Ep: 15100 lr0.005014697136858264 	 Loss Classification: 0.105054 Loss T 0.026818 Method MME

S real T clipart Train Ep: 15200 lr0.004999765027608607 	 Loss Classification: 0.266513 Loss T 0.025644 Method MME

S real T clipart Train Ep: 15300 lr0.004984936254848047 	 Loss Classification: 0.025196 Loss T 0.020752 Method MME

S real T clipart Train Ep: 15400 lr0.004970209699223787 	 Loss Classification: 0.351525 Loss T 0.018199 Method MME

S real T clipart Train Ep: 15500 lr0.0049555842578521995 	 Loss Classification: 0.269743 Loss T 0.012876 Method MME


Labeled Target set: Average loss: 0.0319, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.5496, Accuracy: 14186/18312 F1 (77.4683%)


Val set: Average loss: 1.7276, Accuracy: 264/360 F1 (73.3333%)

best acc test 76.813019  acc val 73.333333 acc labeled target 98.518519
saving model...
S real T clipart Train Ep: 15600 lr0.004941058844013093 	 Loss Classification: 0.267826 Loss T 0.012812 Method MME

S real T clipart Train Ep: 15700 lr0.004926632386850831 	 Loss Classification: 0.303250 Loss T 0.018968 Method MME

S real T clipart Train Ep: 15800 lr0.004912303831082109 	 Loss Classification: 0.318191 Loss T 0.018300 Method MME

S real T clipart Train Ep: 15900 lr0.004898072136710217 	 Loss Classification: 0.498179 Loss T 0.035868 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        0.7777778 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8333333 1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        0.8888889 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 103, 91, 10, 25, 42, 78, 4, 110, 87, 86, 88, 85, 89, 90, 84, 83, 82, 0, 80, 79, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 81, 92, 95, 94, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 109, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 66, 93, 65, 62, 63, 29, 28, 27, 26, 24, 23, 22, 21, 20, 19, 18, 17, 30, 16, 14, 13, 12, 11, 9, 8, 7, 6, 5, 3, 2, 1, 15, 31, 32, 33, 124, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 41, 40, 39, 38, 37, 36, 35, 34, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 16000 lr0.004883936278745637 	 Loss Classification: 0.398241 Loss T 0.016210 Method MME


Labeled Target set: Average loss: 0.0657, Accuracy: 1062/1080 F1 (98.3333%)


Test set: Average loss: 1.5201, Accuracy: 13997/18312 F1 (76.4362%)


Val set: Average loss: 1.6281, Accuracy: 268/360 F1 (74.4444%)

best acc test 76.813019  acc val 74.444444 acc labeled target 98.333333
saving model...
S real T clipart Train Ep: 16100 lr0.004869895246932789 	 Loss Classification: 0.582367 Loss T 0.019074 Method MME

S real T clipart Train Ep: 16200 lr0.004855948045482784 	 Loss Classification: 0.050138 Loss T 0.028715 Method MME

S real T clipart Train Ep: 16300 lr0.004842093692812012 	 Loss Classification: 0.069253 Loss T 0.021529 Method MME

S real T clipart Train Ep: 16400 lr0.004828331221286437 	 Loss Classification: 0.227103 Loss T 0.029771 Method MME

S real T clipart Train Ep: 16500 lr0.004814659676971443 	 Loss Classification: 0.590384 Loss T 0.020977 Method MME


Labeled Target set: Average loss: 0.0369, Accuracy: 1065/1080 F1 (98.6111%)


Test set: Average loss: 1.5843, Accuracy: 14197/18312 F1 (77.5284%)


Val set: Average loss: 1.6122, Accuracy: 267/360 F1 (74.1667%)

best acc test 76.813019  acc val 74.166667 acc labeled target 98.611111
saving model...
S real T clipart Train Ep: 16600 lr0.004801078119387078 	 Loss Classification: 0.131808 Loss T 0.032007 Method MME

S real T clipart Train Ep: 16700 lr0.004787585621268585 	 Loss Classification: 0.358667 Loss T 0.011255 Method MME

S real T clipart Train Ep: 16800 lr0.0047741812683320655 	 Loss Classification: 0.361211 Loss T 0.022467 Method MME

S real T clipart Train Ep: 16900 lr0.004760864159045157 	 Loss Classification: 0.046574 Loss T 0.022077 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        0.8888889 1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 0.8888889
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 42, 44, 104, 108, 91, 122, 89, 88, 87, 86, 85, 84, 83, 66, 82, 67, 70, 71, 80, 69, 90, 79, 78, 77, 76, 75, 74, 73, 72, 81, 68, 0, 65, 123, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 92, 110, 107, 106, 105, 102, 101, 100, 99, 98, 97, 96, 95, 94, 109, 93, 62, 124, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 28, 64, 29, 31, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 43, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 30, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 17000 lr0.0047476334044026 	 Loss Classification: 0.103410 Loss T 0.014743 Method MME


Labeled Target set: Average loss: 0.0837, Accuracy: 1058/1080 F1 (97.9630%)


Test set: Average loss: 1.5479, Accuracy: 14031/18312 F1 (76.6219%)


Val set: Average loss: 1.7093, Accuracy: 260/360 F1 (72.2222%)

best acc test 76.813019  acc val 72.222222 acc labeled target 97.962963
saving model...
S real T clipart Train Ep: 17100 lr0.004734488127706559 	 Loss Classification: 0.476808 Loss T 0.017696 Method MME

S real T clipart Train Ep: 17200 lr0.004721427464351597 	 Loss Classification: 0.030731 Loss T 0.030526 Method MME

S real T clipart Train Ep: 17300 lr0.004708450561614184 	 Loss Classification: 0.210599 Loss T 0.018905 Method MME

S real T clipart Train Ep: 17400 lr0.004695556578446619 	 Loss Classification: 0.634591 Loss T 0.008634 Method MME

S real T clipart Train Ep: 17500 lr0.004682744685275263 	 Loss Classification: 0.008569 Loss T 0.023705 Method MME


Labeled Target set: Average loss: 0.0383, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.5733, Accuracy: 14228/18312 F1 (77.6977%)


Val set: Average loss: 1.7510, Accuracy: 266/360 F1 (73.8889%)

best acc test 76.813019  acc val 73.888889 acc labeled target 98.518519
saving model...
S real T clipart Train Ep: 17600 lr0.004670014063802979 	 Loss Classification: 0.184107 Loss T 0.025501 Method MME

S real T clipart Train Ep: 17700 lr0.004657363906815676 	 Loss Classification: 0.028966 Loss T 0.024773 Method MME

S real T clipart Train Ep: 17800 lr0.004644793417992855 	 Loss Classification: 0.053817 Loss T 0.011045 Method MME

S real T clipart Train Ep: 17900 lr0.004632301811722062 	 Loss Classification: 0.133271 Loss T 0.021251 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        0.8888889 0.8888889 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8888889 1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 91, 103, 54, 94, 26, 106, 18, 108, 95, 114, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 123, 72, 71, 70, 69, 68, 67, 66, 88, 89, 90, 122, 113, 112, 111, 110, 109, 116, 107, 117, 118, 105, 104, 115, 119, 101, 100, 120, 99, 98, 97, 96, 65, 121, 93, 92, 102, 0, 62, 124, 29, 28, 27, 25, 24, 23, 22, 21, 20, 19, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 30, 64, 31, 33, 61, 60, 59, 58, 57, 56, 55, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 18000 lr0.004619888312917149 	 Loss Classification: 0.169276 Loss T 0.018540 Method MME


Labeled Target set: Average loss: 0.0499, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.5791, Accuracy: 14053/18312 F1 (76.7420%)


Val set: Average loss: 1.8326, Accuracy: 256/360 F1 (71.1111%)

best acc test 76.813019  acc val 71.111111 acc labeled target 98.518519
saving model...
S real T clipart Train Ep: 18100 lr0.00460755215684026 	 Loss Classification: 0.093513 Loss T 0.015542 Method MME

S real T clipart Train Ep: 18200 lr0.00459529258892745 	 Loss Classification: 0.310379 Loss T 0.012612 Method MME

S real T clipart Train Ep: 18300 lr0.004583108864617844 	 Loss Classification: 0.042920 Loss T 0.014002 Method MME

S real T clipart Train Ep: 18400 lr0.0045710002491862545 	 Loss Classification: 0.158087 Loss T 0.017778 Method MME

S real T clipart Train Ep: 18500 lr0.0045589660175791875 	 Loss Classification: 0.085273 Loss T 0.010934 Method MME


Labeled Target set: Average loss: 0.0364, Accuracy: 1065/1080 F1 (98.6111%)


Test set: Average loss: 1.6200, Accuracy: 14252/18312 F1 (77.8287%)


Val set: Average loss: 1.5380, Accuracy: 271/360 F1 (75.2778%)

best acc test 76.813019  acc val 75.277778 acc labeled target 98.611111
saving model...
S real T clipart Train Ep: 18600 lr0.004547005454254138 	 Loss Classification: 0.076408 Loss T 0.011964 Method MME

S real T clipart Train Ep: 18700 lr0.004535117853022106 	 Loss Classification: 0.083234 Loss T 0.028695 Method MME

S real T clipart Train Ep: 18800 lr0.004523302516893268 	 Loss Classification: 0.296554 Loss T 0.027839 Method MME

S real T clipart Train Ep: 18900 lr0.004511558757925708 	 Loss Classification: 0.014856 Loss T 0.014050 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        0.8333333 1.        1.        1.        1.
 1.        1.        1.        1.        0.8333333 1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.8888889 1.       ]
Top k classes which perform poorly are:  [47, 103, 63, 95, 86, 124, 13, 105, 31, 89, 88, 87, 81, 85, 84, 83, 82, 80, 0, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 90, 91, 94, 93, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 92, 111, 109, 108, 107, 106, 104, 102, 101, 100, 99, 98, 97, 96, 110, 65, 62, 61, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 29, 30, 32, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 64, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 19000 lr0.004499885897077159 	 Loss Classification: 0.182069 Loss T 0.021311 Method MME


Labeled Target set: Average loss: 0.0609, Accuracy: 1059/1080 F1 (98.0556%)


Test set: Average loss: 1.6077, Accuracy: 14056/18312 F1 (76.7584%)


Val set: Average loss: 1.6588, Accuracy: 272/360 F1 (75.5556%)

best acc test 76.813019  acc val 75.555556 acc labeled target 98.055556
saving model...
S real T clipart Train Ep: 19100 lr0.004488283264059669 	 Loss Classification: 0.329346 Loss T 0.037056 Method MME

S real T clipart Train Ep: 19200 lr0.004476750197197131 	 Loss Classification: 0.022710 Loss T 0.015604 Method MME

S real T clipart Train Ep: 19300 lr0.004465286043285614 	 Loss Classification: 0.072892 Loss T 0.011550 Method MME

S real T clipart Train Ep: 19400 lr0.004453890157456425 	 Loss Classification: 0.071554 Loss T 0.014135 Method MME

S real T clipart Train Ep: 19500 lr0.004442561903041838 	 Loss Classification: 0.223998 Loss T 0.010894 Method MME


Labeled Target set: Average loss: 0.0376, Accuracy: 1066/1080 F1 (98.7037%)


Test set: Average loss: 1.6481, Accuracy: 14292/18312 F1 (78.0472%)


Val set: Average loss: 1.6892, Accuracy: 273/360 F1 (75.8333%)

best acc test 78.047182  acc val 75.833333 acc labeled target 98.703704
saving model...
S real T clipart Train Ep: 19600 lr0.004431300651443432 	 Loss Classification: 0.102757 Loss T 0.019638 Method MME

S real T clipart Train Ep: 19700 lr0.004420105782002992 	 Loss Classification: 0.181949 Loss T 0.008378 Method MME

S real T clipart Train Ep: 19800 lr0.004408976681875879 	 Loss Classification: 0.154028 Loss T 0.024830 Method MME

S real T clipart Train Ep: 19900 lr0.004397912745906863 	 Loss Classification: 0.256523 Loss T 0.016375 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        0.8888889 1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.7777778 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 47, 91, 112, 2, 69, 21, 90, 89, 88, 87, 80, 85, 84, 83, 82, 81, 86, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 68, 67, 66, 92, 93, 0, 65, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 94, 95, 62, 124, 29, 28, 27, 26, 25, 24, 23, 22, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 1, 30, 64, 31, 33, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 32, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 20000 lr0.004386913376508308 	 Loss Classification: 0.260671 Loss T 0.015368 Method MME


Labeled Target set: Average loss: 0.0781, Accuracy: 1055/1080 F1 (97.6852%)


Test set: Average loss: 1.6330, Accuracy: 14049/18312 F1 (76.7202%)


Val set: Average loss: 1.7984, Accuracy: 268/360 F1 (74.4444%)

best acc test 78.047182  acc val 74.444444 acc labeled target 97.685185
saving model...
S real T clipart Train Ep: 20100 lr0.004375977983540715 	 Loss Classification: 0.127185 Loss T 0.007321 Method MME

S real T clipart Train Ep: 20200 lr0.004365105984195512 	 Loss Classification: 0.190614 Loss T 0.009474 Method MME

S real T clipart Train Ep: 20300 lr0.004354296802880095 	 Loss Classification: 0.104369 Loss T 0.012475 Method MME

S real T clipart Train Ep: 20400 lr0.004343549871105023 	 Loss Classification: 0.316144 Loss T 0.010958 Method MME

S real T clipart Train Ep: 20500 lr0.0043328646273733526 	 Loss Classification: 0.326823 Loss T 0.022206 Method MME


Labeled Target set: Average loss: 0.0452, Accuracy: 1064/1080 F1 (98.5185%)


Test set: Average loss: 1.6755, Accuracy: 14304/18312 F1 (78.1127%)


Val set: Average loss: 1.7777, Accuracy: 276/360 F1 (76.6667%)

best acc test 78.112713  acc val 76.666667 acc labeled target 98.518519
saving model...
S real T clipart Train Ep: 20600 lr0.00432224051707205 	 Loss Classification: 0.103258 Loss T 0.010812 Method MME

S real T clipart Train Ep: 20700 lr0.0043116769923654385 	 Loss Classification: 0.019287 Loss T 0.023518 Method MME

S real T clipart Train Ep: 20800 lr0.004301173512090631 	 Loss Classification: 0.130454 Loss T 0.008011 Method MME

S real T clipart Train Ep: 20900 lr0.004290729541654919 	 Loss Classification: 0.021033 Loss T 0.009398 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        0.7777778
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.6666667 0.8888889
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        0.8888889 1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [47, 63, 103, 13, 31, 45, 60, 77, 48, 82, 83, 0, 86, 87, 88, 89, 90, 84, 85, 80, 91, 79, 78, 76, 75, 74, 73, 72, 71, 70, 69, 68, 81, 92, 94, 67, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 93, 110, 108, 107, 106, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 109, 66, 62, 64, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 28, 15, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 14, 65, 29, 32, 124, 61, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 30, 49, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 46, 125]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 21000 lr0.0042803445529350555 	 Loss Classification: 0.016323 Loss T 0.005389 Method MME


Labeled Target set: Average loss: 0.0704, Accuracy: 1060/1080 F1 (98.1481%)


Test set: Average loss: 1.6777, Accuracy: 14143/18312 F1 (77.2335%)


Val set: Average loss: 1.7590, Accuracy: 269/360 F1 (74.7222%)

best acc test 78.112713  acc val 74.722222 acc labeled target 98.148148
saving model...
S real T clipart Train Ep: 21100 lr0.0042700180241784045 	 Loss Classification: 0.082313 Loss T 0.004973 Method MME

S real T clipart Train Ep: 21200 lr0.004259749439905917 	 Loss Classification: 0.266743 Loss T 0.016450 Method MME

S real T clipart Train Ep: 21300 lr0.004249538290816886 	 Loss Classification: 0.247195 Loss T 0.019050 Method MME

S real T clipart Train Ep: 21400 lr0.004239384073695442 	 Loss Classification: 0.155109 Loss T 0.013843 Method MME

S real T clipart Train Ep: 21500 lr0.004229286291318768 	 Loss Classification: 0.041884 Loss T 0.007776 Method MME


Labeled Target set: Average loss: 0.0220, Accuracy: 1068/1080 F1 (98.8889%)


Test set: Average loss: 1.7154, Accuracy: 14330/18312 F1 (78.2547%)


Val set: Average loss: 1.8671, Accuracy: 271/360 F1 (75.2778%)

best acc test 78.112713  acc val 75.277778 acc labeled target 98.888889
saving model...
S real T clipart Train Ep: 21600 lr0.004219244452366975 	 Loss Classification: 0.272143 Loss T 0.006366 Method MME

S real T clipart Train Ep: 21700 lr0.004209258071334615 	 Loss Classification: 0.352550 Loss T 0.019902 Method MME

S real T clipart Train Ep: 21800 lr0.004199326668443797 	 Loss Classification: 0.131438 Loss T 0.008743 Method MME

S real T clipart Train Ep: 21900 lr0.004189449769558871 	 Loss Classification: 0.069496 Loss T 0.016677 Method MME

Per Class Accuracy Calculated According to the Labelled Target examples is:  [1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
       nan 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        0.8888889 1.        0.6666667 1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.6666667 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 0.8888889 1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        0.6666667 1.
 1.        0.8333333 1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.
 1.        1.        1.        1.        1.        1.        1.       ]
Top k classes which perform poorly are:  [63, 103, 47, 106, 45, 91, 70, 89, 88, 87, 86, 85, 84, 83, 82, 65, 81, 80, 68, 66, 79, 90, 78, 77, 76, 75, 74, 73, 72, 71, 69, 67, 0, 64, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 92, 110, 108, 107, 105, 104, 102, 101, 100, 99, 98, 97, 96, 95, 94, 109, 93, 62, 61, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 27, 14, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 124, 29, 31, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 30, 46, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 44, 125, 28]
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
Assigned Classwise weights to source
S real T clipart Train Ep: 22000 lr0.004179626906102638 	 Loss Classification: 0.044429 Loss T 0.012529 Method MME


Labeled Target set: Average loss: 0.0629, Accuracy: 1062/1080 F1 (98.3333%)


Test set: Average loss: 1.6532, Accuracy: 14183/18312 F1 (77.4519%)


Val set: Average loss: 1.8166, Accuracy: 267/360 F1 (74.1667%)

best acc test 78.112713  acc val 74.166667 acc labeled target 98.333333
saving model...
S real T clipart Train Ep: 22100 lr0.004169857614974071 	 Loss Classification: 0.216539 Loss T 0.013996 Method MME

[W python_anomaly_mode.cpp:104] Warning: Error detected in MulBackward0. Traceback of forward call that caused the error:
  File "main_classwise.py", line 412, in <module>
  File "main_classwise.py", line 270, in train
    pass
 (function _print_stack)
Traceback (most recent call last):
  File "main_classwise.py", line 412, in <module>
  File "main_classwise.py", line 294, in train
    #pass
  File "/home/megh/anaconda3/envs/ssal/lib/python3.7/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/megh/anaconda3/envs/ssal/lib/python3.7/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'MulBackward0' returned nan values in its 1th output.
